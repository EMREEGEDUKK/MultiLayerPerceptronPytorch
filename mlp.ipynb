{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Training Loss: 0.3834\n",
      "Epoch [1/200], Validation Loss: 0.6119\n",
      "Epoch [2/200], Training Loss: 0.3208\n",
      "Epoch [2/200], Validation Loss: 0.5595\n",
      "Epoch [3/200], Training Loss: 0.2847\n",
      "Epoch [3/200], Validation Loss: 0.5220\n",
      "Epoch [4/200], Training Loss: 0.2607\n",
      "Epoch [4/200], Validation Loss: 0.4919\n",
      "Epoch [5/200], Training Loss: 0.2442\n",
      "Epoch [5/200], Validation Loss: 0.4672\n",
      "Epoch [6/200], Training Loss: 0.2311\n",
      "Epoch [6/200], Validation Loss: 0.4453\n",
      "Epoch [7/200], Training Loss: 0.2197\n",
      "Epoch [7/200], Validation Loss: 0.4263\n",
      "Epoch [8/200], Training Loss: 0.2104\n",
      "Epoch [8/200], Validation Loss: 0.4090\n",
      "Epoch [9/200], Training Loss: 0.2021\n",
      "Epoch [9/200], Validation Loss: 0.3934\n",
      "Epoch [10/200], Training Loss: 0.1945\n",
      "Epoch [10/200], Validation Loss: 0.3793\n",
      "Epoch [11/200], Training Loss: 0.1879\n",
      "Epoch [11/200], Validation Loss: 0.3664\n",
      "Epoch [12/200], Training Loss: 0.1825\n",
      "Epoch [12/200], Validation Loss: 0.3545\n",
      "Epoch [13/200], Training Loss: 0.1769\n",
      "Epoch [13/200], Validation Loss: 0.3437\n",
      "Epoch [14/200], Training Loss: 0.1718\n",
      "Epoch [14/200], Validation Loss: 0.3338\n",
      "Epoch [15/200], Training Loss: 0.1667\n",
      "Epoch [15/200], Validation Loss: 0.3246\n",
      "Epoch [16/200], Training Loss: 0.1622\n",
      "Epoch [16/200], Validation Loss: 0.3161\n",
      "Epoch [17/200], Training Loss: 0.1574\n",
      "Epoch [17/200], Validation Loss: 0.3082\n",
      "Epoch [18/200], Training Loss: 0.1530\n",
      "Epoch [18/200], Validation Loss: 0.3010\n",
      "Epoch [19/200], Training Loss: 0.1485\n",
      "Epoch [19/200], Validation Loss: 0.2943\n",
      "Epoch [20/200], Training Loss: 0.1441\n",
      "Epoch [20/200], Validation Loss: 0.2881\n",
      "Epoch [21/200], Training Loss: 0.1397\n",
      "Epoch [21/200], Validation Loss: 0.2823\n",
      "Epoch [22/200], Training Loss: 0.1356\n",
      "Epoch [22/200], Validation Loss: 0.2769\n",
      "Epoch [23/200], Training Loss: 0.1326\n",
      "Epoch [23/200], Validation Loss: 0.2717\n",
      "Epoch [24/200], Training Loss: 0.1297\n",
      "Epoch [24/200], Validation Loss: 0.2670\n",
      "Epoch [25/200], Training Loss: 0.1262\n",
      "Epoch [25/200], Validation Loss: 0.2628\n",
      "Epoch [26/200], Training Loss: 0.1229\n",
      "Epoch [26/200], Validation Loss: 0.2586\n",
      "Epoch [27/200], Training Loss: 0.1205\n",
      "Epoch [27/200], Validation Loss: 0.2546\n",
      "Epoch [28/200], Training Loss: 0.1180\n",
      "Epoch [28/200], Validation Loss: 0.2508\n",
      "Epoch [29/200], Training Loss: 0.1155\n",
      "Epoch [29/200], Validation Loss: 0.2472\n",
      "Epoch [30/200], Training Loss: 0.1129\n",
      "Epoch [30/200], Validation Loss: 0.2437\n",
      "Epoch [31/200], Training Loss: 0.1108\n",
      "Epoch [31/200], Validation Loss: 0.2404\n",
      "Epoch [32/200], Training Loss: 0.1090\n",
      "Epoch [32/200], Validation Loss: 0.2375\n",
      "Epoch [33/200], Training Loss: 0.1072\n",
      "Epoch [33/200], Validation Loss: 0.2347\n",
      "Epoch [34/200], Training Loss: 0.1054\n",
      "Epoch [34/200], Validation Loss: 0.2319\n",
      "Epoch [35/200], Training Loss: 0.1038\n",
      "Epoch [35/200], Validation Loss: 0.2293\n",
      "Epoch [36/200], Training Loss: 0.1020\n",
      "Epoch [36/200], Validation Loss: 0.2268\n",
      "Epoch [37/200], Training Loss: 0.1005\n",
      "Epoch [37/200], Validation Loss: 0.2244\n",
      "Epoch [38/200], Training Loss: 0.0991\n",
      "Epoch [38/200], Validation Loss: 0.2221\n",
      "Epoch [39/200], Training Loss: 0.0977\n",
      "Epoch [39/200], Validation Loss: 0.2199\n",
      "Epoch [40/200], Training Loss: 0.0962\n",
      "Epoch [40/200], Validation Loss: 0.2179\n",
      "Epoch [41/200], Training Loss: 0.0947\n",
      "Epoch [41/200], Validation Loss: 0.2159\n",
      "Epoch [42/200], Training Loss: 0.0932\n",
      "Epoch [42/200], Validation Loss: 0.2137\n",
      "Epoch [43/200], Training Loss: 0.0914\n",
      "Epoch [43/200], Validation Loss: 0.2118\n",
      "Epoch [44/200], Training Loss: 0.0897\n",
      "Epoch [44/200], Validation Loss: 0.2099\n",
      "Epoch [45/200], Training Loss: 0.0882\n",
      "Epoch [45/200], Validation Loss: 0.2080\n",
      "Epoch [46/200], Training Loss: 0.0865\n",
      "Epoch [46/200], Validation Loss: 0.2062\n",
      "Epoch [47/200], Training Loss: 0.0851\n",
      "Epoch [47/200], Validation Loss: 0.2046\n",
      "Epoch [48/200], Training Loss: 0.0839\n",
      "Epoch [48/200], Validation Loss: 0.2032\n",
      "Epoch [49/200], Training Loss: 0.0825\n",
      "Epoch [49/200], Validation Loss: 0.2016\n",
      "Epoch [50/200], Training Loss: 0.0809\n",
      "Epoch [50/200], Validation Loss: 0.2002\n",
      "Epoch [51/200], Training Loss: 0.0793\n",
      "Epoch [51/200], Validation Loss: 0.1986\n",
      "Epoch [52/200], Training Loss: 0.0775\n",
      "Epoch [52/200], Validation Loss: 0.1970\n",
      "Epoch [53/200], Training Loss: 0.0762\n",
      "Epoch [53/200], Validation Loss: 0.1956\n",
      "Epoch [54/200], Training Loss: 0.0753\n",
      "Epoch [54/200], Validation Loss: 0.1941\n",
      "Epoch [55/200], Training Loss: 0.0744\n",
      "Epoch [55/200], Validation Loss: 0.1928\n",
      "Epoch [56/200], Training Loss: 0.0733\n",
      "Epoch [56/200], Validation Loss: 0.1914\n",
      "Epoch [57/200], Training Loss: 0.0724\n",
      "Epoch [57/200], Validation Loss: 0.1901\n",
      "Epoch [58/200], Training Loss: 0.0715\n",
      "Epoch [58/200], Validation Loss: 0.1888\n",
      "Epoch [59/200], Training Loss: 0.0706\n",
      "Epoch [59/200], Validation Loss: 0.1876\n",
      "Epoch [60/200], Training Loss: 0.0698\n",
      "Epoch [60/200], Validation Loss: 0.1864\n",
      "Epoch [61/200], Training Loss: 0.0688\n",
      "Epoch [61/200], Validation Loss: 0.1852\n",
      "Epoch [62/200], Training Loss: 0.0680\n",
      "Epoch [62/200], Validation Loss: 0.1841\n",
      "Epoch [63/200], Training Loss: 0.0673\n",
      "Epoch [63/200], Validation Loss: 0.1830\n",
      "Epoch [64/200], Training Loss: 0.0666\n",
      "Epoch [64/200], Validation Loss: 0.1819\n",
      "Epoch [65/200], Training Loss: 0.0658\n",
      "Epoch [65/200], Validation Loss: 0.1809\n",
      "Epoch [66/200], Training Loss: 0.0650\n",
      "Epoch [66/200], Validation Loss: 0.1799\n",
      "Epoch [67/200], Training Loss: 0.0643\n",
      "Epoch [67/200], Validation Loss: 0.1788\n",
      "Epoch [68/200], Training Loss: 0.0638\n",
      "Epoch [68/200], Validation Loss: 0.1778\n",
      "Epoch [69/200], Training Loss: 0.0633\n",
      "Epoch [69/200], Validation Loss: 0.1768\n",
      "Epoch [70/200], Training Loss: 0.0632\n",
      "Epoch [70/200], Validation Loss: 0.1760\n",
      "Epoch [71/200], Training Loss: 0.0627\n",
      "Epoch [71/200], Validation Loss: 0.1750\n",
      "Epoch [72/200], Training Loss: 0.0619\n",
      "Epoch [72/200], Validation Loss: 0.1740\n",
      "Epoch [73/200], Training Loss: 0.0616\n",
      "Epoch [73/200], Validation Loss: 0.1731\n",
      "Epoch [74/200], Training Loss: 0.0610\n",
      "Epoch [74/200], Validation Loss: 0.1722\n",
      "Epoch [75/200], Training Loss: 0.0606\n",
      "Epoch [75/200], Validation Loss: 0.1713\n",
      "Epoch [76/200], Training Loss: 0.0600\n",
      "Epoch [76/200], Validation Loss: 0.1705\n",
      "Epoch [77/200], Training Loss: 0.0598\n",
      "Epoch [77/200], Validation Loss: 0.1697\n",
      "Epoch [78/200], Training Loss: 0.0593\n",
      "Epoch [78/200], Validation Loss: 0.1688\n",
      "Epoch [79/200], Training Loss: 0.0589\n",
      "Epoch [79/200], Validation Loss: 0.1680\n",
      "Epoch [80/200], Training Loss: 0.0584\n",
      "Epoch [80/200], Validation Loss: 0.1672\n",
      "Epoch [81/200], Training Loss: 0.0579\n",
      "Epoch [81/200], Validation Loss: 0.1665\n",
      "Epoch [82/200], Training Loss: 0.0575\n",
      "Epoch [82/200], Validation Loss: 0.1657\n",
      "Epoch [83/200], Training Loss: 0.0570\n",
      "Epoch [83/200], Validation Loss: 0.1649\n",
      "Epoch [84/200], Training Loss: 0.0571\n",
      "Epoch [84/200], Validation Loss: 0.1642\n",
      "Epoch [85/200], Training Loss: 0.0566\n",
      "Epoch [85/200], Validation Loss: 0.1635\n",
      "Epoch [86/200], Training Loss: 0.0562\n",
      "Epoch [86/200], Validation Loss: 0.1627\n",
      "Epoch [87/200], Training Loss: 0.0558\n",
      "Epoch [87/200], Validation Loss: 0.1621\n",
      "Epoch [88/200], Training Loss: 0.0554\n",
      "Epoch [88/200], Validation Loss: 0.1614\n",
      "Epoch [89/200], Training Loss: 0.0550\n",
      "Epoch [89/200], Validation Loss: 0.1607\n",
      "Epoch [90/200], Training Loss: 0.0544\n",
      "Epoch [90/200], Validation Loss: 0.1600\n",
      "Epoch [91/200], Training Loss: 0.0540\n",
      "Epoch [91/200], Validation Loss: 0.1593\n",
      "Epoch [92/200], Training Loss: 0.0540\n",
      "Epoch [92/200], Validation Loss: 0.1587\n",
      "Epoch [93/200], Training Loss: 0.0537\n",
      "Epoch [93/200], Validation Loss: 0.1581\n",
      "Epoch [94/200], Training Loss: 0.0539\n",
      "Epoch [94/200], Validation Loss: 0.1576\n",
      "Epoch [95/200], Training Loss: 0.0539\n",
      "Epoch [95/200], Validation Loss: 0.1570\n",
      "Epoch [96/200], Training Loss: 0.0534\n",
      "Epoch [96/200], Validation Loss: 0.1564\n",
      "Epoch [97/200], Training Loss: 0.0533\n",
      "Epoch [97/200], Validation Loss: 0.1559\n",
      "Epoch [98/200], Training Loss: 0.0528\n",
      "Epoch [98/200], Validation Loss: 0.1553\n",
      "Epoch [99/200], Training Loss: 0.0525\n",
      "Epoch [99/200], Validation Loss: 0.1547\n",
      "Epoch [100/200], Training Loss: 0.0521\n",
      "Epoch [100/200], Validation Loss: 0.1541\n",
      "Epoch [101/200], Training Loss: 0.0519\n",
      "Epoch [101/200], Validation Loss: 0.1536\n",
      "Epoch [102/200], Training Loss: 0.0515\n",
      "Epoch [102/200], Validation Loss: 0.1531\n",
      "Epoch [103/200], Training Loss: 0.0509\n",
      "Epoch [103/200], Validation Loss: 0.1526\n",
      "Epoch [104/200], Training Loss: 0.0504\n",
      "Epoch [104/200], Validation Loss: 0.1519\n",
      "Epoch [105/200], Training Loss: 0.0501\n",
      "Epoch [105/200], Validation Loss: 0.1515\n",
      "Epoch [106/200], Training Loss: 0.0501\n",
      "Epoch [106/200], Validation Loss: 0.1511\n",
      "Epoch [107/200], Training Loss: 0.0497\n",
      "Epoch [107/200], Validation Loss: 0.1507\n",
      "Epoch [108/200], Training Loss: 0.0493\n",
      "Epoch [108/200], Validation Loss: 0.1501\n",
      "Epoch [109/200], Training Loss: 0.0490\n",
      "Epoch [109/200], Validation Loss: 0.1496\n",
      "Epoch [110/200], Training Loss: 0.0484\n",
      "Epoch [110/200], Validation Loss: 0.1492\n",
      "Epoch [111/200], Training Loss: 0.0478\n",
      "Epoch [111/200], Validation Loss: 0.1487\n",
      "Epoch [112/200], Training Loss: 0.0474\n",
      "Epoch [112/200], Validation Loss: 0.1484\n",
      "Epoch [113/200], Training Loss: 0.0465\n",
      "Epoch [113/200], Validation Loss: 0.1479\n",
      "Epoch [114/200], Training Loss: 0.0460\n",
      "Epoch [114/200], Validation Loss: 0.1474\n",
      "Epoch [115/200], Training Loss: 0.0456\n",
      "Epoch [115/200], Validation Loss: 0.1470\n",
      "Epoch [116/200], Training Loss: 0.0453\n",
      "Epoch [116/200], Validation Loss: 0.1466\n",
      "Epoch [117/200], Training Loss: 0.0450\n",
      "Epoch [117/200], Validation Loss: 0.1462\n",
      "Epoch [118/200], Training Loss: 0.0448\n",
      "Epoch [118/200], Validation Loss: 0.1458\n",
      "Epoch [119/200], Training Loss: 0.0442\n",
      "Epoch [119/200], Validation Loss: 0.1454\n",
      "Epoch [120/200], Training Loss: 0.0439\n",
      "Epoch [120/200], Validation Loss: 0.1450\n",
      "Epoch [121/200], Training Loss: 0.0436\n",
      "Epoch [121/200], Validation Loss: 0.1446\n",
      "Epoch [122/200], Training Loss: 0.0436\n",
      "Epoch [122/200], Validation Loss: 0.1442\n",
      "Epoch [123/200], Training Loss: 0.0433\n",
      "Epoch [123/200], Validation Loss: 0.1439\n",
      "Epoch [124/200], Training Loss: 0.0431\n",
      "Epoch [124/200], Validation Loss: 0.1435\n",
      "Epoch [125/200], Training Loss: 0.0430\n",
      "Epoch [125/200], Validation Loss: 0.1432\n",
      "Epoch [126/200], Training Loss: 0.0427\n",
      "Epoch [126/200], Validation Loss: 0.1428\n",
      "Epoch [127/200], Training Loss: 0.0424\n",
      "Epoch [127/200], Validation Loss: 0.1425\n",
      "Epoch [128/200], Training Loss: 0.0424\n",
      "Epoch [128/200], Validation Loss: 0.1423\n",
      "Epoch [129/200], Training Loss: 0.0419\n",
      "Epoch [129/200], Validation Loss: 0.1419\n",
      "Epoch [130/200], Training Loss: 0.0414\n",
      "Epoch [130/200], Validation Loss: 0.1416\n",
      "Epoch [131/200], Training Loss: 0.0415\n",
      "Epoch [131/200], Validation Loss: 0.1413\n",
      "Epoch [132/200], Training Loss: 0.0408\n",
      "Epoch [132/200], Validation Loss: 0.1409\n",
      "Epoch [133/200], Training Loss: 0.0408\n",
      "Epoch [133/200], Validation Loss: 0.1407\n",
      "Epoch [134/200], Training Loss: 0.0404\n",
      "Epoch [134/200], Validation Loss: 0.1404\n",
      "Epoch [135/200], Training Loss: 0.0403\n",
      "Epoch [135/200], Validation Loss: 0.1401\n",
      "Epoch [136/200], Training Loss: 0.0398\n",
      "Epoch [136/200], Validation Loss: 0.1400\n",
      "Epoch [137/200], Training Loss: 0.0393\n",
      "Epoch [137/200], Validation Loss: 0.1397\n",
      "Epoch [138/200], Training Loss: 0.0389\n",
      "Epoch [138/200], Validation Loss: 0.1395\n",
      "Epoch [139/200], Training Loss: 0.0386\n",
      "Epoch [139/200], Validation Loss: 0.1393\n",
      "Epoch [140/200], Training Loss: 0.0383\n",
      "Epoch [140/200], Validation Loss: 0.1391\n",
      "Epoch [141/200], Training Loss: 0.0377\n",
      "Epoch [141/200], Validation Loss: 0.1388\n",
      "Epoch [142/200], Training Loss: 0.0377\n",
      "Epoch [142/200], Validation Loss: 0.1386\n",
      "Epoch [143/200], Training Loss: 0.0372\n",
      "Epoch [143/200], Validation Loss: 0.1385\n",
      "Epoch [144/200], Training Loss: 0.0370\n",
      "Epoch [144/200], Validation Loss: 0.1382\n",
      "Epoch [145/200], Training Loss: 0.0367\n",
      "Epoch [145/200], Validation Loss: 0.1380\n",
      "Epoch [146/200], Training Loss: 0.0362\n",
      "Epoch [146/200], Validation Loss: 0.1378\n",
      "Epoch [147/200], Training Loss: 0.0363\n",
      "Epoch [147/200], Validation Loss: 0.1376\n",
      "Epoch [148/200], Training Loss: 0.0360\n",
      "Epoch [148/200], Validation Loss: 0.1374\n",
      "Epoch [149/200], Training Loss: 0.0355\n",
      "Epoch [149/200], Validation Loss: 0.1371\n",
      "Epoch [150/200], Training Loss: 0.0355\n",
      "Epoch [150/200], Validation Loss: 0.1370\n",
      "Epoch [151/200], Training Loss: 0.0352\n",
      "Epoch [151/200], Validation Loss: 0.1368\n",
      "Epoch [152/200], Training Loss: 0.0351\n",
      "Epoch [152/200], Validation Loss: 0.1366\n",
      "Epoch [153/200], Training Loss: 0.0348\n",
      "Epoch [153/200], Validation Loss: 0.1364\n",
      "Epoch [154/200], Training Loss: 0.0345\n",
      "Epoch [154/200], Validation Loss: 0.1362\n",
      "Epoch [155/200], Training Loss: 0.0343\n",
      "Epoch [155/200], Validation Loss: 0.1361\n",
      "Epoch [156/200], Training Loss: 0.0340\n",
      "Epoch [156/200], Validation Loss: 0.1359\n",
      "Epoch [157/200], Training Loss: 0.0339\n",
      "Epoch [157/200], Validation Loss: 0.1359\n",
      "Epoch [158/200], Training Loss: 0.0336\n",
      "Epoch [158/200], Validation Loss: 0.1356\n",
      "Epoch [159/200], Training Loss: 0.0332\n",
      "Epoch [159/200], Validation Loss: 0.1356\n",
      "Epoch [160/200], Training Loss: 0.0330\n",
      "Epoch [160/200], Validation Loss: 0.1354\n",
      "Epoch [161/200], Training Loss: 0.0330\n",
      "Epoch [161/200], Validation Loss: 0.1353\n",
      "Epoch [162/200], Training Loss: 0.0329\n",
      "Epoch [162/200], Validation Loss: 0.1352\n",
      "Epoch [163/200], Training Loss: 0.0327\n",
      "Epoch [163/200], Validation Loss: 0.1351\n",
      "Epoch [164/200], Training Loss: 0.0323\n",
      "Epoch [164/200], Validation Loss: 0.1350\n",
      "Epoch [165/200], Training Loss: 0.0319\n",
      "Epoch [165/200], Validation Loss: 0.1349\n",
      "Epoch [166/200], Training Loss: 0.0317\n",
      "Epoch [166/200], Validation Loss: 0.1347\n",
      "Epoch [167/200], Training Loss: 0.0317\n",
      "Epoch [167/200], Validation Loss: 0.1346\n",
      "Epoch [168/200], Training Loss: 0.0313\n",
      "Epoch [168/200], Validation Loss: 0.1345\n",
      "Epoch [169/200], Training Loss: 0.0310\n",
      "Epoch [169/200], Validation Loss: 0.1344\n",
      "Epoch [170/200], Training Loss: 0.0309\n",
      "Epoch [170/200], Validation Loss: 0.1343\n",
      "Epoch [171/200], Training Loss: 0.0306\n",
      "Epoch [171/200], Validation Loss: 0.1342\n",
      "Epoch [172/200], Training Loss: 0.0303\n",
      "Epoch [172/200], Validation Loss: 0.1341\n",
      "Epoch [173/200], Training Loss: 0.0301\n",
      "Epoch [173/200], Validation Loss: 0.1340\n",
      "Epoch [174/200], Training Loss: 0.0299\n",
      "Epoch [174/200], Validation Loss: 0.1341\n",
      "Epoch [175/200], Training Loss: 0.0293\n",
      "Epoch [175/200], Validation Loss: 0.1339\n",
      "Epoch [176/200], Training Loss: 0.0293\n",
      "Epoch [176/200], Validation Loss: 0.1338\n",
      "Epoch [177/200], Training Loss: 0.0289\n",
      "Epoch [177/200], Validation Loss: 0.1338\n",
      "Epoch [178/200], Training Loss: 0.0289\n",
      "Epoch [178/200], Validation Loss: 0.1337\n",
      "Epoch [179/200], Training Loss: 0.0286\n",
      "Epoch [179/200], Validation Loss: 0.1337\n",
      "Epoch [180/200], Training Loss: 0.0284\n",
      "Epoch [180/200], Validation Loss: 0.1336\n",
      "Epoch [181/200], Training Loss: 0.0282\n",
      "Epoch [181/200], Validation Loss: 0.1335\n",
      "Epoch [182/200], Training Loss: 0.0280\n",
      "Epoch [182/200], Validation Loss: 0.1334\n",
      "Epoch [183/200], Training Loss: 0.0274\n",
      "Epoch [183/200], Validation Loss: 0.1334\n",
      "Epoch [184/200], Training Loss: 0.0275\n",
      "Epoch [184/200], Validation Loss: 0.1333\n",
      "Epoch [185/200], Training Loss: 0.0274\n",
      "Epoch [185/200], Validation Loss: 0.1333\n",
      "Epoch [186/200], Training Loss: 0.0269\n",
      "Epoch [186/200], Validation Loss: 0.1331\n",
      "Epoch [187/200], Training Loss: 0.0271\n",
      "Epoch [187/200], Validation Loss: 0.1332\n",
      "Epoch [188/200], Training Loss: 0.0266\n",
      "Epoch [188/200], Validation Loss: 0.1331\n",
      "Epoch [189/200], Training Loss: 0.0263\n",
      "Epoch [189/200], Validation Loss: 0.1330\n",
      "Epoch [190/200], Training Loss: 0.0262\n",
      "Epoch [190/200], Validation Loss: 0.1329\n",
      "Epoch [191/200], Training Loss: 0.0260\n",
      "Epoch [191/200], Validation Loss: 0.1329\n",
      "Epoch [192/200], Training Loss: 0.0258\n",
      "Epoch [192/200], Validation Loss: 0.1328\n",
      "Epoch [193/200], Training Loss: 0.0256\n",
      "Epoch [193/200], Validation Loss: 0.1327\n",
      "Epoch [194/200], Training Loss: 0.0253\n",
      "Epoch [194/200], Validation Loss: 0.1327\n",
      "Epoch [195/200], Training Loss: 0.0253\n",
      "Epoch [195/200], Validation Loss: 0.1327\n",
      "Epoch [196/200], Training Loss: 0.0249\n",
      "Epoch [196/200], Validation Loss: 0.1325\n",
      "Epoch [197/200], Training Loss: 0.0248\n",
      "Epoch [197/200], Validation Loss: 0.1325\n",
      "Epoch [198/200], Training Loss: 0.0247\n",
      "Epoch [198/200], Validation Loss: 0.1325\n",
      "Epoch [199/200], Training Loss: 0.0244\n",
      "Epoch [199/200], Validation Loss: 0.1324\n",
      "Epoch [200/200], Training Loss: 0.0241\n",
      "Epoch [200/200], Validation Loss: 0.1324\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "trainData = pd.read_csv('./csv/cure_the_princess_train.csv')\n",
    "validData = pd.read_csv('./csv/cure_the_princess_validation.csv')\n",
    "\n",
    "\n",
    "trainX = trainData.drop(columns=['Cured']).values\n",
    "trainY = trainData['Cured'].values\n",
    "validX = validData.drop(columns=['Cured']).values\n",
    "validY = validData['Cured'].values\n",
    "\n",
    "\n",
    "numInputFeatures = trainX.shape[1]\n",
    "\n",
    "torch.manual_seed(190401070)\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, numInputFeatures):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(numInputFeatures, 100) \n",
    "        self.relu1 = nn.ReLU() \n",
    "        self.fc2 = nn.Linear(100, 50) \n",
    "        self.relu2 = nn.ReLU() \n",
    "        self.fc3 = nn.Linear(50, 1) \n",
    "        self.sigmoid = nn.Sigmoid() \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MLP(numInputFeatures=numInputFeatures)\n",
    "\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0006)\n",
    "\n",
    "\n",
    "numEpochs = 200\n",
    "batchSize = 16\n",
    "trainLosses = []\n",
    "validLosses = []\n",
    "for epoch in range(numEpochs):\n",
    "    for i in range(0, len(trainX), batchSize):\n",
    "        \n",
    "        batchX = torch.tensor(trainX[i:i+batchSize], dtype=torch.float32)\n",
    "        batchY = torch.tensor(trainY[i:i+batchSize], dtype=torch.float32).view(-1, 1)\n",
    "        \n",
    "        \n",
    "        outputs = model(batchX)\n",
    "        loss = criterion(outputs, batchY)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    \n",
    "    trainLosses.append(loss.item())\n",
    "    print('Epoch [%d/%d], Training Loss: %.4f' % (epoch+1, numEpochs, loss.item()))\n",
    "    \n",
    "   \n",
    "    validLoss = criterion(model(torch.tensor(validX, dtype=torch.float32)), torch.tensor(validY, dtype=torch.float32).view(-1, 1)).item()\n",
    "    validLosses.append(validLoss)\n",
    "    print('Epoch [%d/%d], Validation Loss: %.4f' % (epoch+1, numEpochs, validLoss))\n",
    "    \n",
    "\n",
    "\n",
    "plt.plot(trainLosses, label='Training Loss')\n",
    "plt.plot(validLosses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Training Loss: 0.3834\n",
      "Epoch [1/250], Validation Loss: 0.6119\n",
      "Accuracy: 0.6749, Precision: 0.6367, Recall: 0.8222, F1: 0.7177\n",
      "Epoch [2/250], Training Loss: 0.3208\n",
      "Epoch [2/250], Validation Loss: 0.5595\n",
      "Accuracy: 0.7176, Precision: 0.6687, Recall: 0.8686, F1: 0.7556\n",
      "Epoch [3/250], Training Loss: 0.2847\n",
      "Epoch [3/250], Validation Loss: 0.5220\n",
      "Accuracy: 0.7513, Precision: 0.6984, Recall: 0.8892, F1: 0.7823\n",
      "Epoch [4/250], Training Loss: 0.2607\n",
      "Epoch [4/250], Validation Loss: 0.4919\n",
      "Accuracy: 0.7707, Precision: 0.7149, Recall: 0.9046, F1: 0.7986\n",
      "Epoch [5/250], Training Loss: 0.2442\n",
      "Epoch [5/250], Validation Loss: 0.4672\n",
      "Accuracy: 0.7902, Precision: 0.7325, Recall: 0.9175, F1: 0.8146\n",
      "Epoch [6/250], Training Loss: 0.2311\n",
      "Epoch [6/250], Validation Loss: 0.4453\n",
      "Accuracy: 0.8018, Precision: 0.7443, Recall: 0.9227, F1: 0.8239\n",
      "Epoch [7/250], Training Loss: 0.2197\n",
      "Epoch [7/250], Validation Loss: 0.4263\n",
      "Accuracy: 0.8187, Precision: 0.7616, Recall: 0.9304, F1: 0.8376\n",
      "Epoch [8/250], Training Loss: 0.2104\n",
      "Epoch [8/250], Validation Loss: 0.4090\n",
      "Accuracy: 0.8277, Precision: 0.7730, Recall: 0.9304, F1: 0.8444\n",
      "Epoch [9/250], Training Loss: 0.2021\n",
      "Epoch [9/250], Validation Loss: 0.3934\n",
      "Accuracy: 0.8381, Precision: 0.7840, Recall: 0.9356, F1: 0.8531\n",
      "Epoch [10/250], Training Loss: 0.1945\n",
      "Epoch [10/250], Validation Loss: 0.3793\n",
      "Accuracy: 0.8433, Precision: 0.7896, Recall: 0.9381, F1: 0.8575\n",
      "Epoch [11/250], Training Loss: 0.1879\n",
      "Epoch [11/250], Validation Loss: 0.3664\n",
      "Accuracy: 0.8484, Precision: 0.7978, Recall: 0.9356, F1: 0.8612\n",
      "Epoch [12/250], Training Loss: 0.1825\n",
      "Epoch [12/250], Validation Loss: 0.3545\n",
      "Accuracy: 0.8484, Precision: 0.7991, Recall: 0.9330, F1: 0.8609\n",
      "Epoch [13/250], Training Loss: 0.1769\n",
      "Epoch [13/250], Validation Loss: 0.3437\n",
      "Accuracy: 0.8549, Precision: 0.8053, Recall: 0.9381, F1: 0.8667\n",
      "Epoch [14/250], Training Loss: 0.1718\n",
      "Epoch [14/250], Validation Loss: 0.3338\n",
      "Accuracy: 0.8549, Precision: 0.8040, Recall: 0.9407, F1: 0.8670\n",
      "Epoch [15/250], Training Loss: 0.1667\n",
      "Epoch [15/250], Validation Loss: 0.3246\n",
      "Accuracy: 0.8549, Precision: 0.8067, Recall: 0.9356, F1: 0.8663\n",
      "Epoch [16/250], Training Loss: 0.1622\n",
      "Epoch [16/250], Validation Loss: 0.3161\n",
      "Accuracy: 0.8562, Precision: 0.8098, Recall: 0.9330, F1: 0.8671\n",
      "Epoch [17/250], Training Loss: 0.1574\n",
      "Epoch [17/250], Validation Loss: 0.3082\n",
      "Accuracy: 0.8588, Precision: 0.8149, Recall: 0.9304, F1: 0.8688\n",
      "Epoch [18/250], Training Loss: 0.1530\n",
      "Epoch [18/250], Validation Loss: 0.3010\n",
      "Accuracy: 0.8627, Precision: 0.8190, Recall: 0.9330, F1: 0.8723\n",
      "Epoch [19/250], Training Loss: 0.1485\n",
      "Epoch [19/250], Validation Loss: 0.2943\n",
      "Accuracy: 0.8666, Precision: 0.8261, Recall: 0.9304, F1: 0.8752\n",
      "Epoch [20/250], Training Loss: 0.1441\n",
      "Epoch [20/250], Validation Loss: 0.2881\n",
      "Accuracy: 0.8692, Precision: 0.8299, Recall: 0.9304, F1: 0.8773\n",
      "Epoch [21/250], Training Loss: 0.1397\n",
      "Epoch [21/250], Validation Loss: 0.2823\n",
      "Accuracy: 0.8731, Precision: 0.8341, Recall: 0.9330, F1: 0.8808\n",
      "Epoch [22/250], Training Loss: 0.1356\n",
      "Epoch [22/250], Validation Loss: 0.2769\n",
      "Accuracy: 0.8744, Precision: 0.8360, Recall: 0.9330, F1: 0.8819\n",
      "Epoch [23/250], Training Loss: 0.1326\n",
      "Epoch [23/250], Validation Loss: 0.2717\n",
      "Accuracy: 0.8821, Precision: 0.8462, Recall: 0.9356, F1: 0.8886\n",
      "Epoch [24/250], Training Loss: 0.1297\n",
      "Epoch [24/250], Validation Loss: 0.2670\n",
      "Accuracy: 0.8821, Precision: 0.8478, Recall: 0.9330, F1: 0.8883\n",
      "Epoch [25/250], Training Loss: 0.1262\n",
      "Epoch [25/250], Validation Loss: 0.2628\n",
      "Accuracy: 0.8860, Precision: 0.8555, Recall: 0.9304, F1: 0.8914\n",
      "Epoch [26/250], Training Loss: 0.1229\n",
      "Epoch [26/250], Validation Loss: 0.2586\n",
      "Accuracy: 0.8860, Precision: 0.8571, Recall: 0.9278, F1: 0.8911\n",
      "Epoch [27/250], Training Loss: 0.1205\n",
      "Epoch [27/250], Validation Loss: 0.2546\n",
      "Accuracy: 0.8834, Precision: 0.8565, Recall: 0.9227, F1: 0.8883\n",
      "Epoch [28/250], Training Loss: 0.1180\n",
      "Epoch [28/250], Validation Loss: 0.2508\n",
      "Accuracy: 0.8834, Precision: 0.8565, Recall: 0.9227, F1: 0.8883\n",
      "Epoch [29/250], Training Loss: 0.1155\n",
      "Epoch [29/250], Validation Loss: 0.2472\n",
      "Accuracy: 0.8847, Precision: 0.8585, Recall: 0.9227, F1: 0.8894\n",
      "Epoch [30/250], Training Loss: 0.1129\n",
      "Epoch [30/250], Validation Loss: 0.2437\n",
      "Accuracy: 0.8847, Precision: 0.8585, Recall: 0.9227, F1: 0.8894\n",
      "Epoch [31/250], Training Loss: 0.1108\n",
      "Epoch [31/250], Validation Loss: 0.2404\n",
      "Accuracy: 0.8873, Precision: 0.8627, Recall: 0.9227, F1: 0.8917\n",
      "Epoch [32/250], Training Loss: 0.1090\n",
      "Epoch [32/250], Validation Loss: 0.2375\n",
      "Accuracy: 0.8873, Precision: 0.8627, Recall: 0.9227, F1: 0.8917\n",
      "Epoch [33/250], Training Loss: 0.1072\n",
      "Epoch [33/250], Validation Loss: 0.2347\n",
      "Accuracy: 0.8886, Precision: 0.8647, Recall: 0.9227, F1: 0.8928\n",
      "Epoch [34/250], Training Loss: 0.1054\n",
      "Epoch [34/250], Validation Loss: 0.2319\n",
      "Accuracy: 0.8899, Precision: 0.8668, Recall: 0.9227, F1: 0.8939\n",
      "Epoch [35/250], Training Loss: 0.1038\n",
      "Epoch [35/250], Validation Loss: 0.2293\n",
      "Accuracy: 0.8899, Precision: 0.8668, Recall: 0.9227, F1: 0.8939\n",
      "Epoch [36/250], Training Loss: 0.1020\n",
      "Epoch [36/250], Validation Loss: 0.2268\n",
      "Accuracy: 0.8899, Precision: 0.8668, Recall: 0.9227, F1: 0.8939\n",
      "Epoch [37/250], Training Loss: 0.1005\n",
      "Epoch [37/250], Validation Loss: 0.2244\n",
      "Accuracy: 0.8899, Precision: 0.8668, Recall: 0.9227, F1: 0.8939\n",
      "Epoch [38/250], Training Loss: 0.0991\n",
      "Epoch [38/250], Validation Loss: 0.2221\n",
      "Accuracy: 0.8951, Precision: 0.8735, Recall: 0.9253, F1: 0.8986\n",
      "Epoch [39/250], Training Loss: 0.0977\n",
      "Epoch [39/250], Validation Loss: 0.2199\n",
      "Accuracy: 0.8951, Precision: 0.8735, Recall: 0.9253, F1: 0.8986\n",
      "Epoch [40/250], Training Loss: 0.0962\n",
      "Epoch [40/250], Validation Loss: 0.2179\n",
      "Accuracy: 0.8951, Precision: 0.8735, Recall: 0.9253, F1: 0.8986\n",
      "Epoch [41/250], Training Loss: 0.0947\n",
      "Epoch [41/250], Validation Loss: 0.2159\n",
      "Accuracy: 0.8951, Precision: 0.8753, Recall: 0.9227, F1: 0.8984\n",
      "Epoch [42/250], Training Loss: 0.0932\n",
      "Epoch [42/250], Validation Loss: 0.2137\n",
      "Accuracy: 0.8964, Precision: 0.8775, Recall: 0.9227, F1: 0.8995\n",
      "Epoch [43/250], Training Loss: 0.0914\n",
      "Epoch [43/250], Validation Loss: 0.2118\n",
      "Accuracy: 0.8977, Precision: 0.8796, Recall: 0.9227, F1: 0.9006\n",
      "Epoch [44/250], Training Loss: 0.0897\n",
      "Epoch [44/250], Validation Loss: 0.2099\n",
      "Accuracy: 0.9003, Precision: 0.8840, Recall: 0.9227, F1: 0.9029\n",
      "Epoch [45/250], Training Loss: 0.0882\n",
      "Epoch [45/250], Validation Loss: 0.2080\n",
      "Accuracy: 0.9028, Precision: 0.8883, Recall: 0.9227, F1: 0.9052\n",
      "Epoch [46/250], Training Loss: 0.0865\n",
      "Epoch [46/250], Validation Loss: 0.2062\n",
      "Accuracy: 0.9028, Precision: 0.8883, Recall: 0.9227, F1: 0.9052\n",
      "Epoch [47/250], Training Loss: 0.0851\n",
      "Epoch [47/250], Validation Loss: 0.2046\n",
      "Accuracy: 0.9054, Precision: 0.8928, Recall: 0.9227, F1: 0.9075\n",
      "Epoch [48/250], Training Loss: 0.0839\n",
      "Epoch [48/250], Validation Loss: 0.2032\n",
      "Accuracy: 0.9054, Precision: 0.8928, Recall: 0.9227, F1: 0.9075\n",
      "Epoch [49/250], Training Loss: 0.0825\n",
      "Epoch [49/250], Validation Loss: 0.2016\n",
      "Accuracy: 0.9041, Precision: 0.8925, Recall: 0.9201, F1: 0.9061\n",
      "Epoch [50/250], Training Loss: 0.0809\n",
      "Epoch [50/250], Validation Loss: 0.2002\n",
      "Accuracy: 0.9041, Precision: 0.8925, Recall: 0.9201, F1: 0.9061\n",
      "Epoch [51/250], Training Loss: 0.0793\n",
      "Epoch [51/250], Validation Loss: 0.1986\n",
      "Accuracy: 0.9054, Precision: 0.8947, Recall: 0.9201, F1: 0.9072\n",
      "Epoch [52/250], Training Loss: 0.0775\n",
      "Epoch [52/250], Validation Loss: 0.1970\n",
      "Accuracy: 0.9054, Precision: 0.8947, Recall: 0.9201, F1: 0.9072\n",
      "Epoch [53/250], Training Loss: 0.0762\n",
      "Epoch [53/250], Validation Loss: 0.1956\n",
      "Accuracy: 0.9106, Precision: 0.9038, Recall: 0.9201, F1: 0.9119\n",
      "Epoch [54/250], Training Loss: 0.0753\n",
      "Epoch [54/250], Validation Loss: 0.1941\n",
      "Accuracy: 0.9119, Precision: 0.9061, Recall: 0.9201, F1: 0.9130\n",
      "Epoch [55/250], Training Loss: 0.0744\n",
      "Epoch [55/250], Validation Loss: 0.1928\n",
      "Accuracy: 0.9145, Precision: 0.9107, Recall: 0.9201, F1: 0.9154\n",
      "Epoch [56/250], Training Loss: 0.0733\n",
      "Epoch [56/250], Validation Loss: 0.1914\n",
      "Accuracy: 0.9210, Precision: 0.9203, Recall: 0.9227, F1: 0.9215\n",
      "Epoch [57/250], Training Loss: 0.0724\n",
      "Epoch [57/250], Validation Loss: 0.1901\n",
      "Accuracy: 0.9223, Precision: 0.9205, Recall: 0.9253, F1: 0.9229\n",
      "Epoch [58/250], Training Loss: 0.0715\n",
      "Epoch [58/250], Validation Loss: 0.1888\n",
      "Accuracy: 0.9249, Precision: 0.9253, Recall: 0.9253, F1: 0.9253\n",
      "Epoch [59/250], Training Loss: 0.0706\n",
      "Epoch [59/250], Validation Loss: 0.1876\n",
      "Accuracy: 0.9249, Precision: 0.9253, Recall: 0.9253, F1: 0.9253\n",
      "Epoch [60/250], Training Loss: 0.0698\n",
      "Epoch [60/250], Validation Loss: 0.1864\n",
      "Accuracy: 0.9262, Precision: 0.9254, Recall: 0.9278, F1: 0.9266\n",
      "Epoch [61/250], Training Loss: 0.0688\n",
      "Epoch [61/250], Validation Loss: 0.1852\n",
      "Accuracy: 0.9262, Precision: 0.9254, Recall: 0.9278, F1: 0.9266\n",
      "Epoch [62/250], Training Loss: 0.0680\n",
      "Epoch [62/250], Validation Loss: 0.1841\n",
      "Accuracy: 0.9262, Precision: 0.9276, Recall: 0.9253, F1: 0.9265\n",
      "Epoch [63/250], Training Loss: 0.0673\n",
      "Epoch [63/250], Validation Loss: 0.1830\n",
      "Accuracy: 0.9275, Precision: 0.9278, Recall: 0.9278, F1: 0.9278\n",
      "Epoch [64/250], Training Loss: 0.0666\n",
      "Epoch [64/250], Validation Loss: 0.1819\n",
      "Accuracy: 0.9275, Precision: 0.9278, Recall: 0.9278, F1: 0.9278\n",
      "Epoch [65/250], Training Loss: 0.0658\n",
      "Epoch [65/250], Validation Loss: 0.1809\n",
      "Accuracy: 0.9262, Precision: 0.9276, Recall: 0.9253, F1: 0.9265\n",
      "Epoch [66/250], Training Loss: 0.0650\n",
      "Epoch [66/250], Validation Loss: 0.1799\n",
      "Accuracy: 0.9275, Precision: 0.9301, Recall: 0.9253, F1: 0.9276\n",
      "Epoch [67/250], Training Loss: 0.0643\n",
      "Epoch [67/250], Validation Loss: 0.1788\n",
      "Accuracy: 0.9275, Precision: 0.9323, Recall: 0.9227, F1: 0.9275\n",
      "Epoch [68/250], Training Loss: 0.0638\n",
      "Epoch [68/250], Validation Loss: 0.1778\n",
      "Accuracy: 0.9275, Precision: 0.9323, Recall: 0.9227, F1: 0.9275\n",
      "Epoch [69/250], Training Loss: 0.0633\n",
      "Epoch [69/250], Validation Loss: 0.1768\n",
      "Accuracy: 0.9262, Precision: 0.9321, Recall: 0.9201, F1: 0.9261\n",
      "Epoch [70/250], Training Loss: 0.0632\n",
      "Epoch [70/250], Validation Loss: 0.1760\n",
      "Accuracy: 0.9262, Precision: 0.9321, Recall: 0.9201, F1: 0.9261\n",
      "Epoch [71/250], Training Loss: 0.0627\n",
      "Epoch [71/250], Validation Loss: 0.1750\n",
      "Accuracy: 0.9262, Precision: 0.9321, Recall: 0.9201, F1: 0.9261\n",
      "Epoch [72/250], Training Loss: 0.0619\n",
      "Epoch [72/250], Validation Loss: 0.1740\n",
      "Accuracy: 0.9262, Precision: 0.9321, Recall: 0.9201, F1: 0.9261\n",
      "Epoch [73/250], Training Loss: 0.0616\n",
      "Epoch [73/250], Validation Loss: 0.1731\n",
      "Accuracy: 0.9275, Precision: 0.9346, Recall: 0.9201, F1: 0.9273\n",
      "Epoch [74/250], Training Loss: 0.0610\n",
      "Epoch [74/250], Validation Loss: 0.1722\n",
      "Accuracy: 0.9275, Precision: 0.9346, Recall: 0.9201, F1: 0.9273\n",
      "Epoch [75/250], Training Loss: 0.0606\n",
      "Epoch [75/250], Validation Loss: 0.1713\n",
      "Accuracy: 0.9275, Precision: 0.9346, Recall: 0.9201, F1: 0.9273\n",
      "Epoch [76/250], Training Loss: 0.0600\n",
      "Epoch [76/250], Validation Loss: 0.1705\n",
      "Accuracy: 0.9288, Precision: 0.9347, Recall: 0.9227, F1: 0.9287\n",
      "Epoch [77/250], Training Loss: 0.0598\n",
      "Epoch [77/250], Validation Loss: 0.1697\n",
      "Accuracy: 0.9288, Precision: 0.9347, Recall: 0.9227, F1: 0.9287\n",
      "Epoch [78/250], Training Loss: 0.0593\n",
      "Epoch [78/250], Validation Loss: 0.1688\n",
      "Accuracy: 0.9288, Precision: 0.9347, Recall: 0.9227, F1: 0.9287\n",
      "Epoch [79/250], Training Loss: 0.0589\n",
      "Epoch [79/250], Validation Loss: 0.1680\n",
      "Accuracy: 0.9288, Precision: 0.9347, Recall: 0.9227, F1: 0.9287\n",
      "Epoch [80/250], Training Loss: 0.0584\n",
      "Epoch [80/250], Validation Loss: 0.1672\n",
      "Accuracy: 0.9301, Precision: 0.9372, Recall: 0.9227, F1: 0.9299\n",
      "Epoch [81/250], Training Loss: 0.0579\n",
      "Epoch [81/250], Validation Loss: 0.1665\n",
      "Accuracy: 0.9301, Precision: 0.9372, Recall: 0.9227, F1: 0.9299\n",
      "Epoch [82/250], Training Loss: 0.0575\n",
      "Epoch [82/250], Validation Loss: 0.1657\n",
      "Accuracy: 0.9301, Precision: 0.9372, Recall: 0.9227, F1: 0.9299\n",
      "Epoch [83/250], Training Loss: 0.0570\n",
      "Epoch [83/250], Validation Loss: 0.1649\n",
      "Accuracy: 0.9313, Precision: 0.9396, Recall: 0.9227, F1: 0.9311\n",
      "Epoch [84/250], Training Loss: 0.0571\n",
      "Epoch [84/250], Validation Loss: 0.1642\n",
      "Accuracy: 0.9326, Precision: 0.9421, Recall: 0.9227, F1: 0.9323\n",
      "Epoch [85/250], Training Loss: 0.0566\n",
      "Epoch [85/250], Validation Loss: 0.1635\n",
      "Accuracy: 0.9339, Precision: 0.9446, Recall: 0.9227, F1: 0.9335\n",
      "Epoch [86/250], Training Loss: 0.0562\n",
      "Epoch [86/250], Validation Loss: 0.1627\n",
      "Accuracy: 0.9339, Precision: 0.9446, Recall: 0.9227, F1: 0.9335\n",
      "Epoch [87/250], Training Loss: 0.0558\n",
      "Epoch [87/250], Validation Loss: 0.1621\n",
      "Accuracy: 0.9339, Precision: 0.9446, Recall: 0.9227, F1: 0.9335\n",
      "Epoch [88/250], Training Loss: 0.0554\n",
      "Epoch [88/250], Validation Loss: 0.1614\n",
      "Accuracy: 0.9352, Precision: 0.9447, Recall: 0.9253, F1: 0.9349\n",
      "Epoch [89/250], Training Loss: 0.0550\n",
      "Epoch [89/250], Validation Loss: 0.1607\n",
      "Accuracy: 0.9365, Precision: 0.9472, Recall: 0.9253, F1: 0.9361\n",
      "Epoch [90/250], Training Loss: 0.0544\n",
      "Epoch [90/250], Validation Loss: 0.1600\n",
      "Accuracy: 0.9365, Precision: 0.9472, Recall: 0.9253, F1: 0.9361\n",
      "Epoch [91/250], Training Loss: 0.0540\n",
      "Epoch [91/250], Validation Loss: 0.1593\n",
      "Accuracy: 0.9352, Precision: 0.9471, Recall: 0.9227, F1: 0.9347\n",
      "Epoch [92/250], Training Loss: 0.0540\n",
      "Epoch [92/250], Validation Loss: 0.1587\n",
      "Accuracy: 0.9352, Precision: 0.9471, Recall: 0.9227, F1: 0.9347\n",
      "Epoch [93/250], Training Loss: 0.0537\n",
      "Epoch [93/250], Validation Loss: 0.1581\n",
      "Accuracy: 0.9365, Precision: 0.9496, Recall: 0.9227, F1: 0.9359\n",
      "Epoch [94/250], Training Loss: 0.0539\n",
      "Epoch [94/250], Validation Loss: 0.1576\n",
      "Accuracy: 0.9378, Precision: 0.9521, Recall: 0.9227, F1: 0.9372\n",
      "Epoch [95/250], Training Loss: 0.0539\n",
      "Epoch [95/250], Validation Loss: 0.1570\n",
      "Accuracy: 0.9391, Precision: 0.9547, Recall: 0.9227, F1: 0.9384\n",
      "Epoch [96/250], Training Loss: 0.0534\n",
      "Epoch [96/250], Validation Loss: 0.1564\n",
      "Accuracy: 0.9391, Precision: 0.9547, Recall: 0.9227, F1: 0.9384\n",
      "Epoch [97/250], Training Loss: 0.0533\n",
      "Epoch [97/250], Validation Loss: 0.1559\n",
      "Accuracy: 0.9391, Precision: 0.9547, Recall: 0.9227, F1: 0.9384\n",
      "Epoch [98/250], Training Loss: 0.0528\n",
      "Epoch [98/250], Validation Loss: 0.1553\n",
      "Accuracy: 0.9391, Precision: 0.9547, Recall: 0.9227, F1: 0.9384\n",
      "Epoch [99/250], Training Loss: 0.0525\n",
      "Epoch [99/250], Validation Loss: 0.1547\n",
      "Accuracy: 0.9404, Precision: 0.9548, Recall: 0.9253, F1: 0.9398\n",
      "Epoch [100/250], Training Loss: 0.0521\n",
      "Epoch [100/250], Validation Loss: 0.1541\n",
      "Accuracy: 0.9404, Precision: 0.9548, Recall: 0.9253, F1: 0.9398\n",
      "Epoch [101/250], Training Loss: 0.0519\n",
      "Epoch [101/250], Validation Loss: 0.1536\n",
      "Accuracy: 0.9404, Precision: 0.9548, Recall: 0.9253, F1: 0.9398\n",
      "Epoch [102/250], Training Loss: 0.0515\n",
      "Epoch [102/250], Validation Loss: 0.1531\n",
      "Accuracy: 0.9404, Precision: 0.9548, Recall: 0.9253, F1: 0.9398\n",
      "Epoch [103/250], Training Loss: 0.0509\n",
      "Epoch [103/250], Validation Loss: 0.1526\n",
      "Accuracy: 0.9391, Precision: 0.9547, Recall: 0.9227, F1: 0.9384\n",
      "Epoch [104/250], Training Loss: 0.0504\n",
      "Epoch [104/250], Validation Loss: 0.1519\n",
      "Accuracy: 0.9391, Precision: 0.9547, Recall: 0.9227, F1: 0.9384\n",
      "Epoch [105/250], Training Loss: 0.0501\n",
      "Epoch [105/250], Validation Loss: 0.1515\n",
      "Accuracy: 0.9404, Precision: 0.9572, Recall: 0.9227, F1: 0.9396\n",
      "Epoch [106/250], Training Loss: 0.0501\n",
      "Epoch [106/250], Validation Loss: 0.1511\n",
      "Accuracy: 0.9404, Precision: 0.9572, Recall: 0.9227, F1: 0.9396\n",
      "Epoch [107/250], Training Loss: 0.0497\n",
      "Epoch [107/250], Validation Loss: 0.1507\n",
      "Accuracy: 0.9391, Precision: 0.9571, Recall: 0.9201, F1: 0.9382\n",
      "Epoch [108/250], Training Loss: 0.0493\n",
      "Epoch [108/250], Validation Loss: 0.1501\n",
      "Accuracy: 0.9391, Precision: 0.9571, Recall: 0.9201, F1: 0.9382\n",
      "Epoch [109/250], Training Loss: 0.0490\n",
      "Epoch [109/250], Validation Loss: 0.1496\n",
      "Accuracy: 0.9391, Precision: 0.9571, Recall: 0.9201, F1: 0.9382\n",
      "Epoch [110/250], Training Loss: 0.0484\n",
      "Epoch [110/250], Validation Loss: 0.1492\n",
      "Accuracy: 0.9391, Precision: 0.9571, Recall: 0.9201, F1: 0.9382\n",
      "Epoch [111/250], Training Loss: 0.0478\n",
      "Epoch [111/250], Validation Loss: 0.1487\n",
      "Accuracy: 0.9391, Precision: 0.9571, Recall: 0.9201, F1: 0.9382\n",
      "Epoch [112/250], Training Loss: 0.0474\n",
      "Epoch [112/250], Validation Loss: 0.1484\n",
      "Accuracy: 0.9378, Precision: 0.9570, Recall: 0.9175, F1: 0.9368\n",
      "Epoch [113/250], Training Loss: 0.0465\n",
      "Epoch [113/250], Validation Loss: 0.1479\n",
      "Accuracy: 0.9391, Precision: 0.9596, Recall: 0.9175, F1: 0.9381\n",
      "Epoch [114/250], Training Loss: 0.0460\n",
      "Epoch [114/250], Validation Loss: 0.1474\n",
      "Accuracy: 0.9391, Precision: 0.9621, Recall: 0.9149, F1: 0.9379\n",
      "Epoch [115/250], Training Loss: 0.0456\n",
      "Epoch [115/250], Validation Loss: 0.1470\n",
      "Accuracy: 0.9404, Precision: 0.9647, Recall: 0.9149, F1: 0.9392\n",
      "Epoch [116/250], Training Loss: 0.0453\n",
      "Epoch [116/250], Validation Loss: 0.1466\n",
      "Accuracy: 0.9404, Precision: 0.9647, Recall: 0.9149, F1: 0.9392\n",
      "Epoch [117/250], Training Loss: 0.0450\n",
      "Epoch [117/250], Validation Loss: 0.1462\n",
      "Accuracy: 0.9404, Precision: 0.9647, Recall: 0.9149, F1: 0.9392\n",
      "Epoch [118/250], Training Loss: 0.0448\n",
      "Epoch [118/250], Validation Loss: 0.1458\n",
      "Accuracy: 0.9404, Precision: 0.9647, Recall: 0.9149, F1: 0.9392\n",
      "Epoch [119/250], Training Loss: 0.0442\n",
      "Epoch [119/250], Validation Loss: 0.1454\n",
      "Accuracy: 0.9404, Precision: 0.9647, Recall: 0.9149, F1: 0.9392\n",
      "Epoch [120/250], Training Loss: 0.0439\n",
      "Epoch [120/250], Validation Loss: 0.1450\n",
      "Accuracy: 0.9404, Precision: 0.9647, Recall: 0.9149, F1: 0.9392\n",
      "Epoch [121/250], Training Loss: 0.0436\n",
      "Epoch [121/250], Validation Loss: 0.1446\n",
      "Accuracy: 0.9417, Precision: 0.9673, Recall: 0.9149, F1: 0.9404\n",
      "Epoch [122/250], Training Loss: 0.0436\n",
      "Epoch [122/250], Validation Loss: 0.1442\n",
      "Accuracy: 0.9404, Precision: 0.9672, Recall: 0.9124, F1: 0.9390\n",
      "Epoch [123/250], Training Loss: 0.0433\n",
      "Epoch [123/250], Validation Loss: 0.1439\n",
      "Accuracy: 0.9404, Precision: 0.9672, Recall: 0.9124, F1: 0.9390\n",
      "Epoch [124/250], Training Loss: 0.0431\n",
      "Epoch [124/250], Validation Loss: 0.1435\n",
      "Accuracy: 0.9404, Precision: 0.9672, Recall: 0.9124, F1: 0.9390\n",
      "Epoch [125/250], Training Loss: 0.0430\n",
      "Epoch [125/250], Validation Loss: 0.1432\n",
      "Accuracy: 0.9404, Precision: 0.9672, Recall: 0.9124, F1: 0.9390\n",
      "Epoch [126/250], Training Loss: 0.0427\n",
      "Epoch [126/250], Validation Loss: 0.1428\n",
      "Accuracy: 0.9404, Precision: 0.9672, Recall: 0.9124, F1: 0.9390\n",
      "Epoch [127/250], Training Loss: 0.0424\n",
      "Epoch [127/250], Validation Loss: 0.1425\n",
      "Accuracy: 0.9404, Precision: 0.9672, Recall: 0.9124, F1: 0.9390\n",
      "Epoch [128/250], Training Loss: 0.0424\n",
      "Epoch [128/250], Validation Loss: 0.1423\n",
      "Accuracy: 0.9404, Precision: 0.9672, Recall: 0.9124, F1: 0.9390\n",
      "Epoch [129/250], Training Loss: 0.0419\n",
      "Epoch [129/250], Validation Loss: 0.1419\n",
      "Accuracy: 0.9404, Precision: 0.9672, Recall: 0.9124, F1: 0.9390\n",
      "Epoch [130/250], Training Loss: 0.0414\n",
      "Epoch [130/250], Validation Loss: 0.1416\n",
      "Accuracy: 0.9404, Precision: 0.9672, Recall: 0.9124, F1: 0.9390\n",
      "Epoch [131/250], Training Loss: 0.0415\n",
      "Epoch [131/250], Validation Loss: 0.1413\n",
      "Accuracy: 0.9404, Precision: 0.9672, Recall: 0.9124, F1: 0.9390\n",
      "Epoch [132/250], Training Loss: 0.0408\n",
      "Epoch [132/250], Validation Loss: 0.1409\n",
      "Accuracy: 0.9417, Precision: 0.9699, Recall: 0.9124, F1: 0.9402\n",
      "Epoch [133/250], Training Loss: 0.0408\n",
      "Epoch [133/250], Validation Loss: 0.1407\n",
      "Accuracy: 0.9430, Precision: 0.9725, Recall: 0.9124, F1: 0.9415\n",
      "Epoch [134/250], Training Loss: 0.0404\n",
      "Epoch [134/250], Validation Loss: 0.1404\n",
      "Accuracy: 0.9430, Precision: 0.9725, Recall: 0.9124, F1: 0.9415\n",
      "Epoch [135/250], Training Loss: 0.0403\n",
      "Epoch [135/250], Validation Loss: 0.1401\n",
      "Accuracy: 0.9443, Precision: 0.9752, Recall: 0.9124, F1: 0.9427\n",
      "Epoch [136/250], Training Loss: 0.0398\n",
      "Epoch [136/250], Validation Loss: 0.1400\n",
      "Accuracy: 0.9456, Precision: 0.9779, Recall: 0.9124, F1: 0.9440\n",
      "Epoch [137/250], Training Loss: 0.0393\n",
      "Epoch [137/250], Validation Loss: 0.1397\n",
      "Accuracy: 0.9456, Precision: 0.9779, Recall: 0.9124, F1: 0.9440\n",
      "Epoch [138/250], Training Loss: 0.0389\n",
      "Epoch [138/250], Validation Loss: 0.1395\n",
      "Accuracy: 0.9456, Precision: 0.9779, Recall: 0.9124, F1: 0.9440\n",
      "Epoch [139/250], Training Loss: 0.0386\n",
      "Epoch [139/250], Validation Loss: 0.1393\n",
      "Accuracy: 0.9456, Precision: 0.9779, Recall: 0.9124, F1: 0.9440\n",
      "Epoch [140/250], Training Loss: 0.0383\n",
      "Epoch [140/250], Validation Loss: 0.1391\n",
      "Accuracy: 0.9456, Precision: 0.9779, Recall: 0.9124, F1: 0.9440\n",
      "Epoch [141/250], Training Loss: 0.0377\n",
      "Epoch [141/250], Validation Loss: 0.1388\n",
      "Accuracy: 0.9456, Precision: 0.9779, Recall: 0.9124, F1: 0.9440\n",
      "Epoch [142/250], Training Loss: 0.0377\n",
      "Epoch [142/250], Validation Loss: 0.1386\n",
      "Accuracy: 0.9443, Precision: 0.9778, Recall: 0.9098, F1: 0.9426\n",
      "Epoch [143/250], Training Loss: 0.0372\n",
      "Epoch [143/250], Validation Loss: 0.1385\n",
      "Accuracy: 0.9443, Precision: 0.9778, Recall: 0.9098, F1: 0.9426\n",
      "Epoch [144/250], Training Loss: 0.0370\n",
      "Epoch [144/250], Validation Loss: 0.1382\n",
      "Accuracy: 0.9443, Precision: 0.9778, Recall: 0.9098, F1: 0.9426\n",
      "Epoch [145/250], Training Loss: 0.0367\n",
      "Epoch [145/250], Validation Loss: 0.1380\n",
      "Accuracy: 0.9456, Precision: 0.9806, Recall: 0.9098, F1: 0.9439\n",
      "Epoch [146/250], Training Loss: 0.0362\n",
      "Epoch [146/250], Validation Loss: 0.1378\n",
      "Accuracy: 0.9456, Precision: 0.9806, Recall: 0.9098, F1: 0.9439\n",
      "Epoch [147/250], Training Loss: 0.0363\n",
      "Epoch [147/250], Validation Loss: 0.1376\n",
      "Accuracy: 0.9456, Precision: 0.9806, Recall: 0.9098, F1: 0.9439\n",
      "Epoch [148/250], Training Loss: 0.0360\n",
      "Epoch [148/250], Validation Loss: 0.1374\n",
      "Accuracy: 0.9443, Precision: 0.9778, Recall: 0.9098, F1: 0.9426\n",
      "Epoch [149/250], Training Loss: 0.0355\n",
      "Epoch [149/250], Validation Loss: 0.1371\n",
      "Accuracy: 0.9443, Precision: 0.9778, Recall: 0.9098, F1: 0.9426\n",
      "Epoch [150/250], Training Loss: 0.0355\n",
      "Epoch [150/250], Validation Loss: 0.1370\n",
      "Accuracy: 0.9443, Precision: 0.9778, Recall: 0.9098, F1: 0.9426\n",
      "Epoch [151/250], Training Loss: 0.0352\n",
      "Epoch [151/250], Validation Loss: 0.1368\n",
      "Accuracy: 0.9443, Precision: 0.9778, Recall: 0.9098, F1: 0.9426\n",
      "Epoch [152/250], Training Loss: 0.0351\n",
      "Epoch [152/250], Validation Loss: 0.1366\n",
      "Accuracy: 0.9443, Precision: 0.9778, Recall: 0.9098, F1: 0.9426\n",
      "Epoch [153/250], Training Loss: 0.0348\n",
      "Epoch [153/250], Validation Loss: 0.1364\n",
      "Accuracy: 0.9443, Precision: 0.9778, Recall: 0.9098, F1: 0.9426\n",
      "Epoch [154/250], Training Loss: 0.0345\n",
      "Epoch [154/250], Validation Loss: 0.1362\n",
      "Accuracy: 0.9456, Precision: 0.9806, Recall: 0.9098, F1: 0.9439\n",
      "Epoch [155/250], Training Loss: 0.0343\n",
      "Epoch [155/250], Validation Loss: 0.1361\n",
      "Accuracy: 0.9456, Precision: 0.9806, Recall: 0.9098, F1: 0.9439\n",
      "Epoch [156/250], Training Loss: 0.0340\n",
      "Epoch [156/250], Validation Loss: 0.1359\n",
      "Accuracy: 0.9469, Precision: 0.9806, Recall: 0.9124, F1: 0.9453\n",
      "Epoch [157/250], Training Loss: 0.0339\n",
      "Epoch [157/250], Validation Loss: 0.1359\n",
      "Accuracy: 0.9469, Precision: 0.9806, Recall: 0.9124, F1: 0.9453\n",
      "Epoch [158/250], Training Loss: 0.0336\n",
      "Epoch [158/250], Validation Loss: 0.1356\n",
      "Accuracy: 0.9469, Precision: 0.9806, Recall: 0.9124, F1: 0.9453\n",
      "Epoch [159/250], Training Loss: 0.0332\n",
      "Epoch [159/250], Validation Loss: 0.1356\n",
      "Accuracy: 0.9469, Precision: 0.9806, Recall: 0.9124, F1: 0.9453\n",
      "Epoch [160/250], Training Loss: 0.0330\n",
      "Epoch [160/250], Validation Loss: 0.1354\n",
      "Accuracy: 0.9469, Precision: 0.9806, Recall: 0.9124, F1: 0.9453\n",
      "Epoch [161/250], Training Loss: 0.0330\n",
      "Epoch [161/250], Validation Loss: 0.1353\n",
      "Accuracy: 0.9469, Precision: 0.9806, Recall: 0.9124, F1: 0.9453\n",
      "Epoch [162/250], Training Loss: 0.0329\n",
      "Epoch [162/250], Validation Loss: 0.1352\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [163/250], Training Loss: 0.0327\n",
      "Epoch [163/250], Validation Loss: 0.1351\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [164/250], Training Loss: 0.0323\n",
      "Epoch [164/250], Validation Loss: 0.1350\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [165/250], Training Loss: 0.0319\n",
      "Epoch [165/250], Validation Loss: 0.1349\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [166/250], Training Loss: 0.0317\n",
      "Epoch [166/250], Validation Loss: 0.1347\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [167/250], Training Loss: 0.0317\n",
      "Epoch [167/250], Validation Loss: 0.1346\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [168/250], Training Loss: 0.0313\n",
      "Epoch [168/250], Validation Loss: 0.1345\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [169/250], Training Loss: 0.0310\n",
      "Epoch [169/250], Validation Loss: 0.1344\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [170/250], Training Loss: 0.0309\n",
      "Epoch [170/250], Validation Loss: 0.1343\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [171/250], Training Loss: 0.0306\n",
      "Epoch [171/250], Validation Loss: 0.1342\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [172/250], Training Loss: 0.0303\n",
      "Epoch [172/250], Validation Loss: 0.1341\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [173/250], Training Loss: 0.0301\n",
      "Epoch [173/250], Validation Loss: 0.1340\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [174/250], Training Loss: 0.0299\n",
      "Epoch [174/250], Validation Loss: 0.1341\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [175/250], Training Loss: 0.0293\n",
      "Epoch [175/250], Validation Loss: 0.1339\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [176/250], Training Loss: 0.0293\n",
      "Epoch [176/250], Validation Loss: 0.1338\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [177/250], Training Loss: 0.0289\n",
      "Epoch [177/250], Validation Loss: 0.1338\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [178/250], Training Loss: 0.0289\n",
      "Epoch [178/250], Validation Loss: 0.1337\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [179/250], Training Loss: 0.0286\n",
      "Epoch [179/250], Validation Loss: 0.1337\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [180/250], Training Loss: 0.0284\n",
      "Epoch [180/250], Validation Loss: 0.1336\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [181/250], Training Loss: 0.0282\n",
      "Epoch [181/250], Validation Loss: 0.1335\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [182/250], Training Loss: 0.0280\n",
      "Epoch [182/250], Validation Loss: 0.1334\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [183/250], Training Loss: 0.0274\n",
      "Epoch [183/250], Validation Loss: 0.1334\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [184/250], Training Loss: 0.0275\n",
      "Epoch [184/250], Validation Loss: 0.1333\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [185/250], Training Loss: 0.0274\n",
      "Epoch [185/250], Validation Loss: 0.1333\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [186/250], Training Loss: 0.0269\n",
      "Epoch [186/250], Validation Loss: 0.1331\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [187/250], Training Loss: 0.0271\n",
      "Epoch [187/250], Validation Loss: 0.1332\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [188/250], Training Loss: 0.0266\n",
      "Epoch [188/250], Validation Loss: 0.1331\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [189/250], Training Loss: 0.0263\n",
      "Epoch [189/250], Validation Loss: 0.1330\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [190/250], Training Loss: 0.0262\n",
      "Epoch [190/250], Validation Loss: 0.1329\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [191/250], Training Loss: 0.0260\n",
      "Epoch [191/250], Validation Loss: 0.1329\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [192/250], Training Loss: 0.0258\n",
      "Epoch [192/250], Validation Loss: 0.1328\n",
      "Accuracy: 0.9482, Precision: 0.9780, Recall: 0.9175, F1: 0.9468\n",
      "Epoch [193/250], Training Loss: 0.0256\n",
      "Epoch [193/250], Validation Loss: 0.1327\n",
      "Accuracy: 0.9482, Precision: 0.9780, Recall: 0.9175, F1: 0.9468\n",
      "Epoch [194/250], Training Loss: 0.0253\n",
      "Epoch [194/250], Validation Loss: 0.1327\n",
      "Accuracy: 0.9482, Precision: 0.9780, Recall: 0.9175, F1: 0.9468\n",
      "Epoch [195/250], Training Loss: 0.0253\n",
      "Epoch [195/250], Validation Loss: 0.1327\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [196/250], Training Loss: 0.0249\n",
      "Epoch [196/250], Validation Loss: 0.1325\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [197/250], Training Loss: 0.0248\n",
      "Epoch [197/250], Validation Loss: 0.1325\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [198/250], Training Loss: 0.0247\n",
      "Epoch [198/250], Validation Loss: 0.1325\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [199/250], Training Loss: 0.0244\n",
      "Epoch [199/250], Validation Loss: 0.1324\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [200/250], Training Loss: 0.0241\n",
      "Epoch [200/250], Validation Loss: 0.1324\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [201/250], Training Loss: 0.0243\n",
      "Epoch [201/250], Validation Loss: 0.1324\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [202/250], Training Loss: 0.0241\n",
      "Epoch [202/250], Validation Loss: 0.1323\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [203/250], Training Loss: 0.0239\n",
      "Epoch [203/250], Validation Loss: 0.1323\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [204/250], Training Loss: 0.0237\n",
      "Epoch [204/250], Validation Loss: 0.1322\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [205/250], Training Loss: 0.0234\n",
      "Epoch [205/250], Validation Loss: 0.1323\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [206/250], Training Loss: 0.0234\n",
      "Epoch [206/250], Validation Loss: 0.1322\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [207/250], Training Loss: 0.0231\n",
      "Epoch [207/250], Validation Loss: 0.1322\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [208/250], Training Loss: 0.0227\n",
      "Epoch [208/250], Validation Loss: 0.1321\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [209/250], Training Loss: 0.0228\n",
      "Epoch [209/250], Validation Loss: 0.1322\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [210/250], Training Loss: 0.0224\n",
      "Epoch [210/250], Validation Loss: 0.1320\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [211/250], Training Loss: 0.0222\n",
      "Epoch [211/250], Validation Loss: 0.1320\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [212/250], Training Loss: 0.0222\n",
      "Epoch [212/250], Validation Loss: 0.1320\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [213/250], Training Loss: 0.0217\n",
      "Epoch [213/250], Validation Loss: 0.1319\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [214/250], Training Loss: 0.0219\n",
      "Epoch [214/250], Validation Loss: 0.1322\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [215/250], Training Loss: 0.0217\n",
      "Epoch [215/250], Validation Loss: 0.1322\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [216/250], Training Loss: 0.0214\n",
      "Epoch [216/250], Validation Loss: 0.1321\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [217/250], Training Loss: 0.0212\n",
      "Epoch [217/250], Validation Loss: 0.1320\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [218/250], Training Loss: 0.0210\n",
      "Epoch [218/250], Validation Loss: 0.1320\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [219/250], Training Loss: 0.0208\n",
      "Epoch [219/250], Validation Loss: 0.1321\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [220/250], Training Loss: 0.0206\n",
      "Epoch [220/250], Validation Loss: 0.1319\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [221/250], Training Loss: 0.0206\n",
      "Epoch [221/250], Validation Loss: 0.1320\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [222/250], Training Loss: 0.0204\n",
      "Epoch [222/250], Validation Loss: 0.1319\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [223/250], Training Loss: 0.0203\n",
      "Epoch [223/250], Validation Loss: 0.1319\n",
      "Early stopping!!! 222\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainData = pd.read_csv('./csv/cure_the_princess_train.csv')\n",
    "validData = pd.read_csv('./csv/cure_the_princess_validation.csv')\n",
    "testData =  pd.read_csv('./csv/cure_the_princess_test.csv')\n",
    "\n",
    "\n",
    "trainX = trainData.drop(columns=['Cured']).values\n",
    "trainY = trainData['Cured'].values\n",
    "validX = validData.drop(columns=['Cured']).values\n",
    "validY = validData['Cured'].values\n",
    "testX = testData.drop(columns=['Cured']).values\n",
    "testY = testData['Cured'].values\n",
    "\n",
    "\n",
    "numInputFeatures = trainX.shape[1]\n",
    "\n",
    "torch.manual_seed(190401070)\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, numInputFeatures):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(numInputFeatures, 100) \n",
    "        self.relu1 = nn.ReLU() \n",
    "        self.fc2 = nn.Linear(100, 50) \n",
    "        self.relu2 = nn.ReLU() \n",
    "        self.fc3 = nn.Linear(50, 1) \n",
    "        self.sigmoid = nn.Sigmoid() \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MLP(numInputFeatures=numInputFeatures)\n",
    "\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0006)\n",
    "\n",
    "\n",
    "numEpochs = 250\n",
    "batchSize = 16\n",
    "trainLosses = []\n",
    "validLosses = []\n",
    "bestValidLoss = None\n",
    "patience = 10\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(numEpochs):\n",
    "    for i in range(0, len(trainX), batchSize):\n",
    "        \n",
    "        batchX = torch.tensor(trainX[i:i+batchSize], dtype=torch.float32)\n",
    "        batchY = torch.tensor(trainY[i:i+batchSize], dtype=torch.float32).view(-1, 1)\n",
    "        \n",
    "        \n",
    "        outputs = model(batchX)\n",
    "        loss = criterion(outputs, batchY)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    \n",
    "    trainLosses.append(loss.item())\n",
    "    print('Epoch [%d/%d], Training Loss: %.4f' % (epoch+1, numEpochs, loss.item()))\n",
    "    \n",
    "   \n",
    "    validLoss = criterion(model(torch.tensor(validX, dtype=torch.float32)), torch.tensor(validY, dtype=torch.float32).view(-1, 1)).item()\n",
    "    validLosses.append(validLoss)\n",
    "    print('Epoch [%d/%d], Validation Loss: %.4f' % (epoch+1, numEpochs, validLoss))\n",
    "\n",
    "    if bestValidLoss is None or  validLoss < bestValidLoss:\n",
    "        bestValidLoss = validLoss\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping!!!\", epoch)\n",
    "            break\n",
    "\n",
    "    with torch.no_grad():\n",
    "        testOutputs = model(torch.tensor(testX, dtype=torch.float32))\n",
    "        testPredictions = (testOutputs > 0.5).float().view(-1)\n",
    "\n",
    "        \n",
    "        accuracy = (testPredictions == torch.tensor(testY, dtype=torch.float32)).float().mean().item()\n",
    "        precision = (testPredictions[testPredictions == 1] == torch.tensor(testY[testPredictions == 1], dtype=torch.float32)).float().mean().item()\n",
    "        recall = (testPredictions[testY == 1] == torch.tensor(testY[testY == 1], dtype=torch.float32)).float().mean().item()\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "        print('Accuracy: %.4f, Precision: %.4f, Recall: %.4f, F1: %.4f' % (accuracy, precision, recall, f1))\n",
    "\n",
    "   \n",
    "\n",
    "plt.plot(trainLosses, label='Training Loss')\n",
    "plt.plot(validLosses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Training Loss: 0.3834\n",
      "Epoch [1/250], Validation Loss: 0.6119\n",
      "Accuracy: 0.6749, Precision: 0.6367, Recall: 0.8222, F1: 0.7177\n",
      "Epoch [2/250], Training Loss: 0.3208\n",
      "Epoch [2/250], Validation Loss: 0.5595\n",
      "Accuracy: 0.7176, Precision: 0.6687, Recall: 0.8686, F1: 0.7556\n",
      "Epoch [3/250], Training Loss: 0.2847\n",
      "Epoch [3/250], Validation Loss: 0.5220\n",
      "Accuracy: 0.7513, Precision: 0.6984, Recall: 0.8892, F1: 0.7823\n",
      "Epoch [4/250], Training Loss: 0.2607\n",
      "Epoch [4/250], Validation Loss: 0.4919\n",
      "Accuracy: 0.7707, Precision: 0.7149, Recall: 0.9046, F1: 0.7986\n",
      "Epoch [5/250], Training Loss: 0.2442\n",
      "Epoch [5/250], Validation Loss: 0.4672\n",
      "Accuracy: 0.7902, Precision: 0.7325, Recall: 0.9175, F1: 0.8146\n",
      "Epoch [6/250], Training Loss: 0.2311\n",
      "Epoch [6/250], Validation Loss: 0.4453\n",
      "Accuracy: 0.8018, Precision: 0.7443, Recall: 0.9227, F1: 0.8239\n",
      "Epoch [7/250], Training Loss: 0.2197\n",
      "Epoch [7/250], Validation Loss: 0.4263\n",
      "Accuracy: 0.8187, Precision: 0.7616, Recall: 0.9304, F1: 0.8376\n",
      "Epoch [8/250], Training Loss: 0.2104\n",
      "Epoch [8/250], Validation Loss: 0.4090\n",
      "Accuracy: 0.8277, Precision: 0.7730, Recall: 0.9304, F1: 0.8444\n",
      "Epoch [9/250], Training Loss: 0.2021\n",
      "Epoch [9/250], Validation Loss: 0.3934\n",
      "Accuracy: 0.8381, Precision: 0.7840, Recall: 0.9356, F1: 0.8531\n",
      "Epoch [10/250], Training Loss: 0.1945\n",
      "Epoch [10/250], Validation Loss: 0.3793\n",
      "Accuracy: 0.8433, Precision: 0.7896, Recall: 0.9381, F1: 0.8575\n",
      "Epoch [11/250], Training Loss: 0.1879\n",
      "Epoch [11/250], Validation Loss: 0.3664\n",
      "Accuracy: 0.8484, Precision: 0.7978, Recall: 0.9356, F1: 0.8612\n",
      "Epoch [12/250], Training Loss: 0.1825\n",
      "Epoch [12/250], Validation Loss: 0.3545\n",
      "Accuracy: 0.8484, Precision: 0.7991, Recall: 0.9330, F1: 0.8609\n",
      "Epoch [13/250], Training Loss: 0.1769\n",
      "Epoch [13/250], Validation Loss: 0.3437\n",
      "Accuracy: 0.8549, Precision: 0.8053, Recall: 0.9381, F1: 0.8667\n",
      "Epoch [14/250], Training Loss: 0.1718\n",
      "Epoch [14/250], Validation Loss: 0.3338\n",
      "Accuracy: 0.8549, Precision: 0.8040, Recall: 0.9407, F1: 0.8670\n",
      "Epoch [15/250], Training Loss: 0.1667\n",
      "Epoch [15/250], Validation Loss: 0.3246\n",
      "Accuracy: 0.8549, Precision: 0.8067, Recall: 0.9356, F1: 0.8663\n",
      "Epoch [16/250], Training Loss: 0.1622\n",
      "Epoch [16/250], Validation Loss: 0.3161\n",
      "Accuracy: 0.8562, Precision: 0.8098, Recall: 0.9330, F1: 0.8671\n",
      "Epoch [17/250], Training Loss: 0.1574\n",
      "Epoch [17/250], Validation Loss: 0.3082\n",
      "Accuracy: 0.8588, Precision: 0.8149, Recall: 0.9304, F1: 0.8688\n",
      "Epoch [18/250], Training Loss: 0.1530\n",
      "Epoch [18/250], Validation Loss: 0.3010\n",
      "Accuracy: 0.8627, Precision: 0.8190, Recall: 0.9330, F1: 0.8723\n",
      "Epoch [19/250], Training Loss: 0.1485\n",
      "Epoch [19/250], Validation Loss: 0.2943\n",
      "Accuracy: 0.8666, Precision: 0.8261, Recall: 0.9304, F1: 0.8752\n",
      "Epoch [20/250], Training Loss: 0.1441\n",
      "Epoch [20/250], Validation Loss: 0.2881\n",
      "Accuracy: 0.8692, Precision: 0.8299, Recall: 0.9304, F1: 0.8773\n",
      "Epoch [21/250], Training Loss: 0.1397\n",
      "Epoch [21/250], Validation Loss: 0.2823\n",
      "Accuracy: 0.8731, Precision: 0.8341, Recall: 0.9330, F1: 0.8808\n",
      "Epoch [22/250], Training Loss: 0.1356\n",
      "Epoch [22/250], Validation Loss: 0.2769\n",
      "Accuracy: 0.8744, Precision: 0.8360, Recall: 0.9330, F1: 0.8819\n",
      "Epoch [23/250], Training Loss: 0.1326\n",
      "Epoch [23/250], Validation Loss: 0.2717\n",
      "Accuracy: 0.8821, Precision: 0.8462, Recall: 0.9356, F1: 0.8886\n",
      "Epoch [24/250], Training Loss: 0.1297\n",
      "Epoch [24/250], Validation Loss: 0.2670\n",
      "Accuracy: 0.8821, Precision: 0.8478, Recall: 0.9330, F1: 0.8883\n",
      "Epoch [25/250], Training Loss: 0.1262\n",
      "Epoch [25/250], Validation Loss: 0.2628\n",
      "Accuracy: 0.8860, Precision: 0.8555, Recall: 0.9304, F1: 0.8914\n",
      "Epoch [26/250], Training Loss: 0.1229\n",
      "Epoch [26/250], Validation Loss: 0.2586\n",
      "Accuracy: 0.8860, Precision: 0.8571, Recall: 0.9278, F1: 0.8911\n",
      "Epoch [27/250], Training Loss: 0.1205\n",
      "Epoch [27/250], Validation Loss: 0.2546\n",
      "Accuracy: 0.8834, Precision: 0.8565, Recall: 0.9227, F1: 0.8883\n",
      "Epoch [28/250], Training Loss: 0.1180\n",
      "Epoch [28/250], Validation Loss: 0.2508\n",
      "Accuracy: 0.8834, Precision: 0.8565, Recall: 0.9227, F1: 0.8883\n",
      "Epoch [29/250], Training Loss: 0.1155\n",
      "Epoch [29/250], Validation Loss: 0.2472\n",
      "Accuracy: 0.8847, Precision: 0.8585, Recall: 0.9227, F1: 0.8894\n",
      "Epoch [30/250], Training Loss: 0.1129\n",
      "Epoch [30/250], Validation Loss: 0.2437\n",
      "Accuracy: 0.8847, Precision: 0.8585, Recall: 0.9227, F1: 0.8894\n",
      "Epoch [31/250], Training Loss: 0.1108\n",
      "Epoch [31/250], Validation Loss: 0.2404\n",
      "Accuracy: 0.8873, Precision: 0.8627, Recall: 0.9227, F1: 0.8917\n",
      "Epoch [32/250], Training Loss: 0.1090\n",
      "Epoch [32/250], Validation Loss: 0.2375\n",
      "Accuracy: 0.8873, Precision: 0.8627, Recall: 0.9227, F1: 0.8917\n",
      "Epoch [33/250], Training Loss: 0.1072\n",
      "Epoch [33/250], Validation Loss: 0.2347\n",
      "Accuracy: 0.8886, Precision: 0.8647, Recall: 0.9227, F1: 0.8928\n",
      "Epoch [34/250], Training Loss: 0.1054\n",
      "Epoch [34/250], Validation Loss: 0.2319\n",
      "Accuracy: 0.8899, Precision: 0.8668, Recall: 0.9227, F1: 0.8939\n",
      "Epoch [35/250], Training Loss: 0.1038\n",
      "Epoch [35/250], Validation Loss: 0.2293\n",
      "Accuracy: 0.8899, Precision: 0.8668, Recall: 0.9227, F1: 0.8939\n",
      "Epoch [36/250], Training Loss: 0.1020\n",
      "Epoch [36/250], Validation Loss: 0.2268\n",
      "Accuracy: 0.8899, Precision: 0.8668, Recall: 0.9227, F1: 0.8939\n",
      "Epoch [37/250], Training Loss: 0.1005\n",
      "Epoch [37/250], Validation Loss: 0.2244\n",
      "Accuracy: 0.8899, Precision: 0.8668, Recall: 0.9227, F1: 0.8939\n",
      "Epoch [38/250], Training Loss: 0.0991\n",
      "Epoch [38/250], Validation Loss: 0.2221\n",
      "Accuracy: 0.8951, Precision: 0.8735, Recall: 0.9253, F1: 0.8986\n",
      "Epoch [39/250], Training Loss: 0.0977\n",
      "Epoch [39/250], Validation Loss: 0.2199\n",
      "Accuracy: 0.8951, Precision: 0.8735, Recall: 0.9253, F1: 0.8986\n",
      "Epoch [40/250], Training Loss: 0.0962\n",
      "Epoch [40/250], Validation Loss: 0.2179\n",
      "Accuracy: 0.8951, Precision: 0.8735, Recall: 0.9253, F1: 0.8986\n",
      "Epoch [41/250], Training Loss: 0.0947\n",
      "Epoch [41/250], Validation Loss: 0.2159\n",
      "Accuracy: 0.8951, Precision: 0.8753, Recall: 0.9227, F1: 0.8984\n",
      "Epoch [42/250], Training Loss: 0.0932\n",
      "Epoch [42/250], Validation Loss: 0.2137\n",
      "Accuracy: 0.8964, Precision: 0.8775, Recall: 0.9227, F1: 0.8995\n",
      "Epoch [43/250], Training Loss: 0.0914\n",
      "Epoch [43/250], Validation Loss: 0.2118\n",
      "Accuracy: 0.8977, Precision: 0.8796, Recall: 0.9227, F1: 0.9006\n",
      "Epoch [44/250], Training Loss: 0.0897\n",
      "Epoch [44/250], Validation Loss: 0.2099\n",
      "Accuracy: 0.9003, Precision: 0.8840, Recall: 0.9227, F1: 0.9029\n",
      "Epoch [45/250], Training Loss: 0.0882\n",
      "Epoch [45/250], Validation Loss: 0.2080\n",
      "Accuracy: 0.9028, Precision: 0.8883, Recall: 0.9227, F1: 0.9052\n",
      "Epoch [46/250], Training Loss: 0.0865\n",
      "Epoch [46/250], Validation Loss: 0.2062\n",
      "Accuracy: 0.9028, Precision: 0.8883, Recall: 0.9227, F1: 0.9052\n",
      "Epoch [47/250], Training Loss: 0.0851\n",
      "Epoch [47/250], Validation Loss: 0.2046\n",
      "Accuracy: 0.9054, Precision: 0.8928, Recall: 0.9227, F1: 0.9075\n",
      "Epoch [48/250], Training Loss: 0.0839\n",
      "Epoch [48/250], Validation Loss: 0.2032\n",
      "Accuracy: 0.9054, Precision: 0.8928, Recall: 0.9227, F1: 0.9075\n",
      "Epoch [49/250], Training Loss: 0.0825\n",
      "Epoch [49/250], Validation Loss: 0.2016\n",
      "Accuracy: 0.9041, Precision: 0.8925, Recall: 0.9201, F1: 0.9061\n",
      "Epoch [50/250], Training Loss: 0.0809\n",
      "Epoch [50/250], Validation Loss: 0.2002\n",
      "Accuracy: 0.9041, Precision: 0.8925, Recall: 0.9201, F1: 0.9061\n",
      "Epoch [51/250], Training Loss: 0.0793\n",
      "Epoch [51/250], Validation Loss: 0.1986\n",
      "Accuracy: 0.9054, Precision: 0.8947, Recall: 0.9201, F1: 0.9072\n",
      "Epoch [52/250], Training Loss: 0.0775\n",
      "Epoch [52/250], Validation Loss: 0.1970\n",
      "Accuracy: 0.9054, Precision: 0.8947, Recall: 0.9201, F1: 0.9072\n",
      "Epoch [53/250], Training Loss: 0.0762\n",
      "Epoch [53/250], Validation Loss: 0.1956\n",
      "Accuracy: 0.9106, Precision: 0.9038, Recall: 0.9201, F1: 0.9119\n",
      "Epoch [54/250], Training Loss: 0.0753\n",
      "Epoch [54/250], Validation Loss: 0.1941\n",
      "Accuracy: 0.9119, Precision: 0.9061, Recall: 0.9201, F1: 0.9130\n",
      "Epoch [55/250], Training Loss: 0.0744\n",
      "Epoch [55/250], Validation Loss: 0.1928\n",
      "Accuracy: 0.9145, Precision: 0.9107, Recall: 0.9201, F1: 0.9154\n",
      "Epoch [56/250], Training Loss: 0.0733\n",
      "Epoch [56/250], Validation Loss: 0.1914\n",
      "Accuracy: 0.9210, Precision: 0.9203, Recall: 0.9227, F1: 0.9215\n",
      "Epoch [57/250], Training Loss: 0.0724\n",
      "Epoch [57/250], Validation Loss: 0.1901\n",
      "Accuracy: 0.9223, Precision: 0.9205, Recall: 0.9253, F1: 0.9229\n",
      "Epoch [58/250], Training Loss: 0.0715\n",
      "Epoch [58/250], Validation Loss: 0.1888\n",
      "Accuracy: 0.9249, Precision: 0.9253, Recall: 0.9253, F1: 0.9253\n",
      "Epoch [59/250], Training Loss: 0.0706\n",
      "Epoch [59/250], Validation Loss: 0.1876\n",
      "Accuracy: 0.9249, Precision: 0.9253, Recall: 0.9253, F1: 0.9253\n",
      "Epoch [60/250], Training Loss: 0.0698\n",
      "Epoch [60/250], Validation Loss: 0.1864\n",
      "Accuracy: 0.9262, Precision: 0.9254, Recall: 0.9278, F1: 0.9266\n",
      "Epoch [61/250], Training Loss: 0.0688\n",
      "Epoch [61/250], Validation Loss: 0.1852\n",
      "Accuracy: 0.9262, Precision: 0.9254, Recall: 0.9278, F1: 0.9266\n",
      "Epoch [62/250], Training Loss: 0.0680\n",
      "Epoch [62/250], Validation Loss: 0.1841\n",
      "Accuracy: 0.9262, Precision: 0.9276, Recall: 0.9253, F1: 0.9265\n",
      "Epoch [63/250], Training Loss: 0.0673\n",
      "Epoch [63/250], Validation Loss: 0.1830\n",
      "Accuracy: 0.9275, Precision: 0.9278, Recall: 0.9278, F1: 0.9278\n",
      "Epoch [64/250], Training Loss: 0.0666\n",
      "Epoch [64/250], Validation Loss: 0.1819\n",
      "Accuracy: 0.9275, Precision: 0.9278, Recall: 0.9278, F1: 0.9278\n",
      "Epoch [65/250], Training Loss: 0.0658\n",
      "Epoch [65/250], Validation Loss: 0.1809\n",
      "Accuracy: 0.9262, Precision: 0.9276, Recall: 0.9253, F1: 0.9265\n",
      "Epoch [66/250], Training Loss: 0.0650\n",
      "Epoch [66/250], Validation Loss: 0.1799\n",
      "Accuracy: 0.9275, Precision: 0.9301, Recall: 0.9253, F1: 0.9276\n",
      "Epoch [67/250], Training Loss: 0.0643\n",
      "Epoch [67/250], Validation Loss: 0.1788\n",
      "Accuracy: 0.9275, Precision: 0.9323, Recall: 0.9227, F1: 0.9275\n",
      "Epoch [68/250], Training Loss: 0.0638\n",
      "Epoch [68/250], Validation Loss: 0.1778\n",
      "Accuracy: 0.9275, Precision: 0.9323, Recall: 0.9227, F1: 0.9275\n",
      "Epoch [69/250], Training Loss: 0.0633\n",
      "Epoch [69/250], Validation Loss: 0.1768\n",
      "Accuracy: 0.9262, Precision: 0.9321, Recall: 0.9201, F1: 0.9261\n",
      "Epoch [70/250], Training Loss: 0.0632\n",
      "Epoch [70/250], Validation Loss: 0.1760\n",
      "Accuracy: 0.9262, Precision: 0.9321, Recall: 0.9201, F1: 0.9261\n",
      "Epoch [71/250], Training Loss: 0.0627\n",
      "Epoch [71/250], Validation Loss: 0.1750\n",
      "Accuracy: 0.9262, Precision: 0.9321, Recall: 0.9201, F1: 0.9261\n",
      "Epoch [72/250], Training Loss: 0.0619\n",
      "Epoch [72/250], Validation Loss: 0.1740\n",
      "Accuracy: 0.9262, Precision: 0.9321, Recall: 0.9201, F1: 0.9261\n",
      "Epoch [73/250], Training Loss: 0.0616\n",
      "Epoch [73/250], Validation Loss: 0.1731\n",
      "Accuracy: 0.9275, Precision: 0.9346, Recall: 0.9201, F1: 0.9273\n",
      "Epoch [74/250], Training Loss: 0.0610\n",
      "Epoch [74/250], Validation Loss: 0.1722\n",
      "Accuracy: 0.9275, Precision: 0.9346, Recall: 0.9201, F1: 0.9273\n",
      "Epoch [75/250], Training Loss: 0.0606\n",
      "Epoch [75/250], Validation Loss: 0.1713\n",
      "Accuracy: 0.9275, Precision: 0.9346, Recall: 0.9201, F1: 0.9273\n",
      "Epoch [76/250], Training Loss: 0.0600\n",
      "Epoch [76/250], Validation Loss: 0.1705\n",
      "Accuracy: 0.9288, Precision: 0.9347, Recall: 0.9227, F1: 0.9287\n",
      "Epoch [77/250], Training Loss: 0.0598\n",
      "Epoch [77/250], Validation Loss: 0.1697\n",
      "Accuracy: 0.9288, Precision: 0.9347, Recall: 0.9227, F1: 0.9287\n",
      "Epoch [78/250], Training Loss: 0.0593\n",
      "Epoch [78/250], Validation Loss: 0.1688\n",
      "Accuracy: 0.9288, Precision: 0.9347, Recall: 0.9227, F1: 0.9287\n",
      "Epoch [79/250], Training Loss: 0.0589\n",
      "Epoch [79/250], Validation Loss: 0.1680\n",
      "Accuracy: 0.9288, Precision: 0.9347, Recall: 0.9227, F1: 0.9287\n",
      "Epoch [80/250], Training Loss: 0.0584\n",
      "Epoch [80/250], Validation Loss: 0.1672\n",
      "Accuracy: 0.9301, Precision: 0.9372, Recall: 0.9227, F1: 0.9299\n",
      "Epoch [81/250], Training Loss: 0.0579\n",
      "Epoch [81/250], Validation Loss: 0.1665\n",
      "Accuracy: 0.9301, Precision: 0.9372, Recall: 0.9227, F1: 0.9299\n",
      "Epoch [82/250], Training Loss: 0.0575\n",
      "Epoch [82/250], Validation Loss: 0.1657\n",
      "Accuracy: 0.9301, Precision: 0.9372, Recall: 0.9227, F1: 0.9299\n",
      "Epoch [83/250], Training Loss: 0.0570\n",
      "Epoch [83/250], Validation Loss: 0.1649\n",
      "Accuracy: 0.9313, Precision: 0.9396, Recall: 0.9227, F1: 0.9311\n",
      "Epoch [84/250], Training Loss: 0.0571\n",
      "Epoch [84/250], Validation Loss: 0.1642\n",
      "Accuracy: 0.9326, Precision: 0.9421, Recall: 0.9227, F1: 0.9323\n",
      "Epoch [85/250], Training Loss: 0.0566\n",
      "Epoch [85/250], Validation Loss: 0.1635\n",
      "Accuracy: 0.9339, Precision: 0.9446, Recall: 0.9227, F1: 0.9335\n",
      "Epoch [86/250], Training Loss: 0.0562\n",
      "Epoch [86/250], Validation Loss: 0.1627\n",
      "Accuracy: 0.9339, Precision: 0.9446, Recall: 0.9227, F1: 0.9335\n",
      "Epoch [87/250], Training Loss: 0.0558\n",
      "Epoch [87/250], Validation Loss: 0.1621\n",
      "Accuracy: 0.9339, Precision: 0.9446, Recall: 0.9227, F1: 0.9335\n",
      "Epoch [88/250], Training Loss: 0.0554\n",
      "Epoch [88/250], Validation Loss: 0.1614\n",
      "Accuracy: 0.9352, Precision: 0.9447, Recall: 0.9253, F1: 0.9349\n",
      "Epoch [89/250], Training Loss: 0.0550\n",
      "Epoch [89/250], Validation Loss: 0.1607\n",
      "Accuracy: 0.9365, Precision: 0.9472, Recall: 0.9253, F1: 0.9361\n",
      "Epoch [90/250], Training Loss: 0.0544\n",
      "Epoch [90/250], Validation Loss: 0.1600\n",
      "Accuracy: 0.9365, Precision: 0.9472, Recall: 0.9253, F1: 0.9361\n",
      "Epoch [91/250], Training Loss: 0.0540\n",
      "Epoch [91/250], Validation Loss: 0.1593\n",
      "Accuracy: 0.9352, Precision: 0.9471, Recall: 0.9227, F1: 0.9347\n",
      "Epoch [92/250], Training Loss: 0.0540\n",
      "Epoch [92/250], Validation Loss: 0.1587\n",
      "Accuracy: 0.9352, Precision: 0.9471, Recall: 0.9227, F1: 0.9347\n",
      "Epoch [93/250], Training Loss: 0.0537\n",
      "Epoch [93/250], Validation Loss: 0.1581\n",
      "Accuracy: 0.9365, Precision: 0.9496, Recall: 0.9227, F1: 0.9359\n",
      "Epoch [94/250], Training Loss: 0.0539\n",
      "Epoch [94/250], Validation Loss: 0.1576\n",
      "Accuracy: 0.9378, Precision: 0.9521, Recall: 0.9227, F1: 0.9372\n",
      "Epoch [95/250], Training Loss: 0.0539\n",
      "Epoch [95/250], Validation Loss: 0.1570\n",
      "Accuracy: 0.9391, Precision: 0.9547, Recall: 0.9227, F1: 0.9384\n",
      "Epoch [96/250], Training Loss: 0.0534\n",
      "Epoch [96/250], Validation Loss: 0.1564\n",
      "Accuracy: 0.9391, Precision: 0.9547, Recall: 0.9227, F1: 0.9384\n",
      "Epoch [97/250], Training Loss: 0.0533\n",
      "Epoch [97/250], Validation Loss: 0.1559\n",
      "Accuracy: 0.9391, Precision: 0.9547, Recall: 0.9227, F1: 0.9384\n",
      "Epoch [98/250], Training Loss: 0.0528\n",
      "Epoch [98/250], Validation Loss: 0.1553\n",
      "Accuracy: 0.9391, Precision: 0.9547, Recall: 0.9227, F1: 0.9384\n",
      "Epoch [99/250], Training Loss: 0.0525\n",
      "Epoch [99/250], Validation Loss: 0.1547\n",
      "Accuracy: 0.9404, Precision: 0.9548, Recall: 0.9253, F1: 0.9398\n",
      "Epoch [100/250], Training Loss: 0.0521\n",
      "Epoch [100/250], Validation Loss: 0.1541\n",
      "Accuracy: 0.9404, Precision: 0.9548, Recall: 0.9253, F1: 0.9398\n",
      "Epoch [101/250], Training Loss: 0.0519\n",
      "Epoch [101/250], Validation Loss: 0.1536\n",
      "Accuracy: 0.9404, Precision: 0.9548, Recall: 0.9253, F1: 0.9398\n",
      "Epoch [102/250], Training Loss: 0.0515\n",
      "Epoch [102/250], Validation Loss: 0.1531\n",
      "Accuracy: 0.9404, Precision: 0.9548, Recall: 0.9253, F1: 0.9398\n",
      "Epoch [103/250], Training Loss: 0.0509\n",
      "Epoch [103/250], Validation Loss: 0.1526\n",
      "Accuracy: 0.9391, Precision: 0.9547, Recall: 0.9227, F1: 0.9384\n",
      "Epoch [104/250], Training Loss: 0.0504\n",
      "Epoch [104/250], Validation Loss: 0.1519\n",
      "Accuracy: 0.9391, Precision: 0.9547, Recall: 0.9227, F1: 0.9384\n",
      "Epoch [105/250], Training Loss: 0.0501\n",
      "Epoch [105/250], Validation Loss: 0.1515\n",
      "Accuracy: 0.9404, Precision: 0.9572, Recall: 0.9227, F1: 0.9396\n",
      "Epoch [106/250], Training Loss: 0.0501\n",
      "Epoch [106/250], Validation Loss: 0.1511\n",
      "Accuracy: 0.9404, Precision: 0.9572, Recall: 0.9227, F1: 0.9396\n",
      "Epoch [107/250], Training Loss: 0.0497\n",
      "Epoch [107/250], Validation Loss: 0.1507\n",
      "Accuracy: 0.9391, Precision: 0.9571, Recall: 0.9201, F1: 0.9382\n",
      "Epoch [108/250], Training Loss: 0.0493\n",
      "Epoch [108/250], Validation Loss: 0.1501\n",
      "Accuracy: 0.9391, Precision: 0.9571, Recall: 0.9201, F1: 0.9382\n",
      "Epoch [109/250], Training Loss: 0.0490\n",
      "Epoch [109/250], Validation Loss: 0.1496\n",
      "Accuracy: 0.9391, Precision: 0.9571, Recall: 0.9201, F1: 0.9382\n",
      "Epoch [110/250], Training Loss: 0.0484\n",
      "Epoch [110/250], Validation Loss: 0.1492\n",
      "Accuracy: 0.9391, Precision: 0.9571, Recall: 0.9201, F1: 0.9382\n",
      "Epoch [111/250], Training Loss: 0.0478\n",
      "Epoch [111/250], Validation Loss: 0.1487\n",
      "Accuracy: 0.9391, Precision: 0.9571, Recall: 0.9201, F1: 0.9382\n",
      "Epoch [112/250], Training Loss: 0.0474\n",
      "Epoch [112/250], Validation Loss: 0.1484\n",
      "Accuracy: 0.9378, Precision: 0.9570, Recall: 0.9175, F1: 0.9368\n",
      "Epoch [113/250], Training Loss: 0.0465\n",
      "Epoch [113/250], Validation Loss: 0.1479\n",
      "Accuracy: 0.9391, Precision: 0.9596, Recall: 0.9175, F1: 0.9381\n",
      "Epoch [114/250], Training Loss: 0.0460\n",
      "Epoch [114/250], Validation Loss: 0.1474\n",
      "Accuracy: 0.9391, Precision: 0.9621, Recall: 0.9149, F1: 0.9379\n",
      "Epoch [115/250], Training Loss: 0.0456\n",
      "Epoch [115/250], Validation Loss: 0.1470\n",
      "Accuracy: 0.9404, Precision: 0.9647, Recall: 0.9149, F1: 0.9392\n",
      "Epoch [116/250], Training Loss: 0.0453\n",
      "Epoch [116/250], Validation Loss: 0.1466\n",
      "Accuracy: 0.9404, Precision: 0.9647, Recall: 0.9149, F1: 0.9392\n",
      "Epoch [117/250], Training Loss: 0.0450\n",
      "Epoch [117/250], Validation Loss: 0.1462\n",
      "Accuracy: 0.9404, Precision: 0.9647, Recall: 0.9149, F1: 0.9392\n",
      "Epoch [118/250], Training Loss: 0.0448\n",
      "Epoch [118/250], Validation Loss: 0.1458\n",
      "Accuracy: 0.9404, Precision: 0.9647, Recall: 0.9149, F1: 0.9392\n",
      "Epoch [119/250], Training Loss: 0.0442\n",
      "Epoch [119/250], Validation Loss: 0.1454\n",
      "Accuracy: 0.9404, Precision: 0.9647, Recall: 0.9149, F1: 0.9392\n",
      "Epoch [120/250], Training Loss: 0.0439\n",
      "Epoch [120/250], Validation Loss: 0.1450\n",
      "Accuracy: 0.9404, Precision: 0.9647, Recall: 0.9149, F1: 0.9392\n",
      "Epoch [121/250], Training Loss: 0.0436\n",
      "Epoch [121/250], Validation Loss: 0.1446\n",
      "Accuracy: 0.9417, Precision: 0.9673, Recall: 0.9149, F1: 0.9404\n",
      "Epoch [122/250], Training Loss: 0.0436\n",
      "Epoch [122/250], Validation Loss: 0.1442\n",
      "Accuracy: 0.9404, Precision: 0.9672, Recall: 0.9124, F1: 0.9390\n",
      "Epoch [123/250], Training Loss: 0.0433\n",
      "Epoch [123/250], Validation Loss: 0.1439\n",
      "Accuracy: 0.9404, Precision: 0.9672, Recall: 0.9124, F1: 0.9390\n",
      "Epoch [124/250], Training Loss: 0.0431\n",
      "Epoch [124/250], Validation Loss: 0.1435\n",
      "Accuracy: 0.9404, Precision: 0.9672, Recall: 0.9124, F1: 0.9390\n",
      "Epoch [125/250], Training Loss: 0.0430\n",
      "Epoch [125/250], Validation Loss: 0.1432\n",
      "Accuracy: 0.9404, Precision: 0.9672, Recall: 0.9124, F1: 0.9390\n",
      "Epoch [126/250], Training Loss: 0.0427\n",
      "Epoch [126/250], Validation Loss: 0.1428\n",
      "Accuracy: 0.9404, Precision: 0.9672, Recall: 0.9124, F1: 0.9390\n",
      "Epoch [127/250], Training Loss: 0.0424\n",
      "Epoch [127/250], Validation Loss: 0.1425\n",
      "Accuracy: 0.9404, Precision: 0.9672, Recall: 0.9124, F1: 0.9390\n",
      "Epoch [128/250], Training Loss: 0.0424\n",
      "Epoch [128/250], Validation Loss: 0.1423\n",
      "Accuracy: 0.9404, Precision: 0.9672, Recall: 0.9124, F1: 0.9390\n",
      "Epoch [129/250], Training Loss: 0.0419\n",
      "Epoch [129/250], Validation Loss: 0.1419\n",
      "Accuracy: 0.9404, Precision: 0.9672, Recall: 0.9124, F1: 0.9390\n",
      "Epoch [130/250], Training Loss: 0.0414\n",
      "Epoch [130/250], Validation Loss: 0.1416\n",
      "Accuracy: 0.9404, Precision: 0.9672, Recall: 0.9124, F1: 0.9390\n",
      "Epoch [131/250], Training Loss: 0.0415\n",
      "Epoch [131/250], Validation Loss: 0.1413\n",
      "Accuracy: 0.9404, Precision: 0.9672, Recall: 0.9124, F1: 0.9390\n",
      "Epoch [132/250], Training Loss: 0.0408\n",
      "Epoch [132/250], Validation Loss: 0.1409\n",
      "Accuracy: 0.9417, Precision: 0.9699, Recall: 0.9124, F1: 0.9402\n",
      "Epoch [133/250], Training Loss: 0.0408\n",
      "Epoch [133/250], Validation Loss: 0.1407\n",
      "Accuracy: 0.9430, Precision: 0.9725, Recall: 0.9124, F1: 0.9415\n",
      "Epoch [134/250], Training Loss: 0.0404\n",
      "Epoch [134/250], Validation Loss: 0.1404\n",
      "Accuracy: 0.9430, Precision: 0.9725, Recall: 0.9124, F1: 0.9415\n",
      "Epoch [135/250], Training Loss: 0.0403\n",
      "Epoch [135/250], Validation Loss: 0.1401\n",
      "Accuracy: 0.9443, Precision: 0.9752, Recall: 0.9124, F1: 0.9427\n",
      "Epoch [136/250], Training Loss: 0.0398\n",
      "Epoch [136/250], Validation Loss: 0.1400\n",
      "Accuracy: 0.9456, Precision: 0.9779, Recall: 0.9124, F1: 0.9440\n",
      "Epoch [137/250], Training Loss: 0.0393\n",
      "Epoch [137/250], Validation Loss: 0.1397\n",
      "Accuracy: 0.9456, Precision: 0.9779, Recall: 0.9124, F1: 0.9440\n",
      "Epoch [138/250], Training Loss: 0.0389\n",
      "Epoch [138/250], Validation Loss: 0.1395\n",
      "Accuracy: 0.9456, Precision: 0.9779, Recall: 0.9124, F1: 0.9440\n",
      "Epoch [139/250], Training Loss: 0.0386\n",
      "Epoch [139/250], Validation Loss: 0.1393\n",
      "Accuracy: 0.9456, Precision: 0.9779, Recall: 0.9124, F1: 0.9440\n",
      "Epoch [140/250], Training Loss: 0.0383\n",
      "Epoch [140/250], Validation Loss: 0.1391\n",
      "Accuracy: 0.9456, Precision: 0.9779, Recall: 0.9124, F1: 0.9440\n",
      "Epoch [141/250], Training Loss: 0.0377\n",
      "Epoch [141/250], Validation Loss: 0.1388\n",
      "Accuracy: 0.9456, Precision: 0.9779, Recall: 0.9124, F1: 0.9440\n",
      "Epoch [142/250], Training Loss: 0.0377\n",
      "Epoch [142/250], Validation Loss: 0.1386\n",
      "Accuracy: 0.9443, Precision: 0.9778, Recall: 0.9098, F1: 0.9426\n",
      "Epoch [143/250], Training Loss: 0.0372\n",
      "Epoch [143/250], Validation Loss: 0.1385\n",
      "Accuracy: 0.9443, Precision: 0.9778, Recall: 0.9098, F1: 0.9426\n",
      "Epoch [144/250], Training Loss: 0.0370\n",
      "Epoch [144/250], Validation Loss: 0.1382\n",
      "Accuracy: 0.9443, Precision: 0.9778, Recall: 0.9098, F1: 0.9426\n",
      "Epoch [145/250], Training Loss: 0.0367\n",
      "Epoch [145/250], Validation Loss: 0.1380\n",
      "Accuracy: 0.9456, Precision: 0.9806, Recall: 0.9098, F1: 0.9439\n",
      "Epoch [146/250], Training Loss: 0.0362\n",
      "Epoch [146/250], Validation Loss: 0.1378\n",
      "Accuracy: 0.9456, Precision: 0.9806, Recall: 0.9098, F1: 0.9439\n",
      "Epoch [147/250], Training Loss: 0.0363\n",
      "Epoch [147/250], Validation Loss: 0.1376\n",
      "Accuracy: 0.9456, Precision: 0.9806, Recall: 0.9098, F1: 0.9439\n",
      "Epoch [148/250], Training Loss: 0.0360\n",
      "Epoch [148/250], Validation Loss: 0.1374\n",
      "Accuracy: 0.9443, Precision: 0.9778, Recall: 0.9098, F1: 0.9426\n",
      "Epoch [149/250], Training Loss: 0.0355\n",
      "Epoch [149/250], Validation Loss: 0.1371\n",
      "Accuracy: 0.9443, Precision: 0.9778, Recall: 0.9098, F1: 0.9426\n",
      "Epoch [150/250], Training Loss: 0.0355\n",
      "Epoch [150/250], Validation Loss: 0.1370\n",
      "Accuracy: 0.9443, Precision: 0.9778, Recall: 0.9098, F1: 0.9426\n",
      "Epoch [151/250], Training Loss: 0.0352\n",
      "Epoch [151/250], Validation Loss: 0.1368\n",
      "Accuracy: 0.9443, Precision: 0.9778, Recall: 0.9098, F1: 0.9426\n",
      "Epoch [152/250], Training Loss: 0.0351\n",
      "Epoch [152/250], Validation Loss: 0.1366\n",
      "Accuracy: 0.9443, Precision: 0.9778, Recall: 0.9098, F1: 0.9426\n",
      "Epoch [153/250], Training Loss: 0.0348\n",
      "Epoch [153/250], Validation Loss: 0.1364\n",
      "Accuracy: 0.9443, Precision: 0.9778, Recall: 0.9098, F1: 0.9426\n",
      "Epoch [154/250], Training Loss: 0.0345\n",
      "Epoch [154/250], Validation Loss: 0.1362\n",
      "Accuracy: 0.9456, Precision: 0.9806, Recall: 0.9098, F1: 0.9439\n",
      "Epoch [155/250], Training Loss: 0.0343\n",
      "Epoch [155/250], Validation Loss: 0.1361\n",
      "Accuracy: 0.9456, Precision: 0.9806, Recall: 0.9098, F1: 0.9439\n",
      "Epoch [156/250], Training Loss: 0.0340\n",
      "Epoch [156/250], Validation Loss: 0.1359\n",
      "Accuracy: 0.9469, Precision: 0.9806, Recall: 0.9124, F1: 0.9453\n",
      "Epoch [157/250], Training Loss: 0.0339\n",
      "Epoch [157/250], Validation Loss: 0.1359\n",
      "Accuracy: 0.9469, Precision: 0.9806, Recall: 0.9124, F1: 0.9453\n",
      "Epoch [158/250], Training Loss: 0.0336\n",
      "Epoch [158/250], Validation Loss: 0.1356\n",
      "Accuracy: 0.9469, Precision: 0.9806, Recall: 0.9124, F1: 0.9453\n",
      "Epoch [159/250], Training Loss: 0.0332\n",
      "Epoch [159/250], Validation Loss: 0.1356\n",
      "Accuracy: 0.9469, Precision: 0.9806, Recall: 0.9124, F1: 0.9453\n",
      "Epoch [160/250], Training Loss: 0.0330\n",
      "Epoch [160/250], Validation Loss: 0.1354\n",
      "Accuracy: 0.9469, Precision: 0.9806, Recall: 0.9124, F1: 0.9453\n",
      "Epoch [161/250], Training Loss: 0.0330\n",
      "Epoch [161/250], Validation Loss: 0.1353\n",
      "Accuracy: 0.9469, Precision: 0.9806, Recall: 0.9124, F1: 0.9453\n",
      "Epoch [162/250], Training Loss: 0.0329\n",
      "Epoch [162/250], Validation Loss: 0.1352\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [163/250], Training Loss: 0.0327\n",
      "Epoch [163/250], Validation Loss: 0.1351\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [164/250], Training Loss: 0.0323\n",
      "Epoch [164/250], Validation Loss: 0.1350\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [165/250], Training Loss: 0.0319\n",
      "Epoch [165/250], Validation Loss: 0.1349\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [166/250], Training Loss: 0.0317\n",
      "Epoch [166/250], Validation Loss: 0.1347\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [167/250], Training Loss: 0.0317\n",
      "Epoch [167/250], Validation Loss: 0.1346\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [168/250], Training Loss: 0.0313\n",
      "Epoch [168/250], Validation Loss: 0.1345\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [169/250], Training Loss: 0.0310\n",
      "Epoch [169/250], Validation Loss: 0.1344\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [170/250], Training Loss: 0.0309\n",
      "Epoch [170/250], Validation Loss: 0.1343\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [171/250], Training Loss: 0.0306\n",
      "Epoch [171/250], Validation Loss: 0.1342\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [172/250], Training Loss: 0.0303\n",
      "Epoch [172/250], Validation Loss: 0.1341\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [173/250], Training Loss: 0.0301\n",
      "Epoch [173/250], Validation Loss: 0.1340\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [174/250], Training Loss: 0.0299\n",
      "Epoch [174/250], Validation Loss: 0.1341\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [175/250], Training Loss: 0.0293\n",
      "Epoch [175/250], Validation Loss: 0.1339\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [176/250], Training Loss: 0.0293\n",
      "Epoch [176/250], Validation Loss: 0.1338\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [177/250], Training Loss: 0.0289\n",
      "Epoch [177/250], Validation Loss: 0.1338\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [178/250], Training Loss: 0.0289\n",
      "Epoch [178/250], Validation Loss: 0.1337\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [179/250], Training Loss: 0.0286\n",
      "Epoch [179/250], Validation Loss: 0.1337\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [180/250], Training Loss: 0.0284\n",
      "Epoch [180/250], Validation Loss: 0.1336\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [181/250], Training Loss: 0.0282\n",
      "Epoch [181/250], Validation Loss: 0.1335\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [182/250], Training Loss: 0.0280\n",
      "Epoch [182/250], Validation Loss: 0.1334\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [183/250], Training Loss: 0.0274\n",
      "Epoch [183/250], Validation Loss: 0.1334\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [184/250], Training Loss: 0.0275\n",
      "Epoch [184/250], Validation Loss: 0.1333\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [185/250], Training Loss: 0.0274\n",
      "Epoch [185/250], Validation Loss: 0.1333\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [186/250], Training Loss: 0.0269\n",
      "Epoch [186/250], Validation Loss: 0.1331\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [187/250], Training Loss: 0.0271\n",
      "Epoch [187/250], Validation Loss: 0.1332\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [188/250], Training Loss: 0.0266\n",
      "Epoch [188/250], Validation Loss: 0.1331\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [189/250], Training Loss: 0.0263\n",
      "Epoch [189/250], Validation Loss: 0.1330\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [190/250], Training Loss: 0.0262\n",
      "Epoch [190/250], Validation Loss: 0.1329\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [191/250], Training Loss: 0.0260\n",
      "Epoch [191/250], Validation Loss: 0.1329\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [192/250], Training Loss: 0.0258\n",
      "Epoch [192/250], Validation Loss: 0.1328\n",
      "Accuracy: 0.9482, Precision: 0.9780, Recall: 0.9175, F1: 0.9468\n",
      "Epoch [193/250], Training Loss: 0.0256\n",
      "Epoch [193/250], Validation Loss: 0.1327\n",
      "Accuracy: 0.9482, Precision: 0.9780, Recall: 0.9175, F1: 0.9468\n",
      "Epoch [194/250], Training Loss: 0.0253\n",
      "Epoch [194/250], Validation Loss: 0.1327\n",
      "Accuracy: 0.9482, Precision: 0.9780, Recall: 0.9175, F1: 0.9468\n",
      "Epoch [195/250], Training Loss: 0.0253\n",
      "Epoch [195/250], Validation Loss: 0.1327\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [196/250], Training Loss: 0.0249\n",
      "Epoch [196/250], Validation Loss: 0.1325\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [197/250], Training Loss: 0.0248\n",
      "Epoch [197/250], Validation Loss: 0.1325\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [198/250], Training Loss: 0.0247\n",
      "Epoch [198/250], Validation Loss: 0.1325\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [199/250], Training Loss: 0.0244\n",
      "Epoch [199/250], Validation Loss: 0.1324\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [200/250], Training Loss: 0.0241\n",
      "Epoch [200/250], Validation Loss: 0.1324\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [201/250], Training Loss: 0.0243\n",
      "Epoch [201/250], Validation Loss: 0.1324\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [202/250], Training Loss: 0.0241\n",
      "Epoch [202/250], Validation Loss: 0.1323\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [203/250], Training Loss: 0.0239\n",
      "Epoch [203/250], Validation Loss: 0.1323\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [204/250], Training Loss: 0.0237\n",
      "Epoch [204/250], Validation Loss: 0.1322\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [205/250], Training Loss: 0.0234\n",
      "Epoch [205/250], Validation Loss: 0.1323\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [206/250], Training Loss: 0.0234\n",
      "Epoch [206/250], Validation Loss: 0.1322\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [207/250], Training Loss: 0.0231\n",
      "Epoch [207/250], Validation Loss: 0.1322\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [208/250], Training Loss: 0.0227\n",
      "Epoch [208/250], Validation Loss: 0.1321\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [209/250], Training Loss: 0.0228\n",
      "Epoch [209/250], Validation Loss: 0.1322\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [210/250], Training Loss: 0.0224\n",
      "Epoch [210/250], Validation Loss: 0.1320\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [211/250], Training Loss: 0.0222\n",
      "Epoch [211/250], Validation Loss: 0.1320\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [212/250], Training Loss: 0.0222\n",
      "Epoch [212/250], Validation Loss: 0.1320\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [213/250], Training Loss: 0.0217\n",
      "Epoch [213/250], Validation Loss: 0.1319\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [214/250], Training Loss: 0.0219\n",
      "Epoch [214/250], Validation Loss: 0.1322\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [215/250], Training Loss: 0.0217\n",
      "Epoch [215/250], Validation Loss: 0.1322\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [216/250], Training Loss: 0.0214\n",
      "Epoch [216/250], Validation Loss: 0.1321\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [217/250], Training Loss: 0.0212\n",
      "Epoch [217/250], Validation Loss: 0.1320\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [218/250], Training Loss: 0.0210\n",
      "Epoch [218/250], Validation Loss: 0.1320\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [219/250], Training Loss: 0.0208\n",
      "Epoch [219/250], Validation Loss: 0.1321\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [220/250], Training Loss: 0.0206\n",
      "Epoch [220/250], Validation Loss: 0.1319\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [221/250], Training Loss: 0.0206\n",
      "Epoch [221/250], Validation Loss: 0.1320\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [222/250], Training Loss: 0.0204\n",
      "Epoch [222/250], Validation Loss: 0.1319\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [223/250], Training Loss: 0.0203\n",
      "Epoch [223/250], Validation Loss: 0.1319\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [224/250], Training Loss: 0.0200\n",
      "Epoch [224/250], Validation Loss: 0.1321\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [225/250], Training Loss: 0.0199\n",
      "Epoch [225/250], Validation Loss: 0.1319\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [226/250], Training Loss: 0.0198\n",
      "Epoch [226/250], Validation Loss: 0.1319\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [227/250], Training Loss: 0.0197\n",
      "Epoch [227/250], Validation Loss: 0.1320\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [228/250], Training Loss: 0.0194\n",
      "Epoch [228/250], Validation Loss: 0.1318\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [229/250], Training Loss: 0.0193\n",
      "Epoch [229/250], Validation Loss: 0.1318\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [230/250], Training Loss: 0.0190\n",
      "Epoch [230/250], Validation Loss: 0.1320\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [231/250], Training Loss: 0.0189\n",
      "Epoch [231/250], Validation Loss: 0.1318\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [232/250], Training Loss: 0.0187\n",
      "Epoch [232/250], Validation Loss: 0.1321\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [233/250], Training Loss: 0.0185\n",
      "Epoch [233/250], Validation Loss: 0.1319\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [234/250], Training Loss: 0.0184\n",
      "Epoch [234/250], Validation Loss: 0.1319\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [235/250], Training Loss: 0.0184\n",
      "Epoch [235/250], Validation Loss: 0.1319\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [236/250], Training Loss: 0.0181\n",
      "Epoch [236/250], Validation Loss: 0.1318\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [237/250], Training Loss: 0.0181\n",
      "Epoch [237/250], Validation Loss: 0.1318\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [238/250], Training Loss: 0.0178\n",
      "Epoch [238/250], Validation Loss: 0.1318\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [239/250], Training Loss: 0.0178\n",
      "Epoch [239/250], Validation Loss: 0.1317\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [240/250], Training Loss: 0.0176\n",
      "Epoch [240/250], Validation Loss: 0.1317\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [241/250], Training Loss: 0.0176\n",
      "Epoch [241/250], Validation Loss: 0.1317\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [242/250], Training Loss: 0.0172\n",
      "Epoch [242/250], Validation Loss: 0.1318\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [243/250], Training Loss: 0.0170\n",
      "Epoch [243/250], Validation Loss: 0.1316\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [244/250], Training Loss: 0.0169\n",
      "Epoch [244/250], Validation Loss: 0.1317\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [245/250], Training Loss: 0.0167\n",
      "Epoch [245/250], Validation Loss: 0.1315\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [246/250], Training Loss: 0.0166\n",
      "Epoch [246/250], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [247/250], Training Loss: 0.0165\n",
      "Epoch [247/250], Validation Loss: 0.1316\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [248/250], Training Loss: 0.0163\n",
      "Epoch [248/250], Validation Loss: 0.1316\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [249/250], Training Loss: 0.0161\n",
      "Epoch [249/250], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [250/250], Training Loss: 0.0160\n",
      "Epoch [250/250], Validation Loss: 0.1317\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Time:  14.820340871810913\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# early stopping kısmını olmadan cpu da çalışma süresini hesapladım.\n",
    "\n",
    "import time \n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "trainData = pd.read_csv('./csv/cure_the_princess_train.csv')\n",
    "validData = pd.read_csv('./csv/cure_the_princess_validation.csv')\n",
    "testData =  pd.read_csv('./csv/cure_the_princess_test.csv')\n",
    "\n",
    "\n",
    "trainX = trainData.drop(columns=['Cured']).values\n",
    "trainY = trainData['Cured'].values\n",
    "validX = validData.drop(columns=['Cured']).values\n",
    "validY = validData['Cured'].values\n",
    "testX = testData.drop(columns=['Cured']).values\n",
    "testY = testData['Cured'].values\n",
    "\n",
    "\n",
    "numInputFeatures = trainX.shape[1]\n",
    "\n",
    "torch.manual_seed(190401070)\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, numInputFeatures):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(numInputFeatures, 100) \n",
    "        self.relu1 = nn.ReLU() \n",
    "        self.fc2 = nn.Linear(100, 50) \n",
    "        self.relu2 = nn.ReLU() \n",
    "        self.fc3 = nn.Linear(50, 1) \n",
    "        self.sigmoid = nn.Sigmoid() \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MLP(numInputFeatures=numInputFeatures)\n",
    "\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0006)\n",
    "\n",
    "\n",
    "numEpochs = 250\n",
    "batchSize = 16\n",
    "trainLosses = []\n",
    "validLosses = []\n",
    "\n",
    "\n",
    "for epoch in range(numEpochs):\n",
    "    for i in range(0, len(trainX), batchSize):\n",
    "        \n",
    "        batchX = torch.tensor(trainX[i:i+batchSize], dtype=torch.float32)\n",
    "        batchY = torch.tensor(trainY[i:i+batchSize], dtype=torch.float32).view(-1, 1)\n",
    "        \n",
    "        \n",
    "        outputs = model(batchX)\n",
    "        loss = criterion(outputs, batchY)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    \n",
    "    trainLosses.append(loss.item())\n",
    "    print('Epoch [%d/%d], Training Loss: %.4f' % (epoch+1, numEpochs, loss.item()))\n",
    "    \n",
    "   \n",
    "    validLoss = criterion(model(torch.tensor(validX, dtype=torch.float32)), torch.tensor(validY, dtype=torch.float32).view(-1, 1)).item()\n",
    "    validLosses.append(validLoss)\n",
    "    print('Epoch [%d/%d], Validation Loss: %.4f' % (epoch+1, numEpochs, validLoss))\n",
    "\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        testOutputs = model(torch.tensor(testX, dtype=torch.float32))\n",
    "        testPredictions = (testOutputs > 0.5).float().view(-1)\n",
    "\n",
    "        \n",
    "        accuracy = (testPredictions == torch.tensor(testY, dtype=torch.float32)).float().mean().item()\n",
    "        precision = (testPredictions[testPredictions == 1] == torch.tensor(testY[testPredictions == 1], dtype=torch.float32)).float().mean().item()\n",
    "        recall = (testPredictions[testY == 1] == torch.tensor(testY[testY == 1], dtype=torch.float32)).float().mean().item()\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "        print('Accuracy: %.4f, Precision: %.4f, Recall: %.4f, F1: %.4f' % (accuracy, precision, recall, f1))\n",
    "\n",
    "endTime = time.time()\n",
    "\n",
    "print(\"Time: \", endTime - startTime)\n",
    "\n",
    "plt.plot(trainLosses, label='Training Loss')\n",
    "plt.plot(validLosses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4500], Training Loss: 0.3834\n",
      "Epoch [1/4500], Validation Loss: 0.6119\n",
      "Accuracy: 0.6749, Precision: 0.6367, Recall: 0.8222, F1: 0.7177\n",
      "Epoch [2/4500], Training Loss: 0.3208\n",
      "Epoch [2/4500], Validation Loss: 0.5595\n",
      "Accuracy: 0.7176, Precision: 0.6687, Recall: 0.8686, F1: 0.7556\n",
      "Epoch [3/4500], Training Loss: 0.2847\n",
      "Epoch [3/4500], Validation Loss: 0.5220\n",
      "Accuracy: 0.7513, Precision: 0.6984, Recall: 0.8892, F1: 0.7823\n",
      "Epoch [4/4500], Training Loss: 0.2607\n",
      "Epoch [4/4500], Validation Loss: 0.4919\n",
      "Accuracy: 0.7707, Precision: 0.7149, Recall: 0.9046, F1: 0.7986\n",
      "Epoch [5/4500], Training Loss: 0.2442\n",
      "Epoch [5/4500], Validation Loss: 0.4672\n",
      "Accuracy: 0.7902, Precision: 0.7325, Recall: 0.9175, F1: 0.8146\n",
      "Epoch [6/4500], Training Loss: 0.2311\n",
      "Epoch [6/4500], Validation Loss: 0.4453\n",
      "Accuracy: 0.8018, Precision: 0.7443, Recall: 0.9227, F1: 0.8239\n",
      "Epoch [7/4500], Training Loss: 0.2197\n",
      "Epoch [7/4500], Validation Loss: 0.4263\n",
      "Accuracy: 0.8187, Precision: 0.7616, Recall: 0.9304, F1: 0.8376\n",
      "Epoch [8/4500], Training Loss: 0.2104\n",
      "Epoch [8/4500], Validation Loss: 0.4090\n",
      "Accuracy: 0.8277, Precision: 0.7730, Recall: 0.9304, F1: 0.8444\n",
      "Epoch [9/4500], Training Loss: 0.2021\n",
      "Epoch [9/4500], Validation Loss: 0.3934\n",
      "Accuracy: 0.8381, Precision: 0.7840, Recall: 0.9356, F1: 0.8531\n",
      "Epoch [10/4500], Training Loss: 0.1945\n",
      "Epoch [10/4500], Validation Loss: 0.3793\n",
      "Accuracy: 0.8433, Precision: 0.7896, Recall: 0.9381, F1: 0.8575\n",
      "Epoch [11/4500], Training Loss: 0.1879\n",
      "Epoch [11/4500], Validation Loss: 0.3664\n",
      "Accuracy: 0.8484, Precision: 0.7978, Recall: 0.9356, F1: 0.8612\n",
      "Epoch [12/4500], Training Loss: 0.1825\n",
      "Epoch [12/4500], Validation Loss: 0.3545\n",
      "Accuracy: 0.8484, Precision: 0.7991, Recall: 0.9330, F1: 0.8609\n",
      "Epoch [13/4500], Training Loss: 0.1769\n",
      "Epoch [13/4500], Validation Loss: 0.3437\n",
      "Accuracy: 0.8549, Precision: 0.8053, Recall: 0.9381, F1: 0.8667\n",
      "Epoch [14/4500], Training Loss: 0.1718\n",
      "Epoch [14/4500], Validation Loss: 0.3338\n",
      "Accuracy: 0.8549, Precision: 0.8040, Recall: 0.9407, F1: 0.8670\n",
      "Epoch [15/4500], Training Loss: 0.1667\n",
      "Epoch [15/4500], Validation Loss: 0.3246\n",
      "Accuracy: 0.8549, Precision: 0.8067, Recall: 0.9356, F1: 0.8663\n",
      "Epoch [16/4500], Training Loss: 0.1622\n",
      "Epoch [16/4500], Validation Loss: 0.3161\n",
      "Accuracy: 0.8562, Precision: 0.8098, Recall: 0.9330, F1: 0.8671\n",
      "Epoch [17/4500], Training Loss: 0.1574\n",
      "Epoch [17/4500], Validation Loss: 0.3082\n",
      "Accuracy: 0.8588, Precision: 0.8149, Recall: 0.9304, F1: 0.8688\n",
      "Epoch [18/4500], Training Loss: 0.1530\n",
      "Epoch [18/4500], Validation Loss: 0.3010\n",
      "Accuracy: 0.8627, Precision: 0.8190, Recall: 0.9330, F1: 0.8723\n",
      "Epoch [19/4500], Training Loss: 0.1485\n",
      "Epoch [19/4500], Validation Loss: 0.2943\n",
      "Accuracy: 0.8666, Precision: 0.8261, Recall: 0.9304, F1: 0.8752\n",
      "Epoch [20/4500], Training Loss: 0.1441\n",
      "Epoch [20/4500], Validation Loss: 0.2881\n",
      "Accuracy: 0.8692, Precision: 0.8299, Recall: 0.9304, F1: 0.8773\n",
      "Epoch [21/4500], Training Loss: 0.1397\n",
      "Epoch [21/4500], Validation Loss: 0.2823\n",
      "Accuracy: 0.8731, Precision: 0.8341, Recall: 0.9330, F1: 0.8808\n",
      "Epoch [22/4500], Training Loss: 0.1356\n",
      "Epoch [22/4500], Validation Loss: 0.2769\n",
      "Accuracy: 0.8744, Precision: 0.8360, Recall: 0.9330, F1: 0.8819\n",
      "Epoch [23/4500], Training Loss: 0.1326\n",
      "Epoch [23/4500], Validation Loss: 0.2717\n",
      "Accuracy: 0.8821, Precision: 0.8462, Recall: 0.9356, F1: 0.8886\n",
      "Epoch [24/4500], Training Loss: 0.1297\n",
      "Epoch [24/4500], Validation Loss: 0.2670\n",
      "Accuracy: 0.8821, Precision: 0.8478, Recall: 0.9330, F1: 0.8883\n",
      "Epoch [25/4500], Training Loss: 0.1262\n",
      "Epoch [25/4500], Validation Loss: 0.2628\n",
      "Accuracy: 0.8860, Precision: 0.8555, Recall: 0.9304, F1: 0.8914\n",
      "Epoch [26/4500], Training Loss: 0.1229\n",
      "Epoch [26/4500], Validation Loss: 0.2586\n",
      "Accuracy: 0.8860, Precision: 0.8571, Recall: 0.9278, F1: 0.8911\n",
      "Epoch [27/4500], Training Loss: 0.1205\n",
      "Epoch [27/4500], Validation Loss: 0.2546\n",
      "Accuracy: 0.8834, Precision: 0.8565, Recall: 0.9227, F1: 0.8883\n",
      "Epoch [28/4500], Training Loss: 0.1180\n",
      "Epoch [28/4500], Validation Loss: 0.2508\n",
      "Accuracy: 0.8834, Precision: 0.8565, Recall: 0.9227, F1: 0.8883\n",
      "Epoch [29/4500], Training Loss: 0.1155\n",
      "Epoch [29/4500], Validation Loss: 0.2472\n",
      "Accuracy: 0.8847, Precision: 0.8585, Recall: 0.9227, F1: 0.8894\n",
      "Epoch [30/4500], Training Loss: 0.1129\n",
      "Epoch [30/4500], Validation Loss: 0.2437\n",
      "Accuracy: 0.8847, Precision: 0.8585, Recall: 0.9227, F1: 0.8894\n",
      "Epoch [31/4500], Training Loss: 0.1108\n",
      "Epoch [31/4500], Validation Loss: 0.2404\n",
      "Accuracy: 0.8873, Precision: 0.8627, Recall: 0.9227, F1: 0.8917\n",
      "Epoch [32/4500], Training Loss: 0.1090\n",
      "Epoch [32/4500], Validation Loss: 0.2375\n",
      "Accuracy: 0.8873, Precision: 0.8627, Recall: 0.9227, F1: 0.8917\n",
      "Epoch [33/4500], Training Loss: 0.1072\n",
      "Epoch [33/4500], Validation Loss: 0.2347\n",
      "Accuracy: 0.8886, Precision: 0.8647, Recall: 0.9227, F1: 0.8928\n",
      "Epoch [34/4500], Training Loss: 0.1054\n",
      "Epoch [34/4500], Validation Loss: 0.2319\n",
      "Accuracy: 0.8899, Precision: 0.8668, Recall: 0.9227, F1: 0.8939\n",
      "Epoch [35/4500], Training Loss: 0.1038\n",
      "Epoch [35/4500], Validation Loss: 0.2293\n",
      "Accuracy: 0.8899, Precision: 0.8668, Recall: 0.9227, F1: 0.8939\n",
      "Epoch [36/4500], Training Loss: 0.1020\n",
      "Epoch [36/4500], Validation Loss: 0.2268\n",
      "Accuracy: 0.8899, Precision: 0.8668, Recall: 0.9227, F1: 0.8939\n",
      "Epoch [37/4500], Training Loss: 0.1005\n",
      "Epoch [37/4500], Validation Loss: 0.2244\n",
      "Accuracy: 0.8899, Precision: 0.8668, Recall: 0.9227, F1: 0.8939\n",
      "Epoch [38/4500], Training Loss: 0.0991\n",
      "Epoch [38/4500], Validation Loss: 0.2221\n",
      "Accuracy: 0.8951, Precision: 0.8735, Recall: 0.9253, F1: 0.8986\n",
      "Epoch [39/4500], Training Loss: 0.0977\n",
      "Epoch [39/4500], Validation Loss: 0.2199\n",
      "Accuracy: 0.8951, Precision: 0.8735, Recall: 0.9253, F1: 0.8986\n",
      "Epoch [40/4500], Training Loss: 0.0962\n",
      "Epoch [40/4500], Validation Loss: 0.2179\n",
      "Accuracy: 0.8951, Precision: 0.8735, Recall: 0.9253, F1: 0.8986\n",
      "Epoch [41/4500], Training Loss: 0.0947\n",
      "Epoch [41/4500], Validation Loss: 0.2159\n",
      "Accuracy: 0.8951, Precision: 0.8753, Recall: 0.9227, F1: 0.8984\n",
      "Epoch [42/4500], Training Loss: 0.0932\n",
      "Epoch [42/4500], Validation Loss: 0.2137\n",
      "Accuracy: 0.8964, Precision: 0.8775, Recall: 0.9227, F1: 0.8995\n",
      "Epoch [43/4500], Training Loss: 0.0914\n",
      "Epoch [43/4500], Validation Loss: 0.2118\n",
      "Accuracy: 0.8977, Precision: 0.8796, Recall: 0.9227, F1: 0.9006\n",
      "Epoch [44/4500], Training Loss: 0.0897\n",
      "Epoch [44/4500], Validation Loss: 0.2099\n",
      "Accuracy: 0.9003, Precision: 0.8840, Recall: 0.9227, F1: 0.9029\n",
      "Epoch [45/4500], Training Loss: 0.0882\n",
      "Epoch [45/4500], Validation Loss: 0.2080\n",
      "Accuracy: 0.9028, Precision: 0.8883, Recall: 0.9227, F1: 0.9052\n",
      "Epoch [46/4500], Training Loss: 0.0865\n",
      "Epoch [46/4500], Validation Loss: 0.2062\n",
      "Accuracy: 0.9028, Precision: 0.8883, Recall: 0.9227, F1: 0.9052\n",
      "Epoch [47/4500], Training Loss: 0.0851\n",
      "Epoch [47/4500], Validation Loss: 0.2046\n",
      "Accuracy: 0.9054, Precision: 0.8928, Recall: 0.9227, F1: 0.9075\n",
      "Epoch [48/4500], Training Loss: 0.0839\n",
      "Epoch [48/4500], Validation Loss: 0.2032\n",
      "Accuracy: 0.9054, Precision: 0.8928, Recall: 0.9227, F1: 0.9075\n",
      "Epoch [49/4500], Training Loss: 0.0825\n",
      "Epoch [49/4500], Validation Loss: 0.2016\n",
      "Accuracy: 0.9041, Precision: 0.8925, Recall: 0.9201, F1: 0.9061\n",
      "Epoch [50/4500], Training Loss: 0.0809\n",
      "Epoch [50/4500], Validation Loss: 0.2002\n",
      "Accuracy: 0.9041, Precision: 0.8925, Recall: 0.9201, F1: 0.9061\n",
      "Epoch [51/4500], Training Loss: 0.0793\n",
      "Epoch [51/4500], Validation Loss: 0.1986\n",
      "Accuracy: 0.9054, Precision: 0.8947, Recall: 0.9201, F1: 0.9072\n",
      "Epoch [52/4500], Training Loss: 0.0775\n",
      "Epoch [52/4500], Validation Loss: 0.1970\n",
      "Accuracy: 0.9054, Precision: 0.8947, Recall: 0.9201, F1: 0.9072\n",
      "Epoch [53/4500], Training Loss: 0.0762\n",
      "Epoch [53/4500], Validation Loss: 0.1956\n",
      "Accuracy: 0.9106, Precision: 0.9038, Recall: 0.9201, F1: 0.9119\n",
      "Epoch [54/4500], Training Loss: 0.0753\n",
      "Epoch [54/4500], Validation Loss: 0.1941\n",
      "Accuracy: 0.9119, Precision: 0.9061, Recall: 0.9201, F1: 0.9130\n",
      "Epoch [55/4500], Training Loss: 0.0744\n",
      "Epoch [55/4500], Validation Loss: 0.1928\n",
      "Accuracy: 0.9145, Precision: 0.9107, Recall: 0.9201, F1: 0.9154\n",
      "Epoch [56/4500], Training Loss: 0.0733\n",
      "Epoch [56/4500], Validation Loss: 0.1914\n",
      "Accuracy: 0.9210, Precision: 0.9203, Recall: 0.9227, F1: 0.9215\n",
      "Epoch [57/4500], Training Loss: 0.0724\n",
      "Epoch [57/4500], Validation Loss: 0.1901\n",
      "Accuracy: 0.9223, Precision: 0.9205, Recall: 0.9253, F1: 0.9229\n",
      "Epoch [58/4500], Training Loss: 0.0715\n",
      "Epoch [58/4500], Validation Loss: 0.1888\n",
      "Accuracy: 0.9249, Precision: 0.9253, Recall: 0.9253, F1: 0.9253\n",
      "Epoch [59/4500], Training Loss: 0.0706\n",
      "Epoch [59/4500], Validation Loss: 0.1876\n",
      "Accuracy: 0.9249, Precision: 0.9253, Recall: 0.9253, F1: 0.9253\n",
      "Epoch [60/4500], Training Loss: 0.0698\n",
      "Epoch [60/4500], Validation Loss: 0.1864\n",
      "Accuracy: 0.9262, Precision: 0.9254, Recall: 0.9278, F1: 0.9266\n",
      "Epoch [61/4500], Training Loss: 0.0688\n",
      "Epoch [61/4500], Validation Loss: 0.1852\n",
      "Accuracy: 0.9262, Precision: 0.9254, Recall: 0.9278, F1: 0.9266\n",
      "Epoch [62/4500], Training Loss: 0.0680\n",
      "Epoch [62/4500], Validation Loss: 0.1841\n",
      "Accuracy: 0.9262, Precision: 0.9276, Recall: 0.9253, F1: 0.9265\n",
      "Epoch [63/4500], Training Loss: 0.0673\n",
      "Epoch [63/4500], Validation Loss: 0.1830\n",
      "Accuracy: 0.9275, Precision: 0.9278, Recall: 0.9278, F1: 0.9278\n",
      "Epoch [64/4500], Training Loss: 0.0666\n",
      "Epoch [64/4500], Validation Loss: 0.1819\n",
      "Accuracy: 0.9275, Precision: 0.9278, Recall: 0.9278, F1: 0.9278\n",
      "Epoch [65/4500], Training Loss: 0.0658\n",
      "Epoch [65/4500], Validation Loss: 0.1809\n",
      "Accuracy: 0.9262, Precision: 0.9276, Recall: 0.9253, F1: 0.9265\n",
      "Epoch [66/4500], Training Loss: 0.0650\n",
      "Epoch [66/4500], Validation Loss: 0.1799\n",
      "Accuracy: 0.9275, Precision: 0.9301, Recall: 0.9253, F1: 0.9276\n",
      "Epoch [67/4500], Training Loss: 0.0643\n",
      "Epoch [67/4500], Validation Loss: 0.1788\n",
      "Accuracy: 0.9275, Precision: 0.9323, Recall: 0.9227, F1: 0.9275\n",
      "Epoch [68/4500], Training Loss: 0.0638\n",
      "Epoch [68/4500], Validation Loss: 0.1778\n",
      "Accuracy: 0.9275, Precision: 0.9323, Recall: 0.9227, F1: 0.9275\n",
      "Epoch [69/4500], Training Loss: 0.0633\n",
      "Epoch [69/4500], Validation Loss: 0.1768\n",
      "Accuracy: 0.9262, Precision: 0.9321, Recall: 0.9201, F1: 0.9261\n",
      "Epoch [70/4500], Training Loss: 0.0632\n",
      "Epoch [70/4500], Validation Loss: 0.1760\n",
      "Accuracy: 0.9262, Precision: 0.9321, Recall: 0.9201, F1: 0.9261\n",
      "Epoch [71/4500], Training Loss: 0.0627\n",
      "Epoch [71/4500], Validation Loss: 0.1750\n",
      "Accuracy: 0.9262, Precision: 0.9321, Recall: 0.9201, F1: 0.9261\n",
      "Epoch [72/4500], Training Loss: 0.0619\n",
      "Epoch [72/4500], Validation Loss: 0.1740\n",
      "Accuracy: 0.9262, Precision: 0.9321, Recall: 0.9201, F1: 0.9261\n",
      "Epoch [73/4500], Training Loss: 0.0616\n",
      "Epoch [73/4500], Validation Loss: 0.1731\n",
      "Accuracy: 0.9275, Precision: 0.9346, Recall: 0.9201, F1: 0.9273\n",
      "Epoch [74/4500], Training Loss: 0.0610\n",
      "Epoch [74/4500], Validation Loss: 0.1722\n",
      "Accuracy: 0.9275, Precision: 0.9346, Recall: 0.9201, F1: 0.9273\n",
      "Epoch [75/4500], Training Loss: 0.0606\n",
      "Epoch [75/4500], Validation Loss: 0.1713\n",
      "Accuracy: 0.9275, Precision: 0.9346, Recall: 0.9201, F1: 0.9273\n",
      "Epoch [76/4500], Training Loss: 0.0600\n",
      "Epoch [76/4500], Validation Loss: 0.1705\n",
      "Accuracy: 0.9288, Precision: 0.9347, Recall: 0.9227, F1: 0.9287\n",
      "Epoch [77/4500], Training Loss: 0.0598\n",
      "Epoch [77/4500], Validation Loss: 0.1697\n",
      "Accuracy: 0.9288, Precision: 0.9347, Recall: 0.9227, F1: 0.9287\n",
      "Epoch [78/4500], Training Loss: 0.0593\n",
      "Epoch [78/4500], Validation Loss: 0.1688\n",
      "Accuracy: 0.9288, Precision: 0.9347, Recall: 0.9227, F1: 0.9287\n",
      "Epoch [79/4500], Training Loss: 0.0589\n",
      "Epoch [79/4500], Validation Loss: 0.1680\n",
      "Accuracy: 0.9288, Precision: 0.9347, Recall: 0.9227, F1: 0.9287\n",
      "Epoch [80/4500], Training Loss: 0.0584\n",
      "Epoch [80/4500], Validation Loss: 0.1672\n",
      "Accuracy: 0.9301, Precision: 0.9372, Recall: 0.9227, F1: 0.9299\n",
      "Epoch [81/4500], Training Loss: 0.0579\n",
      "Epoch [81/4500], Validation Loss: 0.1665\n",
      "Accuracy: 0.9301, Precision: 0.9372, Recall: 0.9227, F1: 0.9299\n",
      "Epoch [82/4500], Training Loss: 0.0575\n",
      "Epoch [82/4500], Validation Loss: 0.1657\n",
      "Accuracy: 0.9301, Precision: 0.9372, Recall: 0.9227, F1: 0.9299\n",
      "Epoch [83/4500], Training Loss: 0.0570\n",
      "Epoch [83/4500], Validation Loss: 0.1649\n",
      "Accuracy: 0.9313, Precision: 0.9396, Recall: 0.9227, F1: 0.9311\n",
      "Epoch [84/4500], Training Loss: 0.0571\n",
      "Epoch [84/4500], Validation Loss: 0.1642\n",
      "Accuracy: 0.9326, Precision: 0.9421, Recall: 0.9227, F1: 0.9323\n",
      "Epoch [85/4500], Training Loss: 0.0566\n",
      "Epoch [85/4500], Validation Loss: 0.1635\n",
      "Accuracy: 0.9339, Precision: 0.9446, Recall: 0.9227, F1: 0.9335\n",
      "Epoch [86/4500], Training Loss: 0.0562\n",
      "Epoch [86/4500], Validation Loss: 0.1627\n",
      "Accuracy: 0.9339, Precision: 0.9446, Recall: 0.9227, F1: 0.9335\n",
      "Epoch [87/4500], Training Loss: 0.0558\n",
      "Epoch [87/4500], Validation Loss: 0.1621\n",
      "Accuracy: 0.9339, Precision: 0.9446, Recall: 0.9227, F1: 0.9335\n",
      "Epoch [88/4500], Training Loss: 0.0554\n",
      "Epoch [88/4500], Validation Loss: 0.1614\n",
      "Accuracy: 0.9352, Precision: 0.9447, Recall: 0.9253, F1: 0.9349\n",
      "Epoch [89/4500], Training Loss: 0.0550\n",
      "Epoch [89/4500], Validation Loss: 0.1607\n",
      "Accuracy: 0.9365, Precision: 0.9472, Recall: 0.9253, F1: 0.9361\n",
      "Epoch [90/4500], Training Loss: 0.0544\n",
      "Epoch [90/4500], Validation Loss: 0.1600\n",
      "Accuracy: 0.9365, Precision: 0.9472, Recall: 0.9253, F1: 0.9361\n",
      "Epoch [91/4500], Training Loss: 0.0540\n",
      "Epoch [91/4500], Validation Loss: 0.1593\n",
      "Accuracy: 0.9352, Precision: 0.9471, Recall: 0.9227, F1: 0.9347\n",
      "Epoch [92/4500], Training Loss: 0.0540\n",
      "Epoch [92/4500], Validation Loss: 0.1587\n",
      "Accuracy: 0.9352, Precision: 0.9471, Recall: 0.9227, F1: 0.9347\n",
      "Epoch [93/4500], Training Loss: 0.0537\n",
      "Epoch [93/4500], Validation Loss: 0.1581\n",
      "Accuracy: 0.9365, Precision: 0.9496, Recall: 0.9227, F1: 0.9359\n",
      "Epoch [94/4500], Training Loss: 0.0539\n",
      "Epoch [94/4500], Validation Loss: 0.1576\n",
      "Accuracy: 0.9378, Precision: 0.9521, Recall: 0.9227, F1: 0.9372\n",
      "Epoch [95/4500], Training Loss: 0.0539\n",
      "Epoch [95/4500], Validation Loss: 0.1570\n",
      "Accuracy: 0.9391, Precision: 0.9547, Recall: 0.9227, F1: 0.9384\n",
      "Epoch [96/4500], Training Loss: 0.0534\n",
      "Epoch [96/4500], Validation Loss: 0.1564\n",
      "Accuracy: 0.9391, Precision: 0.9547, Recall: 0.9227, F1: 0.9384\n",
      "Epoch [97/4500], Training Loss: 0.0533\n",
      "Epoch [97/4500], Validation Loss: 0.1559\n",
      "Accuracy: 0.9391, Precision: 0.9547, Recall: 0.9227, F1: 0.9384\n",
      "Epoch [98/4500], Training Loss: 0.0528\n",
      "Epoch [98/4500], Validation Loss: 0.1553\n",
      "Accuracy: 0.9391, Precision: 0.9547, Recall: 0.9227, F1: 0.9384\n",
      "Epoch [99/4500], Training Loss: 0.0525\n",
      "Epoch [99/4500], Validation Loss: 0.1547\n",
      "Accuracy: 0.9404, Precision: 0.9548, Recall: 0.9253, F1: 0.9398\n",
      "Epoch [100/4500], Training Loss: 0.0521\n",
      "Epoch [100/4500], Validation Loss: 0.1541\n",
      "Accuracy: 0.9404, Precision: 0.9548, Recall: 0.9253, F1: 0.9398\n",
      "Epoch [101/4500], Training Loss: 0.0519\n",
      "Epoch [101/4500], Validation Loss: 0.1536\n",
      "Accuracy: 0.9404, Precision: 0.9548, Recall: 0.9253, F1: 0.9398\n",
      "Epoch [102/4500], Training Loss: 0.0515\n",
      "Epoch [102/4500], Validation Loss: 0.1531\n",
      "Accuracy: 0.9404, Precision: 0.9548, Recall: 0.9253, F1: 0.9398\n",
      "Epoch [103/4500], Training Loss: 0.0509\n",
      "Epoch [103/4500], Validation Loss: 0.1526\n",
      "Accuracy: 0.9391, Precision: 0.9547, Recall: 0.9227, F1: 0.9384\n",
      "Epoch [104/4500], Training Loss: 0.0504\n",
      "Epoch [104/4500], Validation Loss: 0.1519\n",
      "Accuracy: 0.9391, Precision: 0.9547, Recall: 0.9227, F1: 0.9384\n",
      "Epoch [105/4500], Training Loss: 0.0501\n",
      "Epoch [105/4500], Validation Loss: 0.1515\n",
      "Accuracy: 0.9404, Precision: 0.9572, Recall: 0.9227, F1: 0.9396\n",
      "Epoch [106/4500], Training Loss: 0.0501\n",
      "Epoch [106/4500], Validation Loss: 0.1511\n",
      "Accuracy: 0.9404, Precision: 0.9572, Recall: 0.9227, F1: 0.9396\n",
      "Epoch [107/4500], Training Loss: 0.0497\n",
      "Epoch [107/4500], Validation Loss: 0.1507\n",
      "Accuracy: 0.9391, Precision: 0.9571, Recall: 0.9201, F1: 0.9382\n",
      "Epoch [108/4500], Training Loss: 0.0493\n",
      "Epoch [108/4500], Validation Loss: 0.1501\n",
      "Accuracy: 0.9391, Precision: 0.9571, Recall: 0.9201, F1: 0.9382\n",
      "Epoch [109/4500], Training Loss: 0.0490\n",
      "Epoch [109/4500], Validation Loss: 0.1496\n",
      "Accuracy: 0.9391, Precision: 0.9571, Recall: 0.9201, F1: 0.9382\n",
      "Epoch [110/4500], Training Loss: 0.0484\n",
      "Epoch [110/4500], Validation Loss: 0.1492\n",
      "Accuracy: 0.9391, Precision: 0.9571, Recall: 0.9201, F1: 0.9382\n",
      "Epoch [111/4500], Training Loss: 0.0478\n",
      "Epoch [111/4500], Validation Loss: 0.1487\n",
      "Accuracy: 0.9391, Precision: 0.9571, Recall: 0.9201, F1: 0.9382\n",
      "Epoch [112/4500], Training Loss: 0.0474\n",
      "Epoch [112/4500], Validation Loss: 0.1484\n",
      "Accuracy: 0.9378, Precision: 0.9570, Recall: 0.9175, F1: 0.9368\n",
      "Epoch [113/4500], Training Loss: 0.0465\n",
      "Epoch [113/4500], Validation Loss: 0.1479\n",
      "Accuracy: 0.9391, Precision: 0.9596, Recall: 0.9175, F1: 0.9381\n",
      "Epoch [114/4500], Training Loss: 0.0460\n",
      "Epoch [114/4500], Validation Loss: 0.1474\n",
      "Accuracy: 0.9391, Precision: 0.9621, Recall: 0.9149, F1: 0.9379\n",
      "Epoch [115/4500], Training Loss: 0.0456\n",
      "Epoch [115/4500], Validation Loss: 0.1470\n",
      "Accuracy: 0.9404, Precision: 0.9647, Recall: 0.9149, F1: 0.9392\n",
      "Epoch [116/4500], Training Loss: 0.0453\n",
      "Epoch [116/4500], Validation Loss: 0.1466\n",
      "Accuracy: 0.9404, Precision: 0.9647, Recall: 0.9149, F1: 0.9392\n",
      "Epoch [117/4500], Training Loss: 0.0450\n",
      "Epoch [117/4500], Validation Loss: 0.1462\n",
      "Accuracy: 0.9404, Precision: 0.9647, Recall: 0.9149, F1: 0.9392\n",
      "Epoch [118/4500], Training Loss: 0.0448\n",
      "Epoch [118/4500], Validation Loss: 0.1458\n",
      "Accuracy: 0.9404, Precision: 0.9647, Recall: 0.9149, F1: 0.9392\n",
      "Epoch [119/4500], Training Loss: 0.0442\n",
      "Epoch [119/4500], Validation Loss: 0.1454\n",
      "Accuracy: 0.9404, Precision: 0.9647, Recall: 0.9149, F1: 0.9392\n",
      "Epoch [120/4500], Training Loss: 0.0439\n",
      "Epoch [120/4500], Validation Loss: 0.1450\n",
      "Accuracy: 0.9404, Precision: 0.9647, Recall: 0.9149, F1: 0.9392\n",
      "Epoch [121/4500], Training Loss: 0.0436\n",
      "Epoch [121/4500], Validation Loss: 0.1446\n",
      "Accuracy: 0.9417, Precision: 0.9673, Recall: 0.9149, F1: 0.9404\n",
      "Epoch [122/4500], Training Loss: 0.0436\n",
      "Epoch [122/4500], Validation Loss: 0.1442\n",
      "Accuracy: 0.9404, Precision: 0.9672, Recall: 0.9124, F1: 0.9390\n",
      "Epoch [123/4500], Training Loss: 0.0433\n",
      "Epoch [123/4500], Validation Loss: 0.1439\n",
      "Accuracy: 0.9404, Precision: 0.9672, Recall: 0.9124, F1: 0.9390\n",
      "Epoch [124/4500], Training Loss: 0.0431\n",
      "Epoch [124/4500], Validation Loss: 0.1435\n",
      "Accuracy: 0.9404, Precision: 0.9672, Recall: 0.9124, F1: 0.9390\n",
      "Epoch [125/4500], Training Loss: 0.0430\n",
      "Epoch [125/4500], Validation Loss: 0.1432\n",
      "Accuracy: 0.9404, Precision: 0.9672, Recall: 0.9124, F1: 0.9390\n",
      "Epoch [126/4500], Training Loss: 0.0427\n",
      "Epoch [126/4500], Validation Loss: 0.1428\n",
      "Accuracy: 0.9404, Precision: 0.9672, Recall: 0.9124, F1: 0.9390\n",
      "Epoch [127/4500], Training Loss: 0.0424\n",
      "Epoch [127/4500], Validation Loss: 0.1425\n",
      "Accuracy: 0.9404, Precision: 0.9672, Recall: 0.9124, F1: 0.9390\n",
      "Epoch [128/4500], Training Loss: 0.0424\n",
      "Epoch [128/4500], Validation Loss: 0.1423\n",
      "Accuracy: 0.9404, Precision: 0.9672, Recall: 0.9124, F1: 0.9390\n",
      "Epoch [129/4500], Training Loss: 0.0419\n",
      "Epoch [129/4500], Validation Loss: 0.1419\n",
      "Accuracy: 0.9404, Precision: 0.9672, Recall: 0.9124, F1: 0.9390\n",
      "Epoch [130/4500], Training Loss: 0.0414\n",
      "Epoch [130/4500], Validation Loss: 0.1416\n",
      "Accuracy: 0.9404, Precision: 0.9672, Recall: 0.9124, F1: 0.9390\n",
      "Epoch [131/4500], Training Loss: 0.0415\n",
      "Epoch [131/4500], Validation Loss: 0.1413\n",
      "Accuracy: 0.9404, Precision: 0.9672, Recall: 0.9124, F1: 0.9390\n",
      "Epoch [132/4500], Training Loss: 0.0408\n",
      "Epoch [132/4500], Validation Loss: 0.1409\n",
      "Accuracy: 0.9417, Precision: 0.9699, Recall: 0.9124, F1: 0.9402\n",
      "Epoch [133/4500], Training Loss: 0.0408\n",
      "Epoch [133/4500], Validation Loss: 0.1407\n",
      "Accuracy: 0.9430, Precision: 0.9725, Recall: 0.9124, F1: 0.9415\n",
      "Epoch [134/4500], Training Loss: 0.0404\n",
      "Epoch [134/4500], Validation Loss: 0.1404\n",
      "Accuracy: 0.9430, Precision: 0.9725, Recall: 0.9124, F1: 0.9415\n",
      "Epoch [135/4500], Training Loss: 0.0403\n",
      "Epoch [135/4500], Validation Loss: 0.1401\n",
      "Accuracy: 0.9443, Precision: 0.9752, Recall: 0.9124, F1: 0.9427\n",
      "Epoch [136/4500], Training Loss: 0.0398\n",
      "Epoch [136/4500], Validation Loss: 0.1400\n",
      "Accuracy: 0.9456, Precision: 0.9779, Recall: 0.9124, F1: 0.9440\n",
      "Epoch [137/4500], Training Loss: 0.0393\n",
      "Epoch [137/4500], Validation Loss: 0.1397\n",
      "Accuracy: 0.9456, Precision: 0.9779, Recall: 0.9124, F1: 0.9440\n",
      "Epoch [138/4500], Training Loss: 0.0389\n",
      "Epoch [138/4500], Validation Loss: 0.1395\n",
      "Accuracy: 0.9456, Precision: 0.9779, Recall: 0.9124, F1: 0.9440\n",
      "Epoch [139/4500], Training Loss: 0.0386\n",
      "Epoch [139/4500], Validation Loss: 0.1393\n",
      "Accuracy: 0.9456, Precision: 0.9779, Recall: 0.9124, F1: 0.9440\n",
      "Epoch [140/4500], Training Loss: 0.0383\n",
      "Epoch [140/4500], Validation Loss: 0.1391\n",
      "Accuracy: 0.9456, Precision: 0.9779, Recall: 0.9124, F1: 0.9440\n",
      "Epoch [141/4500], Training Loss: 0.0377\n",
      "Epoch [141/4500], Validation Loss: 0.1388\n",
      "Accuracy: 0.9456, Precision: 0.9779, Recall: 0.9124, F1: 0.9440\n",
      "Epoch [142/4500], Training Loss: 0.0377\n",
      "Epoch [142/4500], Validation Loss: 0.1386\n",
      "Accuracy: 0.9443, Precision: 0.9778, Recall: 0.9098, F1: 0.9426\n",
      "Epoch [143/4500], Training Loss: 0.0372\n",
      "Epoch [143/4500], Validation Loss: 0.1385\n",
      "Accuracy: 0.9443, Precision: 0.9778, Recall: 0.9098, F1: 0.9426\n",
      "Epoch [144/4500], Training Loss: 0.0370\n",
      "Epoch [144/4500], Validation Loss: 0.1382\n",
      "Accuracy: 0.9443, Precision: 0.9778, Recall: 0.9098, F1: 0.9426\n",
      "Epoch [145/4500], Training Loss: 0.0367\n",
      "Epoch [145/4500], Validation Loss: 0.1380\n",
      "Accuracy: 0.9456, Precision: 0.9806, Recall: 0.9098, F1: 0.9439\n",
      "Epoch [146/4500], Training Loss: 0.0362\n",
      "Epoch [146/4500], Validation Loss: 0.1378\n",
      "Accuracy: 0.9456, Precision: 0.9806, Recall: 0.9098, F1: 0.9439\n",
      "Epoch [147/4500], Training Loss: 0.0363\n",
      "Epoch [147/4500], Validation Loss: 0.1376\n",
      "Accuracy: 0.9456, Precision: 0.9806, Recall: 0.9098, F1: 0.9439\n",
      "Epoch [148/4500], Training Loss: 0.0360\n",
      "Epoch [148/4500], Validation Loss: 0.1374\n",
      "Accuracy: 0.9443, Precision: 0.9778, Recall: 0.9098, F1: 0.9426\n",
      "Epoch [149/4500], Training Loss: 0.0355\n",
      "Epoch [149/4500], Validation Loss: 0.1371\n",
      "Accuracy: 0.9443, Precision: 0.9778, Recall: 0.9098, F1: 0.9426\n",
      "Epoch [150/4500], Training Loss: 0.0355\n",
      "Epoch [150/4500], Validation Loss: 0.1370\n",
      "Accuracy: 0.9443, Precision: 0.9778, Recall: 0.9098, F1: 0.9426\n",
      "Epoch [151/4500], Training Loss: 0.0352\n",
      "Epoch [151/4500], Validation Loss: 0.1368\n",
      "Accuracy: 0.9443, Precision: 0.9778, Recall: 0.9098, F1: 0.9426\n",
      "Epoch [152/4500], Training Loss: 0.0351\n",
      "Epoch [152/4500], Validation Loss: 0.1366\n",
      "Accuracy: 0.9443, Precision: 0.9778, Recall: 0.9098, F1: 0.9426\n",
      "Epoch [153/4500], Training Loss: 0.0348\n",
      "Epoch [153/4500], Validation Loss: 0.1364\n",
      "Accuracy: 0.9443, Precision: 0.9778, Recall: 0.9098, F1: 0.9426\n",
      "Epoch [154/4500], Training Loss: 0.0345\n",
      "Epoch [154/4500], Validation Loss: 0.1362\n",
      "Accuracy: 0.9456, Precision: 0.9806, Recall: 0.9098, F1: 0.9439\n",
      "Epoch [155/4500], Training Loss: 0.0343\n",
      "Epoch [155/4500], Validation Loss: 0.1361\n",
      "Accuracy: 0.9456, Precision: 0.9806, Recall: 0.9098, F1: 0.9439\n",
      "Epoch [156/4500], Training Loss: 0.0340\n",
      "Epoch [156/4500], Validation Loss: 0.1359\n",
      "Accuracy: 0.9469, Precision: 0.9806, Recall: 0.9124, F1: 0.9453\n",
      "Epoch [157/4500], Training Loss: 0.0339\n",
      "Epoch [157/4500], Validation Loss: 0.1359\n",
      "Accuracy: 0.9469, Precision: 0.9806, Recall: 0.9124, F1: 0.9453\n",
      "Epoch [158/4500], Training Loss: 0.0336\n",
      "Epoch [158/4500], Validation Loss: 0.1356\n",
      "Accuracy: 0.9469, Precision: 0.9806, Recall: 0.9124, F1: 0.9453\n",
      "Epoch [159/4500], Training Loss: 0.0332\n",
      "Epoch [159/4500], Validation Loss: 0.1356\n",
      "Accuracy: 0.9469, Precision: 0.9806, Recall: 0.9124, F1: 0.9453\n",
      "Epoch [160/4500], Training Loss: 0.0330\n",
      "Epoch [160/4500], Validation Loss: 0.1354\n",
      "Accuracy: 0.9469, Precision: 0.9806, Recall: 0.9124, F1: 0.9453\n",
      "Epoch [161/4500], Training Loss: 0.0330\n",
      "Epoch [161/4500], Validation Loss: 0.1353\n",
      "Accuracy: 0.9469, Precision: 0.9806, Recall: 0.9124, F1: 0.9453\n",
      "Epoch [162/4500], Training Loss: 0.0329\n",
      "Epoch [162/4500], Validation Loss: 0.1352\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [163/4500], Training Loss: 0.0327\n",
      "Epoch [163/4500], Validation Loss: 0.1351\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [164/4500], Training Loss: 0.0323\n",
      "Epoch [164/4500], Validation Loss: 0.1350\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [165/4500], Training Loss: 0.0319\n",
      "Epoch [165/4500], Validation Loss: 0.1349\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [166/4500], Training Loss: 0.0317\n",
      "Epoch [166/4500], Validation Loss: 0.1347\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [167/4500], Training Loss: 0.0317\n",
      "Epoch [167/4500], Validation Loss: 0.1346\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [168/4500], Training Loss: 0.0313\n",
      "Epoch [168/4500], Validation Loss: 0.1345\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [169/4500], Training Loss: 0.0310\n",
      "Epoch [169/4500], Validation Loss: 0.1344\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [170/4500], Training Loss: 0.0309\n",
      "Epoch [170/4500], Validation Loss: 0.1343\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [171/4500], Training Loss: 0.0306\n",
      "Epoch [171/4500], Validation Loss: 0.1342\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [172/4500], Training Loss: 0.0303\n",
      "Epoch [172/4500], Validation Loss: 0.1341\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [173/4500], Training Loss: 0.0301\n",
      "Epoch [173/4500], Validation Loss: 0.1340\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [174/4500], Training Loss: 0.0299\n",
      "Epoch [174/4500], Validation Loss: 0.1341\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [175/4500], Training Loss: 0.0293\n",
      "Epoch [175/4500], Validation Loss: 0.1339\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [176/4500], Training Loss: 0.0293\n",
      "Epoch [176/4500], Validation Loss: 0.1338\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [177/4500], Training Loss: 0.0289\n",
      "Epoch [177/4500], Validation Loss: 0.1338\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [178/4500], Training Loss: 0.0289\n",
      "Epoch [178/4500], Validation Loss: 0.1337\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [179/4500], Training Loss: 0.0286\n",
      "Epoch [179/4500], Validation Loss: 0.1337\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [180/4500], Training Loss: 0.0284\n",
      "Epoch [180/4500], Validation Loss: 0.1336\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [181/4500], Training Loss: 0.0282\n",
      "Epoch [181/4500], Validation Loss: 0.1335\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [182/4500], Training Loss: 0.0280\n",
      "Epoch [182/4500], Validation Loss: 0.1334\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [183/4500], Training Loss: 0.0274\n",
      "Epoch [183/4500], Validation Loss: 0.1334\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [184/4500], Training Loss: 0.0275\n",
      "Epoch [184/4500], Validation Loss: 0.1333\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [185/4500], Training Loss: 0.0274\n",
      "Epoch [185/4500], Validation Loss: 0.1333\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [186/4500], Training Loss: 0.0269\n",
      "Epoch [186/4500], Validation Loss: 0.1331\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [187/4500], Training Loss: 0.0271\n",
      "Epoch [187/4500], Validation Loss: 0.1332\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [188/4500], Training Loss: 0.0266\n",
      "Epoch [188/4500], Validation Loss: 0.1331\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [189/4500], Training Loss: 0.0263\n",
      "Epoch [189/4500], Validation Loss: 0.1330\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [190/4500], Training Loss: 0.0262\n",
      "Epoch [190/4500], Validation Loss: 0.1329\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [191/4500], Training Loss: 0.0260\n",
      "Epoch [191/4500], Validation Loss: 0.1329\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [192/4500], Training Loss: 0.0258\n",
      "Epoch [192/4500], Validation Loss: 0.1328\n",
      "Accuracy: 0.9482, Precision: 0.9780, Recall: 0.9175, F1: 0.9468\n",
      "Epoch [193/4500], Training Loss: 0.0256\n",
      "Epoch [193/4500], Validation Loss: 0.1327\n",
      "Accuracy: 0.9482, Precision: 0.9780, Recall: 0.9175, F1: 0.9468\n",
      "Epoch [194/4500], Training Loss: 0.0253\n",
      "Epoch [194/4500], Validation Loss: 0.1327\n",
      "Accuracy: 0.9482, Precision: 0.9780, Recall: 0.9175, F1: 0.9468\n",
      "Epoch [195/4500], Training Loss: 0.0253\n",
      "Epoch [195/4500], Validation Loss: 0.1327\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [196/4500], Training Loss: 0.0249\n",
      "Epoch [196/4500], Validation Loss: 0.1325\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [197/4500], Training Loss: 0.0248\n",
      "Epoch [197/4500], Validation Loss: 0.1325\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [198/4500], Training Loss: 0.0247\n",
      "Epoch [198/4500], Validation Loss: 0.1325\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [199/4500], Training Loss: 0.0244\n",
      "Epoch [199/4500], Validation Loss: 0.1324\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [200/4500], Training Loss: 0.0241\n",
      "Epoch [200/4500], Validation Loss: 0.1324\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [201/4500], Training Loss: 0.0243\n",
      "Epoch [201/4500], Validation Loss: 0.1324\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [202/4500], Training Loss: 0.0241\n",
      "Epoch [202/4500], Validation Loss: 0.1323\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [203/4500], Training Loss: 0.0239\n",
      "Epoch [203/4500], Validation Loss: 0.1323\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [204/4500], Training Loss: 0.0237\n",
      "Epoch [204/4500], Validation Loss: 0.1322\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [205/4500], Training Loss: 0.0234\n",
      "Epoch [205/4500], Validation Loss: 0.1323\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [206/4500], Training Loss: 0.0234\n",
      "Epoch [206/4500], Validation Loss: 0.1322\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [207/4500], Training Loss: 0.0231\n",
      "Epoch [207/4500], Validation Loss: 0.1322\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [208/4500], Training Loss: 0.0227\n",
      "Epoch [208/4500], Validation Loss: 0.1321\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [209/4500], Training Loss: 0.0228\n",
      "Epoch [209/4500], Validation Loss: 0.1322\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [210/4500], Training Loss: 0.0224\n",
      "Epoch [210/4500], Validation Loss: 0.1320\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [211/4500], Training Loss: 0.0222\n",
      "Epoch [211/4500], Validation Loss: 0.1320\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [212/4500], Training Loss: 0.0222\n",
      "Epoch [212/4500], Validation Loss: 0.1320\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [213/4500], Training Loss: 0.0217\n",
      "Epoch [213/4500], Validation Loss: 0.1319\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [214/4500], Training Loss: 0.0219\n",
      "Epoch [214/4500], Validation Loss: 0.1322\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [215/4500], Training Loss: 0.0217\n",
      "Epoch [215/4500], Validation Loss: 0.1322\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [216/4500], Training Loss: 0.0214\n",
      "Epoch [216/4500], Validation Loss: 0.1321\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [217/4500], Training Loss: 0.0212\n",
      "Epoch [217/4500], Validation Loss: 0.1320\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [218/4500], Training Loss: 0.0210\n",
      "Epoch [218/4500], Validation Loss: 0.1320\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [219/4500], Training Loss: 0.0208\n",
      "Epoch [219/4500], Validation Loss: 0.1321\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [220/4500], Training Loss: 0.0206\n",
      "Epoch [220/4500], Validation Loss: 0.1319\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [221/4500], Training Loss: 0.0206\n",
      "Epoch [221/4500], Validation Loss: 0.1320\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [222/4500], Training Loss: 0.0204\n",
      "Epoch [222/4500], Validation Loss: 0.1319\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [223/4500], Training Loss: 0.0203\n",
      "Epoch [223/4500], Validation Loss: 0.1319\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [224/4500], Training Loss: 0.0200\n",
      "Epoch [224/4500], Validation Loss: 0.1321\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [225/4500], Training Loss: 0.0199\n",
      "Epoch [225/4500], Validation Loss: 0.1319\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [226/4500], Training Loss: 0.0198\n",
      "Epoch [226/4500], Validation Loss: 0.1319\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [227/4500], Training Loss: 0.0197\n",
      "Epoch [227/4500], Validation Loss: 0.1320\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [228/4500], Training Loss: 0.0194\n",
      "Epoch [228/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [229/4500], Training Loss: 0.0193\n",
      "Epoch [229/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [230/4500], Training Loss: 0.0190\n",
      "Epoch [230/4500], Validation Loss: 0.1320\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [231/4500], Training Loss: 0.0189\n",
      "Epoch [231/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [232/4500], Training Loss: 0.0187\n",
      "Epoch [232/4500], Validation Loss: 0.1321\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [233/4500], Training Loss: 0.0185\n",
      "Epoch [233/4500], Validation Loss: 0.1319\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [234/4500], Training Loss: 0.0184\n",
      "Epoch [234/4500], Validation Loss: 0.1319\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [235/4500], Training Loss: 0.0184\n",
      "Epoch [235/4500], Validation Loss: 0.1319\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [236/4500], Training Loss: 0.0181\n",
      "Epoch [236/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [237/4500], Training Loss: 0.0181\n",
      "Epoch [237/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [238/4500], Training Loss: 0.0178\n",
      "Epoch [238/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [239/4500], Training Loss: 0.0178\n",
      "Epoch [239/4500], Validation Loss: 0.1317\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [240/4500], Training Loss: 0.0176\n",
      "Epoch [240/4500], Validation Loss: 0.1317\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [241/4500], Training Loss: 0.0176\n",
      "Epoch [241/4500], Validation Loss: 0.1317\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [242/4500], Training Loss: 0.0172\n",
      "Epoch [242/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [243/4500], Training Loss: 0.0170\n",
      "Epoch [243/4500], Validation Loss: 0.1316\n",
      "Accuracy: 0.9469, Precision: 0.9780, Recall: 0.9149, F1: 0.9454\n",
      "Epoch [244/4500], Training Loss: 0.0169\n",
      "Epoch [244/4500], Validation Loss: 0.1317\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [245/4500], Training Loss: 0.0167\n",
      "Epoch [245/4500], Validation Loss: 0.1315\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [246/4500], Training Loss: 0.0166\n",
      "Epoch [246/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [247/4500], Training Loss: 0.0165\n",
      "Epoch [247/4500], Validation Loss: 0.1316\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [248/4500], Training Loss: 0.0163\n",
      "Epoch [248/4500], Validation Loss: 0.1316\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [249/4500], Training Loss: 0.0161\n",
      "Epoch [249/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [250/4500], Training Loss: 0.0160\n",
      "Epoch [250/4500], Validation Loss: 0.1317\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [251/4500], Training Loss: 0.0159\n",
      "Epoch [251/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [252/4500], Training Loss: 0.0158\n",
      "Epoch [252/4500], Validation Loss: 0.1317\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [253/4500], Training Loss: 0.0156\n",
      "Epoch [253/4500], Validation Loss: 0.1319\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [254/4500], Training Loss: 0.0155\n",
      "Epoch [254/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [255/4500], Training Loss: 0.0155\n",
      "Epoch [255/4500], Validation Loss: 0.1319\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [256/4500], Training Loss: 0.0153\n",
      "Epoch [256/4500], Validation Loss: 0.1317\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [257/4500], Training Loss: 0.0152\n",
      "Epoch [257/4500], Validation Loss: 0.1319\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [258/4500], Training Loss: 0.0152\n",
      "Epoch [258/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [259/4500], Training Loss: 0.0150\n",
      "Epoch [259/4500], Validation Loss: 0.1319\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [260/4500], Training Loss: 0.0150\n",
      "Epoch [260/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [261/4500], Training Loss: 0.0148\n",
      "Epoch [261/4500], Validation Loss: 0.1319\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [262/4500], Training Loss: 0.0147\n",
      "Epoch [262/4500], Validation Loss: 0.1317\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [263/4500], Training Loss: 0.0145\n",
      "Epoch [263/4500], Validation Loss: 0.1320\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [264/4500], Training Loss: 0.0145\n",
      "Epoch [264/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [265/4500], Training Loss: 0.0144\n",
      "Epoch [265/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [266/4500], Training Loss: 0.0144\n",
      "Epoch [266/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [267/4500], Training Loss: 0.0142\n",
      "Epoch [267/4500], Validation Loss: 0.1319\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [268/4500], Training Loss: 0.0141\n",
      "Epoch [268/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [269/4500], Training Loss: 0.0140\n",
      "Epoch [269/4500], Validation Loss: 0.1319\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [270/4500], Training Loss: 0.0141\n",
      "Epoch [270/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [271/4500], Training Loss: 0.0139\n",
      "Epoch [271/4500], Validation Loss: 0.1319\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [272/4500], Training Loss: 0.0138\n",
      "Epoch [272/4500], Validation Loss: 0.1319\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [273/4500], Training Loss: 0.0137\n",
      "Epoch [273/4500], Validation Loss: 0.1319\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [274/4500], Training Loss: 0.0136\n",
      "Epoch [274/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [275/4500], Training Loss: 0.0135\n",
      "Epoch [275/4500], Validation Loss: 0.1319\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [276/4500], Training Loss: 0.0135\n",
      "Epoch [276/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [277/4500], Training Loss: 0.0132\n",
      "Epoch [277/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [278/4500], Training Loss: 0.0132\n",
      "Epoch [278/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [279/4500], Training Loss: 0.0130\n",
      "Epoch [279/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [280/4500], Training Loss: 0.0130\n",
      "Epoch [280/4500], Validation Loss: 0.1317\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [281/4500], Training Loss: 0.0129\n",
      "Epoch [281/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [282/4500], Training Loss: 0.0127\n",
      "Epoch [282/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [283/4500], Training Loss: 0.0126\n",
      "Epoch [283/4500], Validation Loss: 0.1319\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [284/4500], Training Loss: 0.0125\n",
      "Epoch [284/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [285/4500], Training Loss: 0.0124\n",
      "Epoch [285/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [286/4500], Training Loss: 0.0124\n",
      "Epoch [286/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [287/4500], Training Loss: 0.0121\n",
      "Epoch [287/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [288/4500], Training Loss: 0.0122\n",
      "Epoch [288/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [289/4500], Training Loss: 0.0122\n",
      "Epoch [289/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [290/4500], Training Loss: 0.0121\n",
      "Epoch [290/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [291/4500], Training Loss: 0.0121\n",
      "Epoch [291/4500], Validation Loss: 0.1317\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [292/4500], Training Loss: 0.0121\n",
      "Epoch [292/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9469, Precision: 0.9806, Recall: 0.9124, F1: 0.9453\n",
      "Epoch [293/4500], Training Loss: 0.0120\n",
      "Epoch [293/4500], Validation Loss: 0.1317\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [294/4500], Training Loss: 0.0120\n",
      "Epoch [294/4500], Validation Loss: 0.1317\n",
      "Accuracy: 0.9469, Precision: 0.9806, Recall: 0.9124, F1: 0.9453\n",
      "Epoch [295/4500], Training Loss: 0.0121\n",
      "Epoch [295/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [296/4500], Training Loss: 0.0119\n",
      "Epoch [296/4500], Validation Loss: 0.1317\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [297/4500], Training Loss: 0.0119\n",
      "Epoch [297/4500], Validation Loss: 0.1317\n",
      "Accuracy: 0.9469, Precision: 0.9806, Recall: 0.9124, F1: 0.9453\n",
      "Epoch [298/4500], Training Loss: 0.0118\n",
      "Epoch [298/4500], Validation Loss: 0.1316\n",
      "Accuracy: 0.9469, Precision: 0.9806, Recall: 0.9124, F1: 0.9453\n",
      "Epoch [299/4500], Training Loss: 0.0118\n",
      "Epoch [299/4500], Validation Loss: 0.1317\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [300/4500], Training Loss: 0.0117\n",
      "Epoch [300/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [301/4500], Training Loss: 0.0118\n",
      "Epoch [301/4500], Validation Loss: 0.1317\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [302/4500], Training Loss: 0.0115\n",
      "Epoch [302/4500], Validation Loss: 0.1317\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [303/4500], Training Loss: 0.0115\n",
      "Epoch [303/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [304/4500], Training Loss: 0.0114\n",
      "Epoch [304/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9469, Precision: 0.9806, Recall: 0.9124, F1: 0.9453\n",
      "Epoch [305/4500], Training Loss: 0.0113\n",
      "Epoch [305/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [306/4500], Training Loss: 0.0113\n",
      "Epoch [306/4500], Validation Loss: 0.1319\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [307/4500], Training Loss: 0.0112\n",
      "Epoch [307/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9469, Precision: 0.9806, Recall: 0.9124, F1: 0.9453\n",
      "Epoch [308/4500], Training Loss: 0.0111\n",
      "Epoch [308/4500], Validation Loss: 0.1319\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [309/4500], Training Loss: 0.0111\n",
      "Epoch [309/4500], Validation Loss: 0.1319\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [310/4500], Training Loss: 0.0110\n",
      "Epoch [310/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [311/4500], Training Loss: 0.0110\n",
      "Epoch [311/4500], Validation Loss: 0.1319\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [312/4500], Training Loss: 0.0109\n",
      "Epoch [312/4500], Validation Loss: 0.1318\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [313/4500], Training Loss: 0.0108\n",
      "Epoch [313/4500], Validation Loss: 0.1320\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [314/4500], Training Loss: 0.0108\n",
      "Epoch [314/4500], Validation Loss: 0.1320\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [315/4500], Training Loss: 0.0107\n",
      "Epoch [315/4500], Validation Loss: 0.1321\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [316/4500], Training Loss: 0.0106\n",
      "Epoch [316/4500], Validation Loss: 0.1320\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [317/4500], Training Loss: 0.0105\n",
      "Epoch [317/4500], Validation Loss: 0.1321\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [318/4500], Training Loss: 0.0104\n",
      "Epoch [318/4500], Validation Loss: 0.1320\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [319/4500], Training Loss: 0.0103\n",
      "Epoch [319/4500], Validation Loss: 0.1321\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [320/4500], Training Loss: 0.0103\n",
      "Epoch [320/4500], Validation Loss: 0.1321\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [321/4500], Training Loss: 0.0102\n",
      "Epoch [321/4500], Validation Loss: 0.1323\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [322/4500], Training Loss: 0.0101\n",
      "Epoch [322/4500], Validation Loss: 0.1321\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [323/4500], Training Loss: 0.0098\n",
      "Epoch [323/4500], Validation Loss: 0.1320\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [324/4500], Training Loss: 0.0099\n",
      "Epoch [324/4500], Validation Loss: 0.1320\n",
      "Accuracy: 0.9482, Precision: 0.9807, Recall: 0.9149, F1: 0.9467\n",
      "Epoch [325/4500], Training Loss: 0.0099\n",
      "Epoch [325/4500], Validation Loss: 0.1323\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [326/4500], Training Loss: 0.0097\n",
      "Epoch [326/4500], Validation Loss: 0.1322\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [327/4500], Training Loss: 0.0095\n",
      "Epoch [327/4500], Validation Loss: 0.1322\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [328/4500], Training Loss: 0.0097\n",
      "Epoch [328/4500], Validation Loss: 0.1321\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [329/4500], Training Loss: 0.0096\n",
      "Epoch [329/4500], Validation Loss: 0.1325\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [330/4500], Training Loss: 0.0097\n",
      "Epoch [330/4500], Validation Loss: 0.1323\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [331/4500], Training Loss: 0.0095\n",
      "Epoch [331/4500], Validation Loss: 0.1326\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [332/4500], Training Loss: 0.0094\n",
      "Epoch [332/4500], Validation Loss: 0.1324\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [333/4500], Training Loss: 0.0092\n",
      "Epoch [333/4500], Validation Loss: 0.1323\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [334/4500], Training Loss: 0.0092\n",
      "Epoch [334/4500], Validation Loss: 0.1324\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [335/4500], Training Loss: 0.0092\n",
      "Epoch [335/4500], Validation Loss: 0.1328\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [336/4500], Training Loss: 0.0092\n",
      "Epoch [336/4500], Validation Loss: 0.1326\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [337/4500], Training Loss: 0.0090\n",
      "Epoch [337/4500], Validation Loss: 0.1328\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [338/4500], Training Loss: 0.0090\n",
      "Epoch [338/4500], Validation Loss: 0.1327\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [339/4500], Training Loss: 0.0090\n",
      "Epoch [339/4500], Validation Loss: 0.1330\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [340/4500], Training Loss: 0.0089\n",
      "Epoch [340/4500], Validation Loss: 0.1330\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [341/4500], Training Loss: 0.0087\n",
      "Epoch [341/4500], Validation Loss: 0.1330\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [342/4500], Training Loss: 0.0088\n",
      "Epoch [342/4500], Validation Loss: 0.1329\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [343/4500], Training Loss: 0.0086\n",
      "Epoch [343/4500], Validation Loss: 0.1329\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [344/4500], Training Loss: 0.0086\n",
      "Epoch [344/4500], Validation Loss: 0.1329\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [345/4500], Training Loss: 0.0086\n",
      "Epoch [345/4500], Validation Loss: 0.1332\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [346/4500], Training Loss: 0.0085\n",
      "Epoch [346/4500], Validation Loss: 0.1330\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [347/4500], Training Loss: 0.0083\n",
      "Epoch [347/4500], Validation Loss: 0.1331\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [348/4500], Training Loss: 0.0084\n",
      "Epoch [348/4500], Validation Loss: 0.1331\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [349/4500], Training Loss: 0.0083\n",
      "Epoch [349/4500], Validation Loss: 0.1333\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [350/4500], Training Loss: 0.0082\n",
      "Epoch [350/4500], Validation Loss: 0.1333\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [351/4500], Training Loss: 0.0081\n",
      "Epoch [351/4500], Validation Loss: 0.1331\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [352/4500], Training Loss: 0.0082\n",
      "Epoch [352/4500], Validation Loss: 0.1334\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [353/4500], Training Loss: 0.0081\n",
      "Epoch [353/4500], Validation Loss: 0.1333\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [354/4500], Training Loss: 0.0081\n",
      "Epoch [354/4500], Validation Loss: 0.1335\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [355/4500], Training Loss: 0.0080\n",
      "Epoch [355/4500], Validation Loss: 0.1336\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [356/4500], Training Loss: 0.0078\n",
      "Epoch [356/4500], Validation Loss: 0.1332\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [357/4500], Training Loss: 0.0079\n",
      "Epoch [357/4500], Validation Loss: 0.1335\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [358/4500], Training Loss: 0.0079\n",
      "Epoch [358/4500], Validation Loss: 0.1339\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [359/4500], Training Loss: 0.0078\n",
      "Epoch [359/4500], Validation Loss: 0.1337\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [360/4500], Training Loss: 0.0076\n",
      "Epoch [360/4500], Validation Loss: 0.1336\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [361/4500], Training Loss: 0.0077\n",
      "Epoch [361/4500], Validation Loss: 0.1338\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [362/4500], Training Loss: 0.0076\n",
      "Epoch [362/4500], Validation Loss: 0.1336\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [363/4500], Training Loss: 0.0076\n",
      "Epoch [363/4500], Validation Loss: 0.1337\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [364/4500], Training Loss: 0.0076\n",
      "Epoch [364/4500], Validation Loss: 0.1339\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [365/4500], Training Loss: 0.0075\n",
      "Epoch [365/4500], Validation Loss: 0.1341\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [366/4500], Training Loss: 0.0075\n",
      "Epoch [366/4500], Validation Loss: 0.1340\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [367/4500], Training Loss: 0.0073\n",
      "Epoch [367/4500], Validation Loss: 0.1340\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [368/4500], Training Loss: 0.0074\n",
      "Epoch [368/4500], Validation Loss: 0.1339\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [369/4500], Training Loss: 0.0074\n",
      "Epoch [369/4500], Validation Loss: 0.1340\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [370/4500], Training Loss: 0.0072\n",
      "Epoch [370/4500], Validation Loss: 0.1341\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [371/4500], Training Loss: 0.0072\n",
      "Epoch [371/4500], Validation Loss: 0.1341\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [372/4500], Training Loss: 0.0072\n",
      "Epoch [372/4500], Validation Loss: 0.1343\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [373/4500], Training Loss: 0.0072\n",
      "Epoch [373/4500], Validation Loss: 0.1345\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [374/4500], Training Loss: 0.0069\n",
      "Epoch [374/4500], Validation Loss: 0.1341\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [375/4500], Training Loss: 0.0071\n",
      "Epoch [375/4500], Validation Loss: 0.1343\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [376/4500], Training Loss: 0.0069\n",
      "Epoch [376/4500], Validation Loss: 0.1344\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [377/4500], Training Loss: 0.0070\n",
      "Epoch [377/4500], Validation Loss: 0.1344\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [378/4500], Training Loss: 0.0069\n",
      "Epoch [378/4500], Validation Loss: 0.1348\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [379/4500], Training Loss: 0.0069\n",
      "Epoch [379/4500], Validation Loss: 0.1346\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [380/4500], Training Loss: 0.0067\n",
      "Epoch [380/4500], Validation Loss: 0.1345\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [381/4500], Training Loss: 0.0067\n",
      "Epoch [381/4500], Validation Loss: 0.1348\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [382/4500], Training Loss: 0.0068\n",
      "Epoch [382/4500], Validation Loss: 0.1348\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [383/4500], Training Loss: 0.0066\n",
      "Epoch [383/4500], Validation Loss: 0.1348\n",
      "Accuracy: 0.9495, Precision: 0.9807, Recall: 0.9175, F1: 0.9481\n",
      "Epoch [384/4500], Training Loss: 0.0067\n",
      "Epoch [384/4500], Validation Loss: 0.1348\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [385/4500], Training Loss: 0.0066\n",
      "Epoch [385/4500], Validation Loss: 0.1351\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [386/4500], Training Loss: 0.0066\n",
      "Epoch [386/4500], Validation Loss: 0.1352\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [387/4500], Training Loss: 0.0065\n",
      "Epoch [387/4500], Validation Loss: 0.1348\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [388/4500], Training Loss: 0.0065\n",
      "Epoch [388/4500], Validation Loss: 0.1351\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [389/4500], Training Loss: 0.0064\n",
      "Epoch [389/4500], Validation Loss: 0.1350\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [390/4500], Training Loss: 0.0063\n",
      "Epoch [390/4500], Validation Loss: 0.1348\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [391/4500], Training Loss: 0.0064\n",
      "Epoch [391/4500], Validation Loss: 0.1352\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [392/4500], Training Loss: 0.0064\n",
      "Epoch [392/4500], Validation Loss: 0.1351\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [393/4500], Training Loss: 0.0062\n",
      "Epoch [393/4500], Validation Loss: 0.1352\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [394/4500], Training Loss: 0.0063\n",
      "Epoch [394/4500], Validation Loss: 0.1352\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [395/4500], Training Loss: 0.0062\n",
      "Epoch [395/4500], Validation Loss: 0.1355\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [396/4500], Training Loss: 0.0061\n",
      "Epoch [396/4500], Validation Loss: 0.1351\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [397/4500], Training Loss: 0.0061\n",
      "Epoch [397/4500], Validation Loss: 0.1353\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [398/4500], Training Loss: 0.0061\n",
      "Epoch [398/4500], Validation Loss: 0.1355\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [399/4500], Training Loss: 0.0059\n",
      "Epoch [399/4500], Validation Loss: 0.1352\n",
      "Accuracy: 0.9521, Precision: 0.9835, Recall: 0.9201, F1: 0.9507\n",
      "Epoch [400/4500], Training Loss: 0.0061\n",
      "Epoch [400/4500], Validation Loss: 0.1356\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [401/4500], Training Loss: 0.0060\n",
      "Epoch [401/4500], Validation Loss: 0.1356\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [402/4500], Training Loss: 0.0058\n",
      "Epoch [402/4500], Validation Loss: 0.1353\n",
      "Accuracy: 0.9521, Precision: 0.9835, Recall: 0.9201, F1: 0.9507\n",
      "Epoch [403/4500], Training Loss: 0.0059\n",
      "Epoch [403/4500], Validation Loss: 0.1358\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [404/4500], Training Loss: 0.0059\n",
      "Epoch [404/4500], Validation Loss: 0.1357\n",
      "Accuracy: 0.9521, Precision: 0.9835, Recall: 0.9201, F1: 0.9507\n",
      "Epoch [405/4500], Training Loss: 0.0059\n",
      "Epoch [405/4500], Validation Loss: 0.1359\n",
      "Accuracy: 0.9508, Precision: 0.9808, Recall: 0.9201, F1: 0.9495\n",
      "Epoch [406/4500], Training Loss: 0.0058\n",
      "Epoch [406/4500], Validation Loss: 0.1360\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [407/4500], Training Loss: 0.0058\n",
      "Epoch [407/4500], Validation Loss: 0.1359\n",
      "Accuracy: 0.9521, Precision: 0.9835, Recall: 0.9201, F1: 0.9507\n",
      "Epoch [408/4500], Training Loss: 0.0057\n",
      "Epoch [408/4500], Validation Loss: 0.1359\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [409/4500], Training Loss: 0.0057\n",
      "Epoch [409/4500], Validation Loss: 0.1360\n",
      "Accuracy: 0.9521, Precision: 0.9835, Recall: 0.9201, F1: 0.9507\n",
      "Epoch [410/4500], Training Loss: 0.0056\n",
      "Epoch [410/4500], Validation Loss: 0.1359\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [411/4500], Training Loss: 0.0056\n",
      "Epoch [411/4500], Validation Loss: 0.1361\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [412/4500], Training Loss: 0.0057\n",
      "Epoch [412/4500], Validation Loss: 0.1362\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [413/4500], Training Loss: 0.0056\n",
      "Epoch [413/4500], Validation Loss: 0.1365\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [414/4500], Training Loss: 0.0055\n",
      "Epoch [414/4500], Validation Loss: 0.1360\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [415/4500], Training Loss: 0.0055\n",
      "Epoch [415/4500], Validation Loss: 0.1362\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [416/4500], Training Loss: 0.0055\n",
      "Epoch [416/4500], Validation Loss: 0.1364\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [417/4500], Training Loss: 0.0054\n",
      "Epoch [417/4500], Validation Loss: 0.1363\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [418/4500], Training Loss: 0.0055\n",
      "Epoch [418/4500], Validation Loss: 0.1366\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [419/4500], Training Loss: 0.0055\n",
      "Epoch [419/4500], Validation Loss: 0.1366\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [420/4500], Training Loss: 0.0053\n",
      "Epoch [420/4500], Validation Loss: 0.1367\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [421/4500], Training Loss: 0.0055\n",
      "Epoch [421/4500], Validation Loss: 0.1367\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [422/4500], Training Loss: 0.0053\n",
      "Epoch [422/4500], Validation Loss: 0.1366\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [423/4500], Training Loss: 0.0053\n",
      "Epoch [423/4500], Validation Loss: 0.1368\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [424/4500], Training Loss: 0.0053\n",
      "Epoch [424/4500], Validation Loss: 0.1369\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [425/4500], Training Loss: 0.0052\n",
      "Epoch [425/4500], Validation Loss: 0.1365\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [426/4500], Training Loss: 0.0052\n",
      "Epoch [426/4500], Validation Loss: 0.1369\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [427/4500], Training Loss: 0.0052\n",
      "Epoch [427/4500], Validation Loss: 0.1370\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [428/4500], Training Loss: 0.0052\n",
      "Epoch [428/4500], Validation Loss: 0.1369\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [429/4500], Training Loss: 0.0050\n",
      "Epoch [429/4500], Validation Loss: 0.1367\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [430/4500], Training Loss: 0.0051\n",
      "Epoch [430/4500], Validation Loss: 0.1370\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [431/4500], Training Loss: 0.0050\n",
      "Epoch [431/4500], Validation Loss: 0.1371\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [432/4500], Training Loss: 0.0049\n",
      "Epoch [432/4500], Validation Loss: 0.1368\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [433/4500], Training Loss: 0.0049\n",
      "Epoch [433/4500], Validation Loss: 0.1372\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [434/4500], Training Loss: 0.0049\n",
      "Epoch [434/4500], Validation Loss: 0.1372\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [435/4500], Training Loss: 0.0048\n",
      "Epoch [435/4500], Validation Loss: 0.1369\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [436/4500], Training Loss: 0.0049\n",
      "Epoch [436/4500], Validation Loss: 0.1373\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [437/4500], Training Loss: 0.0048\n",
      "Epoch [437/4500], Validation Loss: 0.1373\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [438/4500], Training Loss: 0.0048\n",
      "Epoch [438/4500], Validation Loss: 0.1373\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [439/4500], Training Loss: 0.0048\n",
      "Epoch [439/4500], Validation Loss: 0.1375\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [440/4500], Training Loss: 0.0047\n",
      "Epoch [440/4500], Validation Loss: 0.1373\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [441/4500], Training Loss: 0.0047\n",
      "Epoch [441/4500], Validation Loss: 0.1375\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [442/4500], Training Loss: 0.0046\n",
      "Epoch [442/4500], Validation Loss: 0.1375\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [443/4500], Training Loss: 0.0046\n",
      "Epoch [443/4500], Validation Loss: 0.1373\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [444/4500], Training Loss: 0.0045\n",
      "Epoch [444/4500], Validation Loss: 0.1376\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [445/4500], Training Loss: 0.0045\n",
      "Epoch [445/4500], Validation Loss: 0.1375\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [446/4500], Training Loss: 0.0046\n",
      "Epoch [446/4500], Validation Loss: 0.1377\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [447/4500], Training Loss: 0.0046\n",
      "Epoch [447/4500], Validation Loss: 0.1379\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [448/4500], Training Loss: 0.0045\n",
      "Epoch [448/4500], Validation Loss: 0.1374\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [449/4500], Training Loss: 0.0044\n",
      "Epoch [449/4500], Validation Loss: 0.1378\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [450/4500], Training Loss: 0.0045\n",
      "Epoch [450/4500], Validation Loss: 0.1380\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [451/4500], Training Loss: 0.0044\n",
      "Epoch [451/4500], Validation Loss: 0.1383\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [452/4500], Training Loss: 0.0044\n",
      "Epoch [452/4500], Validation Loss: 0.1380\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [453/4500], Training Loss: 0.0044\n",
      "Epoch [453/4500], Validation Loss: 0.1383\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [454/4500], Training Loss: 0.0043\n",
      "Epoch [454/4500], Validation Loss: 0.1382\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [455/4500], Training Loss: 0.0044\n",
      "Epoch [455/4500], Validation Loss: 0.1384\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [456/4500], Training Loss: 0.0043\n",
      "Epoch [456/4500], Validation Loss: 0.1385\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [457/4500], Training Loss: 0.0042\n",
      "Epoch [457/4500], Validation Loss: 0.1382\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [458/4500], Training Loss: 0.0042\n",
      "Epoch [458/4500], Validation Loss: 0.1384\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [459/4500], Training Loss: 0.0042\n",
      "Epoch [459/4500], Validation Loss: 0.1385\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [460/4500], Training Loss: 0.0041\n",
      "Epoch [460/4500], Validation Loss: 0.1384\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [461/4500], Training Loss: 0.0041\n",
      "Epoch [461/4500], Validation Loss: 0.1388\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [462/4500], Training Loss: 0.0042\n",
      "Epoch [462/4500], Validation Loss: 0.1387\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [463/4500], Training Loss: 0.0041\n",
      "Epoch [463/4500], Validation Loss: 0.1386\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [464/4500], Training Loss: 0.0041\n",
      "Epoch [464/4500], Validation Loss: 0.1387\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [465/4500], Training Loss: 0.0041\n",
      "Epoch [465/4500], Validation Loss: 0.1386\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [466/4500], Training Loss: 0.0040\n",
      "Epoch [466/4500], Validation Loss: 0.1388\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [467/4500], Training Loss: 0.0041\n",
      "Epoch [467/4500], Validation Loss: 0.1389\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [468/4500], Training Loss: 0.0041\n",
      "Epoch [468/4500], Validation Loss: 0.1390\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [469/4500], Training Loss: 0.0040\n",
      "Epoch [469/4500], Validation Loss: 0.1393\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [470/4500], Training Loss: 0.0039\n",
      "Epoch [470/4500], Validation Loss: 0.1388\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [471/4500], Training Loss: 0.0039\n",
      "Epoch [471/4500], Validation Loss: 0.1390\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [472/4500], Training Loss: 0.0039\n",
      "Epoch [472/4500], Validation Loss: 0.1391\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [473/4500], Training Loss: 0.0039\n",
      "Epoch [473/4500], Validation Loss: 0.1395\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [474/4500], Training Loss: 0.0039\n",
      "Epoch [474/4500], Validation Loss: 0.1394\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [475/4500], Training Loss: 0.0039\n",
      "Epoch [475/4500], Validation Loss: 0.1391\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [476/4500], Training Loss: 0.0038\n",
      "Epoch [476/4500], Validation Loss: 0.1395\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [477/4500], Training Loss: 0.0038\n",
      "Epoch [477/4500], Validation Loss: 0.1394\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [478/4500], Training Loss: 0.0038\n",
      "Epoch [478/4500], Validation Loss: 0.1395\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [479/4500], Training Loss: 0.0038\n",
      "Epoch [479/4500], Validation Loss: 0.1396\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [480/4500], Training Loss: 0.0038\n",
      "Epoch [480/4500], Validation Loss: 0.1397\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [481/4500], Training Loss: 0.0037\n",
      "Epoch [481/4500], Validation Loss: 0.1397\n",
      "Accuracy: 0.9508, Precision: 0.9781, Recall: 0.9227, F1: 0.9496\n",
      "Epoch [482/4500], Training Loss: 0.0038\n",
      "Epoch [482/4500], Validation Loss: 0.1397\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [483/4500], Training Loss: 0.0037\n",
      "Epoch [483/4500], Validation Loss: 0.1397\n",
      "Accuracy: 0.9534, Precision: 0.9835, Recall: 0.9227, F1: 0.9521\n",
      "Epoch [484/4500], Training Loss: 0.0037\n",
      "Epoch [484/4500], Validation Loss: 0.1400\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [485/4500], Training Loss: 0.0037\n",
      "Epoch [485/4500], Validation Loss: 0.1400\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [486/4500], Training Loss: 0.0036\n",
      "Epoch [486/4500], Validation Loss: 0.1399\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [487/4500], Training Loss: 0.0036\n",
      "Epoch [487/4500], Validation Loss: 0.1398\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [488/4500], Training Loss: 0.0035\n",
      "Epoch [488/4500], Validation Loss: 0.1400\n",
      "Accuracy: 0.9534, Precision: 0.9809, Recall: 0.9253, F1: 0.9523\n",
      "Epoch [489/4500], Training Loss: 0.0036\n",
      "Epoch [489/4500], Validation Loss: 0.1402\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [490/4500], Training Loss: 0.0036\n",
      "Epoch [490/4500], Validation Loss: 0.1401\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [491/4500], Training Loss: 0.0035\n",
      "Epoch [491/4500], Validation Loss: 0.1400\n",
      "Accuracy: 0.9534, Precision: 0.9809, Recall: 0.9253, F1: 0.9523\n",
      "Epoch [492/4500], Training Loss: 0.0035\n",
      "Epoch [492/4500], Validation Loss: 0.1403\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [493/4500], Training Loss: 0.0035\n",
      "Epoch [493/4500], Validation Loss: 0.1406\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [494/4500], Training Loss: 0.0036\n",
      "Epoch [494/4500], Validation Loss: 0.1406\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [495/4500], Training Loss: 0.0034\n",
      "Epoch [495/4500], Validation Loss: 0.1405\n",
      "Accuracy: 0.9534, Precision: 0.9809, Recall: 0.9253, F1: 0.9523\n",
      "Epoch [496/4500], Training Loss: 0.0034\n",
      "Epoch [496/4500], Validation Loss: 0.1406\n",
      "Accuracy: 0.9534, Precision: 0.9809, Recall: 0.9253, F1: 0.9523\n",
      "Epoch [497/4500], Training Loss: 0.0034\n",
      "Epoch [497/4500], Validation Loss: 0.1406\n",
      "Accuracy: 0.9534, Precision: 0.9809, Recall: 0.9253, F1: 0.9523\n",
      "Epoch [498/4500], Training Loss: 0.0034\n",
      "Epoch [498/4500], Validation Loss: 0.1407\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [499/4500], Training Loss: 0.0033\n",
      "Epoch [499/4500], Validation Loss: 0.1405\n",
      "Accuracy: 0.9534, Precision: 0.9809, Recall: 0.9253, F1: 0.9523\n",
      "Epoch [500/4500], Training Loss: 0.0034\n",
      "Epoch [500/4500], Validation Loss: 0.1409\n",
      "Accuracy: 0.9534, Precision: 0.9809, Recall: 0.9253, F1: 0.9523\n",
      "Epoch [501/4500], Training Loss: 0.0034\n",
      "Epoch [501/4500], Validation Loss: 0.1410\n",
      "Accuracy: 0.9534, Precision: 0.9809, Recall: 0.9253, F1: 0.9523\n",
      "Epoch [502/4500], Training Loss: 0.0033\n",
      "Epoch [502/4500], Validation Loss: 0.1407\n",
      "Accuracy: 0.9534, Precision: 0.9809, Recall: 0.9253, F1: 0.9523\n",
      "Epoch [503/4500], Training Loss: 0.0034\n",
      "Epoch [503/4500], Validation Loss: 0.1412\n",
      "Accuracy: 0.9521, Precision: 0.9808, Recall: 0.9227, F1: 0.9509\n",
      "Epoch [504/4500], Training Loss: 0.0033\n",
      "Epoch [504/4500], Validation Loss: 0.1411\n",
      "Accuracy: 0.9534, Precision: 0.9809, Recall: 0.9253, F1: 0.9523\n",
      "Epoch [505/4500], Training Loss: 0.0033\n",
      "Epoch [505/4500], Validation Loss: 0.1414\n",
      "Accuracy: 0.9534, Precision: 0.9809, Recall: 0.9253, F1: 0.9523\n",
      "Epoch [506/4500], Training Loss: 0.0032\n",
      "Epoch [506/4500], Validation Loss: 0.1409\n",
      "Accuracy: 0.9534, Precision: 0.9809, Recall: 0.9253, F1: 0.9523\n",
      "Epoch [507/4500], Training Loss: 0.0033\n",
      "Epoch [507/4500], Validation Loss: 0.1412\n",
      "Accuracy: 0.9534, Precision: 0.9809, Recall: 0.9253, F1: 0.9523\n",
      "Epoch [508/4500], Training Loss: 0.0032\n",
      "Epoch [508/4500], Validation Loss: 0.1412\n",
      "Accuracy: 0.9534, Precision: 0.9809, Recall: 0.9253, F1: 0.9523\n",
      "Epoch [509/4500], Training Loss: 0.0032\n",
      "Epoch [509/4500], Validation Loss: 0.1410\n",
      "Accuracy: 0.9534, Precision: 0.9809, Recall: 0.9253, F1: 0.9523\n",
      "Epoch [510/4500], Training Loss: 0.0032\n",
      "Epoch [510/4500], Validation Loss: 0.1413\n",
      "Accuracy: 0.9534, Precision: 0.9809, Recall: 0.9253, F1: 0.9523\n",
      "Epoch [511/4500], Training Loss: 0.0033\n",
      "Epoch [511/4500], Validation Loss: 0.1417\n",
      "Accuracy: 0.9534, Precision: 0.9809, Recall: 0.9253, F1: 0.9523\n",
      "Epoch [512/4500], Training Loss: 0.0032\n",
      "Epoch [512/4500], Validation Loss: 0.1417\n",
      "Accuracy: 0.9534, Precision: 0.9809, Recall: 0.9253, F1: 0.9523\n",
      "Epoch [513/4500], Training Loss: 0.0031\n",
      "Epoch [513/4500], Validation Loss: 0.1415\n",
      "Accuracy: 0.9534, Precision: 0.9809, Recall: 0.9253, F1: 0.9523\n",
      "Epoch [514/4500], Training Loss: 0.0031\n",
      "Epoch [514/4500], Validation Loss: 0.1419\n",
      "Accuracy: 0.9534, Precision: 0.9809, Recall: 0.9253, F1: 0.9523\n",
      "Epoch [515/4500], Training Loss: 0.0031\n",
      "Epoch [515/4500], Validation Loss: 0.1419\n",
      "Accuracy: 0.9521, Precision: 0.9782, Recall: 0.9253, F1: 0.9510\n",
      "Epoch [516/4500], Training Loss: 0.0031\n",
      "Epoch [516/4500], Validation Loss: 0.1417\n",
      "Accuracy: 0.9534, Precision: 0.9809, Recall: 0.9253, F1: 0.9523\n",
      "Epoch [517/4500], Training Loss: 0.0031\n",
      "Epoch [517/4500], Validation Loss: 0.1420\n",
      "Accuracy: 0.9521, Precision: 0.9782, Recall: 0.9253, F1: 0.9510\n",
      "Epoch [518/4500], Training Loss: 0.0030\n",
      "Epoch [518/4500], Validation Loss: 0.1419\n",
      "Accuracy: 0.9521, Precision: 0.9782, Recall: 0.9253, F1: 0.9510\n",
      "Epoch [519/4500], Training Loss: 0.0030\n",
      "Epoch [519/4500], Validation Loss: 0.1418\n",
      "Accuracy: 0.9521, Precision: 0.9782, Recall: 0.9253, F1: 0.9510\n",
      "Epoch [520/4500], Training Loss: 0.0030\n",
      "Epoch [520/4500], Validation Loss: 0.1421\n",
      "Accuracy: 0.9521, Precision: 0.9782, Recall: 0.9253, F1: 0.9510\n",
      "Epoch [521/4500], Training Loss: 0.0031\n",
      "Epoch [521/4500], Validation Loss: 0.1424\n",
      "Accuracy: 0.9521, Precision: 0.9782, Recall: 0.9253, F1: 0.9510\n",
      "Epoch [522/4500], Training Loss: 0.0030\n",
      "Epoch [522/4500], Validation Loss: 0.1424\n",
      "Accuracy: 0.9521, Precision: 0.9782, Recall: 0.9253, F1: 0.9510\n",
      "Epoch [523/4500], Training Loss: 0.0030\n",
      "Epoch [523/4500], Validation Loss: 0.1421\n",
      "Accuracy: 0.9521, Precision: 0.9782, Recall: 0.9253, F1: 0.9510\n",
      "Epoch [524/4500], Training Loss: 0.0029\n",
      "Epoch [524/4500], Validation Loss: 0.1426\n",
      "Accuracy: 0.9521, Precision: 0.9782, Recall: 0.9253, F1: 0.9510\n",
      "Epoch [525/4500], Training Loss: 0.0030\n",
      "Epoch [525/4500], Validation Loss: 0.1425\n",
      "Accuracy: 0.9521, Precision: 0.9782, Recall: 0.9253, F1: 0.9510\n",
      "Epoch [526/4500], Training Loss: 0.0029\n",
      "Epoch [526/4500], Validation Loss: 0.1425\n",
      "Accuracy: 0.9521, Precision: 0.9782, Recall: 0.9253, F1: 0.9510\n",
      "Epoch [527/4500], Training Loss: 0.0030\n",
      "Epoch [527/4500], Validation Loss: 0.1426\n",
      "Accuracy: 0.9521, Precision: 0.9782, Recall: 0.9253, F1: 0.9510\n",
      "Epoch [528/4500], Training Loss: 0.0029\n",
      "Epoch [528/4500], Validation Loss: 0.1428\n",
      "Accuracy: 0.9521, Precision: 0.9782, Recall: 0.9253, F1: 0.9510\n",
      "Epoch [529/4500], Training Loss: 0.0029\n",
      "Epoch [529/4500], Validation Loss: 0.1426\n",
      "Accuracy: 0.9521, Precision: 0.9782, Recall: 0.9253, F1: 0.9510\n",
      "Epoch [530/4500], Training Loss: 0.0029\n",
      "Epoch [530/4500], Validation Loss: 0.1428\n",
      "Accuracy: 0.9521, Precision: 0.9782, Recall: 0.9253, F1: 0.9510\n",
      "Epoch [531/4500], Training Loss: 0.0029\n",
      "Epoch [531/4500], Validation Loss: 0.1430\n",
      "Accuracy: 0.9521, Precision: 0.9782, Recall: 0.9253, F1: 0.9510\n",
      "Epoch [532/4500], Training Loss: 0.0029\n",
      "Epoch [532/4500], Validation Loss: 0.1429\n",
      "Accuracy: 0.9521, Precision: 0.9782, Recall: 0.9253, F1: 0.9510\n",
      "Epoch [533/4500], Training Loss: 0.0029\n",
      "Epoch [533/4500], Validation Loss: 0.1430\n",
      "Accuracy: 0.9508, Precision: 0.9781, Recall: 0.9227, F1: 0.9496\n",
      "Epoch [534/4500], Training Loss: 0.0028\n",
      "Epoch [534/4500], Validation Loss: 0.1427\n",
      "Accuracy: 0.9521, Precision: 0.9782, Recall: 0.9253, F1: 0.9510\n",
      "Epoch [535/4500], Training Loss: 0.0028\n",
      "Epoch [535/4500], Validation Loss: 0.1433\n",
      "Accuracy: 0.9521, Precision: 0.9782, Recall: 0.9253, F1: 0.9510\n",
      "Epoch [536/4500], Training Loss: 0.0027\n",
      "Epoch [536/4500], Validation Loss: 0.1429\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [537/4500], Training Loss: 0.0028\n",
      "Epoch [537/4500], Validation Loss: 0.1433\n",
      "Accuracy: 0.9521, Precision: 0.9782, Recall: 0.9253, F1: 0.9510\n",
      "Epoch [538/4500], Training Loss: 0.0028\n",
      "Epoch [538/4500], Validation Loss: 0.1433\n",
      "Accuracy: 0.9521, Precision: 0.9782, Recall: 0.9253, F1: 0.9510\n",
      "Epoch [539/4500], Training Loss: 0.0027\n",
      "Epoch [539/4500], Validation Loss: 0.1435\n",
      "Accuracy: 0.9508, Precision: 0.9781, Recall: 0.9227, F1: 0.9496\n",
      "Epoch [540/4500], Training Loss: 0.0027\n",
      "Epoch [540/4500], Validation Loss: 0.1435\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [541/4500], Training Loss: 0.0027\n",
      "Epoch [541/4500], Validation Loss: 0.1435\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [542/4500], Training Loss: 0.0027\n",
      "Epoch [542/4500], Validation Loss: 0.1438\n",
      "Accuracy: 0.9508, Precision: 0.9781, Recall: 0.9227, F1: 0.9496\n",
      "Epoch [543/4500], Training Loss: 0.0027\n",
      "Epoch [543/4500], Validation Loss: 0.1436\n",
      "Accuracy: 0.9508, Precision: 0.9781, Recall: 0.9227, F1: 0.9496\n",
      "Epoch [544/4500], Training Loss: 0.0027\n",
      "Epoch [544/4500], Validation Loss: 0.1437\n",
      "Accuracy: 0.9508, Precision: 0.9781, Recall: 0.9227, F1: 0.9496\n",
      "Epoch [545/4500], Training Loss: 0.0027\n",
      "Epoch [545/4500], Validation Loss: 0.1440\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [546/4500], Training Loss: 0.0027\n",
      "Epoch [546/4500], Validation Loss: 0.1441\n",
      "Accuracy: 0.9508, Precision: 0.9781, Recall: 0.9227, F1: 0.9496\n",
      "Epoch [547/4500], Training Loss: 0.0026\n",
      "Epoch [547/4500], Validation Loss: 0.1441\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [548/4500], Training Loss: 0.0026\n",
      "Epoch [548/4500], Validation Loss: 0.1439\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [549/4500], Training Loss: 0.0026\n",
      "Epoch [549/4500], Validation Loss: 0.1442\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [550/4500], Training Loss: 0.0026\n",
      "Epoch [550/4500], Validation Loss: 0.1441\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [551/4500], Training Loss: 0.0026\n",
      "Epoch [551/4500], Validation Loss: 0.1445\n",
      "Accuracy: 0.9508, Precision: 0.9781, Recall: 0.9227, F1: 0.9496\n",
      "Epoch [552/4500], Training Loss: 0.0025\n",
      "Epoch [552/4500], Validation Loss: 0.1445\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [553/4500], Training Loss: 0.0026\n",
      "Epoch [553/4500], Validation Loss: 0.1444\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [554/4500], Training Loss: 0.0025\n",
      "Epoch [554/4500], Validation Loss: 0.1447\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [555/4500], Training Loss: 0.0025\n",
      "Epoch [555/4500], Validation Loss: 0.1446\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [556/4500], Training Loss: 0.0025\n",
      "Epoch [556/4500], Validation Loss: 0.1444\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [557/4500], Training Loss: 0.0025\n",
      "Epoch [557/4500], Validation Loss: 0.1447\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [558/4500], Training Loss: 0.0025\n",
      "Epoch [558/4500], Validation Loss: 0.1449\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [559/4500], Training Loss: 0.0024\n",
      "Epoch [559/4500], Validation Loss: 0.1447\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [560/4500], Training Loss: 0.0025\n",
      "Epoch [560/4500], Validation Loss: 0.1451\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [561/4500], Training Loss: 0.0024\n",
      "Epoch [561/4500], Validation Loss: 0.1451\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [562/4500], Training Loss: 0.0024\n",
      "Epoch [562/4500], Validation Loss: 0.1449\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [563/4500], Training Loss: 0.0023\n",
      "Epoch [563/4500], Validation Loss: 0.1453\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [564/4500], Training Loss: 0.0024\n",
      "Epoch [564/4500], Validation Loss: 0.1454\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [565/4500], Training Loss: 0.0023\n",
      "Epoch [565/4500], Validation Loss: 0.1452\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [566/4500], Training Loss: 0.0024\n",
      "Epoch [566/4500], Validation Loss: 0.1456\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [567/4500], Training Loss: 0.0023\n",
      "Epoch [567/4500], Validation Loss: 0.1455\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [568/4500], Training Loss: 0.0023\n",
      "Epoch [568/4500], Validation Loss: 0.1455\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [569/4500], Training Loss: 0.0023\n",
      "Epoch [569/4500], Validation Loss: 0.1455\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [570/4500], Training Loss: 0.0023\n",
      "Epoch [570/4500], Validation Loss: 0.1458\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [571/4500], Training Loss: 0.0023\n",
      "Epoch [571/4500], Validation Loss: 0.1457\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [572/4500], Training Loss: 0.0023\n",
      "Epoch [572/4500], Validation Loss: 0.1461\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [573/4500], Training Loss: 0.0023\n",
      "Epoch [573/4500], Validation Loss: 0.1463\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [574/4500], Training Loss: 0.0022\n",
      "Epoch [574/4500], Validation Loss: 0.1463\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [575/4500], Training Loss: 0.0023\n",
      "Epoch [575/4500], Validation Loss: 0.1460\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [576/4500], Training Loss: 0.0022\n",
      "Epoch [576/4500], Validation Loss: 0.1462\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [577/4500], Training Loss: 0.0022\n",
      "Epoch [577/4500], Validation Loss: 0.1466\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [578/4500], Training Loss: 0.0022\n",
      "Epoch [578/4500], Validation Loss: 0.1467\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [579/4500], Training Loss: 0.0022\n",
      "Epoch [579/4500], Validation Loss: 0.1466\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [580/4500], Training Loss: 0.0021\n",
      "Epoch [580/4500], Validation Loss: 0.1468\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [581/4500], Training Loss: 0.0021\n",
      "Epoch [581/4500], Validation Loss: 0.1468\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [582/4500], Training Loss: 0.0022\n",
      "Epoch [582/4500], Validation Loss: 0.1469\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [583/4500], Training Loss: 0.0021\n",
      "Epoch [583/4500], Validation Loss: 0.1472\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [584/4500], Training Loss: 0.0021\n",
      "Epoch [584/4500], Validation Loss: 0.1473\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [585/4500], Training Loss: 0.0021\n",
      "Epoch [585/4500], Validation Loss: 0.1474\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [586/4500], Training Loss: 0.0021\n",
      "Epoch [586/4500], Validation Loss: 0.1472\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [587/4500], Training Loss: 0.0021\n",
      "Epoch [587/4500], Validation Loss: 0.1473\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [588/4500], Training Loss: 0.0020\n",
      "Epoch [588/4500], Validation Loss: 0.1475\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [589/4500], Training Loss: 0.0020\n",
      "Epoch [589/4500], Validation Loss: 0.1477\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [590/4500], Training Loss: 0.0021\n",
      "Epoch [590/4500], Validation Loss: 0.1478\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [591/4500], Training Loss: 0.0020\n",
      "Epoch [591/4500], Validation Loss: 0.1476\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [592/4500], Training Loss: 0.0020\n",
      "Epoch [592/4500], Validation Loss: 0.1478\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [593/4500], Training Loss: 0.0020\n",
      "Epoch [593/4500], Validation Loss: 0.1482\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [594/4500], Training Loss: 0.0020\n",
      "Epoch [594/4500], Validation Loss: 0.1482\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [595/4500], Training Loss: 0.0020\n",
      "Epoch [595/4500], Validation Loss: 0.1485\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [596/4500], Training Loss: 0.0020\n",
      "Epoch [596/4500], Validation Loss: 0.1485\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [597/4500], Training Loss: 0.0019\n",
      "Epoch [597/4500], Validation Loss: 0.1482\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [598/4500], Training Loss: 0.0019\n",
      "Epoch [598/4500], Validation Loss: 0.1486\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [599/4500], Training Loss: 0.0019\n",
      "Epoch [599/4500], Validation Loss: 0.1488\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [600/4500], Training Loss: 0.0019\n",
      "Epoch [600/4500], Validation Loss: 0.1488\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [601/4500], Training Loss: 0.0019\n",
      "Epoch [601/4500], Validation Loss: 0.1488\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [602/4500], Training Loss: 0.0019\n",
      "Epoch [602/4500], Validation Loss: 0.1490\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [603/4500], Training Loss: 0.0019\n",
      "Epoch [603/4500], Validation Loss: 0.1492\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [604/4500], Training Loss: 0.0019\n",
      "Epoch [604/4500], Validation Loss: 0.1491\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [605/4500], Training Loss: 0.0018\n",
      "Epoch [605/4500], Validation Loss: 0.1493\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [606/4500], Training Loss: 0.0019\n",
      "Epoch [606/4500], Validation Loss: 0.1497\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [607/4500], Training Loss: 0.0018\n",
      "Epoch [607/4500], Validation Loss: 0.1494\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [608/4500], Training Loss: 0.0019\n",
      "Epoch [608/4500], Validation Loss: 0.1495\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [609/4500], Training Loss: 0.0018\n",
      "Epoch [609/4500], Validation Loss: 0.1492\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [610/4500], Training Loss: 0.0018\n",
      "Epoch [610/4500], Validation Loss: 0.1498\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [611/4500], Training Loss: 0.0018\n",
      "Epoch [611/4500], Validation Loss: 0.1499\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [612/4500], Training Loss: 0.0018\n",
      "Epoch [612/4500], Validation Loss: 0.1502\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [613/4500], Training Loss: 0.0018\n",
      "Epoch [613/4500], Validation Loss: 0.1502\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [614/4500], Training Loss: 0.0018\n",
      "Epoch [614/4500], Validation Loss: 0.1502\n",
      "Accuracy: 0.9482, Precision: 0.9754, Recall: 0.9201, F1: 0.9469\n",
      "Epoch [615/4500], Training Loss: 0.0018\n",
      "Epoch [615/4500], Validation Loss: 0.1501\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [616/4500], Training Loss: 0.0018\n",
      "Epoch [616/4500], Validation Loss: 0.1503\n",
      "Accuracy: 0.9482, Precision: 0.9754, Recall: 0.9201, F1: 0.9469\n",
      "Epoch [617/4500], Training Loss: 0.0018\n",
      "Epoch [617/4500], Validation Loss: 0.1502\n",
      "Accuracy: 0.9482, Precision: 0.9754, Recall: 0.9201, F1: 0.9469\n",
      "Epoch [618/4500], Training Loss: 0.0017\n",
      "Epoch [618/4500], Validation Loss: 0.1503\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [619/4500], Training Loss: 0.0017\n",
      "Epoch [619/4500], Validation Loss: 0.1504\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [620/4500], Training Loss: 0.0017\n",
      "Epoch [620/4500], Validation Loss: 0.1506\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [621/4500], Training Loss: 0.0017\n",
      "Epoch [621/4500], Validation Loss: 0.1505\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [622/4500], Training Loss: 0.0017\n",
      "Epoch [622/4500], Validation Loss: 0.1508\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [623/4500], Training Loss: 0.0017\n",
      "Epoch [623/4500], Validation Loss: 0.1512\n",
      "Accuracy: 0.9482, Precision: 0.9754, Recall: 0.9201, F1: 0.9469\n",
      "Epoch [624/4500], Training Loss: 0.0016\n",
      "Epoch [624/4500], Validation Loss: 0.1509\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [625/4500], Training Loss: 0.0016\n",
      "Epoch [625/4500], Validation Loss: 0.1508\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [626/4500], Training Loss: 0.0017\n",
      "Epoch [626/4500], Validation Loss: 0.1512\n",
      "Accuracy: 0.9482, Precision: 0.9754, Recall: 0.9201, F1: 0.9469\n",
      "Epoch [627/4500], Training Loss: 0.0016\n",
      "Epoch [627/4500], Validation Loss: 0.1510\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [628/4500], Training Loss: 0.0017\n",
      "Epoch [628/4500], Validation Loss: 0.1512\n",
      "Accuracy: 0.9482, Precision: 0.9754, Recall: 0.9201, F1: 0.9469\n",
      "Epoch [629/4500], Training Loss: 0.0016\n",
      "Epoch [629/4500], Validation Loss: 0.1513\n",
      "Accuracy: 0.9482, Precision: 0.9754, Recall: 0.9201, F1: 0.9469\n",
      "Epoch [630/4500], Training Loss: 0.0016\n",
      "Epoch [630/4500], Validation Loss: 0.1514\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [631/4500], Training Loss: 0.0016\n",
      "Epoch [631/4500], Validation Loss: 0.1515\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [632/4500], Training Loss: 0.0016\n",
      "Epoch [632/4500], Validation Loss: 0.1518\n",
      "Accuracy: 0.9482, Precision: 0.9754, Recall: 0.9201, F1: 0.9469\n",
      "Epoch [633/4500], Training Loss: 0.0016\n",
      "Epoch [633/4500], Validation Loss: 0.1516\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [634/4500], Training Loss: 0.0016\n",
      "Epoch [634/4500], Validation Loss: 0.1515\n",
      "Accuracy: 0.9482, Precision: 0.9754, Recall: 0.9201, F1: 0.9469\n",
      "Epoch [635/4500], Training Loss: 0.0016\n",
      "Epoch [635/4500], Validation Loss: 0.1521\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [636/4500], Training Loss: 0.0016\n",
      "Epoch [636/4500], Validation Loss: 0.1521\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [637/4500], Training Loss: 0.0016\n",
      "Epoch [637/4500], Validation Loss: 0.1520\n",
      "Accuracy: 0.9482, Precision: 0.9754, Recall: 0.9201, F1: 0.9469\n",
      "Epoch [638/4500], Training Loss: 0.0015\n",
      "Epoch [638/4500], Validation Loss: 0.1520\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [639/4500], Training Loss: 0.0015\n",
      "Epoch [639/4500], Validation Loss: 0.1523\n",
      "Accuracy: 0.9482, Precision: 0.9754, Recall: 0.9201, F1: 0.9469\n",
      "Epoch [640/4500], Training Loss: 0.0015\n",
      "Epoch [640/4500], Validation Loss: 0.1524\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [641/4500], Training Loss: 0.0015\n",
      "Epoch [641/4500], Validation Loss: 0.1526\n",
      "Accuracy: 0.9482, Precision: 0.9754, Recall: 0.9201, F1: 0.9469\n",
      "Epoch [642/4500], Training Loss: 0.0015\n",
      "Epoch [642/4500], Validation Loss: 0.1526\n",
      "Accuracy: 0.9482, Precision: 0.9754, Recall: 0.9201, F1: 0.9469\n",
      "Epoch [643/4500], Training Loss: 0.0015\n",
      "Epoch [643/4500], Validation Loss: 0.1523\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [644/4500], Training Loss: 0.0015\n",
      "Epoch [644/4500], Validation Loss: 0.1528\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [645/4500], Training Loss: 0.0015\n",
      "Epoch [645/4500], Validation Loss: 0.1526\n",
      "Accuracy: 0.9482, Precision: 0.9754, Recall: 0.9201, F1: 0.9469\n",
      "Epoch [646/4500], Training Loss: 0.0015\n",
      "Epoch [646/4500], Validation Loss: 0.1532\n",
      "Accuracy: 0.9482, Precision: 0.9754, Recall: 0.9201, F1: 0.9469\n",
      "Epoch [647/4500], Training Loss: 0.0015\n",
      "Epoch [647/4500], Validation Loss: 0.1527\n",
      "Accuracy: 0.9482, Precision: 0.9754, Recall: 0.9201, F1: 0.9469\n",
      "Epoch [648/4500], Training Loss: 0.0015\n",
      "Epoch [648/4500], Validation Loss: 0.1531\n",
      "Accuracy: 0.9482, Precision: 0.9754, Recall: 0.9201, F1: 0.9469\n",
      "Epoch [649/4500], Training Loss: 0.0015\n",
      "Epoch [649/4500], Validation Loss: 0.1528\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [650/4500], Training Loss: 0.0015\n",
      "Epoch [650/4500], Validation Loss: 0.1531\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [651/4500], Training Loss: 0.0014\n",
      "Epoch [651/4500], Validation Loss: 0.1531\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [652/4500], Training Loss: 0.0015\n",
      "Epoch [652/4500], Validation Loss: 0.1535\n",
      "Accuracy: 0.9482, Precision: 0.9754, Recall: 0.9201, F1: 0.9469\n",
      "Epoch [653/4500], Training Loss: 0.0014\n",
      "Epoch [653/4500], Validation Loss: 0.1534\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [654/4500], Training Loss: 0.0014\n",
      "Epoch [654/4500], Validation Loss: 0.1536\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [655/4500], Training Loss: 0.0015\n",
      "Epoch [655/4500], Validation Loss: 0.1534\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [656/4500], Training Loss: 0.0014\n",
      "Epoch [656/4500], Validation Loss: 0.1537\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [657/4500], Training Loss: 0.0014\n",
      "Epoch [657/4500], Validation Loss: 0.1540\n",
      "Accuracy: 0.9482, Precision: 0.9754, Recall: 0.9201, F1: 0.9469\n",
      "Epoch [658/4500], Training Loss: 0.0014\n",
      "Epoch [658/4500], Validation Loss: 0.1539\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [659/4500], Training Loss: 0.0014\n",
      "Epoch [659/4500], Validation Loss: 0.1537\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [660/4500], Training Loss: 0.0014\n",
      "Epoch [660/4500], Validation Loss: 0.1540\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [661/4500], Training Loss: 0.0014\n",
      "Epoch [661/4500], Validation Loss: 0.1542\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [662/4500], Training Loss: 0.0013\n",
      "Epoch [662/4500], Validation Loss: 0.1542\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [663/4500], Training Loss: 0.0014\n",
      "Epoch [663/4500], Validation Loss: 0.1545\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [664/4500], Training Loss: 0.0014\n",
      "Epoch [664/4500], Validation Loss: 0.1542\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [665/4500], Training Loss: 0.0013\n",
      "Epoch [665/4500], Validation Loss: 0.1546\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [666/4500], Training Loss: 0.0013\n",
      "Epoch [666/4500], Validation Loss: 0.1548\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [667/4500], Training Loss: 0.0014\n",
      "Epoch [667/4500], Validation Loss: 0.1548\n",
      "Accuracy: 0.9482, Precision: 0.9754, Recall: 0.9201, F1: 0.9469\n",
      "Epoch [668/4500], Training Loss: 0.0013\n",
      "Epoch [668/4500], Validation Loss: 0.1545\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [669/4500], Training Loss: 0.0013\n",
      "Epoch [669/4500], Validation Loss: 0.1547\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [670/4500], Training Loss: 0.0013\n",
      "Epoch [670/4500], Validation Loss: 0.1550\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [671/4500], Training Loss: 0.0013\n",
      "Epoch [671/4500], Validation Loss: 0.1551\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [672/4500], Training Loss: 0.0013\n",
      "Epoch [672/4500], Validation Loss: 0.1549\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [673/4500], Training Loss: 0.0013\n",
      "Epoch [673/4500], Validation Loss: 0.1551\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [674/4500], Training Loss: 0.0013\n",
      "Epoch [674/4500], Validation Loss: 0.1552\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [675/4500], Training Loss: 0.0013\n",
      "Epoch [675/4500], Validation Loss: 0.1552\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [676/4500], Training Loss: 0.0013\n",
      "Epoch [676/4500], Validation Loss: 0.1556\n",
      "Accuracy: 0.9482, Precision: 0.9754, Recall: 0.9201, F1: 0.9469\n",
      "Epoch [677/4500], Training Loss: 0.0013\n",
      "Epoch [677/4500], Validation Loss: 0.1557\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [678/4500], Training Loss: 0.0012\n",
      "Epoch [678/4500], Validation Loss: 0.1553\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [679/4500], Training Loss: 0.0013\n",
      "Epoch [679/4500], Validation Loss: 0.1558\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [680/4500], Training Loss: 0.0013\n",
      "Epoch [680/4500], Validation Loss: 0.1557\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [681/4500], Training Loss: 0.0012\n",
      "Epoch [681/4500], Validation Loss: 0.1560\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [682/4500], Training Loss: 0.0012\n",
      "Epoch [682/4500], Validation Loss: 0.1557\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [683/4500], Training Loss: 0.0012\n",
      "Epoch [683/4500], Validation Loss: 0.1563\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [684/4500], Training Loss: 0.0012\n",
      "Epoch [684/4500], Validation Loss: 0.1561\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [685/4500], Training Loss: 0.0012\n",
      "Epoch [685/4500], Validation Loss: 0.1563\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [686/4500], Training Loss: 0.0012\n",
      "Epoch [686/4500], Validation Loss: 0.1559\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [687/4500], Training Loss: 0.0012\n",
      "Epoch [687/4500], Validation Loss: 0.1563\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [688/4500], Training Loss: 0.0012\n",
      "Epoch [688/4500], Validation Loss: 0.1567\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [689/4500], Training Loss: 0.0012\n",
      "Epoch [689/4500], Validation Loss: 0.1564\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [690/4500], Training Loss: 0.0012\n",
      "Epoch [690/4500], Validation Loss: 0.1568\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [691/4500], Training Loss: 0.0012\n",
      "Epoch [691/4500], Validation Loss: 0.1566\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [692/4500], Training Loss: 0.0012\n",
      "Epoch [692/4500], Validation Loss: 0.1568\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [693/4500], Training Loss: 0.0012\n",
      "Epoch [693/4500], Validation Loss: 0.1569\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [694/4500], Training Loss: 0.0012\n",
      "Epoch [694/4500], Validation Loss: 0.1571\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [695/4500], Training Loss: 0.0011\n",
      "Epoch [695/4500], Validation Loss: 0.1570\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [696/4500], Training Loss: 0.0012\n",
      "Epoch [696/4500], Validation Loss: 0.1570\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [697/4500], Training Loss: 0.0011\n",
      "Epoch [697/4500], Validation Loss: 0.1573\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [698/4500], Training Loss: 0.0012\n",
      "Epoch [698/4500], Validation Loss: 0.1574\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [699/4500], Training Loss: 0.0011\n",
      "Epoch [699/4500], Validation Loss: 0.1574\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [700/4500], Training Loss: 0.0011\n",
      "Epoch [700/4500], Validation Loss: 0.1576\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [701/4500], Training Loss: 0.0011\n",
      "Epoch [701/4500], Validation Loss: 0.1572\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [702/4500], Training Loss: 0.0011\n",
      "Epoch [702/4500], Validation Loss: 0.1576\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [703/4500], Training Loss: 0.0011\n",
      "Epoch [703/4500], Validation Loss: 0.1579\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [704/4500], Training Loss: 0.0011\n",
      "Epoch [704/4500], Validation Loss: 0.1578\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [705/4500], Training Loss: 0.0011\n",
      "Epoch [705/4500], Validation Loss: 0.1581\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [706/4500], Training Loss: 0.0011\n",
      "Epoch [706/4500], Validation Loss: 0.1580\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [707/4500], Training Loss: 0.0011\n",
      "Epoch [707/4500], Validation Loss: 0.1582\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [708/4500], Training Loss: 0.0011\n",
      "Epoch [708/4500], Validation Loss: 0.1580\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [709/4500], Training Loss: 0.0011\n",
      "Epoch [709/4500], Validation Loss: 0.1582\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [710/4500], Training Loss: 0.0011\n",
      "Epoch [710/4500], Validation Loss: 0.1582\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [711/4500], Training Loss: 0.0011\n",
      "Epoch [711/4500], Validation Loss: 0.1586\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [712/4500], Training Loss: 0.0011\n",
      "Epoch [712/4500], Validation Loss: 0.1586\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [713/4500], Training Loss: 0.0011\n",
      "Epoch [713/4500], Validation Loss: 0.1589\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [714/4500], Training Loss: 0.0011\n",
      "Epoch [714/4500], Validation Loss: 0.1587\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [715/4500], Training Loss: 0.0011\n",
      "Epoch [715/4500], Validation Loss: 0.1586\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [716/4500], Training Loss: 0.0011\n",
      "Epoch [716/4500], Validation Loss: 0.1593\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [717/4500], Training Loss: 0.0010\n",
      "Epoch [717/4500], Validation Loss: 0.1589\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [718/4500], Training Loss: 0.0010\n",
      "Epoch [718/4500], Validation Loss: 0.1591\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [719/4500], Training Loss: 0.0010\n",
      "Epoch [719/4500], Validation Loss: 0.1589\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [720/4500], Training Loss: 0.0010\n",
      "Epoch [720/4500], Validation Loss: 0.1593\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [721/4500], Training Loss: 0.0010\n",
      "Epoch [721/4500], Validation Loss: 0.1595\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [722/4500], Training Loss: 0.0010\n",
      "Epoch [722/4500], Validation Loss: 0.1595\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [723/4500], Training Loss: 0.0010\n",
      "Epoch [723/4500], Validation Loss: 0.1596\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [724/4500], Training Loss: 0.0010\n",
      "Epoch [724/4500], Validation Loss: 0.1594\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [725/4500], Training Loss: 0.0010\n",
      "Epoch [725/4500], Validation Loss: 0.1598\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [726/4500], Training Loss: 0.0010\n",
      "Epoch [726/4500], Validation Loss: 0.1599\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [727/4500], Training Loss: 0.0010\n",
      "Epoch [727/4500], Validation Loss: 0.1599\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [728/4500], Training Loss: 0.0010\n",
      "Epoch [728/4500], Validation Loss: 0.1603\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [729/4500], Training Loss: 0.0010\n",
      "Epoch [729/4500], Validation Loss: 0.1602\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [730/4500], Training Loss: 0.0010\n",
      "Epoch [730/4500], Validation Loss: 0.1602\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [731/4500], Training Loss: 0.0010\n",
      "Epoch [731/4500], Validation Loss: 0.1605\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [732/4500], Training Loss: 0.0010\n",
      "Epoch [732/4500], Validation Loss: 0.1604\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [733/4500], Training Loss: 0.0010\n",
      "Epoch [733/4500], Validation Loss: 0.1604\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [734/4500], Training Loss: 0.0009\n",
      "Epoch [734/4500], Validation Loss: 0.1605\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [735/4500], Training Loss: 0.0010\n",
      "Epoch [735/4500], Validation Loss: 0.1607\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [736/4500], Training Loss: 0.0009\n",
      "Epoch [736/4500], Validation Loss: 0.1604\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [737/4500], Training Loss: 0.0010\n",
      "Epoch [737/4500], Validation Loss: 0.1610\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [738/4500], Training Loss: 0.0009\n",
      "Epoch [738/4500], Validation Loss: 0.1610\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [739/4500], Training Loss: 0.0010\n",
      "Epoch [739/4500], Validation Loss: 0.1612\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [740/4500], Training Loss: 0.0009\n",
      "Epoch [740/4500], Validation Loss: 0.1610\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [741/4500], Training Loss: 0.0009\n",
      "Epoch [741/4500], Validation Loss: 0.1613\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [742/4500], Training Loss: 0.0009\n",
      "Epoch [742/4500], Validation Loss: 0.1610\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [743/4500], Training Loss: 0.0009\n",
      "Epoch [743/4500], Validation Loss: 0.1611\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [744/4500], Training Loss: 0.0009\n",
      "Epoch [744/4500], Validation Loss: 0.1617\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [745/4500], Training Loss: 0.0009\n",
      "Epoch [745/4500], Validation Loss: 0.1613\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [746/4500], Training Loss: 0.0009\n",
      "Epoch [746/4500], Validation Loss: 0.1618\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [747/4500], Training Loss: 0.0009\n",
      "Epoch [747/4500], Validation Loss: 0.1615\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [748/4500], Training Loss: 0.0009\n",
      "Epoch [748/4500], Validation Loss: 0.1619\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [749/4500], Training Loss: 0.0009\n",
      "Epoch [749/4500], Validation Loss: 0.1619\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [750/4500], Training Loss: 0.0009\n",
      "Epoch [750/4500], Validation Loss: 0.1621\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [751/4500], Training Loss: 0.0009\n",
      "Epoch [751/4500], Validation Loss: 0.1621\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [752/4500], Training Loss: 0.0009\n",
      "Epoch [752/4500], Validation Loss: 0.1620\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [753/4500], Training Loss: 0.0009\n",
      "Epoch [753/4500], Validation Loss: 0.1622\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [754/4500], Training Loss: 0.0009\n",
      "Epoch [754/4500], Validation Loss: 0.1625\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [755/4500], Training Loss: 0.0009\n",
      "Epoch [755/4500], Validation Loss: 0.1623\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [756/4500], Training Loss: 0.0009\n",
      "Epoch [756/4500], Validation Loss: 0.1627\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [757/4500], Training Loss: 0.0009\n",
      "Epoch [757/4500], Validation Loss: 0.1628\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [758/4500], Training Loss: 0.0008\n",
      "Epoch [758/4500], Validation Loss: 0.1629\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [759/4500], Training Loss: 0.0009\n",
      "Epoch [759/4500], Validation Loss: 0.1628\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [760/4500], Training Loss: 0.0008\n",
      "Epoch [760/4500], Validation Loss: 0.1626\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [761/4500], Training Loss: 0.0008\n",
      "Epoch [761/4500], Validation Loss: 0.1629\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [762/4500], Training Loss: 0.0009\n",
      "Epoch [762/4500], Validation Loss: 0.1631\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [763/4500], Training Loss: 0.0008\n",
      "Epoch [763/4500], Validation Loss: 0.1627\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [764/4500], Training Loss: 0.0008\n",
      "Epoch [764/4500], Validation Loss: 0.1635\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [765/4500], Training Loss: 0.0008\n",
      "Epoch [765/4500], Validation Loss: 0.1634\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [766/4500], Training Loss: 0.0008\n",
      "Epoch [766/4500], Validation Loss: 0.1634\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [767/4500], Training Loss: 0.0008\n",
      "Epoch [767/4500], Validation Loss: 0.1634\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [768/4500], Training Loss: 0.0008\n",
      "Epoch [768/4500], Validation Loss: 0.1635\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [769/4500], Training Loss: 0.0008\n",
      "Epoch [769/4500], Validation Loss: 0.1638\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [770/4500], Training Loss: 0.0008\n",
      "Epoch [770/4500], Validation Loss: 0.1638\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [771/4500], Training Loss: 0.0008\n",
      "Epoch [771/4500], Validation Loss: 0.1640\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [772/4500], Training Loss: 0.0008\n",
      "Epoch [772/4500], Validation Loss: 0.1641\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [773/4500], Training Loss: 0.0008\n",
      "Epoch [773/4500], Validation Loss: 0.1642\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [774/4500], Training Loss: 0.0008\n",
      "Epoch [774/4500], Validation Loss: 0.1639\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [775/4500], Training Loss: 0.0008\n",
      "Epoch [775/4500], Validation Loss: 0.1642\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [776/4500], Training Loss: 0.0008\n",
      "Epoch [776/4500], Validation Loss: 0.1642\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [777/4500], Training Loss: 0.0008\n",
      "Epoch [777/4500], Validation Loss: 0.1647\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [778/4500], Training Loss: 0.0008\n",
      "Epoch [778/4500], Validation Loss: 0.1645\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [779/4500], Training Loss: 0.0008\n",
      "Epoch [779/4500], Validation Loss: 0.1644\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [780/4500], Training Loss: 0.0008\n",
      "Epoch [780/4500], Validation Loss: 0.1644\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [781/4500], Training Loss: 0.0008\n",
      "Epoch [781/4500], Validation Loss: 0.1651\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [782/4500], Training Loss: 0.0008\n",
      "Epoch [782/4500], Validation Loss: 0.1649\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [783/4500], Training Loss: 0.0008\n",
      "Epoch [783/4500], Validation Loss: 0.1648\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [784/4500], Training Loss: 0.0008\n",
      "Epoch [784/4500], Validation Loss: 0.1650\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [785/4500], Training Loss: 0.0008\n",
      "Epoch [785/4500], Validation Loss: 0.1655\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [786/4500], Training Loss: 0.0007\n",
      "Epoch [786/4500], Validation Loss: 0.1650\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [787/4500], Training Loss: 0.0007\n",
      "Epoch [787/4500], Validation Loss: 0.1654\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [788/4500], Training Loss: 0.0008\n",
      "Epoch [788/4500], Validation Loss: 0.1654\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [789/4500], Training Loss: 0.0007\n",
      "Epoch [789/4500], Validation Loss: 0.1654\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [790/4500], Training Loss: 0.0008\n",
      "Epoch [790/4500], Validation Loss: 0.1653\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [791/4500], Training Loss: 0.0007\n",
      "Epoch [791/4500], Validation Loss: 0.1659\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [792/4500], Training Loss: 0.0008\n",
      "Epoch [792/4500], Validation Loss: 0.1657\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [793/4500], Training Loss: 0.0007\n",
      "Epoch [793/4500], Validation Loss: 0.1660\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [794/4500], Training Loss: 0.0007\n",
      "Epoch [794/4500], Validation Loss: 0.1659\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [795/4500], Training Loss: 0.0007\n",
      "Epoch [795/4500], Validation Loss: 0.1662\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [796/4500], Training Loss: 0.0007\n",
      "Epoch [796/4500], Validation Loss: 0.1659\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [797/4500], Training Loss: 0.0007\n",
      "Epoch [797/4500], Validation Loss: 0.1663\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [798/4500], Training Loss: 0.0007\n",
      "Epoch [798/4500], Validation Loss: 0.1663\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [799/4500], Training Loss: 0.0007\n",
      "Epoch [799/4500], Validation Loss: 0.1663\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [800/4500], Training Loss: 0.0007\n",
      "Epoch [800/4500], Validation Loss: 0.1666\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [801/4500], Training Loss: 0.0007\n",
      "Epoch [801/4500], Validation Loss: 0.1667\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [802/4500], Training Loss: 0.0007\n",
      "Epoch [802/4500], Validation Loss: 0.1668\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [803/4500], Training Loss: 0.0007\n",
      "Epoch [803/4500], Validation Loss: 0.1668\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [804/4500], Training Loss: 0.0007\n",
      "Epoch [804/4500], Validation Loss: 0.1670\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [805/4500], Training Loss: 0.0007\n",
      "Epoch [805/4500], Validation Loss: 0.1668\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [806/4500], Training Loss: 0.0007\n",
      "Epoch [806/4500], Validation Loss: 0.1673\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [807/4500], Training Loss: 0.0007\n",
      "Epoch [807/4500], Validation Loss: 0.1673\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [808/4500], Training Loss: 0.0007\n",
      "Epoch [808/4500], Validation Loss: 0.1676\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [809/4500], Training Loss: 0.0007\n",
      "Epoch [809/4500], Validation Loss: 0.1674\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [810/4500], Training Loss: 0.0007\n",
      "Epoch [810/4500], Validation Loss: 0.1674\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [811/4500], Training Loss: 0.0007\n",
      "Epoch [811/4500], Validation Loss: 0.1678\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [812/4500], Training Loss: 0.0007\n",
      "Epoch [812/4500], Validation Loss: 0.1678\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [813/4500], Training Loss: 0.0007\n",
      "Epoch [813/4500], Validation Loss: 0.1676\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [814/4500], Training Loss: 0.0007\n",
      "Epoch [814/4500], Validation Loss: 0.1676\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [815/4500], Training Loss: 0.0007\n",
      "Epoch [815/4500], Validation Loss: 0.1681\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [816/4500], Training Loss: 0.0007\n",
      "Epoch [816/4500], Validation Loss: 0.1682\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [817/4500], Training Loss: 0.0007\n",
      "Epoch [817/4500], Validation Loss: 0.1682\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [818/4500], Training Loss: 0.0007\n",
      "Epoch [818/4500], Validation Loss: 0.1685\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [819/4500], Training Loss: 0.0007\n",
      "Epoch [819/4500], Validation Loss: 0.1686\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [820/4500], Training Loss: 0.0007\n",
      "Epoch [820/4500], Validation Loss: 0.1684\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [821/4500], Training Loss: 0.0007\n",
      "Epoch [821/4500], Validation Loss: 0.1685\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [822/4500], Training Loss: 0.0007\n",
      "Epoch [822/4500], Validation Loss: 0.1684\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [823/4500], Training Loss: 0.0006\n",
      "Epoch [823/4500], Validation Loss: 0.1688\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [824/4500], Training Loss: 0.0006\n",
      "Epoch [824/4500], Validation Loss: 0.1690\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [825/4500], Training Loss: 0.0006\n",
      "Epoch [825/4500], Validation Loss: 0.1690\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [826/4500], Training Loss: 0.0006\n",
      "Epoch [826/4500], Validation Loss: 0.1690\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [827/4500], Training Loss: 0.0006\n",
      "Epoch [827/4500], Validation Loss: 0.1691\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [828/4500], Training Loss: 0.0006\n",
      "Epoch [828/4500], Validation Loss: 0.1690\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [829/4500], Training Loss: 0.0006\n",
      "Epoch [829/4500], Validation Loss: 0.1695\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [830/4500], Training Loss: 0.0006\n",
      "Epoch [830/4500], Validation Loss: 0.1695\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [831/4500], Training Loss: 0.0006\n",
      "Epoch [831/4500], Validation Loss: 0.1694\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [832/4500], Training Loss: 0.0006\n",
      "Epoch [832/4500], Validation Loss: 0.1695\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [833/4500], Training Loss: 0.0006\n",
      "Epoch [833/4500], Validation Loss: 0.1696\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [834/4500], Training Loss: 0.0006\n",
      "Epoch [834/4500], Validation Loss: 0.1697\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [835/4500], Training Loss: 0.0006\n",
      "Epoch [835/4500], Validation Loss: 0.1700\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [836/4500], Training Loss: 0.0006\n",
      "Epoch [836/4500], Validation Loss: 0.1699\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [837/4500], Training Loss: 0.0006\n",
      "Epoch [837/4500], Validation Loss: 0.1701\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [838/4500], Training Loss: 0.0006\n",
      "Epoch [838/4500], Validation Loss: 0.1703\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [839/4500], Training Loss: 0.0006\n",
      "Epoch [839/4500], Validation Loss: 0.1702\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [840/4500], Training Loss: 0.0006\n",
      "Epoch [840/4500], Validation Loss: 0.1704\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [841/4500], Training Loss: 0.0006\n",
      "Epoch [841/4500], Validation Loss: 0.1705\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [842/4500], Training Loss: 0.0006\n",
      "Epoch [842/4500], Validation Loss: 0.1706\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [843/4500], Training Loss: 0.0006\n",
      "Epoch [843/4500], Validation Loss: 0.1705\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [844/4500], Training Loss: 0.0006\n",
      "Epoch [844/4500], Validation Loss: 0.1708\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [845/4500], Training Loss: 0.0006\n",
      "Epoch [845/4500], Validation Loss: 0.1708\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [846/4500], Training Loss: 0.0006\n",
      "Epoch [846/4500], Validation Loss: 0.1711\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [847/4500], Training Loss: 0.0006\n",
      "Epoch [847/4500], Validation Loss: 0.1712\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [848/4500], Training Loss: 0.0006\n",
      "Epoch [848/4500], Validation Loss: 0.1713\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [849/4500], Training Loss: 0.0006\n",
      "Epoch [849/4500], Validation Loss: 0.1710\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [850/4500], Training Loss: 0.0006\n",
      "Epoch [850/4500], Validation Loss: 0.1711\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [851/4500], Training Loss: 0.0006\n",
      "Epoch [851/4500], Validation Loss: 0.1716\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [852/4500], Training Loss: 0.0006\n",
      "Epoch [852/4500], Validation Loss: 0.1714\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [853/4500], Training Loss: 0.0006\n",
      "Epoch [853/4500], Validation Loss: 0.1715\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [854/4500], Training Loss: 0.0006\n",
      "Epoch [854/4500], Validation Loss: 0.1714\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [855/4500], Training Loss: 0.0006\n",
      "Epoch [855/4500], Validation Loss: 0.1716\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [856/4500], Training Loss: 0.0006\n",
      "Epoch [856/4500], Validation Loss: 0.1717\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [857/4500], Training Loss: 0.0006\n",
      "Epoch [857/4500], Validation Loss: 0.1717\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [858/4500], Training Loss: 0.0005\n",
      "Epoch [858/4500], Validation Loss: 0.1721\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [859/4500], Training Loss: 0.0005\n",
      "Epoch [859/4500], Validation Loss: 0.1721\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [860/4500], Training Loss: 0.0005\n",
      "Epoch [860/4500], Validation Loss: 0.1720\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [861/4500], Training Loss: 0.0006\n",
      "Epoch [861/4500], Validation Loss: 0.1725\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [862/4500], Training Loss: 0.0006\n",
      "Epoch [862/4500], Validation Loss: 0.1725\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [863/4500], Training Loss: 0.0005\n",
      "Epoch [863/4500], Validation Loss: 0.1722\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [864/4500], Training Loss: 0.0005\n",
      "Epoch [864/4500], Validation Loss: 0.1725\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [865/4500], Training Loss: 0.0005\n",
      "Epoch [865/4500], Validation Loss: 0.1727\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [866/4500], Training Loss: 0.0005\n",
      "Epoch [866/4500], Validation Loss: 0.1726\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [867/4500], Training Loss: 0.0005\n",
      "Epoch [867/4500], Validation Loss: 0.1730\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [868/4500], Training Loss: 0.0005\n",
      "Epoch [868/4500], Validation Loss: 0.1730\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [869/4500], Training Loss: 0.0005\n",
      "Epoch [869/4500], Validation Loss: 0.1731\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [870/4500], Training Loss: 0.0005\n",
      "Epoch [870/4500], Validation Loss: 0.1729\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [871/4500], Training Loss: 0.0005\n",
      "Epoch [871/4500], Validation Loss: 0.1729\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [872/4500], Training Loss: 0.0005\n",
      "Epoch [872/4500], Validation Loss: 0.1736\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [873/4500], Training Loss: 0.0005\n",
      "Epoch [873/4500], Validation Loss: 0.1731\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [874/4500], Training Loss: 0.0005\n",
      "Epoch [874/4500], Validation Loss: 0.1733\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [875/4500], Training Loss: 0.0005\n",
      "Epoch [875/4500], Validation Loss: 0.1734\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [876/4500], Training Loss: 0.0005\n",
      "Epoch [876/4500], Validation Loss: 0.1736\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [877/4500], Training Loss: 0.0005\n",
      "Epoch [877/4500], Validation Loss: 0.1738\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [878/4500], Training Loss: 0.0005\n",
      "Epoch [878/4500], Validation Loss: 0.1739\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [879/4500], Training Loss: 0.0005\n",
      "Epoch [879/4500], Validation Loss: 0.1739\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [880/4500], Training Loss: 0.0005\n",
      "Epoch [880/4500], Validation Loss: 0.1738\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [881/4500], Training Loss: 0.0005\n",
      "Epoch [881/4500], Validation Loss: 0.1739\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [882/4500], Training Loss: 0.0005\n",
      "Epoch [882/4500], Validation Loss: 0.1744\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [883/4500], Training Loss: 0.0005\n",
      "Epoch [883/4500], Validation Loss: 0.1740\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [884/4500], Training Loss: 0.0005\n",
      "Epoch [884/4500], Validation Loss: 0.1741\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [885/4500], Training Loss: 0.0005\n",
      "Epoch [885/4500], Validation Loss: 0.1745\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [886/4500], Training Loss: 0.0005\n",
      "Epoch [886/4500], Validation Loss: 0.1745\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [887/4500], Training Loss: 0.0005\n",
      "Epoch [887/4500], Validation Loss: 0.1747\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [888/4500], Training Loss: 0.0005\n",
      "Epoch [888/4500], Validation Loss: 0.1746\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [889/4500], Training Loss: 0.0005\n",
      "Epoch [889/4500], Validation Loss: 0.1747\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [890/4500], Training Loss: 0.0005\n",
      "Epoch [890/4500], Validation Loss: 0.1746\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [891/4500], Training Loss: 0.0005\n",
      "Epoch [891/4500], Validation Loss: 0.1748\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [892/4500], Training Loss: 0.0005\n",
      "Epoch [892/4500], Validation Loss: 0.1753\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [893/4500], Training Loss: 0.0005\n",
      "Epoch [893/4500], Validation Loss: 0.1750\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [894/4500], Training Loss: 0.0005\n",
      "Epoch [894/4500], Validation Loss: 0.1751\n",
      "Accuracy: 0.9495, Precision: 0.9755, Recall: 0.9227, F1: 0.9483\n",
      "Epoch [895/4500], Training Loss: 0.0005\n",
      "Epoch [895/4500], Validation Loss: 0.1752\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [896/4500], Training Loss: 0.0005\n",
      "Epoch [896/4500], Validation Loss: 0.1751\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [897/4500], Training Loss: 0.0005\n",
      "Epoch [897/4500], Validation Loss: 0.1753\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [898/4500], Training Loss: 0.0005\n",
      "Epoch [898/4500], Validation Loss: 0.1757\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [899/4500], Training Loss: 0.0005\n",
      "Epoch [899/4500], Validation Loss: 0.1757\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [900/4500], Training Loss: 0.0005\n",
      "Epoch [900/4500], Validation Loss: 0.1757\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [901/4500], Training Loss: 0.0005\n",
      "Epoch [901/4500], Validation Loss: 0.1762\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [902/4500], Training Loss: 0.0005\n",
      "Epoch [902/4500], Validation Loss: 0.1759\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [903/4500], Training Loss: 0.0005\n",
      "Epoch [903/4500], Validation Loss: 0.1763\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [904/4500], Training Loss: 0.0005\n",
      "Epoch [904/4500], Validation Loss: 0.1763\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [905/4500], Training Loss: 0.0005\n",
      "Epoch [905/4500], Validation Loss: 0.1760\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [906/4500], Training Loss: 0.0005\n",
      "Epoch [906/4500], Validation Loss: 0.1765\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [907/4500], Training Loss: 0.0004\n",
      "Epoch [907/4500], Validation Loss: 0.1762\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [908/4500], Training Loss: 0.0004\n",
      "Epoch [908/4500], Validation Loss: 0.1764\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [909/4500], Training Loss: 0.0004\n",
      "Epoch [909/4500], Validation Loss: 0.1769\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [910/4500], Training Loss: 0.0005\n",
      "Epoch [910/4500], Validation Loss: 0.1770\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [911/4500], Training Loss: 0.0004\n",
      "Epoch [911/4500], Validation Loss: 0.1768\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [912/4500], Training Loss: 0.0004\n",
      "Epoch [912/4500], Validation Loss: 0.1768\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [913/4500], Training Loss: 0.0004\n",
      "Epoch [913/4500], Validation Loss: 0.1770\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [914/4500], Training Loss: 0.0004\n",
      "Epoch [914/4500], Validation Loss: 0.1771\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [915/4500], Training Loss: 0.0004\n",
      "Epoch [915/4500], Validation Loss: 0.1773\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [916/4500], Training Loss: 0.0004\n",
      "Epoch [916/4500], Validation Loss: 0.1770\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [917/4500], Training Loss: 0.0004\n",
      "Epoch [917/4500], Validation Loss: 0.1771\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [918/4500], Training Loss: 0.0004\n",
      "Epoch [918/4500], Validation Loss: 0.1776\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [919/4500], Training Loss: 0.0004\n",
      "Epoch [919/4500], Validation Loss: 0.1780\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [920/4500], Training Loss: 0.0004\n",
      "Epoch [920/4500], Validation Loss: 0.1776\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [921/4500], Training Loss: 0.0004\n",
      "Epoch [921/4500], Validation Loss: 0.1777\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [922/4500], Training Loss: 0.0004\n",
      "Epoch [922/4500], Validation Loss: 0.1780\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [923/4500], Training Loss: 0.0004\n",
      "Epoch [923/4500], Validation Loss: 0.1780\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [924/4500], Training Loss: 0.0004\n",
      "Epoch [924/4500], Validation Loss: 0.1778\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [925/4500], Training Loss: 0.0004\n",
      "Epoch [925/4500], Validation Loss: 0.1783\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [926/4500], Training Loss: 0.0004\n",
      "Epoch [926/4500], Validation Loss: 0.1783\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [927/4500], Training Loss: 0.0004\n",
      "Epoch [927/4500], Validation Loss: 0.1784\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [928/4500], Training Loss: 0.0004\n",
      "Epoch [928/4500], Validation Loss: 0.1784\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [929/4500], Training Loss: 0.0004\n",
      "Epoch [929/4500], Validation Loss: 0.1784\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [930/4500], Training Loss: 0.0004\n",
      "Epoch [930/4500], Validation Loss: 0.1785\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [931/4500], Training Loss: 0.0004\n",
      "Epoch [931/4500], Validation Loss: 0.1790\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [932/4500], Training Loss: 0.0004\n",
      "Epoch [932/4500], Validation Loss: 0.1787\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [933/4500], Training Loss: 0.0004\n",
      "Epoch [933/4500], Validation Loss: 0.1788\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [934/4500], Training Loss: 0.0004\n",
      "Epoch [934/4500], Validation Loss: 0.1787\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [935/4500], Training Loss: 0.0004\n",
      "Epoch [935/4500], Validation Loss: 0.1793\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [936/4500], Training Loss: 0.0004\n",
      "Epoch [936/4500], Validation Loss: 0.1791\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [937/4500], Training Loss: 0.0004\n",
      "Epoch [937/4500], Validation Loss: 0.1792\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [938/4500], Training Loss: 0.0004\n",
      "Epoch [938/4500], Validation Loss: 0.1794\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [939/4500], Training Loss: 0.0004\n",
      "Epoch [939/4500], Validation Loss: 0.1794\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [940/4500], Training Loss: 0.0004\n",
      "Epoch [940/4500], Validation Loss: 0.1795\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [941/4500], Training Loss: 0.0004\n",
      "Epoch [941/4500], Validation Loss: 0.1799\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [942/4500], Training Loss: 0.0004\n",
      "Epoch [942/4500], Validation Loss: 0.1796\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [943/4500], Training Loss: 0.0004\n",
      "Epoch [943/4500], Validation Loss: 0.1799\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [944/4500], Training Loss: 0.0004\n",
      "Epoch [944/4500], Validation Loss: 0.1797\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [945/4500], Training Loss: 0.0004\n",
      "Epoch [945/4500], Validation Loss: 0.1801\n",
      "Accuracy: 0.9508, Precision: 0.9755, Recall: 0.9253, F1: 0.9497\n",
      "Epoch [946/4500], Training Loss: 0.0004\n",
      "Epoch [946/4500], Validation Loss: 0.1800\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [947/4500], Training Loss: 0.0004\n",
      "Epoch [947/4500], Validation Loss: 0.1803\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [948/4500], Training Loss: 0.0004\n",
      "Epoch [948/4500], Validation Loss: 0.1803\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [949/4500], Training Loss: 0.0004\n",
      "Epoch [949/4500], Validation Loss: 0.1804\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [950/4500], Training Loss: 0.0004\n",
      "Epoch [950/4500], Validation Loss: 0.1804\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [951/4500], Training Loss: 0.0004\n",
      "Epoch [951/4500], Validation Loss: 0.1806\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [952/4500], Training Loss: 0.0004\n",
      "Epoch [952/4500], Validation Loss: 0.1805\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [953/4500], Training Loss: 0.0004\n",
      "Epoch [953/4500], Validation Loss: 0.1808\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [954/4500], Training Loss: 0.0004\n",
      "Epoch [954/4500], Validation Loss: 0.1810\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [955/4500], Training Loss: 0.0004\n",
      "Epoch [955/4500], Validation Loss: 0.1810\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [956/4500], Training Loss: 0.0004\n",
      "Epoch [956/4500], Validation Loss: 0.1810\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [957/4500], Training Loss: 0.0004\n",
      "Epoch [957/4500], Validation Loss: 0.1811\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [958/4500], Training Loss: 0.0004\n",
      "Epoch [958/4500], Validation Loss: 0.1814\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [959/4500], Training Loss: 0.0004\n",
      "Epoch [959/4500], Validation Loss: 0.1815\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [960/4500], Training Loss: 0.0004\n",
      "Epoch [960/4500], Validation Loss: 0.1814\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [961/4500], Training Loss: 0.0004\n",
      "Epoch [961/4500], Validation Loss: 0.1815\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [962/4500], Training Loss: 0.0004\n",
      "Epoch [962/4500], Validation Loss: 0.1817\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [963/4500], Training Loss: 0.0004\n",
      "Epoch [963/4500], Validation Loss: 0.1817\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [964/4500], Training Loss: 0.0004\n",
      "Epoch [964/4500], Validation Loss: 0.1817\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [965/4500], Training Loss: 0.0004\n",
      "Epoch [965/4500], Validation Loss: 0.1819\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [966/4500], Training Loss: 0.0004\n",
      "Epoch [966/4500], Validation Loss: 0.1820\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [967/4500], Training Loss: 0.0004\n",
      "Epoch [967/4500], Validation Loss: 0.1819\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [968/4500], Training Loss: 0.0004\n",
      "Epoch [968/4500], Validation Loss: 0.1822\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [969/4500], Training Loss: 0.0004\n",
      "Epoch [969/4500], Validation Loss: 0.1822\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [970/4500], Training Loss: 0.0004\n",
      "Epoch [970/4500], Validation Loss: 0.1825\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [971/4500], Training Loss: 0.0004\n",
      "Epoch [971/4500], Validation Loss: 0.1825\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [972/4500], Training Loss: 0.0004\n",
      "Epoch [972/4500], Validation Loss: 0.1826\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [973/4500], Training Loss: 0.0004\n",
      "Epoch [973/4500], Validation Loss: 0.1826\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [974/4500], Training Loss: 0.0004\n",
      "Epoch [974/4500], Validation Loss: 0.1829\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [975/4500], Training Loss: 0.0003\n",
      "Epoch [975/4500], Validation Loss: 0.1829\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [976/4500], Training Loss: 0.0003\n",
      "Epoch [976/4500], Validation Loss: 0.1831\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [977/4500], Training Loss: 0.0003\n",
      "Epoch [977/4500], Validation Loss: 0.1829\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [978/4500], Training Loss: 0.0003\n",
      "Epoch [978/4500], Validation Loss: 0.1833\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [979/4500], Training Loss: 0.0003\n",
      "Epoch [979/4500], Validation Loss: 0.1832\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [980/4500], Training Loss: 0.0003\n",
      "Epoch [980/4500], Validation Loss: 0.1833\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [981/4500], Training Loss: 0.0003\n",
      "Epoch [981/4500], Validation Loss: 0.1833\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [982/4500], Training Loss: 0.0003\n",
      "Epoch [982/4500], Validation Loss: 0.1838\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [983/4500], Training Loss: 0.0003\n",
      "Epoch [983/4500], Validation Loss: 0.1836\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [984/4500], Training Loss: 0.0003\n",
      "Epoch [984/4500], Validation Loss: 0.1839\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [985/4500], Training Loss: 0.0003\n",
      "Epoch [985/4500], Validation Loss: 0.1837\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [986/4500], Training Loss: 0.0003\n",
      "Epoch [986/4500], Validation Loss: 0.1839\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [987/4500], Training Loss: 0.0003\n",
      "Epoch [987/4500], Validation Loss: 0.1842\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [988/4500], Training Loss: 0.0003\n",
      "Epoch [988/4500], Validation Loss: 0.1844\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [989/4500], Training Loss: 0.0003\n",
      "Epoch [989/4500], Validation Loss: 0.1842\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [990/4500], Training Loss: 0.0003\n",
      "Epoch [990/4500], Validation Loss: 0.1843\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [991/4500], Training Loss: 0.0003\n",
      "Epoch [991/4500], Validation Loss: 0.1842\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [992/4500], Training Loss: 0.0003\n",
      "Epoch [992/4500], Validation Loss: 0.1844\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [993/4500], Training Loss: 0.0003\n",
      "Epoch [993/4500], Validation Loss: 0.1845\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [994/4500], Training Loss: 0.0003\n",
      "Epoch [994/4500], Validation Loss: 0.1846\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [995/4500], Training Loss: 0.0003\n",
      "Epoch [995/4500], Validation Loss: 0.1850\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [996/4500], Training Loss: 0.0003\n",
      "Epoch [996/4500], Validation Loss: 0.1851\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [997/4500], Training Loss: 0.0003\n",
      "Epoch [997/4500], Validation Loss: 0.1849\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [998/4500], Training Loss: 0.0003\n",
      "Epoch [998/4500], Validation Loss: 0.1850\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [999/4500], Training Loss: 0.0003\n",
      "Epoch [999/4500], Validation Loss: 0.1850\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1000/4500], Training Loss: 0.0003\n",
      "Epoch [1000/4500], Validation Loss: 0.1851\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1001/4500], Training Loss: 0.0003\n",
      "Epoch [1001/4500], Validation Loss: 0.1853\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1002/4500], Training Loss: 0.0003\n",
      "Epoch [1002/4500], Validation Loss: 0.1855\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1003/4500], Training Loss: 0.0003\n",
      "Epoch [1003/4500], Validation Loss: 0.1855\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1004/4500], Training Loss: 0.0003\n",
      "Epoch [1004/4500], Validation Loss: 0.1859\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1005/4500], Training Loss: 0.0003\n",
      "Epoch [1005/4500], Validation Loss: 0.1858\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1006/4500], Training Loss: 0.0003\n",
      "Epoch [1006/4500], Validation Loss: 0.1857\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1007/4500], Training Loss: 0.0003\n",
      "Epoch [1007/4500], Validation Loss: 0.1861\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1008/4500], Training Loss: 0.0003\n",
      "Epoch [1008/4500], Validation Loss: 0.1857\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1009/4500], Training Loss: 0.0003\n",
      "Epoch [1009/4500], Validation Loss: 0.1861\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1010/4500], Training Loss: 0.0003\n",
      "Epoch [1010/4500], Validation Loss: 0.1863\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1011/4500], Training Loss: 0.0003\n",
      "Epoch [1011/4500], Validation Loss: 0.1862\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1012/4500], Training Loss: 0.0003\n",
      "Epoch [1012/4500], Validation Loss: 0.1863\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1013/4500], Training Loss: 0.0003\n",
      "Epoch [1013/4500], Validation Loss: 0.1865\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1014/4500], Training Loss: 0.0003\n",
      "Epoch [1014/4500], Validation Loss: 0.1862\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1015/4500], Training Loss: 0.0003\n",
      "Epoch [1015/4500], Validation Loss: 0.1867\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1016/4500], Training Loss: 0.0003\n",
      "Epoch [1016/4500], Validation Loss: 0.1867\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1017/4500], Training Loss: 0.0003\n",
      "Epoch [1017/4500], Validation Loss: 0.1867\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1018/4500], Training Loss: 0.0003\n",
      "Epoch [1018/4500], Validation Loss: 0.1866\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1019/4500], Training Loss: 0.0003\n",
      "Epoch [1019/4500], Validation Loss: 0.1868\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1020/4500], Training Loss: 0.0003\n",
      "Epoch [1020/4500], Validation Loss: 0.1872\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1021/4500], Training Loss: 0.0003\n",
      "Epoch [1021/4500], Validation Loss: 0.1869\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1022/4500], Training Loss: 0.0003\n",
      "Epoch [1022/4500], Validation Loss: 0.1872\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1023/4500], Training Loss: 0.0003\n",
      "Epoch [1023/4500], Validation Loss: 0.1872\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1024/4500], Training Loss: 0.0003\n",
      "Epoch [1024/4500], Validation Loss: 0.1875\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1025/4500], Training Loss: 0.0003\n",
      "Epoch [1025/4500], Validation Loss: 0.1874\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1026/4500], Training Loss: 0.0003\n",
      "Epoch [1026/4500], Validation Loss: 0.1875\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1027/4500], Training Loss: 0.0003\n",
      "Epoch [1027/4500], Validation Loss: 0.1878\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1028/4500], Training Loss: 0.0003\n",
      "Epoch [1028/4500], Validation Loss: 0.1874\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1029/4500], Training Loss: 0.0003\n",
      "Epoch [1029/4500], Validation Loss: 0.1877\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1030/4500], Training Loss: 0.0003\n",
      "Epoch [1030/4500], Validation Loss: 0.1879\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1031/4500], Training Loss: 0.0003\n",
      "Epoch [1031/4500], Validation Loss: 0.1880\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1032/4500], Training Loss: 0.0003\n",
      "Epoch [1032/4500], Validation Loss: 0.1881\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1033/4500], Training Loss: 0.0003\n",
      "Epoch [1033/4500], Validation Loss: 0.1882\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1034/4500], Training Loss: 0.0003\n",
      "Epoch [1034/4500], Validation Loss: 0.1883\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1035/4500], Training Loss: 0.0003\n",
      "Epoch [1035/4500], Validation Loss: 0.1882\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1036/4500], Training Loss: 0.0003\n",
      "Epoch [1036/4500], Validation Loss: 0.1886\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1037/4500], Training Loss: 0.0003\n",
      "Epoch [1037/4500], Validation Loss: 0.1887\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1038/4500], Training Loss: 0.0003\n",
      "Epoch [1038/4500], Validation Loss: 0.1884\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1039/4500], Training Loss: 0.0003\n",
      "Epoch [1039/4500], Validation Loss: 0.1888\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1040/4500], Training Loss: 0.0003\n",
      "Epoch [1040/4500], Validation Loss: 0.1888\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1041/4500], Training Loss: 0.0003\n",
      "Epoch [1041/4500], Validation Loss: 0.1891\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1042/4500], Training Loss: 0.0003\n",
      "Epoch [1042/4500], Validation Loss: 0.1889\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1043/4500], Training Loss: 0.0003\n",
      "Epoch [1043/4500], Validation Loss: 0.1890\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1044/4500], Training Loss: 0.0003\n",
      "Epoch [1044/4500], Validation Loss: 0.1891\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1045/4500], Training Loss: 0.0003\n",
      "Epoch [1045/4500], Validation Loss: 0.1889\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1046/4500], Training Loss: 0.0003\n",
      "Epoch [1046/4500], Validation Loss: 0.1895\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1047/4500], Training Loss: 0.0003\n",
      "Epoch [1047/4500], Validation Loss: 0.1894\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1048/4500], Training Loss: 0.0003\n",
      "Epoch [1048/4500], Validation Loss: 0.1895\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1049/4500], Training Loss: 0.0003\n",
      "Epoch [1049/4500], Validation Loss: 0.1897\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1050/4500], Training Loss: 0.0003\n",
      "Epoch [1050/4500], Validation Loss: 0.1898\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1051/4500], Training Loss: 0.0003\n",
      "Epoch [1051/4500], Validation Loss: 0.1896\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1052/4500], Training Loss: 0.0003\n",
      "Epoch [1052/4500], Validation Loss: 0.1899\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1053/4500], Training Loss: 0.0003\n",
      "Epoch [1053/4500], Validation Loss: 0.1896\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1054/4500], Training Loss: 0.0003\n",
      "Epoch [1054/4500], Validation Loss: 0.1901\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1055/4500], Training Loss: 0.0003\n",
      "Epoch [1055/4500], Validation Loss: 0.1899\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1056/4500], Training Loss: 0.0003\n",
      "Epoch [1056/4500], Validation Loss: 0.1903\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1057/4500], Training Loss: 0.0003\n",
      "Epoch [1057/4500], Validation Loss: 0.1902\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1058/4500], Training Loss: 0.0003\n",
      "Epoch [1058/4500], Validation Loss: 0.1905\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1059/4500], Training Loss: 0.0003\n",
      "Epoch [1059/4500], Validation Loss: 0.1904\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1060/4500], Training Loss: 0.0003\n",
      "Epoch [1060/4500], Validation Loss: 0.1907\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1061/4500], Training Loss: 0.0003\n",
      "Epoch [1061/4500], Validation Loss: 0.1907\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1062/4500], Training Loss: 0.0002\n",
      "Epoch [1062/4500], Validation Loss: 0.1908\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1063/4500], Training Loss: 0.0003\n",
      "Epoch [1063/4500], Validation Loss: 0.1908\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1064/4500], Training Loss: 0.0003\n",
      "Epoch [1064/4500], Validation Loss: 0.1907\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1065/4500], Training Loss: 0.0002\n",
      "Epoch [1065/4500], Validation Loss: 0.1910\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1066/4500], Training Loss: 0.0002\n",
      "Epoch [1066/4500], Validation Loss: 0.1910\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1067/4500], Training Loss: 0.0003\n",
      "Epoch [1067/4500], Validation Loss: 0.1913\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1068/4500], Training Loss: 0.0002\n",
      "Epoch [1068/4500], Validation Loss: 0.1912\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1069/4500], Training Loss: 0.0002\n",
      "Epoch [1069/4500], Validation Loss: 0.1912\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1070/4500], Training Loss: 0.0002\n",
      "Epoch [1070/4500], Validation Loss: 0.1915\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1071/4500], Training Loss: 0.0002\n",
      "Epoch [1071/4500], Validation Loss: 0.1914\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1072/4500], Training Loss: 0.0002\n",
      "Epoch [1072/4500], Validation Loss: 0.1915\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1073/4500], Training Loss: 0.0002\n",
      "Epoch [1073/4500], Validation Loss: 0.1917\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1074/4500], Training Loss: 0.0002\n",
      "Epoch [1074/4500], Validation Loss: 0.1919\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1075/4500], Training Loss: 0.0002\n",
      "Epoch [1075/4500], Validation Loss: 0.1917\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1076/4500], Training Loss: 0.0002\n",
      "Epoch [1076/4500], Validation Loss: 0.1921\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1077/4500], Training Loss: 0.0002\n",
      "Epoch [1077/4500], Validation Loss: 0.1917\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1078/4500], Training Loss: 0.0002\n",
      "Epoch [1078/4500], Validation Loss: 0.1921\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1079/4500], Training Loss: 0.0002\n",
      "Epoch [1079/4500], Validation Loss: 0.1922\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1080/4500], Training Loss: 0.0002\n",
      "Epoch [1080/4500], Validation Loss: 0.1922\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1081/4500], Training Loss: 0.0002\n",
      "Epoch [1081/4500], Validation Loss: 0.1924\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1082/4500], Training Loss: 0.0002\n",
      "Epoch [1082/4500], Validation Loss: 0.1924\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1083/4500], Training Loss: 0.0002\n",
      "Epoch [1083/4500], Validation Loss: 0.1925\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1084/4500], Training Loss: 0.0002\n",
      "Epoch [1084/4500], Validation Loss: 0.1927\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1085/4500], Training Loss: 0.0002\n",
      "Epoch [1085/4500], Validation Loss: 0.1928\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1086/4500], Training Loss: 0.0002\n",
      "Epoch [1086/4500], Validation Loss: 0.1925\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1087/4500], Training Loss: 0.0002\n",
      "Epoch [1087/4500], Validation Loss: 0.1932\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1088/4500], Training Loss: 0.0002\n",
      "Epoch [1088/4500], Validation Loss: 0.1929\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1089/4500], Training Loss: 0.0002\n",
      "Epoch [1089/4500], Validation Loss: 0.1930\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1090/4500], Training Loss: 0.0002\n",
      "Epoch [1090/4500], Validation Loss: 0.1935\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1091/4500], Training Loss: 0.0002\n",
      "Epoch [1091/4500], Validation Loss: 0.1930\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1092/4500], Training Loss: 0.0002\n",
      "Epoch [1092/4500], Validation Loss: 0.1932\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1093/4500], Training Loss: 0.0002\n",
      "Epoch [1093/4500], Validation Loss: 0.1935\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1094/4500], Training Loss: 0.0002\n",
      "Epoch [1094/4500], Validation Loss: 0.1933\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1095/4500], Training Loss: 0.0002\n",
      "Epoch [1095/4500], Validation Loss: 0.1935\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1096/4500], Training Loss: 0.0002\n",
      "Epoch [1096/4500], Validation Loss: 0.1937\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1097/4500], Training Loss: 0.0002\n",
      "Epoch [1097/4500], Validation Loss: 0.1937\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1098/4500], Training Loss: 0.0002\n",
      "Epoch [1098/4500], Validation Loss: 0.1938\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1099/4500], Training Loss: 0.0002\n",
      "Epoch [1099/4500], Validation Loss: 0.1938\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1100/4500], Training Loss: 0.0002\n",
      "Epoch [1100/4500], Validation Loss: 0.1939\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1101/4500], Training Loss: 0.0002\n",
      "Epoch [1101/4500], Validation Loss: 0.1939\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1102/4500], Training Loss: 0.0002\n",
      "Epoch [1102/4500], Validation Loss: 0.1941\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1103/4500], Training Loss: 0.0002\n",
      "Epoch [1103/4500], Validation Loss: 0.1942\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1104/4500], Training Loss: 0.0002\n",
      "Epoch [1104/4500], Validation Loss: 0.1941\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1105/4500], Training Loss: 0.0002\n",
      "Epoch [1105/4500], Validation Loss: 0.1944\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1106/4500], Training Loss: 0.0002\n",
      "Epoch [1106/4500], Validation Loss: 0.1943\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1107/4500], Training Loss: 0.0002\n",
      "Epoch [1107/4500], Validation Loss: 0.1946\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1108/4500], Training Loss: 0.0002\n",
      "Epoch [1108/4500], Validation Loss: 0.1944\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1109/4500], Training Loss: 0.0002\n",
      "Epoch [1109/4500], Validation Loss: 0.1948\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1110/4500], Training Loss: 0.0002\n",
      "Epoch [1110/4500], Validation Loss: 0.1945\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1111/4500], Training Loss: 0.0002\n",
      "Epoch [1111/4500], Validation Loss: 0.1947\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1112/4500], Training Loss: 0.0002\n",
      "Epoch [1112/4500], Validation Loss: 0.1951\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1113/4500], Training Loss: 0.0002\n",
      "Epoch [1113/4500], Validation Loss: 0.1951\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1114/4500], Training Loss: 0.0002\n",
      "Epoch [1114/4500], Validation Loss: 0.1952\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1115/4500], Training Loss: 0.0002\n",
      "Epoch [1115/4500], Validation Loss: 0.1952\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1116/4500], Training Loss: 0.0002\n",
      "Epoch [1116/4500], Validation Loss: 0.1952\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1117/4500], Training Loss: 0.0002\n",
      "Epoch [1117/4500], Validation Loss: 0.1953\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1118/4500], Training Loss: 0.0002\n",
      "Epoch [1118/4500], Validation Loss: 0.1953\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1119/4500], Training Loss: 0.0002\n",
      "Epoch [1119/4500], Validation Loss: 0.1956\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1120/4500], Training Loss: 0.0002\n",
      "Epoch [1120/4500], Validation Loss: 0.1955\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1121/4500], Training Loss: 0.0002\n",
      "Epoch [1121/4500], Validation Loss: 0.1955\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1122/4500], Training Loss: 0.0002\n",
      "Epoch [1122/4500], Validation Loss: 0.1960\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1123/4500], Training Loss: 0.0002\n",
      "Epoch [1123/4500], Validation Loss: 0.1960\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1124/4500], Training Loss: 0.0002\n",
      "Epoch [1124/4500], Validation Loss: 0.1960\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1125/4500], Training Loss: 0.0002\n",
      "Epoch [1125/4500], Validation Loss: 0.1960\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1126/4500], Training Loss: 0.0002\n",
      "Epoch [1126/4500], Validation Loss: 0.1961\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1127/4500], Training Loss: 0.0002\n",
      "Epoch [1127/4500], Validation Loss: 0.1962\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1128/4500], Training Loss: 0.0002\n",
      "Epoch [1128/4500], Validation Loss: 0.1964\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1129/4500], Training Loss: 0.0002\n",
      "Epoch [1129/4500], Validation Loss: 0.1963\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1130/4500], Training Loss: 0.0002\n",
      "Epoch [1130/4500], Validation Loss: 0.1965\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1131/4500], Training Loss: 0.0002\n",
      "Epoch [1131/4500], Validation Loss: 0.1965\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1132/4500], Training Loss: 0.0002\n",
      "Epoch [1132/4500], Validation Loss: 0.1964\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1133/4500], Training Loss: 0.0002\n",
      "Epoch [1133/4500], Validation Loss: 0.1965\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1134/4500], Training Loss: 0.0002\n",
      "Epoch [1134/4500], Validation Loss: 0.1966\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1135/4500], Training Loss: 0.0002\n",
      "Epoch [1135/4500], Validation Loss: 0.1967\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1136/4500], Training Loss: 0.0002\n",
      "Epoch [1136/4500], Validation Loss: 0.1971\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1137/4500], Training Loss: 0.0002\n",
      "Epoch [1137/4500], Validation Loss: 0.1968\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1138/4500], Training Loss: 0.0002\n",
      "Epoch [1138/4500], Validation Loss: 0.1971\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1139/4500], Training Loss: 0.0002\n",
      "Epoch [1139/4500], Validation Loss: 0.1969\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1140/4500], Training Loss: 0.0002\n",
      "Epoch [1140/4500], Validation Loss: 0.1971\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1141/4500], Training Loss: 0.0002\n",
      "Epoch [1141/4500], Validation Loss: 0.1973\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1142/4500], Training Loss: 0.0002\n",
      "Epoch [1142/4500], Validation Loss: 0.1974\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1143/4500], Training Loss: 0.0002\n",
      "Epoch [1143/4500], Validation Loss: 0.1973\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1144/4500], Training Loss: 0.0002\n",
      "Epoch [1144/4500], Validation Loss: 0.1972\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1145/4500], Training Loss: 0.0002\n",
      "Epoch [1145/4500], Validation Loss: 0.1975\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1146/4500], Training Loss: 0.0002\n",
      "Epoch [1146/4500], Validation Loss: 0.1975\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1147/4500], Training Loss: 0.0002\n",
      "Epoch [1147/4500], Validation Loss: 0.1976\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1148/4500], Training Loss: 0.0002\n",
      "Epoch [1148/4500], Validation Loss: 0.1978\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1149/4500], Training Loss: 0.0002\n",
      "Epoch [1149/4500], Validation Loss: 0.1977\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1150/4500], Training Loss: 0.0002\n",
      "Epoch [1150/4500], Validation Loss: 0.1977\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1151/4500], Training Loss: 0.0002\n",
      "Epoch [1151/4500], Validation Loss: 0.1981\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1152/4500], Training Loss: 0.0002\n",
      "Epoch [1152/4500], Validation Loss: 0.1982\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1153/4500], Training Loss: 0.0002\n",
      "Epoch [1153/4500], Validation Loss: 0.1984\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1154/4500], Training Loss: 0.0002\n",
      "Epoch [1154/4500], Validation Loss: 0.1981\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1155/4500], Training Loss: 0.0002\n",
      "Epoch [1155/4500], Validation Loss: 0.1984\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1156/4500], Training Loss: 0.0002\n",
      "Epoch [1156/4500], Validation Loss: 0.1981\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1157/4500], Training Loss: 0.0002\n",
      "Epoch [1157/4500], Validation Loss: 0.1981\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1158/4500], Training Loss: 0.0002\n",
      "Epoch [1158/4500], Validation Loss: 0.1984\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1159/4500], Training Loss: 0.0002\n",
      "Epoch [1159/4500], Validation Loss: 0.1985\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1160/4500], Training Loss: 0.0002\n",
      "Epoch [1160/4500], Validation Loss: 0.1988\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1161/4500], Training Loss: 0.0002\n",
      "Epoch [1161/4500], Validation Loss: 0.1987\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1162/4500], Training Loss: 0.0002\n",
      "Epoch [1162/4500], Validation Loss: 0.1987\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1163/4500], Training Loss: 0.0002\n",
      "Epoch [1163/4500], Validation Loss: 0.1990\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1164/4500], Training Loss: 0.0002\n",
      "Epoch [1164/4500], Validation Loss: 0.1991\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1165/4500], Training Loss: 0.0002\n",
      "Epoch [1165/4500], Validation Loss: 0.1989\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1166/4500], Training Loss: 0.0002\n",
      "Epoch [1166/4500], Validation Loss: 0.1992\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1167/4500], Training Loss: 0.0002\n",
      "Epoch [1167/4500], Validation Loss: 0.1993\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1168/4500], Training Loss: 0.0002\n",
      "Epoch [1168/4500], Validation Loss: 0.1995\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1169/4500], Training Loss: 0.0002\n",
      "Epoch [1169/4500], Validation Loss: 0.1990\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1170/4500], Training Loss: 0.0002\n",
      "Epoch [1170/4500], Validation Loss: 0.1993\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1171/4500], Training Loss: 0.0002\n",
      "Epoch [1171/4500], Validation Loss: 0.1995\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1172/4500], Training Loss: 0.0002\n",
      "Epoch [1172/4500], Validation Loss: 0.1998\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1173/4500], Training Loss: 0.0002\n",
      "Epoch [1173/4500], Validation Loss: 0.1993\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1174/4500], Training Loss: 0.0002\n",
      "Epoch [1174/4500], Validation Loss: 0.1997\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1175/4500], Training Loss: 0.0002\n",
      "Epoch [1175/4500], Validation Loss: 0.2001\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1176/4500], Training Loss: 0.0002\n",
      "Epoch [1176/4500], Validation Loss: 0.1997\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1177/4500], Training Loss: 0.0002\n",
      "Epoch [1177/4500], Validation Loss: 0.2000\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1178/4500], Training Loss: 0.0002\n",
      "Epoch [1178/4500], Validation Loss: 0.2000\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1179/4500], Training Loss: 0.0002\n",
      "Epoch [1179/4500], Validation Loss: 0.1999\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1180/4500], Training Loss: 0.0002\n",
      "Epoch [1180/4500], Validation Loss: 0.2002\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1181/4500], Training Loss: 0.0002\n",
      "Epoch [1181/4500], Validation Loss: 0.2003\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1182/4500], Training Loss: 0.0002\n",
      "Epoch [1182/4500], Validation Loss: 0.2003\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1183/4500], Training Loss: 0.0002\n",
      "Epoch [1183/4500], Validation Loss: 0.2004\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1184/4500], Training Loss: 0.0002\n",
      "Epoch [1184/4500], Validation Loss: 0.2005\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1185/4500], Training Loss: 0.0002\n",
      "Epoch [1185/4500], Validation Loss: 0.2006\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1186/4500], Training Loss: 0.0002\n",
      "Epoch [1186/4500], Validation Loss: 0.2006\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1187/4500], Training Loss: 0.0002\n",
      "Epoch [1187/4500], Validation Loss: 0.2009\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1188/4500], Training Loss: 0.0002\n",
      "Epoch [1188/4500], Validation Loss: 0.2006\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1189/4500], Training Loss: 0.0002\n",
      "Epoch [1189/4500], Validation Loss: 0.2008\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1190/4500], Training Loss: 0.0002\n",
      "Epoch [1190/4500], Validation Loss: 0.2011\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1191/4500], Training Loss: 0.0002\n",
      "Epoch [1191/4500], Validation Loss: 0.2008\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1192/4500], Training Loss: 0.0002\n",
      "Epoch [1192/4500], Validation Loss: 0.2011\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1193/4500], Training Loss: 0.0002\n",
      "Epoch [1193/4500], Validation Loss: 0.2012\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1194/4500], Training Loss: 0.0002\n",
      "Epoch [1194/4500], Validation Loss: 0.2015\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1195/4500], Training Loss: 0.0002\n",
      "Epoch [1195/4500], Validation Loss: 0.2013\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1196/4500], Training Loss: 0.0002\n",
      "Epoch [1196/4500], Validation Loss: 0.2014\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1197/4500], Training Loss: 0.0002\n",
      "Epoch [1197/4500], Validation Loss: 0.2013\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1198/4500], Training Loss: 0.0002\n",
      "Epoch [1198/4500], Validation Loss: 0.2016\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1199/4500], Training Loss: 0.0002\n",
      "Epoch [1199/4500], Validation Loss: 0.2017\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1200/4500], Training Loss: 0.0002\n",
      "Epoch [1200/4500], Validation Loss: 0.2020\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1201/4500], Training Loss: 0.0002\n",
      "Epoch [1201/4500], Validation Loss: 0.2018\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1202/4500], Training Loss: 0.0002\n",
      "Epoch [1202/4500], Validation Loss: 0.2020\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1203/4500], Training Loss: 0.0002\n",
      "Epoch [1203/4500], Validation Loss: 0.2021\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1204/4500], Training Loss: 0.0002\n",
      "Epoch [1204/4500], Validation Loss: 0.2020\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1205/4500], Training Loss: 0.0002\n",
      "Epoch [1205/4500], Validation Loss: 0.2022\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1206/4500], Training Loss: 0.0002\n",
      "Epoch [1206/4500], Validation Loss: 0.2024\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1207/4500], Training Loss: 0.0002\n",
      "Epoch [1207/4500], Validation Loss: 0.2023\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1208/4500], Training Loss: 0.0002\n",
      "Epoch [1208/4500], Validation Loss: 0.2025\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1209/4500], Training Loss: 0.0002\n",
      "Epoch [1209/4500], Validation Loss: 0.2024\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1210/4500], Training Loss: 0.0002\n",
      "Epoch [1210/4500], Validation Loss: 0.2027\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1211/4500], Training Loss: 0.0002\n",
      "Epoch [1211/4500], Validation Loss: 0.2029\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1212/4500], Training Loss: 0.0002\n",
      "Epoch [1212/4500], Validation Loss: 0.2028\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1213/4500], Training Loss: 0.0002\n",
      "Epoch [1213/4500], Validation Loss: 0.2029\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1214/4500], Training Loss: 0.0002\n",
      "Epoch [1214/4500], Validation Loss: 0.2030\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1215/4500], Training Loss: 0.0002\n",
      "Epoch [1215/4500], Validation Loss: 0.2029\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1216/4500], Training Loss: 0.0002\n",
      "Epoch [1216/4500], Validation Loss: 0.2030\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1217/4500], Training Loss: 0.0002\n",
      "Epoch [1217/4500], Validation Loss: 0.2033\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1218/4500], Training Loss: 0.0002\n",
      "Epoch [1218/4500], Validation Loss: 0.2034\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1219/4500], Training Loss: 0.0001\n",
      "Epoch [1219/4500], Validation Loss: 0.2033\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1220/4500], Training Loss: 0.0002\n",
      "Epoch [1220/4500], Validation Loss: 0.2035\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1221/4500], Training Loss: 0.0001\n",
      "Epoch [1221/4500], Validation Loss: 0.2037\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1222/4500], Training Loss: 0.0001\n",
      "Epoch [1222/4500], Validation Loss: 0.2036\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1223/4500], Training Loss: 0.0001\n",
      "Epoch [1223/4500], Validation Loss: 0.2037\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1224/4500], Training Loss: 0.0001\n",
      "Epoch [1224/4500], Validation Loss: 0.2038\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1225/4500], Training Loss: 0.0001\n",
      "Epoch [1225/4500], Validation Loss: 0.2040\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1226/4500], Training Loss: 0.0001\n",
      "Epoch [1226/4500], Validation Loss: 0.2039\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1227/4500], Training Loss: 0.0001\n",
      "Epoch [1227/4500], Validation Loss: 0.2041\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1228/4500], Training Loss: 0.0001\n",
      "Epoch [1228/4500], Validation Loss: 0.2041\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1229/4500], Training Loss: 0.0001\n",
      "Epoch [1229/4500], Validation Loss: 0.2043\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1230/4500], Training Loss: 0.0001\n",
      "Epoch [1230/4500], Validation Loss: 0.2044\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1231/4500], Training Loss: 0.0001\n",
      "Epoch [1231/4500], Validation Loss: 0.2044\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1232/4500], Training Loss: 0.0001\n",
      "Epoch [1232/4500], Validation Loss: 0.2042\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1233/4500], Training Loss: 0.0001\n",
      "Epoch [1233/4500], Validation Loss: 0.2050\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1234/4500], Training Loss: 0.0001\n",
      "Epoch [1234/4500], Validation Loss: 0.2045\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1235/4500], Training Loss: 0.0001\n",
      "Epoch [1235/4500], Validation Loss: 0.2046\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1236/4500], Training Loss: 0.0001\n",
      "Epoch [1236/4500], Validation Loss: 0.2047\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1237/4500], Training Loss: 0.0001\n",
      "Epoch [1237/4500], Validation Loss: 0.2051\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1238/4500], Training Loss: 0.0001\n",
      "Epoch [1238/4500], Validation Loss: 0.2050\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1239/4500], Training Loss: 0.0001\n",
      "Epoch [1239/4500], Validation Loss: 0.2052\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1240/4500], Training Loss: 0.0001\n",
      "Epoch [1240/4500], Validation Loss: 0.2050\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1241/4500], Training Loss: 0.0001\n",
      "Epoch [1241/4500], Validation Loss: 0.2052\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1242/4500], Training Loss: 0.0001\n",
      "Epoch [1242/4500], Validation Loss: 0.2054\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1243/4500], Training Loss: 0.0001\n",
      "Epoch [1243/4500], Validation Loss: 0.2053\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1244/4500], Training Loss: 0.0001\n",
      "Epoch [1244/4500], Validation Loss: 0.2058\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1245/4500], Training Loss: 0.0001\n",
      "Epoch [1245/4500], Validation Loss: 0.2054\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1246/4500], Training Loss: 0.0001\n",
      "Epoch [1246/4500], Validation Loss: 0.2057\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1247/4500], Training Loss: 0.0001\n",
      "Epoch [1247/4500], Validation Loss: 0.2059\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1248/4500], Training Loss: 0.0001\n",
      "Epoch [1248/4500], Validation Loss: 0.2057\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1249/4500], Training Loss: 0.0001\n",
      "Epoch [1249/4500], Validation Loss: 0.2059\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1250/4500], Training Loss: 0.0001\n",
      "Epoch [1250/4500], Validation Loss: 0.2060\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1251/4500], Training Loss: 0.0001\n",
      "Epoch [1251/4500], Validation Loss: 0.2065\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1252/4500], Training Loss: 0.0001\n",
      "Epoch [1252/4500], Validation Loss: 0.2058\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1253/4500], Training Loss: 0.0001\n",
      "Epoch [1253/4500], Validation Loss: 0.2066\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1254/4500], Training Loss: 0.0001\n",
      "Epoch [1254/4500], Validation Loss: 0.2064\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1255/4500], Training Loss: 0.0001\n",
      "Epoch [1255/4500], Validation Loss: 0.2064\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1256/4500], Training Loss: 0.0001\n",
      "Epoch [1256/4500], Validation Loss: 0.2067\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1257/4500], Training Loss: 0.0001\n",
      "Epoch [1257/4500], Validation Loss: 0.2064\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1258/4500], Training Loss: 0.0001\n",
      "Epoch [1258/4500], Validation Loss: 0.2069\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1259/4500], Training Loss: 0.0001\n",
      "Epoch [1259/4500], Validation Loss: 0.2065\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1260/4500], Training Loss: 0.0001\n",
      "Epoch [1260/4500], Validation Loss: 0.2068\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1261/4500], Training Loss: 0.0001\n",
      "Epoch [1261/4500], Validation Loss: 0.2070\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1262/4500], Training Loss: 0.0001\n",
      "Epoch [1262/4500], Validation Loss: 0.2070\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1263/4500], Training Loss: 0.0001\n",
      "Epoch [1263/4500], Validation Loss: 0.2072\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1264/4500], Training Loss: 0.0001\n",
      "Epoch [1264/4500], Validation Loss: 0.2069\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1265/4500], Training Loss: 0.0001\n",
      "Epoch [1265/4500], Validation Loss: 0.2071\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1266/4500], Training Loss: 0.0001\n",
      "Epoch [1266/4500], Validation Loss: 0.2073\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1267/4500], Training Loss: 0.0001\n",
      "Epoch [1267/4500], Validation Loss: 0.2075\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1268/4500], Training Loss: 0.0001\n",
      "Epoch [1268/4500], Validation Loss: 0.2074\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1269/4500], Training Loss: 0.0001\n",
      "Epoch [1269/4500], Validation Loss: 0.2074\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1270/4500], Training Loss: 0.0001\n",
      "Epoch [1270/4500], Validation Loss: 0.2077\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1271/4500], Training Loss: 0.0001\n",
      "Epoch [1271/4500], Validation Loss: 0.2078\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1272/4500], Training Loss: 0.0001\n",
      "Epoch [1272/4500], Validation Loss: 0.2078\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1273/4500], Training Loss: 0.0001\n",
      "Epoch [1273/4500], Validation Loss: 0.2078\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1274/4500], Training Loss: 0.0001\n",
      "Epoch [1274/4500], Validation Loss: 0.2079\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1275/4500], Training Loss: 0.0001\n",
      "Epoch [1275/4500], Validation Loss: 0.2081\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1276/4500], Training Loss: 0.0001\n",
      "Epoch [1276/4500], Validation Loss: 0.2082\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1277/4500], Training Loss: 0.0001\n",
      "Epoch [1277/4500], Validation Loss: 0.2080\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1278/4500], Training Loss: 0.0001\n",
      "Epoch [1278/4500], Validation Loss: 0.2081\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1279/4500], Training Loss: 0.0001\n",
      "Epoch [1279/4500], Validation Loss: 0.2084\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1280/4500], Training Loss: 0.0001\n",
      "Epoch [1280/4500], Validation Loss: 0.2082\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1281/4500], Training Loss: 0.0001\n",
      "Epoch [1281/4500], Validation Loss: 0.2086\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1282/4500], Training Loss: 0.0001\n",
      "Epoch [1282/4500], Validation Loss: 0.2086\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1283/4500], Training Loss: 0.0001\n",
      "Epoch [1283/4500], Validation Loss: 0.2088\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1284/4500], Training Loss: 0.0001\n",
      "Epoch [1284/4500], Validation Loss: 0.2088\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1285/4500], Training Loss: 0.0001\n",
      "Epoch [1285/4500], Validation Loss: 0.2088\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1286/4500], Training Loss: 0.0001\n",
      "Epoch [1286/4500], Validation Loss: 0.2089\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1287/4500], Training Loss: 0.0001\n",
      "Epoch [1287/4500], Validation Loss: 0.2089\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1288/4500], Training Loss: 0.0001\n",
      "Epoch [1288/4500], Validation Loss: 0.2092\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1289/4500], Training Loss: 0.0001\n",
      "Epoch [1289/4500], Validation Loss: 0.2091\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1290/4500], Training Loss: 0.0001\n",
      "Epoch [1290/4500], Validation Loss: 0.2089\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1291/4500], Training Loss: 0.0001\n",
      "Epoch [1291/4500], Validation Loss: 0.2091\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1292/4500], Training Loss: 0.0001\n",
      "Epoch [1292/4500], Validation Loss: 0.2094\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1293/4500], Training Loss: 0.0001\n",
      "Epoch [1293/4500], Validation Loss: 0.2095\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1294/4500], Training Loss: 0.0001\n",
      "Epoch [1294/4500], Validation Loss: 0.2094\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1295/4500], Training Loss: 0.0001\n",
      "Epoch [1295/4500], Validation Loss: 0.2096\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1296/4500], Training Loss: 0.0001\n",
      "Epoch [1296/4500], Validation Loss: 0.2097\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1297/4500], Training Loss: 0.0001\n",
      "Epoch [1297/4500], Validation Loss: 0.2099\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1298/4500], Training Loss: 0.0001\n",
      "Epoch [1298/4500], Validation Loss: 0.2097\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1299/4500], Training Loss: 0.0001\n",
      "Epoch [1299/4500], Validation Loss: 0.2099\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1300/4500], Training Loss: 0.0001\n",
      "Epoch [1300/4500], Validation Loss: 0.2099\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1301/4500], Training Loss: 0.0001\n",
      "Epoch [1301/4500], Validation Loss: 0.2103\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1302/4500], Training Loss: 0.0001\n",
      "Epoch [1302/4500], Validation Loss: 0.2101\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1303/4500], Training Loss: 0.0001\n",
      "Epoch [1303/4500], Validation Loss: 0.2101\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1304/4500], Training Loss: 0.0001\n",
      "Epoch [1304/4500], Validation Loss: 0.2102\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1305/4500], Training Loss: 0.0001\n",
      "Epoch [1305/4500], Validation Loss: 0.2105\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1306/4500], Training Loss: 0.0001\n",
      "Epoch [1306/4500], Validation Loss: 0.2105\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1307/4500], Training Loss: 0.0001\n",
      "Epoch [1307/4500], Validation Loss: 0.2104\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1308/4500], Training Loss: 0.0001\n",
      "Epoch [1308/4500], Validation Loss: 0.2107\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1309/4500], Training Loss: 0.0001\n",
      "Epoch [1309/4500], Validation Loss: 0.2106\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1310/4500], Training Loss: 0.0001\n",
      "Epoch [1310/4500], Validation Loss: 0.2107\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1311/4500], Training Loss: 0.0001\n",
      "Epoch [1311/4500], Validation Loss: 0.2107\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1312/4500], Training Loss: 0.0001\n",
      "Epoch [1312/4500], Validation Loss: 0.2109\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1313/4500], Training Loss: 0.0001\n",
      "Epoch [1313/4500], Validation Loss: 0.2109\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1314/4500], Training Loss: 0.0001\n",
      "Epoch [1314/4500], Validation Loss: 0.2111\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1315/4500], Training Loss: 0.0001\n",
      "Epoch [1315/4500], Validation Loss: 0.2110\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1316/4500], Training Loss: 0.0001\n",
      "Epoch [1316/4500], Validation Loss: 0.2114\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1317/4500], Training Loss: 0.0001\n",
      "Epoch [1317/4500], Validation Loss: 0.2111\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1318/4500], Training Loss: 0.0001\n",
      "Epoch [1318/4500], Validation Loss: 0.2112\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1319/4500], Training Loss: 0.0001\n",
      "Epoch [1319/4500], Validation Loss: 0.2114\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1320/4500], Training Loss: 0.0001\n",
      "Epoch [1320/4500], Validation Loss: 0.2117\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1321/4500], Training Loss: 0.0001\n",
      "Epoch [1321/4500], Validation Loss: 0.2115\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1322/4500], Training Loss: 0.0001\n",
      "Epoch [1322/4500], Validation Loss: 0.2115\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1323/4500], Training Loss: 0.0001\n",
      "Epoch [1323/4500], Validation Loss: 0.2115\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1324/4500], Training Loss: 0.0001\n",
      "Epoch [1324/4500], Validation Loss: 0.2120\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1325/4500], Training Loss: 0.0001\n",
      "Epoch [1325/4500], Validation Loss: 0.2116\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1326/4500], Training Loss: 0.0001\n",
      "Epoch [1326/4500], Validation Loss: 0.2117\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1327/4500], Training Loss: 0.0001\n",
      "Epoch [1327/4500], Validation Loss: 0.2121\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1328/4500], Training Loss: 0.0001\n",
      "Epoch [1328/4500], Validation Loss: 0.2122\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1329/4500], Training Loss: 0.0001\n",
      "Epoch [1329/4500], Validation Loss: 0.2120\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1330/4500], Training Loss: 0.0001\n",
      "Epoch [1330/4500], Validation Loss: 0.2124\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1331/4500], Training Loss: 0.0001\n",
      "Epoch [1331/4500], Validation Loss: 0.2123\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1332/4500], Training Loss: 0.0001\n",
      "Epoch [1332/4500], Validation Loss: 0.2122\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1333/4500], Training Loss: 0.0001\n",
      "Epoch [1333/4500], Validation Loss: 0.2123\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1334/4500], Training Loss: 0.0001\n",
      "Epoch [1334/4500], Validation Loss: 0.2125\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1335/4500], Training Loss: 0.0001\n",
      "Epoch [1335/4500], Validation Loss: 0.2127\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1336/4500], Training Loss: 0.0001\n",
      "Epoch [1336/4500], Validation Loss: 0.2125\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1337/4500], Training Loss: 0.0001\n",
      "Epoch [1337/4500], Validation Loss: 0.2130\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1338/4500], Training Loss: 0.0001\n",
      "Epoch [1338/4500], Validation Loss: 0.2128\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1339/4500], Training Loss: 0.0001\n",
      "Epoch [1339/4500], Validation Loss: 0.2126\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1340/4500], Training Loss: 0.0001\n",
      "Epoch [1340/4500], Validation Loss: 0.2129\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1341/4500], Training Loss: 0.0001\n",
      "Epoch [1341/4500], Validation Loss: 0.2128\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1342/4500], Training Loss: 0.0001\n",
      "Epoch [1342/4500], Validation Loss: 0.2129\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1343/4500], Training Loss: 0.0001\n",
      "Epoch [1343/4500], Validation Loss: 0.2133\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1344/4500], Training Loss: 0.0001\n",
      "Epoch [1344/4500], Validation Loss: 0.2131\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1345/4500], Training Loss: 0.0001\n",
      "Epoch [1345/4500], Validation Loss: 0.2133\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1346/4500], Training Loss: 0.0001\n",
      "Epoch [1346/4500], Validation Loss: 0.2134\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1347/4500], Training Loss: 0.0001\n",
      "Epoch [1347/4500], Validation Loss: 0.2133\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1348/4500], Training Loss: 0.0001\n",
      "Epoch [1348/4500], Validation Loss: 0.2133\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1349/4500], Training Loss: 0.0001\n",
      "Epoch [1349/4500], Validation Loss: 0.2134\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1350/4500], Training Loss: 0.0001\n",
      "Epoch [1350/4500], Validation Loss: 0.2137\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1351/4500], Training Loss: 0.0001\n",
      "Epoch [1351/4500], Validation Loss: 0.2136\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1352/4500], Training Loss: 0.0001\n",
      "Epoch [1352/4500], Validation Loss: 0.2140\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1353/4500], Training Loss: 0.0001\n",
      "Epoch [1353/4500], Validation Loss: 0.2138\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1354/4500], Training Loss: 0.0001\n",
      "Epoch [1354/4500], Validation Loss: 0.2138\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1355/4500], Training Loss: 0.0001\n",
      "Epoch [1355/4500], Validation Loss: 0.2142\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1356/4500], Training Loss: 0.0001\n",
      "Epoch [1356/4500], Validation Loss: 0.2140\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1357/4500], Training Loss: 0.0001\n",
      "Epoch [1357/4500], Validation Loss: 0.2140\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1358/4500], Training Loss: 0.0001\n",
      "Epoch [1358/4500], Validation Loss: 0.2143\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1359/4500], Training Loss: 0.0001\n",
      "Epoch [1359/4500], Validation Loss: 0.2142\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1360/4500], Training Loss: 0.0001\n",
      "Epoch [1360/4500], Validation Loss: 0.2146\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1361/4500], Training Loss: 0.0001\n",
      "Epoch [1361/4500], Validation Loss: 0.2143\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1362/4500], Training Loss: 0.0001\n",
      "Epoch [1362/4500], Validation Loss: 0.2145\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1363/4500], Training Loss: 0.0001\n",
      "Epoch [1363/4500], Validation Loss: 0.2144\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1364/4500], Training Loss: 0.0001\n",
      "Epoch [1364/4500], Validation Loss: 0.2146\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1365/4500], Training Loss: 0.0001\n",
      "Epoch [1365/4500], Validation Loss: 0.2148\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1366/4500], Training Loss: 0.0001\n",
      "Epoch [1366/4500], Validation Loss: 0.2148\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1367/4500], Training Loss: 0.0001\n",
      "Epoch [1367/4500], Validation Loss: 0.2149\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1368/4500], Training Loss: 0.0001\n",
      "Epoch [1368/4500], Validation Loss: 0.2149\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1369/4500], Training Loss: 0.0001\n",
      "Epoch [1369/4500], Validation Loss: 0.2151\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1370/4500], Training Loss: 0.0001\n",
      "Epoch [1370/4500], Validation Loss: 0.2151\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1371/4500], Training Loss: 0.0001\n",
      "Epoch [1371/4500], Validation Loss: 0.2151\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1372/4500], Training Loss: 0.0001\n",
      "Epoch [1372/4500], Validation Loss: 0.2152\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1373/4500], Training Loss: 0.0001\n",
      "Epoch [1373/4500], Validation Loss: 0.2152\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1374/4500], Training Loss: 0.0001\n",
      "Epoch [1374/4500], Validation Loss: 0.2154\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1375/4500], Training Loss: 0.0001\n",
      "Epoch [1375/4500], Validation Loss: 0.2154\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1376/4500], Training Loss: 0.0001\n",
      "Epoch [1376/4500], Validation Loss: 0.2157\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1377/4500], Training Loss: 0.0001\n",
      "Epoch [1377/4500], Validation Loss: 0.2155\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1378/4500], Training Loss: 0.0001\n",
      "Epoch [1378/4500], Validation Loss: 0.2156\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1379/4500], Training Loss: 0.0001\n",
      "Epoch [1379/4500], Validation Loss: 0.2157\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1380/4500], Training Loss: 0.0001\n",
      "Epoch [1380/4500], Validation Loss: 0.2158\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1381/4500], Training Loss: 0.0001\n",
      "Epoch [1381/4500], Validation Loss: 0.2157\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1382/4500], Training Loss: 0.0001\n",
      "Epoch [1382/4500], Validation Loss: 0.2161\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1383/4500], Training Loss: 0.0001\n",
      "Epoch [1383/4500], Validation Loss: 0.2157\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1384/4500], Training Loss: 0.0001\n",
      "Epoch [1384/4500], Validation Loss: 0.2159\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1385/4500], Training Loss: 0.0001\n",
      "Epoch [1385/4500], Validation Loss: 0.2162\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1386/4500], Training Loss: 0.0001\n",
      "Epoch [1386/4500], Validation Loss: 0.2161\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1387/4500], Training Loss: 0.0001\n",
      "Epoch [1387/4500], Validation Loss: 0.2164\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1388/4500], Training Loss: 0.0001\n",
      "Epoch [1388/4500], Validation Loss: 0.2162\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1389/4500], Training Loss: 0.0001\n",
      "Epoch [1389/4500], Validation Loss: 0.2165\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1390/4500], Training Loss: 0.0001\n",
      "Epoch [1390/4500], Validation Loss: 0.2165\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1391/4500], Training Loss: 0.0001\n",
      "Epoch [1391/4500], Validation Loss: 0.2164\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1392/4500], Training Loss: 0.0001\n",
      "Epoch [1392/4500], Validation Loss: 0.2170\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1393/4500], Training Loss: 0.0001\n",
      "Epoch [1393/4500], Validation Loss: 0.2164\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1394/4500], Training Loss: 0.0001\n",
      "Epoch [1394/4500], Validation Loss: 0.2169\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1395/4500], Training Loss: 0.0001\n",
      "Epoch [1395/4500], Validation Loss: 0.2168\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1396/4500], Training Loss: 0.0001\n",
      "Epoch [1396/4500], Validation Loss: 0.2169\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1397/4500], Training Loss: 0.0001\n",
      "Epoch [1397/4500], Validation Loss: 0.2168\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1398/4500], Training Loss: 0.0001\n",
      "Epoch [1398/4500], Validation Loss: 0.2171\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1399/4500], Training Loss: 0.0001\n",
      "Epoch [1399/4500], Validation Loss: 0.2171\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1400/4500], Training Loss: 0.0001\n",
      "Epoch [1400/4500], Validation Loss: 0.2173\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1401/4500], Training Loss: 0.0001\n",
      "Epoch [1401/4500], Validation Loss: 0.2171\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1402/4500], Training Loss: 0.0001\n",
      "Epoch [1402/4500], Validation Loss: 0.2174\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1403/4500], Training Loss: 0.0001\n",
      "Epoch [1403/4500], Validation Loss: 0.2172\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1404/4500], Training Loss: 0.0001\n",
      "Epoch [1404/4500], Validation Loss: 0.2176\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1405/4500], Training Loss: 0.0001\n",
      "Epoch [1405/4500], Validation Loss: 0.2175\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1406/4500], Training Loss: 0.0001\n",
      "Epoch [1406/4500], Validation Loss: 0.2179\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1407/4500], Training Loss: 0.0001\n",
      "Epoch [1407/4500], Validation Loss: 0.2175\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1408/4500], Training Loss: 0.0001\n",
      "Epoch [1408/4500], Validation Loss: 0.2177\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1409/4500], Training Loss: 0.0001\n",
      "Epoch [1409/4500], Validation Loss: 0.2181\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1410/4500], Training Loss: 0.0001\n",
      "Epoch [1410/4500], Validation Loss: 0.2177\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1411/4500], Training Loss: 0.0001\n",
      "Epoch [1411/4500], Validation Loss: 0.2178\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1412/4500], Training Loss: 0.0001\n",
      "Epoch [1412/4500], Validation Loss: 0.2180\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1413/4500], Training Loss: 0.0001\n",
      "Epoch [1413/4500], Validation Loss: 0.2181\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1414/4500], Training Loss: 0.0001\n",
      "Epoch [1414/4500], Validation Loss: 0.2182\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1415/4500], Training Loss: 0.0001\n",
      "Epoch [1415/4500], Validation Loss: 0.2183\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1416/4500], Training Loss: 0.0001\n",
      "Epoch [1416/4500], Validation Loss: 0.2186\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1417/4500], Training Loss: 0.0001\n",
      "Epoch [1417/4500], Validation Loss: 0.2182\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1418/4500], Training Loss: 0.0001\n",
      "Epoch [1418/4500], Validation Loss: 0.2184\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1419/4500], Training Loss: 0.0001\n",
      "Epoch [1419/4500], Validation Loss: 0.2186\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1420/4500], Training Loss: 0.0001\n",
      "Epoch [1420/4500], Validation Loss: 0.2188\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1421/4500], Training Loss: 0.0001\n",
      "Epoch [1421/4500], Validation Loss: 0.2187\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1422/4500], Training Loss: 0.0001\n",
      "Epoch [1422/4500], Validation Loss: 0.2185\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1423/4500], Training Loss: 0.0001\n",
      "Epoch [1423/4500], Validation Loss: 0.2188\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1424/4500], Training Loss: 0.0001\n",
      "Epoch [1424/4500], Validation Loss: 0.2189\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1425/4500], Training Loss: 0.0001\n",
      "Epoch [1425/4500], Validation Loss: 0.2191\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1426/4500], Training Loss: 0.0001\n",
      "Epoch [1426/4500], Validation Loss: 0.2191\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1427/4500], Training Loss: 0.0001\n",
      "Epoch [1427/4500], Validation Loss: 0.2193\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1428/4500], Training Loss: 0.0001\n",
      "Epoch [1428/4500], Validation Loss: 0.2191\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1429/4500], Training Loss: 0.0001\n",
      "Epoch [1429/4500], Validation Loss: 0.2194\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1430/4500], Training Loss: 0.0001\n",
      "Epoch [1430/4500], Validation Loss: 0.2192\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1431/4500], Training Loss: 0.0001\n",
      "Epoch [1431/4500], Validation Loss: 0.2195\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1432/4500], Training Loss: 0.0001\n",
      "Epoch [1432/4500], Validation Loss: 0.2196\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1433/4500], Training Loss: 0.0001\n",
      "Epoch [1433/4500], Validation Loss: 0.2196\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1434/4500], Training Loss: 0.0001\n",
      "Epoch [1434/4500], Validation Loss: 0.2197\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1435/4500], Training Loss: 0.0001\n",
      "Epoch [1435/4500], Validation Loss: 0.2197\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1436/4500], Training Loss: 0.0001\n",
      "Epoch [1436/4500], Validation Loss: 0.2196\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1437/4500], Training Loss: 0.0001\n",
      "Epoch [1437/4500], Validation Loss: 0.2200\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1438/4500], Training Loss: 0.0001\n",
      "Epoch [1438/4500], Validation Loss: 0.2196\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1439/4500], Training Loss: 0.0001\n",
      "Epoch [1439/4500], Validation Loss: 0.2201\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1440/4500], Training Loss: 0.0001\n",
      "Epoch [1440/4500], Validation Loss: 0.2197\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1441/4500], Training Loss: 0.0001\n",
      "Epoch [1441/4500], Validation Loss: 0.2203\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1442/4500], Training Loss: 0.0001\n",
      "Epoch [1442/4500], Validation Loss: 0.2201\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1443/4500], Training Loss: 0.0001\n",
      "Epoch [1443/4500], Validation Loss: 0.2202\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1444/4500], Training Loss: 0.0001\n",
      "Epoch [1444/4500], Validation Loss: 0.2203\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1445/4500], Training Loss: 0.0001\n",
      "Epoch [1445/4500], Validation Loss: 0.2205\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1446/4500], Training Loss: 0.0001\n",
      "Epoch [1446/4500], Validation Loss: 0.2203\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1447/4500], Training Loss: 0.0001\n",
      "Epoch [1447/4500], Validation Loss: 0.2208\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1448/4500], Training Loss: 0.0001\n",
      "Epoch [1448/4500], Validation Loss: 0.2204\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1449/4500], Training Loss: 0.0001\n",
      "Epoch [1449/4500], Validation Loss: 0.2206\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1450/4500], Training Loss: 0.0001\n",
      "Epoch [1450/4500], Validation Loss: 0.2206\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1451/4500], Training Loss: 0.0001\n",
      "Epoch [1451/4500], Validation Loss: 0.2209\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1452/4500], Training Loss: 0.0001\n",
      "Epoch [1452/4500], Validation Loss: 0.2209\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1453/4500], Training Loss: 0.0001\n",
      "Epoch [1453/4500], Validation Loss: 0.2209\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1454/4500], Training Loss: 0.0001\n",
      "Epoch [1454/4500], Validation Loss: 0.2208\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1455/4500], Training Loss: 0.0001\n",
      "Epoch [1455/4500], Validation Loss: 0.2211\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1456/4500], Training Loss: 0.0001\n",
      "Epoch [1456/4500], Validation Loss: 0.2210\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1457/4500], Training Loss: 0.0001\n",
      "Epoch [1457/4500], Validation Loss: 0.2212\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1458/4500], Training Loss: 0.0001\n",
      "Epoch [1458/4500], Validation Loss: 0.2215\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1459/4500], Training Loss: 0.0001\n",
      "Epoch [1459/4500], Validation Loss: 0.2215\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1460/4500], Training Loss: 0.0001\n",
      "Epoch [1460/4500], Validation Loss: 0.2213\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1461/4500], Training Loss: 0.0001\n",
      "Epoch [1461/4500], Validation Loss: 0.2214\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1462/4500], Training Loss: 0.0001\n",
      "Epoch [1462/4500], Validation Loss: 0.2216\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1463/4500], Training Loss: 0.0001\n",
      "Epoch [1463/4500], Validation Loss: 0.2217\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1464/4500], Training Loss: 0.0001\n",
      "Epoch [1464/4500], Validation Loss: 0.2215\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1465/4500], Training Loss: 0.0001\n",
      "Epoch [1465/4500], Validation Loss: 0.2217\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1466/4500], Training Loss: 0.0001\n",
      "Epoch [1466/4500], Validation Loss: 0.2220\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1467/4500], Training Loss: 0.0001\n",
      "Epoch [1467/4500], Validation Loss: 0.2218\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1468/4500], Training Loss: 0.0001\n",
      "Epoch [1468/4500], Validation Loss: 0.2220\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1469/4500], Training Loss: 0.0001\n",
      "Epoch [1469/4500], Validation Loss: 0.2220\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1470/4500], Training Loss: 0.0001\n",
      "Epoch [1470/4500], Validation Loss: 0.2222\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1471/4500], Training Loss: 0.0001\n",
      "Epoch [1471/4500], Validation Loss: 0.2220\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1472/4500], Training Loss: 0.0001\n",
      "Epoch [1472/4500], Validation Loss: 0.2224\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1473/4500], Training Loss: 0.0001\n",
      "Epoch [1473/4500], Validation Loss: 0.2222\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1474/4500], Training Loss: 0.0001\n",
      "Epoch [1474/4500], Validation Loss: 0.2226\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1475/4500], Training Loss: 0.0001\n",
      "Epoch [1475/4500], Validation Loss: 0.2223\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1476/4500], Training Loss: 0.0001\n",
      "Epoch [1476/4500], Validation Loss: 0.2228\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1477/4500], Training Loss: 0.0001\n",
      "Epoch [1477/4500], Validation Loss: 0.2227\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1478/4500], Training Loss: 0.0001\n",
      "Epoch [1478/4500], Validation Loss: 0.2225\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1479/4500], Training Loss: 0.0001\n",
      "Epoch [1479/4500], Validation Loss: 0.2227\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1480/4500], Training Loss: 0.0001\n",
      "Epoch [1480/4500], Validation Loss: 0.2227\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1481/4500], Training Loss: 0.0001\n",
      "Epoch [1481/4500], Validation Loss: 0.2229\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1482/4500], Training Loss: 0.0001\n",
      "Epoch [1482/4500], Validation Loss: 0.2229\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1483/4500], Training Loss: 0.0001\n",
      "Epoch [1483/4500], Validation Loss: 0.2229\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1484/4500], Training Loss: 0.0001\n",
      "Epoch [1484/4500], Validation Loss: 0.2230\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1485/4500], Training Loss: 0.0001\n",
      "Epoch [1485/4500], Validation Loss: 0.2232\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1486/4500], Training Loss: 0.0001\n",
      "Epoch [1486/4500], Validation Loss: 0.2230\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1487/4500], Training Loss: 0.0001\n",
      "Epoch [1487/4500], Validation Loss: 0.2233\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1488/4500], Training Loss: 0.0001\n",
      "Epoch [1488/4500], Validation Loss: 0.2234\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1489/4500], Training Loss: 0.0001\n",
      "Epoch [1489/4500], Validation Loss: 0.2237\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1490/4500], Training Loss: 0.0001\n",
      "Epoch [1490/4500], Validation Loss: 0.2234\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1491/4500], Training Loss: 0.0001\n",
      "Epoch [1491/4500], Validation Loss: 0.2236\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1492/4500], Training Loss: 0.0001\n",
      "Epoch [1492/4500], Validation Loss: 0.2236\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1493/4500], Training Loss: 0.0001\n",
      "Epoch [1493/4500], Validation Loss: 0.2236\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1494/4500], Training Loss: 0.0001\n",
      "Epoch [1494/4500], Validation Loss: 0.2242\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1495/4500], Training Loss: 0.0001\n",
      "Epoch [1495/4500], Validation Loss: 0.2238\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1496/4500], Training Loss: 0.0001\n",
      "Epoch [1496/4500], Validation Loss: 0.2238\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1497/4500], Training Loss: 0.0001\n",
      "Epoch [1497/4500], Validation Loss: 0.2240\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1498/4500], Training Loss: 0.0001\n",
      "Epoch [1498/4500], Validation Loss: 0.2241\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1499/4500], Training Loss: 0.0001\n",
      "Epoch [1499/4500], Validation Loss: 0.2241\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1500/4500], Training Loss: 0.0001\n",
      "Epoch [1500/4500], Validation Loss: 0.2242\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1501/4500], Training Loss: 0.0001\n",
      "Epoch [1501/4500], Validation Loss: 0.2242\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1502/4500], Training Loss: 0.0001\n",
      "Epoch [1502/4500], Validation Loss: 0.2242\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1503/4500], Training Loss: 0.0001\n",
      "Epoch [1503/4500], Validation Loss: 0.2242\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1504/4500], Training Loss: 0.0001\n",
      "Epoch [1504/4500], Validation Loss: 0.2245\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1505/4500], Training Loss: 0.0001\n",
      "Epoch [1505/4500], Validation Loss: 0.2245\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1506/4500], Training Loss: 0.0001\n",
      "Epoch [1506/4500], Validation Loss: 0.2246\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1507/4500], Training Loss: 0.0001\n",
      "Epoch [1507/4500], Validation Loss: 0.2247\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1508/4500], Training Loss: 0.0001\n",
      "Epoch [1508/4500], Validation Loss: 0.2246\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1509/4500], Training Loss: 0.0001\n",
      "Epoch [1509/4500], Validation Loss: 0.2249\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1510/4500], Training Loss: 0.0001\n",
      "Epoch [1510/4500], Validation Loss: 0.2249\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1511/4500], Training Loss: 0.0001\n",
      "Epoch [1511/4500], Validation Loss: 0.2249\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1512/4500], Training Loss: 0.0001\n",
      "Epoch [1512/4500], Validation Loss: 0.2250\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1513/4500], Training Loss: 0.0001\n",
      "Epoch [1513/4500], Validation Loss: 0.2252\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1514/4500], Training Loss: 0.0001\n",
      "Epoch [1514/4500], Validation Loss: 0.2250\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1515/4500], Training Loss: 0.0001\n",
      "Epoch [1515/4500], Validation Loss: 0.2252\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1516/4500], Training Loss: 0.0001\n",
      "Epoch [1516/4500], Validation Loss: 0.2253\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1517/4500], Training Loss: 0.0001\n",
      "Epoch [1517/4500], Validation Loss: 0.2253\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1518/4500], Training Loss: 0.0001\n",
      "Epoch [1518/4500], Validation Loss: 0.2255\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1519/4500], Training Loss: 0.0001\n",
      "Epoch [1519/4500], Validation Loss: 0.2255\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1520/4500], Training Loss: 0.0001\n",
      "Epoch [1520/4500], Validation Loss: 0.2257\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1521/4500], Training Loss: 0.0001\n",
      "Epoch [1521/4500], Validation Loss: 0.2258\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1522/4500], Training Loss: 0.0001\n",
      "Epoch [1522/4500], Validation Loss: 0.2256\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1523/4500], Training Loss: 0.0001\n",
      "Epoch [1523/4500], Validation Loss: 0.2256\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1524/4500], Training Loss: 0.0001\n",
      "Epoch [1524/4500], Validation Loss: 0.2261\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1525/4500], Training Loss: 0.0001\n",
      "Epoch [1525/4500], Validation Loss: 0.2257\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1526/4500], Training Loss: 0.0001\n",
      "Epoch [1526/4500], Validation Loss: 0.2259\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1527/4500], Training Loss: 0.0001\n",
      "Epoch [1527/4500], Validation Loss: 0.2261\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1528/4500], Training Loss: 0.0001\n",
      "Epoch [1528/4500], Validation Loss: 0.2261\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1529/4500], Training Loss: 0.0001\n",
      "Epoch [1529/4500], Validation Loss: 0.2264\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1530/4500], Training Loss: 0.0001\n",
      "Epoch [1530/4500], Validation Loss: 0.2262\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1531/4500], Training Loss: 0.0001\n",
      "Epoch [1531/4500], Validation Loss: 0.2263\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1532/4500], Training Loss: 0.0001\n",
      "Epoch [1532/4500], Validation Loss: 0.2263\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1533/4500], Training Loss: 0.0001\n",
      "Epoch [1533/4500], Validation Loss: 0.2264\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1534/4500], Training Loss: 0.0001\n",
      "Epoch [1534/4500], Validation Loss: 0.2265\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1535/4500], Training Loss: 0.0001\n",
      "Epoch [1535/4500], Validation Loss: 0.2265\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1536/4500], Training Loss: 0.0001\n",
      "Epoch [1536/4500], Validation Loss: 0.2265\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1537/4500], Training Loss: 0.0001\n",
      "Epoch [1537/4500], Validation Loss: 0.2268\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1538/4500], Training Loss: 0.0001\n",
      "Epoch [1538/4500], Validation Loss: 0.2268\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1539/4500], Training Loss: 0.0001\n",
      "Epoch [1539/4500], Validation Loss: 0.2267\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1540/4500], Training Loss: 0.0001\n",
      "Epoch [1540/4500], Validation Loss: 0.2268\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1541/4500], Training Loss: 0.0001\n",
      "Epoch [1541/4500], Validation Loss: 0.2273\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1542/4500], Training Loss: 0.0001\n",
      "Epoch [1542/4500], Validation Loss: 0.2268\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1543/4500], Training Loss: 0.0001\n",
      "Epoch [1543/4500], Validation Loss: 0.2271\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1544/4500], Training Loss: 0.0001\n",
      "Epoch [1544/4500], Validation Loss: 0.2271\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1545/4500], Training Loss: 0.0001\n",
      "Epoch [1545/4500], Validation Loss: 0.2274\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1546/4500], Training Loss: 0.0001\n",
      "Epoch [1546/4500], Validation Loss: 0.2272\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1547/4500], Training Loss: 0.0001\n",
      "Epoch [1547/4500], Validation Loss: 0.2275\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1548/4500], Training Loss: 0.0001\n",
      "Epoch [1548/4500], Validation Loss: 0.2273\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1549/4500], Training Loss: 0.0001\n",
      "Epoch [1549/4500], Validation Loss: 0.2279\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1550/4500], Training Loss: 0.0001\n",
      "Epoch [1550/4500], Validation Loss: 0.2274\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1551/4500], Training Loss: 0.0001\n",
      "Epoch [1551/4500], Validation Loss: 0.2278\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1552/4500], Training Loss: 0.0001\n",
      "Epoch [1552/4500], Validation Loss: 0.2278\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1553/4500], Training Loss: 0.0001\n",
      "Epoch [1553/4500], Validation Loss: 0.2278\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1554/4500], Training Loss: 0.0001\n",
      "Epoch [1554/4500], Validation Loss: 0.2276\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1555/4500], Training Loss: 0.0001\n",
      "Epoch [1555/4500], Validation Loss: 0.2280\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1556/4500], Training Loss: 0.0001\n",
      "Epoch [1556/4500], Validation Loss: 0.2279\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1557/4500], Training Loss: 0.0001\n",
      "Epoch [1557/4500], Validation Loss: 0.2281\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1558/4500], Training Loss: 0.0001\n",
      "Epoch [1558/4500], Validation Loss: 0.2280\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1559/4500], Training Loss: 0.0001\n",
      "Epoch [1559/4500], Validation Loss: 0.2282\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1560/4500], Training Loss: 0.0001\n",
      "Epoch [1560/4500], Validation Loss: 0.2284\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1561/4500], Training Loss: 0.0001\n",
      "Epoch [1561/4500], Validation Loss: 0.2281\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1562/4500], Training Loss: 0.0001\n",
      "Epoch [1562/4500], Validation Loss: 0.2286\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1563/4500], Training Loss: 0.0001\n",
      "Epoch [1563/4500], Validation Loss: 0.2284\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1564/4500], Training Loss: 0.0001\n",
      "Epoch [1564/4500], Validation Loss: 0.2284\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1565/4500], Training Loss: 0.0001\n",
      "Epoch [1565/4500], Validation Loss: 0.2286\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1566/4500], Training Loss: 0.0001\n",
      "Epoch [1566/4500], Validation Loss: 0.2287\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1567/4500], Training Loss: 0.0001\n",
      "Epoch [1567/4500], Validation Loss: 0.2286\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1568/4500], Training Loss: 0.0001\n",
      "Epoch [1568/4500], Validation Loss: 0.2288\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1569/4500], Training Loss: 0.0001\n",
      "Epoch [1569/4500], Validation Loss: 0.2287\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1570/4500], Training Loss: 0.0001\n",
      "Epoch [1570/4500], Validation Loss: 0.2288\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1571/4500], Training Loss: 0.0001\n",
      "Epoch [1571/4500], Validation Loss: 0.2287\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1572/4500], Training Loss: 0.0001\n",
      "Epoch [1572/4500], Validation Loss: 0.2291\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1573/4500], Training Loss: 0.0001\n",
      "Epoch [1573/4500], Validation Loss: 0.2290\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1574/4500], Training Loss: 0.0001\n",
      "Epoch [1574/4500], Validation Loss: 0.2293\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1575/4500], Training Loss: 0.0001\n",
      "Epoch [1575/4500], Validation Loss: 0.2294\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1576/4500], Training Loss: 0.0001\n",
      "Epoch [1576/4500], Validation Loss: 0.2293\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1577/4500], Training Loss: 0.0001\n",
      "Epoch [1577/4500], Validation Loss: 0.2294\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1578/4500], Training Loss: 0.0001\n",
      "Epoch [1578/4500], Validation Loss: 0.2294\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1579/4500], Training Loss: 0.0001\n",
      "Epoch [1579/4500], Validation Loss: 0.2295\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1580/4500], Training Loss: 0.0001\n",
      "Epoch [1580/4500], Validation Loss: 0.2295\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1581/4500], Training Loss: 0.0001\n",
      "Epoch [1581/4500], Validation Loss: 0.2297\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1582/4500], Training Loss: 0.0001\n",
      "Epoch [1582/4500], Validation Loss: 0.2297\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1583/4500], Training Loss: 0.0001\n",
      "Epoch [1583/4500], Validation Loss: 0.2298\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1584/4500], Training Loss: 0.0001\n",
      "Epoch [1584/4500], Validation Loss: 0.2297\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1585/4500], Training Loss: 0.0001\n",
      "Epoch [1585/4500], Validation Loss: 0.2298\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1586/4500], Training Loss: 0.0001\n",
      "Epoch [1586/4500], Validation Loss: 0.2303\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1587/4500], Training Loss: 0.0001\n",
      "Epoch [1587/4500], Validation Loss: 0.2300\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1588/4500], Training Loss: 0.0001\n",
      "Epoch [1588/4500], Validation Loss: 0.2300\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1589/4500], Training Loss: 0.0001\n",
      "Epoch [1589/4500], Validation Loss: 0.2301\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1590/4500], Training Loss: 0.0001\n",
      "Epoch [1590/4500], Validation Loss: 0.2303\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1591/4500], Training Loss: 0.0001\n",
      "Epoch [1591/4500], Validation Loss: 0.2302\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1592/4500], Training Loss: 0.0001\n",
      "Epoch [1592/4500], Validation Loss: 0.2302\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1593/4500], Training Loss: 0.0001\n",
      "Epoch [1593/4500], Validation Loss: 0.2304\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1594/4500], Training Loss: 0.0001\n",
      "Epoch [1594/4500], Validation Loss: 0.2305\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1595/4500], Training Loss: 0.0001\n",
      "Epoch [1595/4500], Validation Loss: 0.2307\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1596/4500], Training Loss: 0.0001\n",
      "Epoch [1596/4500], Validation Loss: 0.2304\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1597/4500], Training Loss: 0.0001\n",
      "Epoch [1597/4500], Validation Loss: 0.2309\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1598/4500], Training Loss: 0.0001\n",
      "Epoch [1598/4500], Validation Loss: 0.2304\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1599/4500], Training Loss: 0.0001\n",
      "Epoch [1599/4500], Validation Loss: 0.2309\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1600/4500], Training Loss: 0.0001\n",
      "Epoch [1600/4500], Validation Loss: 0.2308\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1601/4500], Training Loss: 0.0001\n",
      "Epoch [1601/4500], Validation Loss: 0.2309\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1602/4500], Training Loss: 0.0001\n",
      "Epoch [1602/4500], Validation Loss: 0.2310\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1603/4500], Training Loss: 0.0001\n",
      "Epoch [1603/4500], Validation Loss: 0.2311\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1604/4500], Training Loss: 0.0001\n",
      "Epoch [1604/4500], Validation Loss: 0.2310\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1605/4500], Training Loss: 0.0001\n",
      "Epoch [1605/4500], Validation Loss: 0.2314\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1606/4500], Training Loss: 0.0001\n",
      "Epoch [1606/4500], Validation Loss: 0.2310\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1607/4500], Training Loss: 0.0001\n",
      "Epoch [1607/4500], Validation Loss: 0.2315\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1608/4500], Training Loss: 0.0001\n",
      "Epoch [1608/4500], Validation Loss: 0.2311\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1609/4500], Training Loss: 0.0001\n",
      "Epoch [1609/4500], Validation Loss: 0.2316\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1610/4500], Training Loss: 0.0001\n",
      "Epoch [1610/4500], Validation Loss: 0.2314\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1611/4500], Training Loss: 0.0001\n",
      "Epoch [1611/4500], Validation Loss: 0.2317\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1612/4500], Training Loss: 0.0001\n",
      "Epoch [1612/4500], Validation Loss: 0.2314\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1613/4500], Training Loss: 0.0001\n",
      "Epoch [1613/4500], Validation Loss: 0.2317\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1614/4500], Training Loss: 0.0001\n",
      "Epoch [1614/4500], Validation Loss: 0.2318\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1615/4500], Training Loss: 0.0001\n",
      "Epoch [1615/4500], Validation Loss: 0.2320\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1616/4500], Training Loss: 0.0001\n",
      "Epoch [1616/4500], Validation Loss: 0.2317\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1617/4500], Training Loss: 0.0001\n",
      "Epoch [1617/4500], Validation Loss: 0.2318\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1618/4500], Training Loss: 0.0001\n",
      "Epoch [1618/4500], Validation Loss: 0.2318\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1619/4500], Training Loss: 0.0001\n",
      "Epoch [1619/4500], Validation Loss: 0.2321\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1620/4500], Training Loss: 0.0001\n",
      "Epoch [1620/4500], Validation Loss: 0.2323\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1621/4500], Training Loss: 0.0001\n",
      "Epoch [1621/4500], Validation Loss: 0.2320\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1622/4500], Training Loss: 0.0001\n",
      "Epoch [1622/4500], Validation Loss: 0.2321\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1623/4500], Training Loss: 0.0001\n",
      "Epoch [1623/4500], Validation Loss: 0.2326\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1624/4500], Training Loss: 0.0001\n",
      "Epoch [1624/4500], Validation Loss: 0.2323\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1625/4500], Training Loss: 0.0001\n",
      "Epoch [1625/4500], Validation Loss: 0.2323\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1626/4500], Training Loss: 0.0001\n",
      "Epoch [1626/4500], Validation Loss: 0.2323\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1627/4500], Training Loss: 0.0001\n",
      "Epoch [1627/4500], Validation Loss: 0.2326\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1628/4500], Training Loss: 0.0001\n",
      "Epoch [1628/4500], Validation Loss: 0.2327\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1629/4500], Training Loss: 0.0001\n",
      "Epoch [1629/4500], Validation Loss: 0.2326\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1630/4500], Training Loss: 0.0001\n",
      "Epoch [1630/4500], Validation Loss: 0.2330\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1631/4500], Training Loss: 0.0001\n",
      "Epoch [1631/4500], Validation Loss: 0.2327\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1632/4500], Training Loss: 0.0001\n",
      "Epoch [1632/4500], Validation Loss: 0.2328\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1633/4500], Training Loss: 0.0001\n",
      "Epoch [1633/4500], Validation Loss: 0.2331\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1634/4500], Training Loss: 0.0001\n",
      "Epoch [1634/4500], Validation Loss: 0.2330\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1635/4500], Training Loss: 0.0001\n",
      "Epoch [1635/4500], Validation Loss: 0.2330\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1636/4500], Training Loss: 0.0000\n",
      "Epoch [1636/4500], Validation Loss: 0.2331\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1637/4500], Training Loss: 0.0000\n",
      "Epoch [1637/4500], Validation Loss: 0.2333\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1638/4500], Training Loss: 0.0000\n",
      "Epoch [1638/4500], Validation Loss: 0.2332\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1639/4500], Training Loss: 0.0001\n",
      "Epoch [1639/4500], Validation Loss: 0.2334\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1640/4500], Training Loss: 0.0000\n",
      "Epoch [1640/4500], Validation Loss: 0.2334\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1641/4500], Training Loss: 0.0000\n",
      "Epoch [1641/4500], Validation Loss: 0.2334\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1642/4500], Training Loss: 0.0000\n",
      "Epoch [1642/4500], Validation Loss: 0.2335\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1643/4500], Training Loss: 0.0000\n",
      "Epoch [1643/4500], Validation Loss: 0.2335\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1644/4500], Training Loss: 0.0000\n",
      "Epoch [1644/4500], Validation Loss: 0.2336\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1645/4500], Training Loss: 0.0000\n",
      "Epoch [1645/4500], Validation Loss: 0.2336\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1646/4500], Training Loss: 0.0000\n",
      "Epoch [1646/4500], Validation Loss: 0.2337\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1647/4500], Training Loss: 0.0000\n",
      "Epoch [1647/4500], Validation Loss: 0.2339\n",
      "Accuracy: 0.9508, Precision: 0.9730, Recall: 0.9278, F1: 0.9499\n",
      "Epoch [1648/4500], Training Loss: 0.0000\n",
      "Epoch [1648/4500], Validation Loss: 0.2338\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1649/4500], Training Loss: 0.0000\n",
      "Epoch [1649/4500], Validation Loss: 0.2338\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1650/4500], Training Loss: 0.0000\n",
      "Epoch [1650/4500], Validation Loss: 0.2339\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1651/4500], Training Loss: 0.0000\n",
      "Epoch [1651/4500], Validation Loss: 0.2340\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1652/4500], Training Loss: 0.0000\n",
      "Epoch [1652/4500], Validation Loss: 0.2341\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1653/4500], Training Loss: 0.0000\n",
      "Epoch [1653/4500], Validation Loss: 0.2342\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1654/4500], Training Loss: 0.0000\n",
      "Epoch [1654/4500], Validation Loss: 0.2342\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1655/4500], Training Loss: 0.0000\n",
      "Epoch [1655/4500], Validation Loss: 0.2342\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1656/4500], Training Loss: 0.0000\n",
      "Epoch [1656/4500], Validation Loss: 0.2345\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1657/4500], Training Loss: 0.0000\n",
      "Epoch [1657/4500], Validation Loss: 0.2345\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1658/4500], Training Loss: 0.0000\n",
      "Epoch [1658/4500], Validation Loss: 0.2344\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1659/4500], Training Loss: 0.0000\n",
      "Epoch [1659/4500], Validation Loss: 0.2344\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1660/4500], Training Loss: 0.0000\n",
      "Epoch [1660/4500], Validation Loss: 0.2346\n",
      "Accuracy: 0.9521, Precision: 0.9730, Recall: 0.9304, F1: 0.9513\n",
      "Epoch [1661/4500], Training Loss: 0.0000\n",
      "Epoch [1661/4500], Validation Loss: 0.2346\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1662/4500], Training Loss: 0.0000\n",
      "Epoch [1662/4500], Validation Loss: 0.2347\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1663/4500], Training Loss: 0.0000\n",
      "Epoch [1663/4500], Validation Loss: 0.2350\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1664/4500], Training Loss: 0.0000\n",
      "Epoch [1664/4500], Validation Loss: 0.2348\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1665/4500], Training Loss: 0.0000\n",
      "Epoch [1665/4500], Validation Loss: 0.2351\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1666/4500], Training Loss: 0.0000\n",
      "Epoch [1666/4500], Validation Loss: 0.2349\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1667/4500], Training Loss: 0.0000\n",
      "Epoch [1667/4500], Validation Loss: 0.2348\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1668/4500], Training Loss: 0.0000\n",
      "Epoch [1668/4500], Validation Loss: 0.2352\n",
      "Accuracy: 0.9521, Precision: 0.9756, Recall: 0.9278, F1: 0.9511\n",
      "Epoch [1669/4500], Training Loss: 0.0000\n",
      "Epoch [1669/4500], Validation Loss: 0.2349\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1670/4500], Training Loss: 0.0000\n",
      "Epoch [1670/4500], Validation Loss: 0.2351\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1671/4500], Training Loss: 0.0000\n",
      "Epoch [1671/4500], Validation Loss: 0.2352\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1672/4500], Training Loss: 0.0000\n",
      "Epoch [1672/4500], Validation Loss: 0.2353\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1673/4500], Training Loss: 0.0000\n",
      "Epoch [1673/4500], Validation Loss: 0.2355\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1674/4500], Training Loss: 0.0000\n",
      "Epoch [1674/4500], Validation Loss: 0.2354\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1675/4500], Training Loss: 0.0000\n",
      "Epoch [1675/4500], Validation Loss: 0.2356\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1676/4500], Training Loss: 0.0000\n",
      "Epoch [1676/4500], Validation Loss: 0.2355\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1677/4500], Training Loss: 0.0000\n",
      "Epoch [1677/4500], Validation Loss: 0.2355\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1678/4500], Training Loss: 0.0000\n",
      "Epoch [1678/4500], Validation Loss: 0.2357\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1679/4500], Training Loss: 0.0000\n",
      "Epoch [1679/4500], Validation Loss: 0.2358\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1680/4500], Training Loss: 0.0000\n",
      "Epoch [1680/4500], Validation Loss: 0.2358\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1681/4500], Training Loss: 0.0000\n",
      "Epoch [1681/4500], Validation Loss: 0.2358\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1682/4500], Training Loss: 0.0000\n",
      "Epoch [1682/4500], Validation Loss: 0.2360\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1683/4500], Training Loss: 0.0000\n",
      "Epoch [1683/4500], Validation Loss: 0.2360\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1684/4500], Training Loss: 0.0000\n",
      "Epoch [1684/4500], Validation Loss: 0.2359\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1685/4500], Training Loss: 0.0000\n",
      "Epoch [1685/4500], Validation Loss: 0.2361\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1686/4500], Training Loss: 0.0000\n",
      "Epoch [1686/4500], Validation Loss: 0.2363\n",
      "Accuracy: 0.9534, Precision: 0.9757, Recall: 0.9304, F1: 0.9525\n",
      "Epoch [1687/4500], Training Loss: 0.0000\n",
      "Epoch [1687/4500], Validation Loss: 0.2360\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1688/4500], Training Loss: 0.0000\n",
      "Epoch [1688/4500], Validation Loss: 0.2362\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1689/4500], Training Loss: 0.0000\n",
      "Epoch [1689/4500], Validation Loss: 0.2363\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1690/4500], Training Loss: 0.0000\n",
      "Epoch [1690/4500], Validation Loss: 0.2360\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1691/4500], Training Loss: 0.0000\n",
      "Epoch [1691/4500], Validation Loss: 0.2366\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1692/4500], Training Loss: 0.0000\n",
      "Epoch [1692/4500], Validation Loss: 0.2365\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1693/4500], Training Loss: 0.0000\n",
      "Epoch [1693/4500], Validation Loss: 0.2367\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1694/4500], Training Loss: 0.0000\n",
      "Epoch [1694/4500], Validation Loss: 0.2367\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1695/4500], Training Loss: 0.0000\n",
      "Epoch [1695/4500], Validation Loss: 0.2365\n",
      "Accuracy: 0.9534, Precision: 0.9731, Recall: 0.9330, F1: 0.9526\n",
      "Epoch [1696/4500], Training Loss: 0.0000\n",
      "Epoch [1696/4500], Validation Loss: 0.2367\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1697/4500], Training Loss: 0.0000\n",
      "Epoch [1697/4500], Validation Loss: 0.2370\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1698/4500], Training Loss: 0.0000\n",
      "Epoch [1698/4500], Validation Loss: 0.2368\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1699/4500], Training Loss: 0.0000\n",
      "Epoch [1699/4500], Validation Loss: 0.2370\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1700/4500], Training Loss: 0.0000\n",
      "Epoch [1700/4500], Validation Loss: 0.2369\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1701/4500], Training Loss: 0.0000\n",
      "Epoch [1701/4500], Validation Loss: 0.2372\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1702/4500], Training Loss: 0.0000\n",
      "Epoch [1702/4500], Validation Loss: 0.2369\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1703/4500], Training Loss: 0.0000\n",
      "Epoch [1703/4500], Validation Loss: 0.2371\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1704/4500], Training Loss: 0.0000\n",
      "Epoch [1704/4500], Validation Loss: 0.2371\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1705/4500], Training Loss: 0.0000\n",
      "Epoch [1705/4500], Validation Loss: 0.2375\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1706/4500], Training Loss: 0.0000\n",
      "Epoch [1706/4500], Validation Loss: 0.2371\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1707/4500], Training Loss: 0.0000\n",
      "Epoch [1707/4500], Validation Loss: 0.2374\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1708/4500], Training Loss: 0.0000\n",
      "Epoch [1708/4500], Validation Loss: 0.2374\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1709/4500], Training Loss: 0.0000\n",
      "Epoch [1709/4500], Validation Loss: 0.2374\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1710/4500], Training Loss: 0.0000\n",
      "Epoch [1710/4500], Validation Loss: 0.2378\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1711/4500], Training Loss: 0.0000\n",
      "Epoch [1711/4500], Validation Loss: 0.2374\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1712/4500], Training Loss: 0.0000\n",
      "Epoch [1712/4500], Validation Loss: 0.2376\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1713/4500], Training Loss: 0.0000\n",
      "Epoch [1713/4500], Validation Loss: 0.2378\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1714/4500], Training Loss: 0.0000\n",
      "Epoch [1714/4500], Validation Loss: 0.2377\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1715/4500], Training Loss: 0.0000\n",
      "Epoch [1715/4500], Validation Loss: 0.2377\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1716/4500], Training Loss: 0.0000\n",
      "Epoch [1716/4500], Validation Loss: 0.2381\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1717/4500], Training Loss: 0.0000\n",
      "Epoch [1717/4500], Validation Loss: 0.2378\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1718/4500], Training Loss: 0.0000\n",
      "Epoch [1718/4500], Validation Loss: 0.2378\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1719/4500], Training Loss: 0.0000\n",
      "Epoch [1719/4500], Validation Loss: 0.2380\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1720/4500], Training Loss: 0.0000\n",
      "Epoch [1720/4500], Validation Loss: 0.2381\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1721/4500], Training Loss: 0.0000\n",
      "Epoch [1721/4500], Validation Loss: 0.2382\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1722/4500], Training Loss: 0.0000\n",
      "Epoch [1722/4500], Validation Loss: 0.2381\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1723/4500], Training Loss: 0.0000\n",
      "Epoch [1723/4500], Validation Loss: 0.2383\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1724/4500], Training Loss: 0.0000\n",
      "Epoch [1724/4500], Validation Loss: 0.2385\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1725/4500], Training Loss: 0.0000\n",
      "Epoch [1725/4500], Validation Loss: 0.2384\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1726/4500], Training Loss: 0.0000\n",
      "Epoch [1726/4500], Validation Loss: 0.2384\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1727/4500], Training Loss: 0.0000\n",
      "Epoch [1727/4500], Validation Loss: 0.2383\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1728/4500], Training Loss: 0.0000\n",
      "Epoch [1728/4500], Validation Loss: 0.2385\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1729/4500], Training Loss: 0.0000\n",
      "Epoch [1729/4500], Validation Loss: 0.2384\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1730/4500], Training Loss: 0.0000\n",
      "Epoch [1730/4500], Validation Loss: 0.2389\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1731/4500], Training Loss: 0.0000\n",
      "Epoch [1731/4500], Validation Loss: 0.2385\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1732/4500], Training Loss: 0.0000\n",
      "Epoch [1732/4500], Validation Loss: 0.2388\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1733/4500], Training Loss: 0.0000\n",
      "Epoch [1733/4500], Validation Loss: 0.2388\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1734/4500], Training Loss: 0.0000\n",
      "Epoch [1734/4500], Validation Loss: 0.2389\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1735/4500], Training Loss: 0.0000\n",
      "Epoch [1735/4500], Validation Loss: 0.2390\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1736/4500], Training Loss: 0.0000\n",
      "Epoch [1736/4500], Validation Loss: 0.2387\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1737/4500], Training Loss: 0.0000\n",
      "Epoch [1737/4500], Validation Loss: 0.2391\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1738/4500], Training Loss: 0.0000\n",
      "Epoch [1738/4500], Validation Loss: 0.2393\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1739/4500], Training Loss: 0.0000\n",
      "Epoch [1739/4500], Validation Loss: 0.2391\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1740/4500], Training Loss: 0.0000\n",
      "Epoch [1740/4500], Validation Loss: 0.2392\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1741/4500], Training Loss: 0.0000\n",
      "Epoch [1741/4500], Validation Loss: 0.2391\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1742/4500], Training Loss: 0.0000\n",
      "Epoch [1742/4500], Validation Loss: 0.2392\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1743/4500], Training Loss: 0.0000\n",
      "Epoch [1743/4500], Validation Loss: 0.2396\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1744/4500], Training Loss: 0.0000\n",
      "Epoch [1744/4500], Validation Loss: 0.2394\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1745/4500], Training Loss: 0.0000\n",
      "Epoch [1745/4500], Validation Loss: 0.2394\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1746/4500], Training Loss: 0.0000\n",
      "Epoch [1746/4500], Validation Loss: 0.2394\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1747/4500], Training Loss: 0.0000\n",
      "Epoch [1747/4500], Validation Loss: 0.2395\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1748/4500], Training Loss: 0.0000\n",
      "Epoch [1748/4500], Validation Loss: 0.2396\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1749/4500], Training Loss: 0.0000\n",
      "Epoch [1749/4500], Validation Loss: 0.2398\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1750/4500], Training Loss: 0.0000\n",
      "Epoch [1750/4500], Validation Loss: 0.2398\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1751/4500], Training Loss: 0.0000\n",
      "Epoch [1751/4500], Validation Loss: 0.2399\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1752/4500], Training Loss: 0.0000\n",
      "Epoch [1752/4500], Validation Loss: 0.2399\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1753/4500], Training Loss: 0.0000\n",
      "Epoch [1753/4500], Validation Loss: 0.2399\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1754/4500], Training Loss: 0.0000\n",
      "Epoch [1754/4500], Validation Loss: 0.2403\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1755/4500], Training Loss: 0.0000\n",
      "Epoch [1755/4500], Validation Loss: 0.2400\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1756/4500], Training Loss: 0.0000\n",
      "Epoch [1756/4500], Validation Loss: 0.2399\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1757/4500], Training Loss: 0.0000\n",
      "Epoch [1757/4500], Validation Loss: 0.2401\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1758/4500], Training Loss: 0.0000\n",
      "Epoch [1758/4500], Validation Loss: 0.2402\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1759/4500], Training Loss: 0.0000\n",
      "Epoch [1759/4500], Validation Loss: 0.2403\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1760/4500], Training Loss: 0.0000\n",
      "Epoch [1760/4500], Validation Loss: 0.2402\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1761/4500], Training Loss: 0.0000\n",
      "Epoch [1761/4500], Validation Loss: 0.2405\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1762/4500], Training Loss: 0.0000\n",
      "Epoch [1762/4500], Validation Loss: 0.2404\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1763/4500], Training Loss: 0.0000\n",
      "Epoch [1763/4500], Validation Loss: 0.2403\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1764/4500], Training Loss: 0.0000\n",
      "Epoch [1764/4500], Validation Loss: 0.2405\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1765/4500], Training Loss: 0.0000\n",
      "Epoch [1765/4500], Validation Loss: 0.2406\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1766/4500], Training Loss: 0.0000\n",
      "Epoch [1766/4500], Validation Loss: 0.2404\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1767/4500], Training Loss: 0.0000\n",
      "Epoch [1767/4500], Validation Loss: 0.2408\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1768/4500], Training Loss: 0.0000\n",
      "Epoch [1768/4500], Validation Loss: 0.2405\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1769/4500], Training Loss: 0.0000\n",
      "Epoch [1769/4500], Validation Loss: 0.2409\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1770/4500], Training Loss: 0.0000\n",
      "Epoch [1770/4500], Validation Loss: 0.2407\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1771/4500], Training Loss: 0.0000\n",
      "Epoch [1771/4500], Validation Loss: 0.2409\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1772/4500], Training Loss: 0.0000\n",
      "Epoch [1772/4500], Validation Loss: 0.2409\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1773/4500], Training Loss: 0.0000\n",
      "Epoch [1773/4500], Validation Loss: 0.2410\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1774/4500], Training Loss: 0.0000\n",
      "Epoch [1774/4500], Validation Loss: 0.2411\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1775/4500], Training Loss: 0.0000\n",
      "Epoch [1775/4500], Validation Loss: 0.2410\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1776/4500], Training Loss: 0.0000\n",
      "Epoch [1776/4500], Validation Loss: 0.2409\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1777/4500], Training Loss: 0.0000\n",
      "Epoch [1777/4500], Validation Loss: 0.2412\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1778/4500], Training Loss: 0.0000\n",
      "Epoch [1778/4500], Validation Loss: 0.2413\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1779/4500], Training Loss: 0.0000\n",
      "Epoch [1779/4500], Validation Loss: 0.2412\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1780/4500], Training Loss: 0.0000\n",
      "Epoch [1780/4500], Validation Loss: 0.2414\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1781/4500], Training Loss: 0.0000\n",
      "Epoch [1781/4500], Validation Loss: 0.2413\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1782/4500], Training Loss: 0.0000\n",
      "Epoch [1782/4500], Validation Loss: 0.2414\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1783/4500], Training Loss: 0.0000\n",
      "Epoch [1783/4500], Validation Loss: 0.2416\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1784/4500], Training Loss: 0.0000\n",
      "Epoch [1784/4500], Validation Loss: 0.2414\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1785/4500], Training Loss: 0.0000\n",
      "Epoch [1785/4500], Validation Loss: 0.2416\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1786/4500], Training Loss: 0.0000\n",
      "Epoch [1786/4500], Validation Loss: 0.2415\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1787/4500], Training Loss: 0.0000\n",
      "Epoch [1787/4500], Validation Loss: 0.2417\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1788/4500], Training Loss: 0.0000\n",
      "Epoch [1788/4500], Validation Loss: 0.2415\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1789/4500], Training Loss: 0.0000\n",
      "Epoch [1789/4500], Validation Loss: 0.2421\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1790/4500], Training Loss: 0.0000\n",
      "Epoch [1790/4500], Validation Loss: 0.2417\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1791/4500], Training Loss: 0.0000\n",
      "Epoch [1791/4500], Validation Loss: 0.2419\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1792/4500], Training Loss: 0.0000\n",
      "Epoch [1792/4500], Validation Loss: 0.2417\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1793/4500], Training Loss: 0.0000\n",
      "Epoch [1793/4500], Validation Loss: 0.2420\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1794/4500], Training Loss: 0.0000\n",
      "Epoch [1794/4500], Validation Loss: 0.2420\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1795/4500], Training Loss: 0.0000\n",
      "Epoch [1795/4500], Validation Loss: 0.2420\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1796/4500], Training Loss: 0.0000\n",
      "Epoch [1796/4500], Validation Loss: 0.2421\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1797/4500], Training Loss: 0.0000\n",
      "Epoch [1797/4500], Validation Loss: 0.2421\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1798/4500], Training Loss: 0.0000\n",
      "Epoch [1798/4500], Validation Loss: 0.2424\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1799/4500], Training Loss: 0.0000\n",
      "Epoch [1799/4500], Validation Loss: 0.2422\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1800/4500], Training Loss: 0.0000\n",
      "Epoch [1800/4500], Validation Loss: 0.2424\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1801/4500], Training Loss: 0.0000\n",
      "Epoch [1801/4500], Validation Loss: 0.2423\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1802/4500], Training Loss: 0.0000\n",
      "Epoch [1802/4500], Validation Loss: 0.2425\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1803/4500], Training Loss: 0.0000\n",
      "Epoch [1803/4500], Validation Loss: 0.2425\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1804/4500], Training Loss: 0.0000\n",
      "Epoch [1804/4500], Validation Loss: 0.2425\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1805/4500], Training Loss: 0.0000\n",
      "Epoch [1805/4500], Validation Loss: 0.2424\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1806/4500], Training Loss: 0.0000\n",
      "Epoch [1806/4500], Validation Loss: 0.2428\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1807/4500], Training Loss: 0.0000\n",
      "Epoch [1807/4500], Validation Loss: 0.2426\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1808/4500], Training Loss: 0.0000\n",
      "Epoch [1808/4500], Validation Loss: 0.2428\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1809/4500], Training Loss: 0.0000\n",
      "Epoch [1809/4500], Validation Loss: 0.2427\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1810/4500], Training Loss: 0.0000\n",
      "Epoch [1810/4500], Validation Loss: 0.2430\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1811/4500], Training Loss: 0.0000\n",
      "Epoch [1811/4500], Validation Loss: 0.2431\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1812/4500], Training Loss: 0.0000\n",
      "Epoch [1812/4500], Validation Loss: 0.2431\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1813/4500], Training Loss: 0.0000\n",
      "Epoch [1813/4500], Validation Loss: 0.2430\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1814/4500], Training Loss: 0.0000\n",
      "Epoch [1814/4500], Validation Loss: 0.2428\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1815/4500], Training Loss: 0.0000\n",
      "Epoch [1815/4500], Validation Loss: 0.2433\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1816/4500], Training Loss: 0.0000\n",
      "Epoch [1816/4500], Validation Loss: 0.2431\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1817/4500], Training Loss: 0.0000\n",
      "Epoch [1817/4500], Validation Loss: 0.2433\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1818/4500], Training Loss: 0.0000\n",
      "Epoch [1818/4500], Validation Loss: 0.2432\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1819/4500], Training Loss: 0.0000\n",
      "Epoch [1819/4500], Validation Loss: 0.2436\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1820/4500], Training Loss: 0.0000\n",
      "Epoch [1820/4500], Validation Loss: 0.2433\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1821/4500], Training Loss: 0.0000\n",
      "Epoch [1821/4500], Validation Loss: 0.2435\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1822/4500], Training Loss: 0.0000\n",
      "Epoch [1822/4500], Validation Loss: 0.2435\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1823/4500], Training Loss: 0.0000\n",
      "Epoch [1823/4500], Validation Loss: 0.2435\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1824/4500], Training Loss: 0.0000\n",
      "Epoch [1824/4500], Validation Loss: 0.2435\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1825/4500], Training Loss: 0.0000\n",
      "Epoch [1825/4500], Validation Loss: 0.2436\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1826/4500], Training Loss: 0.0000\n",
      "Epoch [1826/4500], Validation Loss: 0.2437\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1827/4500], Training Loss: 0.0000\n",
      "Epoch [1827/4500], Validation Loss: 0.2439\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1828/4500], Training Loss: 0.0000\n",
      "Epoch [1828/4500], Validation Loss: 0.2436\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1829/4500], Training Loss: 0.0000\n",
      "Epoch [1829/4500], Validation Loss: 0.2440\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1830/4500], Training Loss: 0.0000\n",
      "Epoch [1830/4500], Validation Loss: 0.2437\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1831/4500], Training Loss: 0.0000\n",
      "Epoch [1831/4500], Validation Loss: 0.2440\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1832/4500], Training Loss: 0.0000\n",
      "Epoch [1832/4500], Validation Loss: 0.2438\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1833/4500], Training Loss: 0.0000\n",
      "Epoch [1833/4500], Validation Loss: 0.2442\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1834/4500], Training Loss: 0.0000\n",
      "Epoch [1834/4500], Validation Loss: 0.2441\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1835/4500], Training Loss: 0.0000\n",
      "Epoch [1835/4500], Validation Loss: 0.2443\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1836/4500], Training Loss: 0.0000\n",
      "Epoch [1836/4500], Validation Loss: 0.2441\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1837/4500], Training Loss: 0.0000\n",
      "Epoch [1837/4500], Validation Loss: 0.2442\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1838/4500], Training Loss: 0.0000\n",
      "Epoch [1838/4500], Validation Loss: 0.2444\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1839/4500], Training Loss: 0.0000\n",
      "Epoch [1839/4500], Validation Loss: 0.2443\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1840/4500], Training Loss: 0.0000\n",
      "Epoch [1840/4500], Validation Loss: 0.2445\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1841/4500], Training Loss: 0.0000\n",
      "Epoch [1841/4500], Validation Loss: 0.2445\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1842/4500], Training Loss: 0.0000\n",
      "Epoch [1842/4500], Validation Loss: 0.2446\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1843/4500], Training Loss: 0.0000\n",
      "Epoch [1843/4500], Validation Loss: 0.2443\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1844/4500], Training Loss: 0.0000\n",
      "Epoch [1844/4500], Validation Loss: 0.2445\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1845/4500], Training Loss: 0.0000\n",
      "Epoch [1845/4500], Validation Loss: 0.2447\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1846/4500], Training Loss: 0.0000\n",
      "Epoch [1846/4500], Validation Loss: 0.2445\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1847/4500], Training Loss: 0.0000\n",
      "Epoch [1847/4500], Validation Loss: 0.2450\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1848/4500], Training Loss: 0.0000\n",
      "Epoch [1848/4500], Validation Loss: 0.2447\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1849/4500], Training Loss: 0.0000\n",
      "Epoch [1849/4500], Validation Loss: 0.2449\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1850/4500], Training Loss: 0.0000\n",
      "Epoch [1850/4500], Validation Loss: 0.2445\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1851/4500], Training Loss: 0.0000\n",
      "Epoch [1851/4500], Validation Loss: 0.2450\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1852/4500], Training Loss: 0.0000\n",
      "Epoch [1852/4500], Validation Loss: 0.2449\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1853/4500], Training Loss: 0.0000\n",
      "Epoch [1853/4500], Validation Loss: 0.2450\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1854/4500], Training Loss: 0.0000\n",
      "Epoch [1854/4500], Validation Loss: 0.2451\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1855/4500], Training Loss: 0.0000\n",
      "Epoch [1855/4500], Validation Loss: 0.2450\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1856/4500], Training Loss: 0.0000\n",
      "Epoch [1856/4500], Validation Loss: 0.2453\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1857/4500], Training Loss: 0.0000\n",
      "Epoch [1857/4500], Validation Loss: 0.2452\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1858/4500], Training Loss: 0.0000\n",
      "Epoch [1858/4500], Validation Loss: 0.2452\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1859/4500], Training Loss: 0.0000\n",
      "Epoch [1859/4500], Validation Loss: 0.2452\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1860/4500], Training Loss: 0.0000\n",
      "Epoch [1860/4500], Validation Loss: 0.2455\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1861/4500], Training Loss: 0.0000\n",
      "Epoch [1861/4500], Validation Loss: 0.2454\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1862/4500], Training Loss: 0.0000\n",
      "Epoch [1862/4500], Validation Loss: 0.2455\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1863/4500], Training Loss: 0.0000\n",
      "Epoch [1863/4500], Validation Loss: 0.2455\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1864/4500], Training Loss: 0.0000\n",
      "Epoch [1864/4500], Validation Loss: 0.2455\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1865/4500], Training Loss: 0.0000\n",
      "Epoch [1865/4500], Validation Loss: 0.2455\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1866/4500], Training Loss: 0.0000\n",
      "Epoch [1866/4500], Validation Loss: 0.2458\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1867/4500], Training Loss: 0.0000\n",
      "Epoch [1867/4500], Validation Loss: 0.2456\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1868/4500], Training Loss: 0.0000\n",
      "Epoch [1868/4500], Validation Loss: 0.2460\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1869/4500], Training Loss: 0.0000\n",
      "Epoch [1869/4500], Validation Loss: 0.2457\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1870/4500], Training Loss: 0.0000\n",
      "Epoch [1870/4500], Validation Loss: 0.2459\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1871/4500], Training Loss: 0.0000\n",
      "Epoch [1871/4500], Validation Loss: 0.2457\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1872/4500], Training Loss: 0.0000\n",
      "Epoch [1872/4500], Validation Loss: 0.2463\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1873/4500], Training Loss: 0.0000\n",
      "Epoch [1873/4500], Validation Loss: 0.2460\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1874/4500], Training Loss: 0.0000\n",
      "Epoch [1874/4500], Validation Loss: 0.2461\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1875/4500], Training Loss: 0.0000\n",
      "Epoch [1875/4500], Validation Loss: 0.2459\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1876/4500], Training Loss: 0.0000\n",
      "Epoch [1876/4500], Validation Loss: 0.2462\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1877/4500], Training Loss: 0.0000\n",
      "Epoch [1877/4500], Validation Loss: 0.2462\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1878/4500], Training Loss: 0.0000\n",
      "Epoch [1878/4500], Validation Loss: 0.2460\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1879/4500], Training Loss: 0.0000\n",
      "Epoch [1879/4500], Validation Loss: 0.2464\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1880/4500], Training Loss: 0.0000\n",
      "Epoch [1880/4500], Validation Loss: 0.2462\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1881/4500], Training Loss: 0.0000\n",
      "Epoch [1881/4500], Validation Loss: 0.2465\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1882/4500], Training Loss: 0.0000\n",
      "Epoch [1882/4500], Validation Loss: 0.2463\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1883/4500], Training Loss: 0.0000\n",
      "Epoch [1883/4500], Validation Loss: 0.2464\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1884/4500], Training Loss: 0.0000\n",
      "Epoch [1884/4500], Validation Loss: 0.2466\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1885/4500], Training Loss: 0.0000\n",
      "Epoch [1885/4500], Validation Loss: 0.2468\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1886/4500], Training Loss: 0.0000\n",
      "Epoch [1886/4500], Validation Loss: 0.2467\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1887/4500], Training Loss: 0.0000\n",
      "Epoch [1887/4500], Validation Loss: 0.2467\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1888/4500], Training Loss: 0.0000\n",
      "Epoch [1888/4500], Validation Loss: 0.2467\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1889/4500], Training Loss: 0.0000\n",
      "Epoch [1889/4500], Validation Loss: 0.2467\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1890/4500], Training Loss: 0.0000\n",
      "Epoch [1890/4500], Validation Loss: 0.2467\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1891/4500], Training Loss: 0.0000\n",
      "Epoch [1891/4500], Validation Loss: 0.2469\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1892/4500], Training Loss: 0.0000\n",
      "Epoch [1892/4500], Validation Loss: 0.2468\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1893/4500], Training Loss: 0.0000\n",
      "Epoch [1893/4500], Validation Loss: 0.2472\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1894/4500], Training Loss: 0.0000\n",
      "Epoch [1894/4500], Validation Loss: 0.2470\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1895/4500], Training Loss: 0.0000\n",
      "Epoch [1895/4500], Validation Loss: 0.2469\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1896/4500], Training Loss: 0.0000\n",
      "Epoch [1896/4500], Validation Loss: 0.2470\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1897/4500], Training Loss: 0.0000\n",
      "Epoch [1897/4500], Validation Loss: 0.2471\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1898/4500], Training Loss: 0.0000\n",
      "Epoch [1898/4500], Validation Loss: 0.2473\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1899/4500], Training Loss: 0.0000\n",
      "Epoch [1899/4500], Validation Loss: 0.2471\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1900/4500], Training Loss: 0.0000\n",
      "Epoch [1900/4500], Validation Loss: 0.2473\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1901/4500], Training Loss: 0.0000\n",
      "Epoch [1901/4500], Validation Loss: 0.2473\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1902/4500], Training Loss: 0.0000\n",
      "Epoch [1902/4500], Validation Loss: 0.2474\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1903/4500], Training Loss: 0.0000\n",
      "Epoch [1903/4500], Validation Loss: 0.2476\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1904/4500], Training Loss: 0.0000\n",
      "Epoch [1904/4500], Validation Loss: 0.2475\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1905/4500], Training Loss: 0.0000\n",
      "Epoch [1905/4500], Validation Loss: 0.2476\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1906/4500], Training Loss: 0.0000\n",
      "Epoch [1906/4500], Validation Loss: 0.2477\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1907/4500], Training Loss: 0.0000\n",
      "Epoch [1907/4500], Validation Loss: 0.2477\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1908/4500], Training Loss: 0.0000\n",
      "Epoch [1908/4500], Validation Loss: 0.2476\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1909/4500], Training Loss: 0.0000\n",
      "Epoch [1909/4500], Validation Loss: 0.2479\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1910/4500], Training Loss: 0.0000\n",
      "Epoch [1910/4500], Validation Loss: 0.2477\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1911/4500], Training Loss: 0.0000\n",
      "Epoch [1911/4500], Validation Loss: 0.2476\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1912/4500], Training Loss: 0.0000\n",
      "Epoch [1912/4500], Validation Loss: 0.2478\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1913/4500], Training Loss: 0.0000\n",
      "Epoch [1913/4500], Validation Loss: 0.2477\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1914/4500], Training Loss: 0.0000\n",
      "Epoch [1914/4500], Validation Loss: 0.2478\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1915/4500], Training Loss: 0.0000\n",
      "Epoch [1915/4500], Validation Loss: 0.2478\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1916/4500], Training Loss: 0.0000\n",
      "Epoch [1916/4500], Validation Loss: 0.2482\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1917/4500], Training Loss: 0.0000\n",
      "Epoch [1917/4500], Validation Loss: 0.2482\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1918/4500], Training Loss: 0.0000\n",
      "Epoch [1918/4500], Validation Loss: 0.2481\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1919/4500], Training Loss: 0.0000\n",
      "Epoch [1919/4500], Validation Loss: 0.2480\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1920/4500], Training Loss: 0.0000\n",
      "Epoch [1920/4500], Validation Loss: 0.2482\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1921/4500], Training Loss: 0.0000\n",
      "Epoch [1921/4500], Validation Loss: 0.2485\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1922/4500], Training Loss: 0.0000\n",
      "Epoch [1922/4500], Validation Loss: 0.2483\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1923/4500], Training Loss: 0.0000\n",
      "Epoch [1923/4500], Validation Loss: 0.2484\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1924/4500], Training Loss: 0.0000\n",
      "Epoch [1924/4500], Validation Loss: 0.2483\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1925/4500], Training Loss: 0.0000\n",
      "Epoch [1925/4500], Validation Loss: 0.2485\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1926/4500], Training Loss: 0.0000\n",
      "Epoch [1926/4500], Validation Loss: 0.2484\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1927/4500], Training Loss: 0.0000\n",
      "Epoch [1927/4500], Validation Loss: 0.2486\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1928/4500], Training Loss: 0.0000\n",
      "Epoch [1928/4500], Validation Loss: 0.2484\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1929/4500], Training Loss: 0.0000\n",
      "Epoch [1929/4500], Validation Loss: 0.2487\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1930/4500], Training Loss: 0.0000\n",
      "Epoch [1930/4500], Validation Loss: 0.2486\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1931/4500], Training Loss: 0.0000\n",
      "Epoch [1931/4500], Validation Loss: 0.2489\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1932/4500], Training Loss: 0.0000\n",
      "Epoch [1932/4500], Validation Loss: 0.2487\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1933/4500], Training Loss: 0.0000\n",
      "Epoch [1933/4500], Validation Loss: 0.2490\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1934/4500], Training Loss: 0.0000\n",
      "Epoch [1934/4500], Validation Loss: 0.2485\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1935/4500], Training Loss: 0.0000\n",
      "Epoch [1935/4500], Validation Loss: 0.2490\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1936/4500], Training Loss: 0.0000\n",
      "Epoch [1936/4500], Validation Loss: 0.2488\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1937/4500], Training Loss: 0.0000\n",
      "Epoch [1937/4500], Validation Loss: 0.2493\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1938/4500], Training Loss: 0.0000\n",
      "Epoch [1938/4500], Validation Loss: 0.2489\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1939/4500], Training Loss: 0.0000\n",
      "Epoch [1939/4500], Validation Loss: 0.2492\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1940/4500], Training Loss: 0.0000\n",
      "Epoch [1940/4500], Validation Loss: 0.2492\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1941/4500], Training Loss: 0.0000\n",
      "Epoch [1941/4500], Validation Loss: 0.2493\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1942/4500], Training Loss: 0.0000\n",
      "Epoch [1942/4500], Validation Loss: 0.2492\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1943/4500], Training Loss: 0.0000\n",
      "Epoch [1943/4500], Validation Loss: 0.2494\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1944/4500], Training Loss: 0.0000\n",
      "Epoch [1944/4500], Validation Loss: 0.2493\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1945/4500], Training Loss: 0.0000\n",
      "Epoch [1945/4500], Validation Loss: 0.2491\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1946/4500], Training Loss: 0.0000\n",
      "Epoch [1946/4500], Validation Loss: 0.2494\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1947/4500], Training Loss: 0.0000\n",
      "Epoch [1947/4500], Validation Loss: 0.2493\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1948/4500], Training Loss: 0.0000\n",
      "Epoch [1948/4500], Validation Loss: 0.2496\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1949/4500], Training Loss: 0.0000\n",
      "Epoch [1949/4500], Validation Loss: 0.2494\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1950/4500], Training Loss: 0.0000\n",
      "Epoch [1950/4500], Validation Loss: 0.2495\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1951/4500], Training Loss: 0.0000\n",
      "Epoch [1951/4500], Validation Loss: 0.2496\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1952/4500], Training Loss: 0.0000\n",
      "Epoch [1952/4500], Validation Loss: 0.2496\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1953/4500], Training Loss: 0.0000\n",
      "Epoch [1953/4500], Validation Loss: 0.2495\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1954/4500], Training Loss: 0.0000\n",
      "Epoch [1954/4500], Validation Loss: 0.2499\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1955/4500], Training Loss: 0.0000\n",
      "Epoch [1955/4500], Validation Loss: 0.2497\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1956/4500], Training Loss: 0.0000\n",
      "Epoch [1956/4500], Validation Loss: 0.2499\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1957/4500], Training Loss: 0.0000\n",
      "Epoch [1957/4500], Validation Loss: 0.2498\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1958/4500], Training Loss: 0.0000\n",
      "Epoch [1958/4500], Validation Loss: 0.2497\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1959/4500], Training Loss: 0.0000\n",
      "Epoch [1959/4500], Validation Loss: 0.2501\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1960/4500], Training Loss: 0.0000\n",
      "Epoch [1960/4500], Validation Loss: 0.2499\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1961/4500], Training Loss: 0.0000\n",
      "Epoch [1961/4500], Validation Loss: 0.2500\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1962/4500], Training Loss: 0.0000\n",
      "Epoch [1962/4500], Validation Loss: 0.2502\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1963/4500], Training Loss: 0.0000\n",
      "Epoch [1963/4500], Validation Loss: 0.2501\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1964/4500], Training Loss: 0.0000\n",
      "Epoch [1964/4500], Validation Loss: 0.2503\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1965/4500], Training Loss: 0.0000\n",
      "Epoch [1965/4500], Validation Loss: 0.2503\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1966/4500], Training Loss: 0.0000\n",
      "Epoch [1966/4500], Validation Loss: 0.2503\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1967/4500], Training Loss: 0.0000\n",
      "Epoch [1967/4500], Validation Loss: 0.2503\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1968/4500], Training Loss: 0.0000\n",
      "Epoch [1968/4500], Validation Loss: 0.2503\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1969/4500], Training Loss: 0.0000\n",
      "Epoch [1969/4500], Validation Loss: 0.2503\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1970/4500], Training Loss: 0.0000\n",
      "Epoch [1970/4500], Validation Loss: 0.2502\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1971/4500], Training Loss: 0.0000\n",
      "Epoch [1971/4500], Validation Loss: 0.2506\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1972/4500], Training Loss: 0.0000\n",
      "Epoch [1972/4500], Validation Loss: 0.2504\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1973/4500], Training Loss: 0.0000\n",
      "Epoch [1973/4500], Validation Loss: 0.2506\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1974/4500], Training Loss: 0.0000\n",
      "Epoch [1974/4500], Validation Loss: 0.2504\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1975/4500], Training Loss: 0.0000\n",
      "Epoch [1975/4500], Validation Loss: 0.2505\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1976/4500], Training Loss: 0.0000\n",
      "Epoch [1976/4500], Validation Loss: 0.2505\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1977/4500], Training Loss: 0.0000\n",
      "Epoch [1977/4500], Validation Loss: 0.2507\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1978/4500], Training Loss: 0.0000\n",
      "Epoch [1978/4500], Validation Loss: 0.2505\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1979/4500], Training Loss: 0.0000\n",
      "Epoch [1979/4500], Validation Loss: 0.2506\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1980/4500], Training Loss: 0.0000\n",
      "Epoch [1980/4500], Validation Loss: 0.2507\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1981/4500], Training Loss: 0.0000\n",
      "Epoch [1981/4500], Validation Loss: 0.2509\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1982/4500], Training Loss: 0.0000\n",
      "Epoch [1982/4500], Validation Loss: 0.2510\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1983/4500], Training Loss: 0.0000\n",
      "Epoch [1983/4500], Validation Loss: 0.2507\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1984/4500], Training Loss: 0.0000\n",
      "Epoch [1984/4500], Validation Loss: 0.2507\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1985/4500], Training Loss: 0.0000\n",
      "Epoch [1985/4500], Validation Loss: 0.2509\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1986/4500], Training Loss: 0.0000\n",
      "Epoch [1986/4500], Validation Loss: 0.2508\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1987/4500], Training Loss: 0.0000\n",
      "Epoch [1987/4500], Validation Loss: 0.2511\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1988/4500], Training Loss: 0.0000\n",
      "Epoch [1988/4500], Validation Loss: 0.2508\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1989/4500], Training Loss: 0.0000\n",
      "Epoch [1989/4500], Validation Loss: 0.2511\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1990/4500], Training Loss: 0.0000\n",
      "Epoch [1990/4500], Validation Loss: 0.2512\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1991/4500], Training Loss: 0.0000\n",
      "Epoch [1991/4500], Validation Loss: 0.2509\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1992/4500], Training Loss: 0.0000\n",
      "Epoch [1992/4500], Validation Loss: 0.2512\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1993/4500], Training Loss: 0.0000\n",
      "Epoch [1993/4500], Validation Loss: 0.2510\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1994/4500], Training Loss: 0.0000\n",
      "Epoch [1994/4500], Validation Loss: 0.2512\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1995/4500], Training Loss: 0.0000\n",
      "Epoch [1995/4500], Validation Loss: 0.2512\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1996/4500], Training Loss: 0.0000\n",
      "Epoch [1996/4500], Validation Loss: 0.2513\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1997/4500], Training Loss: 0.0000\n",
      "Epoch [1997/4500], Validation Loss: 0.2512\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1998/4500], Training Loss: 0.0000\n",
      "Epoch [1998/4500], Validation Loss: 0.2515\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [1999/4500], Training Loss: 0.0000\n",
      "Epoch [1999/4500], Validation Loss: 0.2515\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2000/4500], Training Loss: 0.0000\n",
      "Epoch [2000/4500], Validation Loss: 0.2514\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2001/4500], Training Loss: 0.0000\n",
      "Epoch [2001/4500], Validation Loss: 0.2515\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2002/4500], Training Loss: 0.0000\n",
      "Epoch [2002/4500], Validation Loss: 0.2516\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2003/4500], Training Loss: 0.0000\n",
      "Epoch [2003/4500], Validation Loss: 0.2514\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2004/4500], Training Loss: 0.0000\n",
      "Epoch [2004/4500], Validation Loss: 0.2518\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2005/4500], Training Loss: 0.0000\n",
      "Epoch [2005/4500], Validation Loss: 0.2516\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2006/4500], Training Loss: 0.0000\n",
      "Epoch [2006/4500], Validation Loss: 0.2517\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2007/4500], Training Loss: 0.0000\n",
      "Epoch [2007/4500], Validation Loss: 0.2517\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2008/4500], Training Loss: 0.0000\n",
      "Epoch [2008/4500], Validation Loss: 0.2516\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2009/4500], Training Loss: 0.0000\n",
      "Epoch [2009/4500], Validation Loss: 0.2517\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2010/4500], Training Loss: 0.0000\n",
      "Epoch [2010/4500], Validation Loss: 0.2518\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2011/4500], Training Loss: 0.0000\n",
      "Epoch [2011/4500], Validation Loss: 0.2520\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2012/4500], Training Loss: 0.0000\n",
      "Epoch [2012/4500], Validation Loss: 0.2518\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2013/4500], Training Loss: 0.0000\n",
      "Epoch [2013/4500], Validation Loss: 0.2518\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2014/4500], Training Loss: 0.0000\n",
      "Epoch [2014/4500], Validation Loss: 0.2521\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2015/4500], Training Loss: 0.0000\n",
      "Epoch [2015/4500], Validation Loss: 0.2519\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2016/4500], Training Loss: 0.0000\n",
      "Epoch [2016/4500], Validation Loss: 0.2522\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2017/4500], Training Loss: 0.0000\n",
      "Epoch [2017/4500], Validation Loss: 0.2522\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2018/4500], Training Loss: 0.0000\n",
      "Epoch [2018/4500], Validation Loss: 0.2521\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2019/4500], Training Loss: 0.0000\n",
      "Epoch [2019/4500], Validation Loss: 0.2524\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2020/4500], Training Loss: 0.0000\n",
      "Epoch [2020/4500], Validation Loss: 0.2522\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2021/4500], Training Loss: 0.0000\n",
      "Epoch [2021/4500], Validation Loss: 0.2524\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2022/4500], Training Loss: 0.0000\n",
      "Epoch [2022/4500], Validation Loss: 0.2522\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2023/4500], Training Loss: 0.0000\n",
      "Epoch [2023/4500], Validation Loss: 0.2525\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2024/4500], Training Loss: 0.0000\n",
      "Epoch [2024/4500], Validation Loss: 0.2524\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2025/4500], Training Loss: 0.0000\n",
      "Epoch [2025/4500], Validation Loss: 0.2524\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2026/4500], Training Loss: 0.0000\n",
      "Epoch [2026/4500], Validation Loss: 0.2524\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2027/4500], Training Loss: 0.0000\n",
      "Epoch [2027/4500], Validation Loss: 0.2527\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2028/4500], Training Loss: 0.0000\n",
      "Epoch [2028/4500], Validation Loss: 0.2525\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2029/4500], Training Loss: 0.0000\n",
      "Epoch [2029/4500], Validation Loss: 0.2527\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2030/4500], Training Loss: 0.0000\n",
      "Epoch [2030/4500], Validation Loss: 0.2527\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2031/4500], Training Loss: 0.0000\n",
      "Epoch [2031/4500], Validation Loss: 0.2528\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2032/4500], Training Loss: 0.0000\n",
      "Epoch [2032/4500], Validation Loss: 0.2526\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2033/4500], Training Loss: 0.0000\n",
      "Epoch [2033/4500], Validation Loss: 0.2530\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2034/4500], Training Loss: 0.0000\n",
      "Epoch [2034/4500], Validation Loss: 0.2531\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2035/4500], Training Loss: 0.0000\n",
      "Epoch [2035/4500], Validation Loss: 0.2530\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2036/4500], Training Loss: 0.0000\n",
      "Epoch [2036/4500], Validation Loss: 0.2529\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2037/4500], Training Loss: 0.0000\n",
      "Epoch [2037/4500], Validation Loss: 0.2530\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2038/4500], Training Loss: 0.0000\n",
      "Epoch [2038/4500], Validation Loss: 0.2532\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2039/4500], Training Loss: 0.0000\n",
      "Epoch [2039/4500], Validation Loss: 0.2532\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2040/4500], Training Loss: 0.0000\n",
      "Epoch [2040/4500], Validation Loss: 0.2529\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2041/4500], Training Loss: 0.0000\n",
      "Epoch [2041/4500], Validation Loss: 0.2534\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2042/4500], Training Loss: 0.0000\n",
      "Epoch [2042/4500], Validation Loss: 0.2535\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2043/4500], Training Loss: 0.0000\n",
      "Epoch [2043/4500], Validation Loss: 0.2532\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2044/4500], Training Loss: 0.0000\n",
      "Epoch [2044/4500], Validation Loss: 0.2537\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2045/4500], Training Loss: 0.0000\n",
      "Epoch [2045/4500], Validation Loss: 0.2534\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2046/4500], Training Loss: 0.0000\n",
      "Epoch [2046/4500], Validation Loss: 0.2533\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2047/4500], Training Loss: 0.0000\n",
      "Epoch [2047/4500], Validation Loss: 0.2533\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2048/4500], Training Loss: 0.0000\n",
      "Epoch [2048/4500], Validation Loss: 0.2537\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2049/4500], Training Loss: 0.0000\n",
      "Epoch [2049/4500], Validation Loss: 0.2535\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2050/4500], Training Loss: 0.0000\n",
      "Epoch [2050/4500], Validation Loss: 0.2535\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2051/4500], Training Loss: 0.0000\n",
      "Epoch [2051/4500], Validation Loss: 0.2536\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2052/4500], Training Loss: 0.0000\n",
      "Epoch [2052/4500], Validation Loss: 0.2536\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2053/4500], Training Loss: 0.0000\n",
      "Epoch [2053/4500], Validation Loss: 0.2537\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2054/4500], Training Loss: 0.0000\n",
      "Epoch [2054/4500], Validation Loss: 0.2537\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2055/4500], Training Loss: 0.0000\n",
      "Epoch [2055/4500], Validation Loss: 0.2539\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2056/4500], Training Loss: 0.0000\n",
      "Epoch [2056/4500], Validation Loss: 0.2537\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2057/4500], Training Loss: 0.0000\n",
      "Epoch [2057/4500], Validation Loss: 0.2538\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2058/4500], Training Loss: 0.0000\n",
      "Epoch [2058/4500], Validation Loss: 0.2539\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2059/4500], Training Loss: 0.0000\n",
      "Epoch [2059/4500], Validation Loss: 0.2541\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2060/4500], Training Loss: 0.0000\n",
      "Epoch [2060/4500], Validation Loss: 0.2540\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2061/4500], Training Loss: 0.0000\n",
      "Epoch [2061/4500], Validation Loss: 0.2543\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2062/4500], Training Loss: 0.0000\n",
      "Epoch [2062/4500], Validation Loss: 0.2541\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2063/4500], Training Loss: 0.0000\n",
      "Epoch [2063/4500], Validation Loss: 0.2544\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2064/4500], Training Loss: 0.0000\n",
      "Epoch [2064/4500], Validation Loss: 0.2544\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2065/4500], Training Loss: 0.0000\n",
      "Epoch [2065/4500], Validation Loss: 0.2541\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2066/4500], Training Loss: 0.0000\n",
      "Epoch [2066/4500], Validation Loss: 0.2543\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2067/4500], Training Loss: 0.0000\n",
      "Epoch [2067/4500], Validation Loss: 0.2543\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2068/4500], Training Loss: 0.0000\n",
      "Epoch [2068/4500], Validation Loss: 0.2546\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2069/4500], Training Loss: 0.0000\n",
      "Epoch [2069/4500], Validation Loss: 0.2545\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2070/4500], Training Loss: 0.0000\n",
      "Epoch [2070/4500], Validation Loss: 0.2546\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2071/4500], Training Loss: 0.0000\n",
      "Epoch [2071/4500], Validation Loss: 0.2545\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2072/4500], Training Loss: 0.0000\n",
      "Epoch [2072/4500], Validation Loss: 0.2546\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2073/4500], Training Loss: 0.0000\n",
      "Epoch [2073/4500], Validation Loss: 0.2547\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2074/4500], Training Loss: 0.0000\n",
      "Epoch [2074/4500], Validation Loss: 0.2547\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2075/4500], Training Loss: 0.0000\n",
      "Epoch [2075/4500], Validation Loss: 0.2546\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2076/4500], Training Loss: 0.0000\n",
      "Epoch [2076/4500], Validation Loss: 0.2547\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2077/4500], Training Loss: 0.0000\n",
      "Epoch [2077/4500], Validation Loss: 0.2548\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2078/4500], Training Loss: 0.0000\n",
      "Epoch [2078/4500], Validation Loss: 0.2546\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2079/4500], Training Loss: 0.0000\n",
      "Epoch [2079/4500], Validation Loss: 0.2550\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2080/4500], Training Loss: 0.0000\n",
      "Epoch [2080/4500], Validation Loss: 0.2547\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2081/4500], Training Loss: 0.0000\n",
      "Epoch [2081/4500], Validation Loss: 0.2549\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2082/4500], Training Loss: 0.0000\n",
      "Epoch [2082/4500], Validation Loss: 0.2549\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2083/4500], Training Loss: 0.0000\n",
      "Epoch [2083/4500], Validation Loss: 0.2550\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2084/4500], Training Loss: 0.0000\n",
      "Epoch [2084/4500], Validation Loss: 0.2549\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2085/4500], Training Loss: 0.0000\n",
      "Epoch [2085/4500], Validation Loss: 0.2550\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2086/4500], Training Loss: 0.0000\n",
      "Epoch [2086/4500], Validation Loss: 0.2550\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2087/4500], Training Loss: 0.0000\n",
      "Epoch [2087/4500], Validation Loss: 0.2549\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2088/4500], Training Loss: 0.0000\n",
      "Epoch [2088/4500], Validation Loss: 0.2551\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2089/4500], Training Loss: 0.0000\n",
      "Epoch [2089/4500], Validation Loss: 0.2553\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2090/4500], Training Loss: 0.0000\n",
      "Epoch [2090/4500], Validation Loss: 0.2550\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2091/4500], Training Loss: 0.0000\n",
      "Epoch [2091/4500], Validation Loss: 0.2553\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2092/4500], Training Loss: 0.0000\n",
      "Epoch [2092/4500], Validation Loss: 0.2555\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2093/4500], Training Loss: 0.0000\n",
      "Epoch [2093/4500], Validation Loss: 0.2555\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2094/4500], Training Loss: 0.0000\n",
      "Epoch [2094/4500], Validation Loss: 0.2556\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2095/4500], Training Loss: 0.0000\n",
      "Epoch [2095/4500], Validation Loss: 0.2555\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2096/4500], Training Loss: 0.0000\n",
      "Epoch [2096/4500], Validation Loss: 0.2556\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2097/4500], Training Loss: 0.0000\n",
      "Epoch [2097/4500], Validation Loss: 0.2556\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2098/4500], Training Loss: 0.0000\n",
      "Epoch [2098/4500], Validation Loss: 0.2557\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2099/4500], Training Loss: 0.0000\n",
      "Epoch [2099/4500], Validation Loss: 0.2556\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2100/4500], Training Loss: 0.0000\n",
      "Epoch [2100/4500], Validation Loss: 0.2560\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2101/4500], Training Loss: 0.0000\n",
      "Epoch [2101/4500], Validation Loss: 0.2558\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2102/4500], Training Loss: 0.0000\n",
      "Epoch [2102/4500], Validation Loss: 0.2560\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2103/4500], Training Loss: 0.0000\n",
      "Epoch [2103/4500], Validation Loss: 0.2556\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2104/4500], Training Loss: 0.0000\n",
      "Epoch [2104/4500], Validation Loss: 0.2560\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2105/4500], Training Loss: 0.0000\n",
      "Epoch [2105/4500], Validation Loss: 0.2558\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2106/4500], Training Loss: 0.0000\n",
      "Epoch [2106/4500], Validation Loss: 0.2558\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2107/4500], Training Loss: 0.0000\n",
      "Epoch [2107/4500], Validation Loss: 0.2558\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2108/4500], Training Loss: 0.0000\n",
      "Epoch [2108/4500], Validation Loss: 0.2562\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2109/4500], Training Loss: 0.0000\n",
      "Epoch [2109/4500], Validation Loss: 0.2559\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2110/4500], Training Loss: 0.0000\n",
      "Epoch [2110/4500], Validation Loss: 0.2560\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2111/4500], Training Loss: 0.0000\n",
      "Epoch [2111/4500], Validation Loss: 0.2562\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2112/4500], Training Loss: 0.0000\n",
      "Epoch [2112/4500], Validation Loss: 0.2561\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2113/4500], Training Loss: 0.0000\n",
      "Epoch [2113/4500], Validation Loss: 0.2560\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2114/4500], Training Loss: 0.0000\n",
      "Epoch [2114/4500], Validation Loss: 0.2563\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2115/4500], Training Loss: 0.0000\n",
      "Epoch [2115/4500], Validation Loss: 0.2562\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2116/4500], Training Loss: 0.0000\n",
      "Epoch [2116/4500], Validation Loss: 0.2562\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2117/4500], Training Loss: 0.0000\n",
      "Epoch [2117/4500], Validation Loss: 0.2565\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2118/4500], Training Loss: 0.0000\n",
      "Epoch [2118/4500], Validation Loss: 0.2563\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2119/4500], Training Loss: 0.0000\n",
      "Epoch [2119/4500], Validation Loss: 0.2565\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2120/4500], Training Loss: 0.0000\n",
      "Epoch [2120/4500], Validation Loss: 0.2565\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2121/4500], Training Loss: 0.0000\n",
      "Epoch [2121/4500], Validation Loss: 0.2565\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2122/4500], Training Loss: 0.0000\n",
      "Epoch [2122/4500], Validation Loss: 0.2565\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2123/4500], Training Loss: 0.0000\n",
      "Epoch [2123/4500], Validation Loss: 0.2566\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2124/4500], Training Loss: 0.0000\n",
      "Epoch [2124/4500], Validation Loss: 0.2567\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2125/4500], Training Loss: 0.0000\n",
      "Epoch [2125/4500], Validation Loss: 0.2567\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2126/4500], Training Loss: 0.0000\n",
      "Epoch [2126/4500], Validation Loss: 0.2570\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2127/4500], Training Loss: 0.0000\n",
      "Epoch [2127/4500], Validation Loss: 0.2568\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2128/4500], Training Loss: 0.0000\n",
      "Epoch [2128/4500], Validation Loss: 0.2569\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2129/4500], Training Loss: 0.0000\n",
      "Epoch [2129/4500], Validation Loss: 0.2570\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2130/4500], Training Loss: 0.0000\n",
      "Epoch [2130/4500], Validation Loss: 0.2572\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2131/4500], Training Loss: 0.0000\n",
      "Epoch [2131/4500], Validation Loss: 0.2568\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2132/4500], Training Loss: 0.0000\n",
      "Epoch [2132/4500], Validation Loss: 0.2571\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2133/4500], Training Loss: 0.0000\n",
      "Epoch [2133/4500], Validation Loss: 0.2571\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2134/4500], Training Loss: 0.0000\n",
      "Epoch [2134/4500], Validation Loss: 0.2571\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2135/4500], Training Loss: 0.0000\n",
      "Epoch [2135/4500], Validation Loss: 0.2570\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2136/4500], Training Loss: 0.0000\n",
      "Epoch [2136/4500], Validation Loss: 0.2570\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2137/4500], Training Loss: 0.0000\n",
      "Epoch [2137/4500], Validation Loss: 0.2571\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2138/4500], Training Loss: 0.0000\n",
      "Epoch [2138/4500], Validation Loss: 0.2572\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2139/4500], Training Loss: 0.0000\n",
      "Epoch [2139/4500], Validation Loss: 0.2572\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2140/4500], Training Loss: 0.0000\n",
      "Epoch [2140/4500], Validation Loss: 0.2571\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2141/4500], Training Loss: 0.0000\n",
      "Epoch [2141/4500], Validation Loss: 0.2572\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2142/4500], Training Loss: 0.0000\n",
      "Epoch [2142/4500], Validation Loss: 0.2573\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2143/4500], Training Loss: 0.0000\n",
      "Epoch [2143/4500], Validation Loss: 0.2577\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2144/4500], Training Loss: 0.0000\n",
      "Epoch [2144/4500], Validation Loss: 0.2574\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2145/4500], Training Loss: 0.0000\n",
      "Epoch [2145/4500], Validation Loss: 0.2574\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2146/4500], Training Loss: 0.0000\n",
      "Epoch [2146/4500], Validation Loss: 0.2574\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2147/4500], Training Loss: 0.0000\n",
      "Epoch [2147/4500], Validation Loss: 0.2575\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2148/4500], Training Loss: 0.0000\n",
      "Epoch [2148/4500], Validation Loss: 0.2576\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2149/4500], Training Loss: 0.0000\n",
      "Epoch [2149/4500], Validation Loss: 0.2574\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2150/4500], Training Loss: 0.0000\n",
      "Epoch [2150/4500], Validation Loss: 0.2576\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2151/4500], Training Loss: 0.0000\n",
      "Epoch [2151/4500], Validation Loss: 0.2576\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2152/4500], Training Loss: 0.0000\n",
      "Epoch [2152/4500], Validation Loss: 0.2577\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2153/4500], Training Loss: 0.0000\n",
      "Epoch [2153/4500], Validation Loss: 0.2579\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2154/4500], Training Loss: 0.0000\n",
      "Epoch [2154/4500], Validation Loss: 0.2577\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2155/4500], Training Loss: 0.0000\n",
      "Epoch [2155/4500], Validation Loss: 0.2576\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2156/4500], Training Loss: 0.0000\n",
      "Epoch [2156/4500], Validation Loss: 0.2580\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2157/4500], Training Loss: 0.0000\n",
      "Epoch [2157/4500], Validation Loss: 0.2579\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2158/4500], Training Loss: 0.0000\n",
      "Epoch [2158/4500], Validation Loss: 0.2581\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2159/4500], Training Loss: 0.0000\n",
      "Epoch [2159/4500], Validation Loss: 0.2580\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2160/4500], Training Loss: 0.0000\n",
      "Epoch [2160/4500], Validation Loss: 0.2582\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2161/4500], Training Loss: 0.0000\n",
      "Epoch [2161/4500], Validation Loss: 0.2582\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2162/4500], Training Loss: 0.0000\n",
      "Epoch [2162/4500], Validation Loss: 0.2582\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2163/4500], Training Loss: 0.0000\n",
      "Epoch [2163/4500], Validation Loss: 0.2581\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2164/4500], Training Loss: 0.0000\n",
      "Epoch [2164/4500], Validation Loss: 0.2583\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2165/4500], Training Loss: 0.0000\n",
      "Epoch [2165/4500], Validation Loss: 0.2583\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2166/4500], Training Loss: 0.0000\n",
      "Epoch [2166/4500], Validation Loss: 0.2582\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2167/4500], Training Loss: 0.0000\n",
      "Epoch [2167/4500], Validation Loss: 0.2583\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2168/4500], Training Loss: 0.0000\n",
      "Epoch [2168/4500], Validation Loss: 0.2583\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2169/4500], Training Loss: 0.0000\n",
      "Epoch [2169/4500], Validation Loss: 0.2585\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2170/4500], Training Loss: 0.0000\n",
      "Epoch [2170/4500], Validation Loss: 0.2587\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2171/4500], Training Loss: 0.0000\n",
      "Epoch [2171/4500], Validation Loss: 0.2585\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2172/4500], Training Loss: 0.0000\n",
      "Epoch [2172/4500], Validation Loss: 0.2587\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2173/4500], Training Loss: 0.0000\n",
      "Epoch [2173/4500], Validation Loss: 0.2585\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2174/4500], Training Loss: 0.0000\n",
      "Epoch [2174/4500], Validation Loss: 0.2587\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2175/4500], Training Loss: 0.0000\n",
      "Epoch [2175/4500], Validation Loss: 0.2584\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2176/4500], Training Loss: 0.0000\n",
      "Epoch [2176/4500], Validation Loss: 0.2587\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2177/4500], Training Loss: 0.0000\n",
      "Epoch [2177/4500], Validation Loss: 0.2584\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2178/4500], Training Loss: 0.0000\n",
      "Epoch [2178/4500], Validation Loss: 0.2587\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2179/4500], Training Loss: 0.0000\n",
      "Epoch [2179/4500], Validation Loss: 0.2587\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2180/4500], Training Loss: 0.0000\n",
      "Epoch [2180/4500], Validation Loss: 0.2587\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2181/4500], Training Loss: 0.0000\n",
      "Epoch [2181/4500], Validation Loss: 0.2591\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2182/4500], Training Loss: 0.0000\n",
      "Epoch [2182/4500], Validation Loss: 0.2587\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2183/4500], Training Loss: 0.0000\n",
      "Epoch [2183/4500], Validation Loss: 0.2589\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2184/4500], Training Loss: 0.0000\n",
      "Epoch [2184/4500], Validation Loss: 0.2588\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2185/4500], Training Loss: 0.0000\n",
      "Epoch [2185/4500], Validation Loss: 0.2588\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2186/4500], Training Loss: 0.0000\n",
      "Epoch [2186/4500], Validation Loss: 0.2590\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2187/4500], Training Loss: 0.0000\n",
      "Epoch [2187/4500], Validation Loss: 0.2590\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2188/4500], Training Loss: 0.0000\n",
      "Epoch [2188/4500], Validation Loss: 0.2592\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2189/4500], Training Loss: 0.0000\n",
      "Epoch [2189/4500], Validation Loss: 0.2590\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2190/4500], Training Loss: 0.0000\n",
      "Epoch [2190/4500], Validation Loss: 0.2589\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2191/4500], Training Loss: 0.0000\n",
      "Epoch [2191/4500], Validation Loss: 0.2590\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2192/4500], Training Loss: 0.0000\n",
      "Epoch [2192/4500], Validation Loss: 0.2591\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2193/4500], Training Loss: 0.0000\n",
      "Epoch [2193/4500], Validation Loss: 0.2593\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2194/4500], Training Loss: 0.0000\n",
      "Epoch [2194/4500], Validation Loss: 0.2592\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2195/4500], Training Loss: 0.0000\n",
      "Epoch [2195/4500], Validation Loss: 0.2596\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2196/4500], Training Loss: 0.0000\n",
      "Epoch [2196/4500], Validation Loss: 0.2596\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2197/4500], Training Loss: 0.0000\n",
      "Epoch [2197/4500], Validation Loss: 0.2595\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2198/4500], Training Loss: 0.0000\n",
      "Epoch [2198/4500], Validation Loss: 0.2595\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2199/4500], Training Loss: 0.0000\n",
      "Epoch [2199/4500], Validation Loss: 0.2595\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2200/4500], Training Loss: 0.0000\n",
      "Epoch [2200/4500], Validation Loss: 0.2598\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2201/4500], Training Loss: 0.0000\n",
      "Epoch [2201/4500], Validation Loss: 0.2596\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2202/4500], Training Loss: 0.0000\n",
      "Epoch [2202/4500], Validation Loss: 0.2595\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2203/4500], Training Loss: 0.0000\n",
      "Epoch [2203/4500], Validation Loss: 0.2601\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2204/4500], Training Loss: 0.0000\n",
      "Epoch [2204/4500], Validation Loss: 0.2598\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2205/4500], Training Loss: 0.0000\n",
      "Epoch [2205/4500], Validation Loss: 0.2597\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2206/4500], Training Loss: 0.0000\n",
      "Epoch [2206/4500], Validation Loss: 0.2597\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2207/4500], Training Loss: 0.0000\n",
      "Epoch [2207/4500], Validation Loss: 0.2599\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2208/4500], Training Loss: 0.0000\n",
      "Epoch [2208/4500], Validation Loss: 0.2600\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2209/4500], Training Loss: 0.0000\n",
      "Epoch [2209/4500], Validation Loss: 0.2599\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2210/4500], Training Loss: 0.0000\n",
      "Epoch [2210/4500], Validation Loss: 0.2600\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2211/4500], Training Loss: 0.0000\n",
      "Epoch [2211/4500], Validation Loss: 0.2598\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2212/4500], Training Loss: 0.0000\n",
      "Epoch [2212/4500], Validation Loss: 0.2602\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2213/4500], Training Loss: 0.0000\n",
      "Epoch [2213/4500], Validation Loss: 0.2599\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2214/4500], Training Loss: 0.0000\n",
      "Epoch [2214/4500], Validation Loss: 0.2601\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2215/4500], Training Loss: 0.0000\n",
      "Epoch [2215/4500], Validation Loss: 0.2601\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2216/4500], Training Loss: 0.0000\n",
      "Epoch [2216/4500], Validation Loss: 0.2601\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2217/4500], Training Loss: 0.0000\n",
      "Epoch [2217/4500], Validation Loss: 0.2602\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2218/4500], Training Loss: 0.0000\n",
      "Epoch [2218/4500], Validation Loss: 0.2600\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2219/4500], Training Loss: 0.0000\n",
      "Epoch [2219/4500], Validation Loss: 0.2603\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2220/4500], Training Loss: 0.0000\n",
      "Epoch [2220/4500], Validation Loss: 0.2602\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2221/4500], Training Loss: 0.0000\n",
      "Epoch [2221/4500], Validation Loss: 0.2603\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2222/4500], Training Loss: 0.0000\n",
      "Epoch [2222/4500], Validation Loss: 0.2603\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2223/4500], Training Loss: 0.0000\n",
      "Epoch [2223/4500], Validation Loss: 0.2602\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2224/4500], Training Loss: 0.0000\n",
      "Epoch [2224/4500], Validation Loss: 0.2605\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2225/4500], Training Loss: 0.0000\n",
      "Epoch [2225/4500], Validation Loss: 0.2602\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2226/4500], Training Loss: 0.0000\n",
      "Epoch [2226/4500], Validation Loss: 0.2605\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2227/4500], Training Loss: 0.0000\n",
      "Epoch [2227/4500], Validation Loss: 0.2603\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2228/4500], Training Loss: 0.0000\n",
      "Epoch [2228/4500], Validation Loss: 0.2606\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2229/4500], Training Loss: 0.0000\n",
      "Epoch [2229/4500], Validation Loss: 0.2605\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2230/4500], Training Loss: 0.0000\n",
      "Epoch [2230/4500], Validation Loss: 0.2604\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2231/4500], Training Loss: 0.0000\n",
      "Epoch [2231/4500], Validation Loss: 0.2610\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2232/4500], Training Loss: 0.0000\n",
      "Epoch [2232/4500], Validation Loss: 0.2609\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2233/4500], Training Loss: 0.0000\n",
      "Epoch [2233/4500], Validation Loss: 0.2606\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2234/4500], Training Loss: 0.0000\n",
      "Epoch [2234/4500], Validation Loss: 0.2610\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2235/4500], Training Loss: 0.0000\n",
      "Epoch [2235/4500], Validation Loss: 0.2610\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2236/4500], Training Loss: 0.0000\n",
      "Epoch [2236/4500], Validation Loss: 0.2611\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2237/4500], Training Loss: 0.0000\n",
      "Epoch [2237/4500], Validation Loss: 0.2610\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2238/4500], Training Loss: 0.0000\n",
      "Epoch [2238/4500], Validation Loss: 0.2610\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2239/4500], Training Loss: 0.0000\n",
      "Epoch [2239/4500], Validation Loss: 0.2611\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2240/4500], Training Loss: 0.0000\n",
      "Epoch [2240/4500], Validation Loss: 0.2613\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2241/4500], Training Loss: 0.0000\n",
      "Epoch [2241/4500], Validation Loss: 0.2612\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2242/4500], Training Loss: 0.0000\n",
      "Epoch [2242/4500], Validation Loss: 0.2614\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2243/4500], Training Loss: 0.0000\n",
      "Epoch [2243/4500], Validation Loss: 0.2613\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2244/4500], Training Loss: 0.0000\n",
      "Epoch [2244/4500], Validation Loss: 0.2613\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2245/4500], Training Loss: 0.0000\n",
      "Epoch [2245/4500], Validation Loss: 0.2613\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2246/4500], Training Loss: 0.0000\n",
      "Epoch [2246/4500], Validation Loss: 0.2613\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2247/4500], Training Loss: 0.0000\n",
      "Epoch [2247/4500], Validation Loss: 0.2612\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2248/4500], Training Loss: 0.0000\n",
      "Epoch [2248/4500], Validation Loss: 0.2615\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2249/4500], Training Loss: 0.0000\n",
      "Epoch [2249/4500], Validation Loss: 0.2613\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2250/4500], Training Loss: 0.0000\n",
      "Epoch [2250/4500], Validation Loss: 0.2616\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2251/4500], Training Loss: 0.0000\n",
      "Epoch [2251/4500], Validation Loss: 0.2616\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2252/4500], Training Loss: 0.0000\n",
      "Epoch [2252/4500], Validation Loss: 0.2615\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2253/4500], Training Loss: 0.0000\n",
      "Epoch [2253/4500], Validation Loss: 0.2614\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2254/4500], Training Loss: 0.0000\n",
      "Epoch [2254/4500], Validation Loss: 0.2616\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2255/4500], Training Loss: 0.0000\n",
      "Epoch [2255/4500], Validation Loss: 0.2617\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2256/4500], Training Loss: 0.0000\n",
      "Epoch [2256/4500], Validation Loss: 0.2617\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2257/4500], Training Loss: 0.0000\n",
      "Epoch [2257/4500], Validation Loss: 0.2617\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2258/4500], Training Loss: 0.0000\n",
      "Epoch [2258/4500], Validation Loss: 0.2618\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2259/4500], Training Loss: 0.0000\n",
      "Epoch [2259/4500], Validation Loss: 0.2617\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2260/4500], Training Loss: 0.0000\n",
      "Epoch [2260/4500], Validation Loss: 0.2619\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2261/4500], Training Loss: 0.0000\n",
      "Epoch [2261/4500], Validation Loss: 0.2617\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2262/4500], Training Loss: 0.0000\n",
      "Epoch [2262/4500], Validation Loss: 0.2618\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2263/4500], Training Loss: 0.0000\n",
      "Epoch [2263/4500], Validation Loss: 0.2619\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2264/4500], Training Loss: 0.0000\n",
      "Epoch [2264/4500], Validation Loss: 0.2621\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2265/4500], Training Loss: 0.0000\n",
      "Epoch [2265/4500], Validation Loss: 0.2618\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2266/4500], Training Loss: 0.0000\n",
      "Epoch [2266/4500], Validation Loss: 0.2621\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2267/4500], Training Loss: 0.0000\n",
      "Epoch [2267/4500], Validation Loss: 0.2619\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2268/4500], Training Loss: 0.0000\n",
      "Epoch [2268/4500], Validation Loss: 0.2622\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2269/4500], Training Loss: 0.0000\n",
      "Epoch [2269/4500], Validation Loss: 0.2618\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2270/4500], Training Loss: 0.0000\n",
      "Epoch [2270/4500], Validation Loss: 0.2621\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2271/4500], Training Loss: 0.0000\n",
      "Epoch [2271/4500], Validation Loss: 0.2622\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2272/4500], Training Loss: 0.0000\n",
      "Epoch [2272/4500], Validation Loss: 0.2621\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2273/4500], Training Loss: 0.0000\n",
      "Epoch [2273/4500], Validation Loss: 0.2624\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2274/4500], Training Loss: 0.0000\n",
      "Epoch [2274/4500], Validation Loss: 0.2623\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2275/4500], Training Loss: 0.0000\n",
      "Epoch [2275/4500], Validation Loss: 0.2623\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2276/4500], Training Loss: 0.0000\n",
      "Epoch [2276/4500], Validation Loss: 0.2626\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2277/4500], Training Loss: 0.0000\n",
      "Epoch [2277/4500], Validation Loss: 0.2623\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2278/4500], Training Loss: 0.0000\n",
      "Epoch [2278/4500], Validation Loss: 0.2627\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2279/4500], Training Loss: 0.0000\n",
      "Epoch [2279/4500], Validation Loss: 0.2629\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2280/4500], Training Loss: 0.0000\n",
      "Epoch [2280/4500], Validation Loss: 0.2628\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2281/4500], Training Loss: 0.0000\n",
      "Epoch [2281/4500], Validation Loss: 0.2629\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2282/4500], Training Loss: 0.0000\n",
      "Epoch [2282/4500], Validation Loss: 0.2627\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2283/4500], Training Loss: 0.0000\n",
      "Epoch [2283/4500], Validation Loss: 0.2630\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2284/4500], Training Loss: 0.0000\n",
      "Epoch [2284/4500], Validation Loss: 0.2630\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2285/4500], Training Loss: 0.0000\n",
      "Epoch [2285/4500], Validation Loss: 0.2628\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2286/4500], Training Loss: 0.0000\n",
      "Epoch [2286/4500], Validation Loss: 0.2630\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2287/4500], Training Loss: 0.0000\n",
      "Epoch [2287/4500], Validation Loss: 0.2630\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2288/4500], Training Loss: 0.0000\n",
      "Epoch [2288/4500], Validation Loss: 0.2632\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2289/4500], Training Loss: 0.0000\n",
      "Epoch [2289/4500], Validation Loss: 0.2629\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2290/4500], Training Loss: 0.0000\n",
      "Epoch [2290/4500], Validation Loss: 0.2633\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2291/4500], Training Loss: 0.0000\n",
      "Epoch [2291/4500], Validation Loss: 0.2630\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2292/4500], Training Loss: 0.0000\n",
      "Epoch [2292/4500], Validation Loss: 0.2633\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2293/4500], Training Loss: 0.0000\n",
      "Epoch [2293/4500], Validation Loss: 0.2632\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2294/4500], Training Loss: 0.0000\n",
      "Epoch [2294/4500], Validation Loss: 0.2633\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2295/4500], Training Loss: 0.0000\n",
      "Epoch [2295/4500], Validation Loss: 0.2632\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2296/4500], Training Loss: 0.0000\n",
      "Epoch [2296/4500], Validation Loss: 0.2633\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2297/4500], Training Loss: 0.0000\n",
      "Epoch [2297/4500], Validation Loss: 0.2635\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2298/4500], Training Loss: 0.0000\n",
      "Epoch [2298/4500], Validation Loss: 0.2633\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2299/4500], Training Loss: 0.0000\n",
      "Epoch [2299/4500], Validation Loss: 0.2634\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2300/4500], Training Loss: 0.0000\n",
      "Epoch [2300/4500], Validation Loss: 0.2634\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2301/4500], Training Loss: 0.0000\n",
      "Epoch [2301/4500], Validation Loss: 0.2636\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2302/4500], Training Loss: 0.0000\n",
      "Epoch [2302/4500], Validation Loss: 0.2635\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2303/4500], Training Loss: 0.0000\n",
      "Epoch [2303/4500], Validation Loss: 0.2637\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2304/4500], Training Loss: 0.0000\n",
      "Epoch [2304/4500], Validation Loss: 0.2638\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2305/4500], Training Loss: 0.0000\n",
      "Epoch [2305/4500], Validation Loss: 0.2637\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2306/4500], Training Loss: 0.0000\n",
      "Epoch [2306/4500], Validation Loss: 0.2636\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2307/4500], Training Loss: 0.0000\n",
      "Epoch [2307/4500], Validation Loss: 0.2636\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2308/4500], Training Loss: 0.0000\n",
      "Epoch [2308/4500], Validation Loss: 0.2638\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2309/4500], Training Loss: 0.0000\n",
      "Epoch [2309/4500], Validation Loss: 0.2636\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2310/4500], Training Loss: 0.0000\n",
      "Epoch [2310/4500], Validation Loss: 0.2637\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2311/4500], Training Loss: 0.0000\n",
      "Epoch [2311/4500], Validation Loss: 0.2639\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2312/4500], Training Loss: 0.0000\n",
      "Epoch [2312/4500], Validation Loss: 0.2638\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2313/4500], Training Loss: 0.0000\n",
      "Epoch [2313/4500], Validation Loss: 0.2640\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2314/4500], Training Loss: 0.0000\n",
      "Epoch [2314/4500], Validation Loss: 0.2638\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2315/4500], Training Loss: 0.0000\n",
      "Epoch [2315/4500], Validation Loss: 0.2640\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2316/4500], Training Loss: 0.0000\n",
      "Epoch [2316/4500], Validation Loss: 0.2640\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2317/4500], Training Loss: 0.0000\n",
      "Epoch [2317/4500], Validation Loss: 0.2640\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2318/4500], Training Loss: 0.0000\n",
      "Epoch [2318/4500], Validation Loss: 0.2642\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2319/4500], Training Loss: 0.0000\n",
      "Epoch [2319/4500], Validation Loss: 0.2641\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2320/4500], Training Loss: 0.0000\n",
      "Epoch [2320/4500], Validation Loss: 0.2639\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2321/4500], Training Loss: 0.0000\n",
      "Epoch [2321/4500], Validation Loss: 0.2643\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2322/4500], Training Loss: 0.0000\n",
      "Epoch [2322/4500], Validation Loss: 0.2642\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2323/4500], Training Loss: 0.0000\n",
      "Epoch [2323/4500], Validation Loss: 0.2643\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2324/4500], Training Loss: 0.0000\n",
      "Epoch [2324/4500], Validation Loss: 0.2640\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2325/4500], Training Loss: 0.0000\n",
      "Epoch [2325/4500], Validation Loss: 0.2642\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2326/4500], Training Loss: 0.0000\n",
      "Epoch [2326/4500], Validation Loss: 0.2643\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2327/4500], Training Loss: 0.0000\n",
      "Epoch [2327/4500], Validation Loss: 0.2642\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2328/4500], Training Loss: 0.0000\n",
      "Epoch [2328/4500], Validation Loss: 0.2644\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2329/4500], Training Loss: 0.0000\n",
      "Epoch [2329/4500], Validation Loss: 0.2645\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2330/4500], Training Loss: 0.0000\n",
      "Epoch [2330/4500], Validation Loss: 0.2644\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2331/4500], Training Loss: 0.0000\n",
      "Epoch [2331/4500], Validation Loss: 0.2648\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2332/4500], Training Loss: 0.0000\n",
      "Epoch [2332/4500], Validation Loss: 0.2646\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2333/4500], Training Loss: 0.0000\n",
      "Epoch [2333/4500], Validation Loss: 0.2651\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2334/4500], Training Loss: 0.0000\n",
      "Epoch [2334/4500], Validation Loss: 0.2649\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2335/4500], Training Loss: 0.0000\n",
      "Epoch [2335/4500], Validation Loss: 0.2649\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2336/4500], Training Loss: 0.0000\n",
      "Epoch [2336/4500], Validation Loss: 0.2650\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2337/4500], Training Loss: 0.0000\n",
      "Epoch [2337/4500], Validation Loss: 0.2650\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2338/4500], Training Loss: 0.0000\n",
      "Epoch [2338/4500], Validation Loss: 0.2650\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2339/4500], Training Loss: 0.0000\n",
      "Epoch [2339/4500], Validation Loss: 0.2650\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2340/4500], Training Loss: 0.0000\n",
      "Epoch [2340/4500], Validation Loss: 0.2651\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2341/4500], Training Loss: 0.0000\n",
      "Epoch [2341/4500], Validation Loss: 0.2651\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2342/4500], Training Loss: 0.0000\n",
      "Epoch [2342/4500], Validation Loss: 0.2653\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2343/4500], Training Loss: 0.0000\n",
      "Epoch [2343/4500], Validation Loss: 0.2652\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2344/4500], Training Loss: 0.0000\n",
      "Epoch [2344/4500], Validation Loss: 0.2653\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2345/4500], Training Loss: 0.0000\n",
      "Epoch [2345/4500], Validation Loss: 0.2652\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2346/4500], Training Loss: 0.0000\n",
      "Epoch [2346/4500], Validation Loss: 0.2653\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2347/4500], Training Loss: 0.0000\n",
      "Epoch [2347/4500], Validation Loss: 0.2655\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2348/4500], Training Loss: 0.0000\n",
      "Epoch [2348/4500], Validation Loss: 0.2653\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2349/4500], Training Loss: 0.0000\n",
      "Epoch [2349/4500], Validation Loss: 0.2655\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2350/4500], Training Loss: 0.0000\n",
      "Epoch [2350/4500], Validation Loss: 0.2655\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2351/4500], Training Loss: 0.0000\n",
      "Epoch [2351/4500], Validation Loss: 0.2655\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2352/4500], Training Loss: 0.0000\n",
      "Epoch [2352/4500], Validation Loss: 0.2654\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2353/4500], Training Loss: 0.0000\n",
      "Epoch [2353/4500], Validation Loss: 0.2655\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2354/4500], Training Loss: 0.0000\n",
      "Epoch [2354/4500], Validation Loss: 0.2656\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2355/4500], Training Loss: 0.0000\n",
      "Epoch [2355/4500], Validation Loss: 0.2657\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2356/4500], Training Loss: 0.0000\n",
      "Epoch [2356/4500], Validation Loss: 0.2654\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2357/4500], Training Loss: 0.0000\n",
      "Epoch [2357/4500], Validation Loss: 0.2658\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2358/4500], Training Loss: 0.0000\n",
      "Epoch [2358/4500], Validation Loss: 0.2657\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2359/4500], Training Loss: 0.0000\n",
      "Epoch [2359/4500], Validation Loss: 0.2657\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2360/4500], Training Loss: 0.0000\n",
      "Epoch [2360/4500], Validation Loss: 0.2658\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2361/4500], Training Loss: 0.0000\n",
      "Epoch [2361/4500], Validation Loss: 0.2658\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2362/4500], Training Loss: 0.0000\n",
      "Epoch [2362/4500], Validation Loss: 0.2657\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2363/4500], Training Loss: 0.0000\n",
      "Epoch [2363/4500], Validation Loss: 0.2659\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2364/4500], Training Loss: 0.0000\n",
      "Epoch [2364/4500], Validation Loss: 0.2657\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2365/4500], Training Loss: 0.0000\n",
      "Epoch [2365/4500], Validation Loss: 0.2660\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2366/4500], Training Loss: 0.0000\n",
      "Epoch [2366/4500], Validation Loss: 0.2657\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2367/4500], Training Loss: 0.0000\n",
      "Epoch [2367/4500], Validation Loss: 0.2660\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2368/4500], Training Loss: 0.0000\n",
      "Epoch [2368/4500], Validation Loss: 0.2660\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2369/4500], Training Loss: 0.0000\n",
      "Epoch [2369/4500], Validation Loss: 0.2662\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2370/4500], Training Loss: 0.0000\n",
      "Epoch [2370/4500], Validation Loss: 0.2661\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2371/4500], Training Loss: 0.0000\n",
      "Epoch [2371/4500], Validation Loss: 0.2661\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2372/4500], Training Loss: 0.0000\n",
      "Epoch [2372/4500], Validation Loss: 0.2662\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2373/4500], Training Loss: 0.0000\n",
      "Epoch [2373/4500], Validation Loss: 0.2659\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2374/4500], Training Loss: 0.0000\n",
      "Epoch [2374/4500], Validation Loss: 0.2662\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2375/4500], Training Loss: 0.0000\n",
      "Epoch [2375/4500], Validation Loss: 0.2662\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2376/4500], Training Loss: 0.0000\n",
      "Epoch [2376/4500], Validation Loss: 0.2663\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2377/4500], Training Loss: 0.0000\n",
      "Epoch [2377/4500], Validation Loss: 0.2664\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2378/4500], Training Loss: 0.0000\n",
      "Epoch [2378/4500], Validation Loss: 0.2664\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2379/4500], Training Loss: 0.0000\n",
      "Epoch [2379/4500], Validation Loss: 0.2664\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2380/4500], Training Loss: 0.0000\n",
      "Epoch [2380/4500], Validation Loss: 0.2663\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2381/4500], Training Loss: 0.0000\n",
      "Epoch [2381/4500], Validation Loss: 0.2664\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2382/4500], Training Loss: 0.0000\n",
      "Epoch [2382/4500], Validation Loss: 0.2664\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2383/4500], Training Loss: 0.0000\n",
      "Epoch [2383/4500], Validation Loss: 0.2664\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2384/4500], Training Loss: 0.0000\n",
      "Epoch [2384/4500], Validation Loss: 0.2663\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2385/4500], Training Loss: 0.0000\n",
      "Epoch [2385/4500], Validation Loss: 0.2664\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2386/4500], Training Loss: 0.0000\n",
      "Epoch [2386/4500], Validation Loss: 0.2666\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2387/4500], Training Loss: 0.0000\n",
      "Epoch [2387/4500], Validation Loss: 0.2668\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2388/4500], Training Loss: 0.0000\n",
      "Epoch [2388/4500], Validation Loss: 0.2670\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2389/4500], Training Loss: 0.0000\n",
      "Epoch [2389/4500], Validation Loss: 0.2670\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2390/4500], Training Loss: 0.0000\n",
      "Epoch [2390/4500], Validation Loss: 0.2666\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2391/4500], Training Loss: 0.0000\n",
      "Epoch [2391/4500], Validation Loss: 0.2672\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2392/4500], Training Loss: 0.0000\n",
      "Epoch [2392/4500], Validation Loss: 0.2669\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2393/4500], Training Loss: 0.0000\n",
      "Epoch [2393/4500], Validation Loss: 0.2672\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2394/4500], Training Loss: 0.0000\n",
      "Epoch [2394/4500], Validation Loss: 0.2673\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2395/4500], Training Loss: 0.0000\n",
      "Epoch [2395/4500], Validation Loss: 0.2672\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2396/4500], Training Loss: 0.0000\n",
      "Epoch [2396/4500], Validation Loss: 0.2672\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2397/4500], Training Loss: 0.0000\n",
      "Epoch [2397/4500], Validation Loss: 0.2672\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2398/4500], Training Loss: 0.0000\n",
      "Epoch [2398/4500], Validation Loss: 0.2674\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2399/4500], Training Loss: 0.0000\n",
      "Epoch [2399/4500], Validation Loss: 0.2672\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2400/4500], Training Loss: 0.0000\n",
      "Epoch [2400/4500], Validation Loss: 0.2675\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2401/4500], Training Loss: 0.0000\n",
      "Epoch [2401/4500], Validation Loss: 0.2676\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2402/4500], Training Loss: 0.0000\n",
      "Epoch [2402/4500], Validation Loss: 0.2675\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2403/4500], Training Loss: 0.0000\n",
      "Epoch [2403/4500], Validation Loss: 0.2674\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2404/4500], Training Loss: 0.0000\n",
      "Epoch [2404/4500], Validation Loss: 0.2677\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2405/4500], Training Loss: 0.0000\n",
      "Epoch [2405/4500], Validation Loss: 0.2675\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2406/4500], Training Loss: 0.0000\n",
      "Epoch [2406/4500], Validation Loss: 0.2674\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2407/4500], Training Loss: 0.0000\n",
      "Epoch [2407/4500], Validation Loss: 0.2677\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2408/4500], Training Loss: 0.0000\n",
      "Epoch [2408/4500], Validation Loss: 0.2676\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2409/4500], Training Loss: 0.0000\n",
      "Epoch [2409/4500], Validation Loss: 0.2676\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2410/4500], Training Loss: 0.0000\n",
      "Epoch [2410/4500], Validation Loss: 0.2676\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2411/4500], Training Loss: 0.0000\n",
      "Epoch [2411/4500], Validation Loss: 0.2678\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2412/4500], Training Loss: 0.0000\n",
      "Epoch [2412/4500], Validation Loss: 0.2677\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2413/4500], Training Loss: 0.0000\n",
      "Epoch [2413/4500], Validation Loss: 0.2680\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2414/4500], Training Loss: 0.0000\n",
      "Epoch [2414/4500], Validation Loss: 0.2678\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2415/4500], Training Loss: 0.0000\n",
      "Epoch [2415/4500], Validation Loss: 0.2680\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2416/4500], Training Loss: 0.0000\n",
      "Epoch [2416/4500], Validation Loss: 0.2677\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2417/4500], Training Loss: 0.0000\n",
      "Epoch [2417/4500], Validation Loss: 0.2683\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2418/4500], Training Loss: 0.0000\n",
      "Epoch [2418/4500], Validation Loss: 0.2679\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2419/4500], Training Loss: 0.0000\n",
      "Epoch [2419/4500], Validation Loss: 0.2679\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2420/4500], Training Loss: 0.0000\n",
      "Epoch [2420/4500], Validation Loss: 0.2679\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2421/4500], Training Loss: 0.0000\n",
      "Epoch [2421/4500], Validation Loss: 0.2682\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2422/4500], Training Loss: 0.0000\n",
      "Epoch [2422/4500], Validation Loss: 0.2680\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2423/4500], Training Loss: 0.0000\n",
      "Epoch [2423/4500], Validation Loss: 0.2681\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2424/4500], Training Loss: 0.0000\n",
      "Epoch [2424/4500], Validation Loss: 0.2681\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2425/4500], Training Loss: 0.0000\n",
      "Epoch [2425/4500], Validation Loss: 0.2681\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2426/4500], Training Loss: 0.0000\n",
      "Epoch [2426/4500], Validation Loss: 0.2681\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2427/4500], Training Loss: 0.0000\n",
      "Epoch [2427/4500], Validation Loss: 0.2681\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2428/4500], Training Loss: 0.0000\n",
      "Epoch [2428/4500], Validation Loss: 0.2680\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2429/4500], Training Loss: 0.0000\n",
      "Epoch [2429/4500], Validation Loss: 0.2684\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2430/4500], Training Loss: 0.0000\n",
      "Epoch [2430/4500], Validation Loss: 0.2682\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2431/4500], Training Loss: 0.0000\n",
      "Epoch [2431/4500], Validation Loss: 0.2683\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2432/4500], Training Loss: 0.0000\n",
      "Epoch [2432/4500], Validation Loss: 0.2684\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2433/4500], Training Loss: 0.0000\n",
      "Epoch [2433/4500], Validation Loss: 0.2683\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2434/4500], Training Loss: 0.0000\n",
      "Epoch [2434/4500], Validation Loss: 0.2684\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2435/4500], Training Loss: 0.0000\n",
      "Epoch [2435/4500], Validation Loss: 0.2685\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2436/4500], Training Loss: 0.0000\n",
      "Epoch [2436/4500], Validation Loss: 0.2685\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2437/4500], Training Loss: 0.0000\n",
      "Epoch [2437/4500], Validation Loss: 0.2685\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2438/4500], Training Loss: 0.0000\n",
      "Epoch [2438/4500], Validation Loss: 0.2684\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2439/4500], Training Loss: 0.0000\n",
      "Epoch [2439/4500], Validation Loss: 0.2685\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2440/4500], Training Loss: 0.0000\n",
      "Epoch [2440/4500], Validation Loss: 0.2687\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2441/4500], Training Loss: 0.0000\n",
      "Epoch [2441/4500], Validation Loss: 0.2687\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2442/4500], Training Loss: 0.0000\n",
      "Epoch [2442/4500], Validation Loss: 0.2685\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2443/4500], Training Loss: 0.0000\n",
      "Epoch [2443/4500], Validation Loss: 0.2687\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2444/4500], Training Loss: 0.0000\n",
      "Epoch [2444/4500], Validation Loss: 0.2687\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2445/4500], Training Loss: 0.0000\n",
      "Epoch [2445/4500], Validation Loss: 0.2687\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2446/4500], Training Loss: 0.0000\n",
      "Epoch [2446/4500], Validation Loss: 0.2688\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2447/4500], Training Loss: 0.0000\n",
      "Epoch [2447/4500], Validation Loss: 0.2688\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2448/4500], Training Loss: 0.0000\n",
      "Epoch [2448/4500], Validation Loss: 0.2688\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2449/4500], Training Loss: 0.0000\n",
      "Epoch [2449/4500], Validation Loss: 0.2688\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2450/4500], Training Loss: 0.0000\n",
      "Epoch [2450/4500], Validation Loss: 0.2691\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2451/4500], Training Loss: 0.0000\n",
      "Epoch [2451/4500], Validation Loss: 0.2689\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2452/4500], Training Loss: 0.0000\n",
      "Epoch [2452/4500], Validation Loss: 0.2688\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2453/4500], Training Loss: 0.0000\n",
      "Epoch [2453/4500], Validation Loss: 0.2690\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2454/4500], Training Loss: 0.0000\n",
      "Epoch [2454/4500], Validation Loss: 0.2690\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2455/4500], Training Loss: 0.0000\n",
      "Epoch [2455/4500], Validation Loss: 0.2691\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2456/4500], Training Loss: 0.0000\n",
      "Epoch [2456/4500], Validation Loss: 0.2695\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2457/4500], Training Loss: 0.0000\n",
      "Epoch [2457/4500], Validation Loss: 0.2690\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2458/4500], Training Loss: 0.0000\n",
      "Epoch [2458/4500], Validation Loss: 0.2691\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2459/4500], Training Loss: 0.0000\n",
      "Epoch [2459/4500], Validation Loss: 0.2691\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2460/4500], Training Loss: 0.0000\n",
      "Epoch [2460/4500], Validation Loss: 0.2696\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2461/4500], Training Loss: 0.0000\n",
      "Epoch [2461/4500], Validation Loss: 0.2697\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2462/4500], Training Loss: 0.0000\n",
      "Epoch [2462/4500], Validation Loss: 0.2697\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2463/4500], Training Loss: 0.0000\n",
      "Epoch [2463/4500], Validation Loss: 0.2698\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2464/4500], Training Loss: 0.0000\n",
      "Epoch [2464/4500], Validation Loss: 0.2696\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2465/4500], Training Loss: 0.0000\n",
      "Epoch [2465/4500], Validation Loss: 0.2699\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2466/4500], Training Loss: 0.0000\n",
      "Epoch [2466/4500], Validation Loss: 0.2698\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2467/4500], Training Loss: 0.0000\n",
      "Epoch [2467/4500], Validation Loss: 0.2698\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2468/4500], Training Loss: 0.0000\n",
      "Epoch [2468/4500], Validation Loss: 0.2699\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2469/4500], Training Loss: 0.0000\n",
      "Epoch [2469/4500], Validation Loss: 0.2699\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2470/4500], Training Loss: 0.0000\n",
      "Epoch [2470/4500], Validation Loss: 0.2699\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2471/4500], Training Loss: 0.0000\n",
      "Epoch [2471/4500], Validation Loss: 0.2699\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2472/4500], Training Loss: 0.0000\n",
      "Epoch [2472/4500], Validation Loss: 0.2700\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2473/4500], Training Loss: 0.0000\n",
      "Epoch [2473/4500], Validation Loss: 0.2700\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2474/4500], Training Loss: 0.0000\n",
      "Epoch [2474/4500], Validation Loss: 0.2701\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2475/4500], Training Loss: 0.0000\n",
      "Epoch [2475/4500], Validation Loss: 0.2699\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2476/4500], Training Loss: 0.0000\n",
      "Epoch [2476/4500], Validation Loss: 0.2702\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2477/4500], Training Loss: 0.0000\n",
      "Epoch [2477/4500], Validation Loss: 0.2703\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2478/4500], Training Loss: 0.0000\n",
      "Epoch [2478/4500], Validation Loss: 0.2700\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2479/4500], Training Loss: 0.0000\n",
      "Epoch [2479/4500], Validation Loss: 0.2703\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2480/4500], Training Loss: 0.0000\n",
      "Epoch [2480/4500], Validation Loss: 0.2701\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2481/4500], Training Loss: 0.0000\n",
      "Epoch [2481/4500], Validation Loss: 0.2702\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2482/4500], Training Loss: 0.0000\n",
      "Epoch [2482/4500], Validation Loss: 0.2705\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2483/4500], Training Loss: 0.0000\n",
      "Epoch [2483/4500], Validation Loss: 0.2703\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2484/4500], Training Loss: 0.0000\n",
      "Epoch [2484/4500], Validation Loss: 0.2702\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2485/4500], Training Loss: 0.0000\n",
      "Epoch [2485/4500], Validation Loss: 0.2705\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2486/4500], Training Loss: 0.0000\n",
      "Epoch [2486/4500], Validation Loss: 0.2705\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2487/4500], Training Loss: 0.0000\n",
      "Epoch [2487/4500], Validation Loss: 0.2705\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2488/4500], Training Loss: 0.0000\n",
      "Epoch [2488/4500], Validation Loss: 0.2704\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2489/4500], Training Loss: 0.0000\n",
      "Epoch [2489/4500], Validation Loss: 0.2704\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2490/4500], Training Loss: 0.0000\n",
      "Epoch [2490/4500], Validation Loss: 0.2704\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2491/4500], Training Loss: 0.0000\n",
      "Epoch [2491/4500], Validation Loss: 0.2705\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2492/4500], Training Loss: 0.0000\n",
      "Epoch [2492/4500], Validation Loss: 0.2706\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2493/4500], Training Loss: 0.0000\n",
      "Epoch [2493/4500], Validation Loss: 0.2706\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2494/4500], Training Loss: 0.0000\n",
      "Epoch [2494/4500], Validation Loss: 0.2706\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2495/4500], Training Loss: 0.0000\n",
      "Epoch [2495/4500], Validation Loss: 0.2707\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2496/4500], Training Loss: 0.0000\n",
      "Epoch [2496/4500], Validation Loss: 0.2705\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2497/4500], Training Loss: 0.0000\n",
      "Epoch [2497/4500], Validation Loss: 0.2707\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2498/4500], Training Loss: 0.0000\n",
      "Epoch [2498/4500], Validation Loss: 0.2709\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2499/4500], Training Loss: 0.0000\n",
      "Epoch [2499/4500], Validation Loss: 0.2706\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2500/4500], Training Loss: 0.0000\n",
      "Epoch [2500/4500], Validation Loss: 0.2710\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2501/4500], Training Loss: 0.0000\n",
      "Epoch [2501/4500], Validation Loss: 0.2707\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2502/4500], Training Loss: 0.0000\n",
      "Epoch [2502/4500], Validation Loss: 0.2710\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2503/4500], Training Loss: 0.0000\n",
      "Epoch [2503/4500], Validation Loss: 0.2708\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2504/4500], Training Loss: 0.0000\n",
      "Epoch [2504/4500], Validation Loss: 0.2709\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2505/4500], Training Loss: 0.0000\n",
      "Epoch [2505/4500], Validation Loss: 0.2709\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2506/4500], Training Loss: 0.0000\n",
      "Epoch [2506/4500], Validation Loss: 0.2708\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2507/4500], Training Loss: 0.0000\n",
      "Epoch [2507/4500], Validation Loss: 0.2709\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2508/4500], Training Loss: 0.0000\n",
      "Epoch [2508/4500], Validation Loss: 0.2711\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2509/4500], Training Loss: 0.0000\n",
      "Epoch [2509/4500], Validation Loss: 0.2710\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2510/4500], Training Loss: 0.0000\n",
      "Epoch [2510/4500], Validation Loss: 0.2713\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2511/4500], Training Loss: 0.0000\n",
      "Epoch [2511/4500], Validation Loss: 0.2710\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2512/4500], Training Loss: 0.0000\n",
      "Epoch [2512/4500], Validation Loss: 0.2712\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2513/4500], Training Loss: 0.0000\n",
      "Epoch [2513/4500], Validation Loss: 0.2713\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2514/4500], Training Loss: 0.0000\n",
      "Epoch [2514/4500], Validation Loss: 0.2711\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2515/4500], Training Loss: 0.0000\n",
      "Epoch [2515/4500], Validation Loss: 0.2713\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2516/4500], Training Loss: 0.0000\n",
      "Epoch [2516/4500], Validation Loss: 0.2711\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2517/4500], Training Loss: 0.0000\n",
      "Epoch [2517/4500], Validation Loss: 0.2713\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2518/4500], Training Loss: 0.0000\n",
      "Epoch [2518/4500], Validation Loss: 0.2712\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2519/4500], Training Loss: 0.0000\n",
      "Epoch [2519/4500], Validation Loss: 0.2712\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2520/4500], Training Loss: 0.0000\n",
      "Epoch [2520/4500], Validation Loss: 0.2714\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2521/4500], Training Loss: 0.0000\n",
      "Epoch [2521/4500], Validation Loss: 0.2712\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2522/4500], Training Loss: 0.0000\n",
      "Epoch [2522/4500], Validation Loss: 0.2715\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2523/4500], Training Loss: 0.0000\n",
      "Epoch [2523/4500], Validation Loss: 0.2713\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2524/4500], Training Loss: 0.0000\n",
      "Epoch [2524/4500], Validation Loss: 0.2716\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2525/4500], Training Loss: 0.0000\n",
      "Epoch [2525/4500], Validation Loss: 0.2715\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2526/4500], Training Loss: 0.0000\n",
      "Epoch [2526/4500], Validation Loss: 0.2715\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2527/4500], Training Loss: 0.0000\n",
      "Epoch [2527/4500], Validation Loss: 0.2716\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2528/4500], Training Loss: 0.0000\n",
      "Epoch [2528/4500], Validation Loss: 0.2716\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2529/4500], Training Loss: 0.0000\n",
      "Epoch [2529/4500], Validation Loss: 0.2715\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2530/4500], Training Loss: 0.0000\n",
      "Epoch [2530/4500], Validation Loss: 0.2717\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2531/4500], Training Loss: 0.0000\n",
      "Epoch [2531/4500], Validation Loss: 0.2718\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2532/4500], Training Loss: 0.0000\n",
      "Epoch [2532/4500], Validation Loss: 0.2715\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2533/4500], Training Loss: 0.0000\n",
      "Epoch [2533/4500], Validation Loss: 0.2715\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2534/4500], Training Loss: 0.0000\n",
      "Epoch [2534/4500], Validation Loss: 0.2718\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2535/4500], Training Loss: 0.0000\n",
      "Epoch [2535/4500], Validation Loss: 0.2717\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2536/4500], Training Loss: 0.0000\n",
      "Epoch [2536/4500], Validation Loss: 0.2718\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2537/4500], Training Loss: 0.0000\n",
      "Epoch [2537/4500], Validation Loss: 0.2719\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2538/4500], Training Loss: 0.0000\n",
      "Epoch [2538/4500], Validation Loss: 0.2719\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2539/4500], Training Loss: 0.0000\n",
      "Epoch [2539/4500], Validation Loss: 0.2717\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2540/4500], Training Loss: 0.0000\n",
      "Epoch [2540/4500], Validation Loss: 0.2719\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2541/4500], Training Loss: 0.0000\n",
      "Epoch [2541/4500], Validation Loss: 0.2721\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2542/4500], Training Loss: 0.0000\n",
      "Epoch [2542/4500], Validation Loss: 0.2719\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2543/4500], Training Loss: 0.0000\n",
      "Epoch [2543/4500], Validation Loss: 0.2721\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2544/4500], Training Loss: 0.0000\n",
      "Epoch [2544/4500], Validation Loss: 0.2725\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2545/4500], Training Loss: 0.0000\n",
      "Epoch [2545/4500], Validation Loss: 0.2721\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2546/4500], Training Loss: 0.0000\n",
      "Epoch [2546/4500], Validation Loss: 0.2720\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2547/4500], Training Loss: 0.0000\n",
      "Epoch [2547/4500], Validation Loss: 0.2727\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2548/4500], Training Loss: 0.0000\n",
      "Epoch [2548/4500], Validation Loss: 0.2727\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2549/4500], Training Loss: 0.0000\n",
      "Epoch [2549/4500], Validation Loss: 0.2726\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2550/4500], Training Loss: 0.0000\n",
      "Epoch [2550/4500], Validation Loss: 0.2727\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2551/4500], Training Loss: 0.0000\n",
      "Epoch [2551/4500], Validation Loss: 0.2726\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2552/4500], Training Loss: 0.0000\n",
      "Epoch [2552/4500], Validation Loss: 0.2729\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2553/4500], Training Loss: 0.0000\n",
      "Epoch [2553/4500], Validation Loss: 0.2727\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2554/4500], Training Loss: 0.0000\n",
      "Epoch [2554/4500], Validation Loss: 0.2730\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2555/4500], Training Loss: 0.0000\n",
      "Epoch [2555/4500], Validation Loss: 0.2729\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2556/4500], Training Loss: 0.0000\n",
      "Epoch [2556/4500], Validation Loss: 0.2732\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2557/4500], Training Loss: 0.0000\n",
      "Epoch [2557/4500], Validation Loss: 0.2729\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2558/4500], Training Loss: 0.0000\n",
      "Epoch [2558/4500], Validation Loss: 0.2730\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2559/4500], Training Loss: 0.0000\n",
      "Epoch [2559/4500], Validation Loss: 0.2732\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2560/4500], Training Loss: 0.0000\n",
      "Epoch [2560/4500], Validation Loss: 0.2730\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2561/4500], Training Loss: 0.0000\n",
      "Epoch [2561/4500], Validation Loss: 0.2731\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2562/4500], Training Loss: 0.0000\n",
      "Epoch [2562/4500], Validation Loss: 0.2731\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2563/4500], Training Loss: 0.0000\n",
      "Epoch [2563/4500], Validation Loss: 0.2732\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2564/4500], Training Loss: 0.0000\n",
      "Epoch [2564/4500], Validation Loss: 0.2733\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2565/4500], Training Loss: 0.0000\n",
      "Epoch [2565/4500], Validation Loss: 0.2733\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2566/4500], Training Loss: 0.0000\n",
      "Epoch [2566/4500], Validation Loss: 0.2733\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2567/4500], Training Loss: 0.0000\n",
      "Epoch [2567/4500], Validation Loss: 0.2734\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2568/4500], Training Loss: 0.0000\n",
      "Epoch [2568/4500], Validation Loss: 0.2735\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2569/4500], Training Loss: 0.0000\n",
      "Epoch [2569/4500], Validation Loss: 0.2733\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2570/4500], Training Loss: 0.0000\n",
      "Epoch [2570/4500], Validation Loss: 0.2733\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2571/4500], Training Loss: 0.0000\n",
      "Epoch [2571/4500], Validation Loss: 0.2733\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2572/4500], Training Loss: 0.0000\n",
      "Epoch [2572/4500], Validation Loss: 0.2734\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2573/4500], Training Loss: 0.0000\n",
      "Epoch [2573/4500], Validation Loss: 0.2735\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2574/4500], Training Loss: 0.0000\n",
      "Epoch [2574/4500], Validation Loss: 0.2736\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2575/4500], Training Loss: 0.0000\n",
      "Epoch [2575/4500], Validation Loss: 0.2735\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2576/4500], Training Loss: 0.0000\n",
      "Epoch [2576/4500], Validation Loss: 0.2735\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2577/4500], Training Loss: 0.0000\n",
      "Epoch [2577/4500], Validation Loss: 0.2735\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2578/4500], Training Loss: 0.0000\n",
      "Epoch [2578/4500], Validation Loss: 0.2737\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2579/4500], Training Loss: 0.0000\n",
      "Epoch [2579/4500], Validation Loss: 0.2737\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2580/4500], Training Loss: 0.0000\n",
      "Epoch [2580/4500], Validation Loss: 0.2736\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2581/4500], Training Loss: 0.0000\n",
      "Epoch [2581/4500], Validation Loss: 0.2738\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2582/4500], Training Loss: 0.0000\n",
      "Epoch [2582/4500], Validation Loss: 0.2736\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2583/4500], Training Loss: 0.0000\n",
      "Epoch [2583/4500], Validation Loss: 0.2738\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2584/4500], Training Loss: 0.0000\n",
      "Epoch [2584/4500], Validation Loss: 0.2738\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2585/4500], Training Loss: 0.0000\n",
      "Epoch [2585/4500], Validation Loss: 0.2739\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2586/4500], Training Loss: 0.0000\n",
      "Epoch [2586/4500], Validation Loss: 0.2739\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2587/4500], Training Loss: 0.0000\n",
      "Epoch [2587/4500], Validation Loss: 0.2738\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2588/4500], Training Loss: 0.0000\n",
      "Epoch [2588/4500], Validation Loss: 0.2740\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2589/4500], Training Loss: 0.0000\n",
      "Epoch [2589/4500], Validation Loss: 0.2738\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2590/4500], Training Loss: 0.0000\n",
      "Epoch [2590/4500], Validation Loss: 0.2740\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2591/4500], Training Loss: 0.0000\n",
      "Epoch [2591/4500], Validation Loss: 0.2739\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2592/4500], Training Loss: 0.0000\n",
      "Epoch [2592/4500], Validation Loss: 0.2740\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2593/4500], Training Loss: 0.0000\n",
      "Epoch [2593/4500], Validation Loss: 0.2741\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2594/4500], Training Loss: 0.0000\n",
      "Epoch [2594/4500], Validation Loss: 0.2740\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2595/4500], Training Loss: 0.0000\n",
      "Epoch [2595/4500], Validation Loss: 0.2741\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2596/4500], Training Loss: 0.0000\n",
      "Epoch [2596/4500], Validation Loss: 0.2742\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2597/4500], Training Loss: 0.0000\n",
      "Epoch [2597/4500], Validation Loss: 0.2741\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2598/4500], Training Loss: 0.0000\n",
      "Epoch [2598/4500], Validation Loss: 0.2741\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2599/4500], Training Loss: 0.0000\n",
      "Epoch [2599/4500], Validation Loss: 0.2741\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2600/4500], Training Loss: 0.0000\n",
      "Epoch [2600/4500], Validation Loss: 0.2744\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2601/4500], Training Loss: 0.0000\n",
      "Epoch [2601/4500], Validation Loss: 0.2742\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2602/4500], Training Loss: 0.0000\n",
      "Epoch [2602/4500], Validation Loss: 0.2743\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2603/4500], Training Loss: 0.0000\n",
      "Epoch [2603/4500], Validation Loss: 0.2744\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2604/4500], Training Loss: 0.0000\n",
      "Epoch [2604/4500], Validation Loss: 0.2743\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2605/4500], Training Loss: 0.0000\n",
      "Epoch [2605/4500], Validation Loss: 0.2744\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2606/4500], Training Loss: 0.0000\n",
      "Epoch [2606/4500], Validation Loss: 0.2744\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2607/4500], Training Loss: 0.0000\n",
      "Epoch [2607/4500], Validation Loss: 0.2745\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2608/4500], Training Loss: 0.0000\n",
      "Epoch [2608/4500], Validation Loss: 0.2745\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2609/4500], Training Loss: 0.0000\n",
      "Epoch [2609/4500], Validation Loss: 0.2745\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2610/4500], Training Loss: 0.0000\n",
      "Epoch [2610/4500], Validation Loss: 0.2747\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2611/4500], Training Loss: 0.0000\n",
      "Epoch [2611/4500], Validation Loss: 0.2746\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2612/4500], Training Loss: 0.0000\n",
      "Epoch [2612/4500], Validation Loss: 0.2747\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2613/4500], Training Loss: 0.0000\n",
      "Epoch [2613/4500], Validation Loss: 0.2745\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2614/4500], Training Loss: 0.0000\n",
      "Epoch [2614/4500], Validation Loss: 0.2746\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2615/4500], Training Loss: 0.0000\n",
      "Epoch [2615/4500], Validation Loss: 0.2747\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2616/4500], Training Loss: 0.0000\n",
      "Epoch [2616/4500], Validation Loss: 0.2748\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2617/4500], Training Loss: 0.0000\n",
      "Epoch [2617/4500], Validation Loss: 0.2749\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2618/4500], Training Loss: 0.0000\n",
      "Epoch [2618/4500], Validation Loss: 0.2746\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2619/4500], Training Loss: 0.0000\n",
      "Epoch [2619/4500], Validation Loss: 0.2748\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2620/4500], Training Loss: 0.0000\n",
      "Epoch [2620/4500], Validation Loss: 0.2749\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2621/4500], Training Loss: 0.0000\n",
      "Epoch [2621/4500], Validation Loss: 0.2749\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2622/4500], Training Loss: 0.0000\n",
      "Epoch [2622/4500], Validation Loss: 0.2750\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2623/4500], Training Loss: 0.0000\n",
      "Epoch [2623/4500], Validation Loss: 0.2750\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2624/4500], Training Loss: 0.0000\n",
      "Epoch [2624/4500], Validation Loss: 0.2750\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2625/4500], Training Loss: 0.0000\n",
      "Epoch [2625/4500], Validation Loss: 0.2748\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2626/4500], Training Loss: 0.0000\n",
      "Epoch [2626/4500], Validation Loss: 0.2750\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2627/4500], Training Loss: 0.0000\n",
      "Epoch [2627/4500], Validation Loss: 0.2750\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2628/4500], Training Loss: 0.0000\n",
      "Epoch [2628/4500], Validation Loss: 0.2750\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2629/4500], Training Loss: 0.0000\n",
      "Epoch [2629/4500], Validation Loss: 0.2751\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2630/4500], Training Loss: 0.0000\n",
      "Epoch [2630/4500], Validation Loss: 0.2749\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2631/4500], Training Loss: 0.0000\n",
      "Epoch [2631/4500], Validation Loss: 0.2754\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2632/4500], Training Loss: 0.0000\n",
      "Epoch [2632/4500], Validation Loss: 0.2750\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2633/4500], Training Loss: 0.0000\n",
      "Epoch [2633/4500], Validation Loss: 0.2752\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2634/4500], Training Loss: 0.0000\n",
      "Epoch [2634/4500], Validation Loss: 0.2752\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2635/4500], Training Loss: 0.0000\n",
      "Epoch [2635/4500], Validation Loss: 0.2752\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2636/4500], Training Loss: 0.0000\n",
      "Epoch [2636/4500], Validation Loss: 0.2750\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2637/4500], Training Loss: 0.0000\n",
      "Epoch [2637/4500], Validation Loss: 0.2753\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2638/4500], Training Loss: 0.0000\n",
      "Epoch [2638/4500], Validation Loss: 0.2753\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2639/4500], Training Loss: 0.0000\n",
      "Epoch [2639/4500], Validation Loss: 0.2751\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2640/4500], Training Loss: 0.0000\n",
      "Epoch [2640/4500], Validation Loss: 0.2755\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2641/4500], Training Loss: 0.0000\n",
      "Epoch [2641/4500], Validation Loss: 0.2754\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2642/4500], Training Loss: 0.0000\n",
      "Epoch [2642/4500], Validation Loss: 0.2754\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2643/4500], Training Loss: 0.0000\n",
      "Epoch [2643/4500], Validation Loss: 0.2753\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2644/4500], Training Loss: 0.0000\n",
      "Epoch [2644/4500], Validation Loss: 0.2755\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2645/4500], Training Loss: 0.0000\n",
      "Epoch [2645/4500], Validation Loss: 0.2756\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2646/4500], Training Loss: 0.0000\n",
      "Epoch [2646/4500], Validation Loss: 0.2755\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2647/4500], Training Loss: 0.0000\n",
      "Epoch [2647/4500], Validation Loss: 0.2757\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2648/4500], Training Loss: 0.0000\n",
      "Epoch [2648/4500], Validation Loss: 0.2755\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2649/4500], Training Loss: 0.0000\n",
      "Epoch [2649/4500], Validation Loss: 0.2756\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2650/4500], Training Loss: 0.0000\n",
      "Epoch [2650/4500], Validation Loss: 0.2756\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2651/4500], Training Loss: 0.0000\n",
      "Epoch [2651/4500], Validation Loss: 0.2758\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2652/4500], Training Loss: 0.0000\n",
      "Epoch [2652/4500], Validation Loss: 0.2761\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2653/4500], Training Loss: 0.0000\n",
      "Epoch [2653/4500], Validation Loss: 0.2766\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2654/4500], Training Loss: 0.0000\n",
      "Epoch [2654/4500], Validation Loss: 0.2764\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2655/4500], Training Loss: 0.0000\n",
      "Epoch [2655/4500], Validation Loss: 0.2758\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2656/4500], Training Loss: 0.0000\n",
      "Epoch [2656/4500], Validation Loss: 0.2765\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2657/4500], Training Loss: 0.0000\n",
      "Epoch [2657/4500], Validation Loss: 0.2766\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2658/4500], Training Loss: 0.0000\n",
      "Epoch [2658/4500], Validation Loss: 0.2765\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2659/4500], Training Loss: 0.0000\n",
      "Epoch [2659/4500], Validation Loss: 0.2766\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2660/4500], Training Loss: 0.0000\n",
      "Epoch [2660/4500], Validation Loss: 0.2767\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2661/4500], Training Loss: 0.0000\n",
      "Epoch [2661/4500], Validation Loss: 0.2766\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2662/4500], Training Loss: 0.0000\n",
      "Epoch [2662/4500], Validation Loss: 0.2767\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2663/4500], Training Loss: 0.0000\n",
      "Epoch [2663/4500], Validation Loss: 0.2767\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2664/4500], Training Loss: 0.0000\n",
      "Epoch [2664/4500], Validation Loss: 0.2765\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2665/4500], Training Loss: 0.0000\n",
      "Epoch [2665/4500], Validation Loss: 0.2768\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2666/4500], Training Loss: 0.0000\n",
      "Epoch [2666/4500], Validation Loss: 0.2769\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2667/4500], Training Loss: 0.0000\n",
      "Epoch [2667/4500], Validation Loss: 0.2767\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2668/4500], Training Loss: 0.0000\n",
      "Epoch [2668/4500], Validation Loss: 0.2769\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2669/4500], Training Loss: 0.0000\n",
      "Epoch [2669/4500], Validation Loss: 0.2769\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2670/4500], Training Loss: 0.0000\n",
      "Epoch [2670/4500], Validation Loss: 0.2767\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2671/4500], Training Loss: 0.0000\n",
      "Epoch [2671/4500], Validation Loss: 0.2770\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2672/4500], Training Loss: 0.0000\n",
      "Epoch [2672/4500], Validation Loss: 0.2769\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2673/4500], Training Loss: 0.0000\n",
      "Epoch [2673/4500], Validation Loss: 0.2770\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2674/4500], Training Loss: 0.0000\n",
      "Epoch [2674/4500], Validation Loss: 0.2771\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2675/4500], Training Loss: 0.0000\n",
      "Epoch [2675/4500], Validation Loss: 0.2772\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2676/4500], Training Loss: 0.0000\n",
      "Epoch [2676/4500], Validation Loss: 0.2770\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2677/4500], Training Loss: 0.0000\n",
      "Epoch [2677/4500], Validation Loss: 0.2770\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2678/4500], Training Loss: 0.0000\n",
      "Epoch [2678/4500], Validation Loss: 0.2772\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2679/4500], Training Loss: 0.0000\n",
      "Epoch [2679/4500], Validation Loss: 0.2773\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2680/4500], Training Loss: 0.0000\n",
      "Epoch [2680/4500], Validation Loss: 0.2771\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2681/4500], Training Loss: 0.0000\n",
      "Epoch [2681/4500], Validation Loss: 0.2770\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2682/4500], Training Loss: 0.0000\n",
      "Epoch [2682/4500], Validation Loss: 0.2772\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2683/4500], Training Loss: 0.0000\n",
      "Epoch [2683/4500], Validation Loss: 0.2773\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2684/4500], Training Loss: 0.0000\n",
      "Epoch [2684/4500], Validation Loss: 0.2773\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2685/4500], Training Loss: 0.0000\n",
      "Epoch [2685/4500], Validation Loss: 0.2772\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2686/4500], Training Loss: 0.0000\n",
      "Epoch [2686/4500], Validation Loss: 0.2772\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2687/4500], Training Loss: 0.0000\n",
      "Epoch [2687/4500], Validation Loss: 0.2774\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2688/4500], Training Loss: 0.0000\n",
      "Epoch [2688/4500], Validation Loss: 0.2774\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2689/4500], Training Loss: 0.0000\n",
      "Epoch [2689/4500], Validation Loss: 0.2775\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2690/4500], Training Loss: 0.0000\n",
      "Epoch [2690/4500], Validation Loss: 0.2773\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2691/4500], Training Loss: 0.0000\n",
      "Epoch [2691/4500], Validation Loss: 0.2774\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2692/4500], Training Loss: 0.0000\n",
      "Epoch [2692/4500], Validation Loss: 0.2775\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2693/4500], Training Loss: 0.0000\n",
      "Epoch [2693/4500], Validation Loss: 0.2774\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2694/4500], Training Loss: 0.0000\n",
      "Epoch [2694/4500], Validation Loss: 0.2777\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2695/4500], Training Loss: 0.0000\n",
      "Epoch [2695/4500], Validation Loss: 0.2775\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2696/4500], Training Loss: 0.0000\n",
      "Epoch [2696/4500], Validation Loss: 0.2778\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2697/4500], Training Loss: 0.0000\n",
      "Epoch [2697/4500], Validation Loss: 0.2776\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2698/4500], Training Loss: 0.0000\n",
      "Epoch [2698/4500], Validation Loss: 0.2777\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2699/4500], Training Loss: 0.0000\n",
      "Epoch [2699/4500], Validation Loss: 0.2778\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2700/4500], Training Loss: 0.0000\n",
      "Epoch [2700/4500], Validation Loss: 0.2778\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2701/4500], Training Loss: 0.0000\n",
      "Epoch [2701/4500], Validation Loss: 0.2776\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2702/4500], Training Loss: 0.0000\n",
      "Epoch [2702/4500], Validation Loss: 0.2778\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2703/4500], Training Loss: 0.0000\n",
      "Epoch [2703/4500], Validation Loss: 0.2778\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2704/4500], Training Loss: 0.0000\n",
      "Epoch [2704/4500], Validation Loss: 0.2778\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2705/4500], Training Loss: 0.0000\n",
      "Epoch [2705/4500], Validation Loss: 0.2777\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2706/4500], Training Loss: 0.0000\n",
      "Epoch [2706/4500], Validation Loss: 0.2779\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2707/4500], Training Loss: 0.0000\n",
      "Epoch [2707/4500], Validation Loss: 0.2781\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2708/4500], Training Loss: 0.0000\n",
      "Epoch [2708/4500], Validation Loss: 0.2779\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2709/4500], Training Loss: 0.0000\n",
      "Epoch [2709/4500], Validation Loss: 0.2779\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2710/4500], Training Loss: 0.0000\n",
      "Epoch [2710/4500], Validation Loss: 0.2780\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2711/4500], Training Loss: 0.0000\n",
      "Epoch [2711/4500], Validation Loss: 0.2781\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2712/4500], Training Loss: 0.0000\n",
      "Epoch [2712/4500], Validation Loss: 0.2780\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2713/4500], Training Loss: 0.0000\n",
      "Epoch [2713/4500], Validation Loss: 0.2780\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2714/4500], Training Loss: 0.0000\n",
      "Epoch [2714/4500], Validation Loss: 0.2781\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2715/4500], Training Loss: 0.0000\n",
      "Epoch [2715/4500], Validation Loss: 0.2780\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2716/4500], Training Loss: 0.0000\n",
      "Epoch [2716/4500], Validation Loss: 0.2781\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2717/4500], Training Loss: 0.0000\n",
      "Epoch [2717/4500], Validation Loss: 0.2783\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2718/4500], Training Loss: 0.0000\n",
      "Epoch [2718/4500], Validation Loss: 0.2782\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2719/4500], Training Loss: 0.0000\n",
      "Epoch [2719/4500], Validation Loss: 0.2782\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2720/4500], Training Loss: 0.0000\n",
      "Epoch [2720/4500], Validation Loss: 0.2782\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2721/4500], Training Loss: 0.0000\n",
      "Epoch [2721/4500], Validation Loss: 0.2783\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2722/4500], Training Loss: 0.0000\n",
      "Epoch [2722/4500], Validation Loss: 0.2783\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2723/4500], Training Loss: 0.0000\n",
      "Epoch [2723/4500], Validation Loss: 0.2782\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2724/4500], Training Loss: 0.0000\n",
      "Epoch [2724/4500], Validation Loss: 0.2784\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2725/4500], Training Loss: 0.0000\n",
      "Epoch [2725/4500], Validation Loss: 0.2784\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2726/4500], Training Loss: 0.0000\n",
      "Epoch [2726/4500], Validation Loss: 0.2783\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2727/4500], Training Loss: 0.0000\n",
      "Epoch [2727/4500], Validation Loss: 0.2786\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2728/4500], Training Loss: 0.0000\n",
      "Epoch [2728/4500], Validation Loss: 0.2786\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2729/4500], Training Loss: 0.0000\n",
      "Epoch [2729/4500], Validation Loss: 0.2786\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2730/4500], Training Loss: 0.0000\n",
      "Epoch [2730/4500], Validation Loss: 0.2785\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2731/4500], Training Loss: 0.0000\n",
      "Epoch [2731/4500], Validation Loss: 0.2786\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2732/4500], Training Loss: 0.0000\n",
      "Epoch [2732/4500], Validation Loss: 0.2786\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2733/4500], Training Loss: 0.0000\n",
      "Epoch [2733/4500], Validation Loss: 0.2786\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2734/4500], Training Loss: 0.0000\n",
      "Epoch [2734/4500], Validation Loss: 0.2787\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2735/4500], Training Loss: 0.0000\n",
      "Epoch [2735/4500], Validation Loss: 0.2785\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2736/4500], Training Loss: 0.0000\n",
      "Epoch [2736/4500], Validation Loss: 0.2786\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2737/4500], Training Loss: 0.0000\n",
      "Epoch [2737/4500], Validation Loss: 0.2788\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2738/4500], Training Loss: 0.0000\n",
      "Epoch [2738/4500], Validation Loss: 0.2787\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2739/4500], Training Loss: 0.0000\n",
      "Epoch [2739/4500], Validation Loss: 0.2786\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2740/4500], Training Loss: 0.0000\n",
      "Epoch [2740/4500], Validation Loss: 0.2789\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2741/4500], Training Loss: 0.0000\n",
      "Epoch [2741/4500], Validation Loss: 0.2789\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2742/4500], Training Loss: 0.0000\n",
      "Epoch [2742/4500], Validation Loss: 0.2788\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2743/4500], Training Loss: 0.0000\n",
      "Epoch [2743/4500], Validation Loss: 0.2789\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2744/4500], Training Loss: 0.0000\n",
      "Epoch [2744/4500], Validation Loss: 0.2789\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2745/4500], Training Loss: 0.0000\n",
      "Epoch [2745/4500], Validation Loss: 0.2789\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2746/4500], Training Loss: 0.0000\n",
      "Epoch [2746/4500], Validation Loss: 0.2790\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2747/4500], Training Loss: 0.0000\n",
      "Epoch [2747/4500], Validation Loss: 0.2790\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2748/4500], Training Loss: 0.0000\n",
      "Epoch [2748/4500], Validation Loss: 0.2790\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2749/4500], Training Loss: 0.0000\n",
      "Epoch [2749/4500], Validation Loss: 0.2792\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2750/4500], Training Loss: 0.0000\n",
      "Epoch [2750/4500], Validation Loss: 0.2789\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2751/4500], Training Loss: 0.0000\n",
      "Epoch [2751/4500], Validation Loss: 0.2790\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2752/4500], Training Loss: 0.0000\n",
      "Epoch [2752/4500], Validation Loss: 0.2791\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2753/4500], Training Loss: 0.0000\n",
      "Epoch [2753/4500], Validation Loss: 0.2793\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2754/4500], Training Loss: 0.0000\n",
      "Epoch [2754/4500], Validation Loss: 0.2792\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2755/4500], Training Loss: 0.0000\n",
      "Epoch [2755/4500], Validation Loss: 0.2790\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2756/4500], Training Loss: 0.0000\n",
      "Epoch [2756/4500], Validation Loss: 0.2792\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2757/4500], Training Loss: 0.0000\n",
      "Epoch [2757/4500], Validation Loss: 0.2792\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2758/4500], Training Loss: 0.0000\n",
      "Epoch [2758/4500], Validation Loss: 0.2792\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2759/4500], Training Loss: 0.0000\n",
      "Epoch [2759/4500], Validation Loss: 0.2792\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2760/4500], Training Loss: 0.0000\n",
      "Epoch [2760/4500], Validation Loss: 0.2794\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2761/4500], Training Loss: 0.0000\n",
      "Epoch [2761/4500], Validation Loss: 0.2793\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2762/4500], Training Loss: 0.0000\n",
      "Epoch [2762/4500], Validation Loss: 0.2794\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2763/4500], Training Loss: 0.0000\n",
      "Epoch [2763/4500], Validation Loss: 0.2794\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2764/4500], Training Loss: 0.0000\n",
      "Epoch [2764/4500], Validation Loss: 0.2794\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2765/4500], Training Loss: 0.0000\n",
      "Epoch [2765/4500], Validation Loss: 0.2795\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2766/4500], Training Loss: 0.0000\n",
      "Epoch [2766/4500], Validation Loss: 0.2796\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2767/4500], Training Loss: 0.0000\n",
      "Epoch [2767/4500], Validation Loss: 0.2794\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2768/4500], Training Loss: 0.0000\n",
      "Epoch [2768/4500], Validation Loss: 0.2795\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2769/4500], Training Loss: 0.0000\n",
      "Epoch [2769/4500], Validation Loss: 0.2795\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2770/4500], Training Loss: 0.0000\n",
      "Epoch [2770/4500], Validation Loss: 0.2796\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2771/4500], Training Loss: 0.0000\n",
      "Epoch [2771/4500], Validation Loss: 0.2796\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2772/4500], Training Loss: 0.0000\n",
      "Epoch [2772/4500], Validation Loss: 0.2796\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2773/4500], Training Loss: 0.0000\n",
      "Epoch [2773/4500], Validation Loss: 0.2795\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2774/4500], Training Loss: 0.0000\n",
      "Epoch [2774/4500], Validation Loss: 0.2797\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2775/4500], Training Loss: 0.0000\n",
      "Epoch [2775/4500], Validation Loss: 0.2796\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2776/4500], Training Loss: 0.0000\n",
      "Epoch [2776/4500], Validation Loss: 0.2800\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2777/4500], Training Loss: 0.0000\n",
      "Epoch [2777/4500], Validation Loss: 0.2797\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2778/4500], Training Loss: 0.0000\n",
      "Epoch [2778/4500], Validation Loss: 0.2799\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2779/4500], Training Loss: 0.0000\n",
      "Epoch [2779/4500], Validation Loss: 0.2798\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2780/4500], Training Loss: 0.0000\n",
      "Epoch [2780/4500], Validation Loss: 0.2798\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2781/4500], Training Loss: 0.0000\n",
      "Epoch [2781/4500], Validation Loss: 0.2799\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2782/4500], Training Loss: 0.0000\n",
      "Epoch [2782/4500], Validation Loss: 0.2800\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2783/4500], Training Loss: 0.0000\n",
      "Epoch [2783/4500], Validation Loss: 0.2800\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2784/4500], Training Loss: 0.0000\n",
      "Epoch [2784/4500], Validation Loss: 0.2799\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2785/4500], Training Loss: 0.0000\n",
      "Epoch [2785/4500], Validation Loss: 0.2797\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2786/4500], Training Loss: 0.0000\n",
      "Epoch [2786/4500], Validation Loss: 0.2800\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2787/4500], Training Loss: 0.0000\n",
      "Epoch [2787/4500], Validation Loss: 0.2801\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2788/4500], Training Loss: 0.0000\n",
      "Epoch [2788/4500], Validation Loss: 0.2799\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2789/4500], Training Loss: 0.0000\n",
      "Epoch [2789/4500], Validation Loss: 0.2802\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2790/4500], Training Loss: 0.0000\n",
      "Epoch [2790/4500], Validation Loss: 0.2800\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2791/4500], Training Loss: 0.0000\n",
      "Epoch [2791/4500], Validation Loss: 0.2801\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2792/4500], Training Loss: 0.0000\n",
      "Epoch [2792/4500], Validation Loss: 0.2802\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2793/4500], Training Loss: 0.0000\n",
      "Epoch [2793/4500], Validation Loss: 0.2802\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2794/4500], Training Loss: 0.0000\n",
      "Epoch [2794/4500], Validation Loss: 0.2802\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2795/4500], Training Loss: 0.0000\n",
      "Epoch [2795/4500], Validation Loss: 0.2803\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2796/4500], Training Loss: 0.0000\n",
      "Epoch [2796/4500], Validation Loss: 0.2812\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2797/4500], Training Loss: 0.0000\n",
      "Epoch [2797/4500], Validation Loss: 0.2803\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2798/4500], Training Loss: 0.0000\n",
      "Epoch [2798/4500], Validation Loss: 0.2811\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2799/4500], Training Loss: 0.0000\n",
      "Epoch [2799/4500], Validation Loss: 0.2803\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2800/4500], Training Loss: 0.0000\n",
      "Epoch [2800/4500], Validation Loss: 0.2813\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2801/4500], Training Loss: 0.0000\n",
      "Epoch [2801/4500], Validation Loss: 0.2815\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2802/4500], Training Loss: 0.0000\n",
      "Epoch [2802/4500], Validation Loss: 0.2813\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2803/4500], Training Loss: 0.0000\n",
      "Epoch [2803/4500], Validation Loss: 0.2814\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2804/4500], Training Loss: 0.0000\n",
      "Epoch [2804/4500], Validation Loss: 0.2813\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2805/4500], Training Loss: 0.0000\n",
      "Epoch [2805/4500], Validation Loss: 0.2814\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2806/4500], Training Loss: 0.0000\n",
      "Epoch [2806/4500], Validation Loss: 0.2816\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2807/4500], Training Loss: 0.0000\n",
      "Epoch [2807/4500], Validation Loss: 0.2813\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2808/4500], Training Loss: 0.0000\n",
      "Epoch [2808/4500], Validation Loss: 0.2815\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2809/4500], Training Loss: 0.0000\n",
      "Epoch [2809/4500], Validation Loss: 0.2815\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2810/4500], Training Loss: 0.0000\n",
      "Epoch [2810/4500], Validation Loss: 0.2817\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2811/4500], Training Loss: 0.0000\n",
      "Epoch [2811/4500], Validation Loss: 0.2816\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2812/4500], Training Loss: 0.0000\n",
      "Epoch [2812/4500], Validation Loss: 0.2816\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2813/4500], Training Loss: 0.0000\n",
      "Epoch [2813/4500], Validation Loss: 0.2814\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2814/4500], Training Loss: 0.0000\n",
      "Epoch [2814/4500], Validation Loss: 0.2817\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2815/4500], Training Loss: 0.0000\n",
      "Epoch [2815/4500], Validation Loss: 0.2818\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2816/4500], Training Loss: 0.0000\n",
      "Epoch [2816/4500], Validation Loss: 0.2819\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2817/4500], Training Loss: 0.0000\n",
      "Epoch [2817/4500], Validation Loss: 0.2818\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2818/4500], Training Loss: 0.0000\n",
      "Epoch [2818/4500], Validation Loss: 0.2817\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2819/4500], Training Loss: 0.0000\n",
      "Epoch [2819/4500], Validation Loss: 0.2817\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2820/4500], Training Loss: 0.0000\n",
      "Epoch [2820/4500], Validation Loss: 0.2817\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2821/4500], Training Loss: 0.0000\n",
      "Epoch [2821/4500], Validation Loss: 0.2819\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2822/4500], Training Loss: 0.0000\n",
      "Epoch [2822/4500], Validation Loss: 0.2818\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2823/4500], Training Loss: 0.0000\n",
      "Epoch [2823/4500], Validation Loss: 0.2819\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2824/4500], Training Loss: 0.0000\n",
      "Epoch [2824/4500], Validation Loss: 0.2819\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2825/4500], Training Loss: 0.0000\n",
      "Epoch [2825/4500], Validation Loss: 0.2819\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2826/4500], Training Loss: 0.0000\n",
      "Epoch [2826/4500], Validation Loss: 0.2819\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2827/4500], Training Loss: 0.0000\n",
      "Epoch [2827/4500], Validation Loss: 0.2820\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2828/4500], Training Loss: 0.0000\n",
      "Epoch [2828/4500], Validation Loss: 0.2821\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2829/4500], Training Loss: 0.0000\n",
      "Epoch [2829/4500], Validation Loss: 0.2820\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2830/4500], Training Loss: 0.0000\n",
      "Epoch [2830/4500], Validation Loss: 0.2821\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2831/4500], Training Loss: 0.0000\n",
      "Epoch [2831/4500], Validation Loss: 0.2819\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2832/4500], Training Loss: 0.0000\n",
      "Epoch [2832/4500], Validation Loss: 0.2822\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2833/4500], Training Loss: 0.0000\n",
      "Epoch [2833/4500], Validation Loss: 0.2821\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2834/4500], Training Loss: 0.0000\n",
      "Epoch [2834/4500], Validation Loss: 0.2822\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2835/4500], Training Loss: 0.0000\n",
      "Epoch [2835/4500], Validation Loss: 0.2821\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2836/4500], Training Loss: 0.0000\n",
      "Epoch [2836/4500], Validation Loss: 0.2822\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2837/4500], Training Loss: 0.0000\n",
      "Epoch [2837/4500], Validation Loss: 0.2822\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2838/4500], Training Loss: 0.0000\n",
      "Epoch [2838/4500], Validation Loss: 0.2823\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2839/4500], Training Loss: 0.0000\n",
      "Epoch [2839/4500], Validation Loss: 0.2824\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2840/4500], Training Loss: 0.0000\n",
      "Epoch [2840/4500], Validation Loss: 0.2824\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2841/4500], Training Loss: 0.0000\n",
      "Epoch [2841/4500], Validation Loss: 0.2822\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2842/4500], Training Loss: 0.0000\n",
      "Epoch [2842/4500], Validation Loss: 0.2824\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2843/4500], Training Loss: 0.0000\n",
      "Epoch [2843/4500], Validation Loss: 0.2825\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2844/4500], Training Loss: 0.0000\n",
      "Epoch [2844/4500], Validation Loss: 0.2823\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2845/4500], Training Loss: 0.0000\n",
      "Epoch [2845/4500], Validation Loss: 0.2826\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2846/4500], Training Loss: 0.0000\n",
      "Epoch [2846/4500], Validation Loss: 0.2826\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2847/4500], Training Loss: 0.0000\n",
      "Epoch [2847/4500], Validation Loss: 0.2824\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2848/4500], Training Loss: 0.0000\n",
      "Epoch [2848/4500], Validation Loss: 0.2826\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2849/4500], Training Loss: 0.0000\n",
      "Epoch [2849/4500], Validation Loss: 0.2826\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2850/4500], Training Loss: 0.0000\n",
      "Epoch [2850/4500], Validation Loss: 0.2826\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2851/4500], Training Loss: 0.0000\n",
      "Epoch [2851/4500], Validation Loss: 0.2826\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2852/4500], Training Loss: 0.0000\n",
      "Epoch [2852/4500], Validation Loss: 0.2826\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2853/4500], Training Loss: 0.0000\n",
      "Epoch [2853/4500], Validation Loss: 0.2826\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2854/4500], Training Loss: 0.0000\n",
      "Epoch [2854/4500], Validation Loss: 0.2827\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2855/4500], Training Loss: 0.0000\n",
      "Epoch [2855/4500], Validation Loss: 0.2828\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2856/4500], Training Loss: 0.0000\n",
      "Epoch [2856/4500], Validation Loss: 0.2826\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2857/4500], Training Loss: 0.0000\n",
      "Epoch [2857/4500], Validation Loss: 0.2827\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2858/4500], Training Loss: 0.0000\n",
      "Epoch [2858/4500], Validation Loss: 0.2827\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2859/4500], Training Loss: 0.0000\n",
      "Epoch [2859/4500], Validation Loss: 0.2828\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2860/4500], Training Loss: 0.0000\n",
      "Epoch [2860/4500], Validation Loss: 0.2828\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2861/4500], Training Loss: 0.0000\n",
      "Epoch [2861/4500], Validation Loss: 0.2830\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2862/4500], Training Loss: 0.0000\n",
      "Epoch [2862/4500], Validation Loss: 0.2829\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2863/4500], Training Loss: 0.0000\n",
      "Epoch [2863/4500], Validation Loss: 0.2828\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2864/4500], Training Loss: 0.0000\n",
      "Epoch [2864/4500], Validation Loss: 0.2829\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2865/4500], Training Loss: 0.0000\n",
      "Epoch [2865/4500], Validation Loss: 0.2829\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2866/4500], Training Loss: 0.0000\n",
      "Epoch [2866/4500], Validation Loss: 0.2830\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2867/4500], Training Loss: 0.0000\n",
      "Epoch [2867/4500], Validation Loss: 0.2830\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2868/4500], Training Loss: 0.0000\n",
      "Epoch [2868/4500], Validation Loss: 0.2831\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2869/4500], Training Loss: 0.0000\n",
      "Epoch [2869/4500], Validation Loss: 0.2832\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2870/4500], Training Loss: 0.0000\n",
      "Epoch [2870/4500], Validation Loss: 0.2831\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2871/4500], Training Loss: 0.0000\n",
      "Epoch [2871/4500], Validation Loss: 0.2831\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2872/4500], Training Loss: 0.0000\n",
      "Epoch [2872/4500], Validation Loss: 0.2830\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2873/4500], Training Loss: 0.0000\n",
      "Epoch [2873/4500], Validation Loss: 0.2833\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2874/4500], Training Loss: 0.0000\n",
      "Epoch [2874/4500], Validation Loss: 0.2831\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2875/4500], Training Loss: 0.0000\n",
      "Epoch [2875/4500], Validation Loss: 0.2832\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2876/4500], Training Loss: 0.0000\n",
      "Epoch [2876/4500], Validation Loss: 0.2833\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2877/4500], Training Loss: 0.0000\n",
      "Epoch [2877/4500], Validation Loss: 0.2832\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2878/4500], Training Loss: 0.0000\n",
      "Epoch [2878/4500], Validation Loss: 0.2833\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2879/4500], Training Loss: 0.0000\n",
      "Epoch [2879/4500], Validation Loss: 0.2834\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2880/4500], Training Loss: 0.0000\n",
      "Epoch [2880/4500], Validation Loss: 0.2834\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2881/4500], Training Loss: 0.0000\n",
      "Epoch [2881/4500], Validation Loss: 0.2834\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2882/4500], Training Loss: 0.0000\n",
      "Epoch [2882/4500], Validation Loss: 0.2833\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2883/4500], Training Loss: 0.0000\n",
      "Epoch [2883/4500], Validation Loss: 0.2834\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2884/4500], Training Loss: 0.0000\n",
      "Epoch [2884/4500], Validation Loss: 0.2834\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2885/4500], Training Loss: 0.0000\n",
      "Epoch [2885/4500], Validation Loss: 0.2835\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2886/4500], Training Loss: 0.0000\n",
      "Epoch [2886/4500], Validation Loss: 0.2834\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2887/4500], Training Loss: 0.0000\n",
      "Epoch [2887/4500], Validation Loss: 0.2836\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2888/4500], Training Loss: 0.0000\n",
      "Epoch [2888/4500], Validation Loss: 0.2836\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2889/4500], Training Loss: 0.0000\n",
      "Epoch [2889/4500], Validation Loss: 0.2835\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2890/4500], Training Loss: 0.0000\n",
      "Epoch [2890/4500], Validation Loss: 0.2835\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2891/4500], Training Loss: 0.0000\n",
      "Epoch [2891/4500], Validation Loss: 0.2836\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2892/4500], Training Loss: 0.0000\n",
      "Epoch [2892/4500], Validation Loss: 0.2837\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2893/4500], Training Loss: 0.0000\n",
      "Epoch [2893/4500], Validation Loss: 0.2835\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2894/4500], Training Loss: 0.0000\n",
      "Epoch [2894/4500], Validation Loss: 0.2838\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2895/4500], Training Loss: 0.0000\n",
      "Epoch [2895/4500], Validation Loss: 0.2837\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2896/4500], Training Loss: 0.0000\n",
      "Epoch [2896/4500], Validation Loss: 0.2838\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2897/4500], Training Loss: 0.0000\n",
      "Epoch [2897/4500], Validation Loss: 0.2838\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2898/4500], Training Loss: 0.0000\n",
      "Epoch [2898/4500], Validation Loss: 0.2837\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2899/4500], Training Loss: 0.0000\n",
      "Epoch [2899/4500], Validation Loss: 0.2840\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2900/4500], Training Loss: 0.0000\n",
      "Epoch [2900/4500], Validation Loss: 0.2838\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2901/4500], Training Loss: 0.0000\n",
      "Epoch [2901/4500], Validation Loss: 0.2840\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2902/4500], Training Loss: 0.0000\n",
      "Epoch [2902/4500], Validation Loss: 0.2839\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2903/4500], Training Loss: 0.0000\n",
      "Epoch [2903/4500], Validation Loss: 0.2839\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2904/4500], Training Loss: 0.0000\n",
      "Epoch [2904/4500], Validation Loss: 0.2840\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2905/4500], Training Loss: 0.0000\n",
      "Epoch [2905/4500], Validation Loss: 0.2838\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2906/4500], Training Loss: 0.0000\n",
      "Epoch [2906/4500], Validation Loss: 0.2840\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2907/4500], Training Loss: 0.0000\n",
      "Epoch [2907/4500], Validation Loss: 0.2840\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2908/4500], Training Loss: 0.0000\n",
      "Epoch [2908/4500], Validation Loss: 0.2841\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2909/4500], Training Loss: 0.0000\n",
      "Epoch [2909/4500], Validation Loss: 0.2841\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2910/4500], Training Loss: 0.0000\n",
      "Epoch [2910/4500], Validation Loss: 0.2842\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2911/4500], Training Loss: 0.0000\n",
      "Epoch [2911/4500], Validation Loss: 0.2842\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2912/4500], Training Loss: 0.0000\n",
      "Epoch [2912/4500], Validation Loss: 0.2842\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2913/4500], Training Loss: 0.0000\n",
      "Epoch [2913/4500], Validation Loss: 0.2843\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2914/4500], Training Loss: 0.0000\n",
      "Epoch [2914/4500], Validation Loss: 0.2841\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2915/4500], Training Loss: 0.0000\n",
      "Epoch [2915/4500], Validation Loss: 0.2844\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2916/4500], Training Loss: 0.0000\n",
      "Epoch [2916/4500], Validation Loss: 0.2841\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2917/4500], Training Loss: 0.0000\n",
      "Epoch [2917/4500], Validation Loss: 0.2842\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2918/4500], Training Loss: 0.0000\n",
      "Epoch [2918/4500], Validation Loss: 0.2842\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2919/4500], Training Loss: 0.0000\n",
      "Epoch [2919/4500], Validation Loss: 0.2844\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2920/4500], Training Loss: 0.0000\n",
      "Epoch [2920/4500], Validation Loss: 0.2844\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2921/4500], Training Loss: 0.0000\n",
      "Epoch [2921/4500], Validation Loss: 0.2845\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2922/4500], Training Loss: 0.0000\n",
      "Epoch [2922/4500], Validation Loss: 0.2843\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2923/4500], Training Loss: 0.0000\n",
      "Epoch [2923/4500], Validation Loss: 0.2845\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2924/4500], Training Loss: 0.0000\n",
      "Epoch [2924/4500], Validation Loss: 0.2847\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2925/4500], Training Loss: 0.0000\n",
      "Epoch [2925/4500], Validation Loss: 0.2844\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2926/4500], Training Loss: 0.0000\n",
      "Epoch [2926/4500], Validation Loss: 0.2844\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2927/4500], Training Loss: 0.0000\n",
      "Epoch [2927/4500], Validation Loss: 0.2846\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2928/4500], Training Loss: 0.0000\n",
      "Epoch [2928/4500], Validation Loss: 0.2846\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2929/4500], Training Loss: 0.0000\n",
      "Epoch [2929/4500], Validation Loss: 0.2846\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2930/4500], Training Loss: 0.0000\n",
      "Epoch [2930/4500], Validation Loss: 0.2846\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2931/4500], Training Loss: 0.0000\n",
      "Epoch [2931/4500], Validation Loss: 0.2846\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2932/4500], Training Loss: 0.0000\n",
      "Epoch [2932/4500], Validation Loss: 0.2848\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2933/4500], Training Loss: 0.0000\n",
      "Epoch [2933/4500], Validation Loss: 0.2847\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2934/4500], Training Loss: 0.0000\n",
      "Epoch [2934/4500], Validation Loss: 0.2847\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2935/4500], Training Loss: 0.0000\n",
      "Epoch [2935/4500], Validation Loss: 0.2848\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2936/4500], Training Loss: 0.0000\n",
      "Epoch [2936/4500], Validation Loss: 0.2847\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2937/4500], Training Loss: 0.0000\n",
      "Epoch [2937/4500], Validation Loss: 0.2849\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2938/4500], Training Loss: 0.0000\n",
      "Epoch [2938/4500], Validation Loss: 0.2848\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2939/4500], Training Loss: 0.0000\n",
      "Epoch [2939/4500], Validation Loss: 0.2848\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2940/4500], Training Loss: 0.0000\n",
      "Epoch [2940/4500], Validation Loss: 0.2849\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2941/4500], Training Loss: 0.0000\n",
      "Epoch [2941/4500], Validation Loss: 0.2850\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2942/4500], Training Loss: 0.0000\n",
      "Epoch [2942/4500], Validation Loss: 0.2849\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2943/4500], Training Loss: 0.0000\n",
      "Epoch [2943/4500], Validation Loss: 0.2850\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2944/4500], Training Loss: 0.0000\n",
      "Epoch [2944/4500], Validation Loss: 0.2850\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2945/4500], Training Loss: 0.0000\n",
      "Epoch [2945/4500], Validation Loss: 0.2850\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2946/4500], Training Loss: 0.0000\n",
      "Epoch [2946/4500], Validation Loss: 0.2850\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2947/4500], Training Loss: 0.0000\n",
      "Epoch [2947/4500], Validation Loss: 0.2851\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2948/4500], Training Loss: 0.0000\n",
      "Epoch [2948/4500], Validation Loss: 0.2850\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2949/4500], Training Loss: 0.0000\n",
      "Epoch [2949/4500], Validation Loss: 0.2850\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2950/4500], Training Loss: 0.0000\n",
      "Epoch [2950/4500], Validation Loss: 0.2852\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2951/4500], Training Loss: 0.0000\n",
      "Epoch [2951/4500], Validation Loss: 0.2853\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2952/4500], Training Loss: 0.0000\n",
      "Epoch [2952/4500], Validation Loss: 0.2851\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2953/4500], Training Loss: 0.0000\n",
      "Epoch [2953/4500], Validation Loss: 0.2850\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2954/4500], Training Loss: 0.0000\n",
      "Epoch [2954/4500], Validation Loss: 0.2852\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2955/4500], Training Loss: 0.0000\n",
      "Epoch [2955/4500], Validation Loss: 0.2852\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2956/4500], Training Loss: 0.0000\n",
      "Epoch [2956/4500], Validation Loss: 0.2852\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2957/4500], Training Loss: 0.0000\n",
      "Epoch [2957/4500], Validation Loss: 0.2853\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2958/4500], Training Loss: 0.0000\n",
      "Epoch [2958/4500], Validation Loss: 0.2852\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2959/4500], Training Loss: 0.0000\n",
      "Epoch [2959/4500], Validation Loss: 0.2854\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2960/4500], Training Loss: 0.0000\n",
      "Epoch [2960/4500], Validation Loss: 0.2854\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2961/4500], Training Loss: 0.0000\n",
      "Epoch [2961/4500], Validation Loss: 0.2853\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2962/4500], Training Loss: 0.0000\n",
      "Epoch [2962/4500], Validation Loss: 0.2854\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2963/4500], Training Loss: 0.0000\n",
      "Epoch [2963/4500], Validation Loss: 0.2855\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2964/4500], Training Loss: 0.0000\n",
      "Epoch [2964/4500], Validation Loss: 0.2855\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2965/4500], Training Loss: 0.0000\n",
      "Epoch [2965/4500], Validation Loss: 0.2854\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2966/4500], Training Loss: 0.0000\n",
      "Epoch [2966/4500], Validation Loss: 0.2855\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2967/4500], Training Loss: 0.0000\n",
      "Epoch [2967/4500], Validation Loss: 0.2855\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2968/4500], Training Loss: 0.0000\n",
      "Epoch [2968/4500], Validation Loss: 0.2856\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2969/4500], Training Loss: 0.0000\n",
      "Epoch [2969/4500], Validation Loss: 0.2857\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2970/4500], Training Loss: 0.0000\n",
      "Epoch [2970/4500], Validation Loss: 0.2855\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2971/4500], Training Loss: 0.0000\n",
      "Epoch [2971/4500], Validation Loss: 0.2856\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2972/4500], Training Loss: 0.0000\n",
      "Epoch [2972/4500], Validation Loss: 0.2855\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2973/4500], Training Loss: 0.0000\n",
      "Epoch [2973/4500], Validation Loss: 0.2857\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2974/4500], Training Loss: 0.0000\n",
      "Epoch [2974/4500], Validation Loss: 0.2858\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2975/4500], Training Loss: 0.0000\n",
      "Epoch [2975/4500], Validation Loss: 0.2857\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2976/4500], Training Loss: 0.0000\n",
      "Epoch [2976/4500], Validation Loss: 0.2859\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2977/4500], Training Loss: 0.0000\n",
      "Epoch [2977/4500], Validation Loss: 0.2857\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2978/4500], Training Loss: 0.0000\n",
      "Epoch [2978/4500], Validation Loss: 0.2857\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2979/4500], Training Loss: 0.0000\n",
      "Epoch [2979/4500], Validation Loss: 0.2858\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2980/4500], Training Loss: 0.0000\n",
      "Epoch [2980/4500], Validation Loss: 0.2858\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2981/4500], Training Loss: 0.0000\n",
      "Epoch [2981/4500], Validation Loss: 0.2860\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2982/4500], Training Loss: 0.0000\n",
      "Epoch [2982/4500], Validation Loss: 0.2859\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2983/4500], Training Loss: 0.0000\n",
      "Epoch [2983/4500], Validation Loss: 0.2860\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2984/4500], Training Loss: 0.0000\n",
      "Epoch [2984/4500], Validation Loss: 0.2858\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2985/4500], Training Loss: 0.0000\n",
      "Epoch [2985/4500], Validation Loss: 0.2859\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2986/4500], Training Loss: 0.0000\n",
      "Epoch [2986/4500], Validation Loss: 0.2860\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2987/4500], Training Loss: 0.0000\n",
      "Epoch [2987/4500], Validation Loss: 0.2861\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2988/4500], Training Loss: 0.0000\n",
      "Epoch [2988/4500], Validation Loss: 0.2859\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2989/4500], Training Loss: 0.0000\n",
      "Epoch [2989/4500], Validation Loss: 0.2861\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2990/4500], Training Loss: 0.0000\n",
      "Epoch [2990/4500], Validation Loss: 0.2860\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2991/4500], Training Loss: 0.0000\n",
      "Epoch [2991/4500], Validation Loss: 0.2863\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2992/4500], Training Loss: 0.0000\n",
      "Epoch [2992/4500], Validation Loss: 0.2863\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2993/4500], Training Loss: 0.0000\n",
      "Epoch [2993/4500], Validation Loss: 0.2862\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2994/4500], Training Loss: 0.0000\n",
      "Epoch [2994/4500], Validation Loss: 0.2861\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2995/4500], Training Loss: 0.0000\n",
      "Epoch [2995/4500], Validation Loss: 0.2861\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2996/4500], Training Loss: 0.0000\n",
      "Epoch [2996/4500], Validation Loss: 0.2863\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2997/4500], Training Loss: 0.0000\n",
      "Epoch [2997/4500], Validation Loss: 0.2862\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2998/4500], Training Loss: 0.0000\n",
      "Epoch [2998/4500], Validation Loss: 0.2862\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [2999/4500], Training Loss: 0.0000\n",
      "Epoch [2999/4500], Validation Loss: 0.2862\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3000/4500], Training Loss: 0.0000\n",
      "Epoch [3000/4500], Validation Loss: 0.2863\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3001/4500], Training Loss: 0.0000\n",
      "Epoch [3001/4500], Validation Loss: 0.2864\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3002/4500], Training Loss: 0.0000\n",
      "Epoch [3002/4500], Validation Loss: 0.2865\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3003/4500], Training Loss: 0.0000\n",
      "Epoch [3003/4500], Validation Loss: 0.2862\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3004/4500], Training Loss: 0.0000\n",
      "Epoch [3004/4500], Validation Loss: 0.2865\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3005/4500], Training Loss: 0.0000\n",
      "Epoch [3005/4500], Validation Loss: 0.2866\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3006/4500], Training Loss: 0.0000\n",
      "Epoch [3006/4500], Validation Loss: 0.2866\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3007/4500], Training Loss: 0.0000\n",
      "Epoch [3007/4500], Validation Loss: 0.2877\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3008/4500], Training Loss: 0.0000\n",
      "Epoch [3008/4500], Validation Loss: 0.2865\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3009/4500], Training Loss: 0.0000\n",
      "Epoch [3009/4500], Validation Loss: 0.2878\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3010/4500], Training Loss: 0.0000\n",
      "Epoch [3010/4500], Validation Loss: 0.2879\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3011/4500], Training Loss: 0.0000\n",
      "Epoch [3011/4500], Validation Loss: 0.2880\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3012/4500], Training Loss: 0.0000\n",
      "Epoch [3012/4500], Validation Loss: 0.2879\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3013/4500], Training Loss: 0.0000\n",
      "Epoch [3013/4500], Validation Loss: 0.2879\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3014/4500], Training Loss: 0.0000\n",
      "Epoch [3014/4500], Validation Loss: 0.2879\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3015/4500], Training Loss: 0.0000\n",
      "Epoch [3015/4500], Validation Loss: 0.2880\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3016/4500], Training Loss: 0.0000\n",
      "Epoch [3016/4500], Validation Loss: 0.2881\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3017/4500], Training Loss: 0.0000\n",
      "Epoch [3017/4500], Validation Loss: 0.2882\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3018/4500], Training Loss: 0.0000\n",
      "Epoch [3018/4500], Validation Loss: 0.2880\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3019/4500], Training Loss: 0.0000\n",
      "Epoch [3019/4500], Validation Loss: 0.2881\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3020/4500], Training Loss: 0.0000\n",
      "Epoch [3020/4500], Validation Loss: 0.2881\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3021/4500], Training Loss: 0.0000\n",
      "Epoch [3021/4500], Validation Loss: 0.2880\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3022/4500], Training Loss: 0.0000\n",
      "Epoch [3022/4500], Validation Loss: 0.2882\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3023/4500], Training Loss: 0.0000\n",
      "Epoch [3023/4500], Validation Loss: 0.2883\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3024/4500], Training Loss: 0.0000\n",
      "Epoch [3024/4500], Validation Loss: 0.2882\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3025/4500], Training Loss: 0.0000\n",
      "Epoch [3025/4500], Validation Loss: 0.2882\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3026/4500], Training Loss: 0.0000\n",
      "Epoch [3026/4500], Validation Loss: 0.2881\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3027/4500], Training Loss: 0.0000\n",
      "Epoch [3027/4500], Validation Loss: 0.2883\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3028/4500], Training Loss: 0.0000\n",
      "Epoch [3028/4500], Validation Loss: 0.2883\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3029/4500], Training Loss: 0.0000\n",
      "Epoch [3029/4500], Validation Loss: 0.2885\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3030/4500], Training Loss: 0.0000\n",
      "Epoch [3030/4500], Validation Loss: 0.2882\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3031/4500], Training Loss: 0.0000\n",
      "Epoch [3031/4500], Validation Loss: 0.2884\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3032/4500], Training Loss: 0.0000\n",
      "Epoch [3032/4500], Validation Loss: 0.2884\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3033/4500], Training Loss: 0.0000\n",
      "Epoch [3033/4500], Validation Loss: 0.2883\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3034/4500], Training Loss: 0.0000\n",
      "Epoch [3034/4500], Validation Loss: 0.2886\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3035/4500], Training Loss: 0.0000\n",
      "Epoch [3035/4500], Validation Loss: 0.2885\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3036/4500], Training Loss: 0.0000\n",
      "Epoch [3036/4500], Validation Loss: 0.2885\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3037/4500], Training Loss: 0.0000\n",
      "Epoch [3037/4500], Validation Loss: 0.2885\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3038/4500], Training Loss: 0.0000\n",
      "Epoch [3038/4500], Validation Loss: 0.2885\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3039/4500], Training Loss: 0.0000\n",
      "Epoch [3039/4500], Validation Loss: 0.2886\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3040/4500], Training Loss: 0.0000\n",
      "Epoch [3040/4500], Validation Loss: 0.2886\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3041/4500], Training Loss: 0.0000\n",
      "Epoch [3041/4500], Validation Loss: 0.2885\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3042/4500], Training Loss: 0.0000\n",
      "Epoch [3042/4500], Validation Loss: 0.2885\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3043/4500], Training Loss: 0.0000\n",
      "Epoch [3043/4500], Validation Loss: 0.2887\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3044/4500], Training Loss: 0.0000\n",
      "Epoch [3044/4500], Validation Loss: 0.2887\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3045/4500], Training Loss: 0.0000\n",
      "Epoch [3045/4500], Validation Loss: 0.2885\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3046/4500], Training Loss: 0.0000\n",
      "Epoch [3046/4500], Validation Loss: 0.2886\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3047/4500], Training Loss: 0.0000\n",
      "Epoch [3047/4500], Validation Loss: 0.2888\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3048/4500], Training Loss: 0.0000\n",
      "Epoch [3048/4500], Validation Loss: 0.2887\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3049/4500], Training Loss: 0.0000\n",
      "Epoch [3049/4500], Validation Loss: 0.2887\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3050/4500], Training Loss: 0.0000\n",
      "Epoch [3050/4500], Validation Loss: 0.2888\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3051/4500], Training Loss: 0.0000\n",
      "Epoch [3051/4500], Validation Loss: 0.2890\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3052/4500], Training Loss: 0.0000\n",
      "Epoch [3052/4500], Validation Loss: 0.2889\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3053/4500], Training Loss: 0.0000\n",
      "Epoch [3053/4500], Validation Loss: 0.2889\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3054/4500], Training Loss: 0.0000\n",
      "Epoch [3054/4500], Validation Loss: 0.2888\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3055/4500], Training Loss: 0.0000\n",
      "Epoch [3055/4500], Validation Loss: 0.2890\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3056/4500], Training Loss: 0.0000\n",
      "Epoch [3056/4500], Validation Loss: 0.2890\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3057/4500], Training Loss: 0.0000\n",
      "Epoch [3057/4500], Validation Loss: 0.2889\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3058/4500], Training Loss: 0.0000\n",
      "Epoch [3058/4500], Validation Loss: 0.2892\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3059/4500], Training Loss: 0.0000\n",
      "Epoch [3059/4500], Validation Loss: 0.2891\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3060/4500], Training Loss: 0.0000\n",
      "Epoch [3060/4500], Validation Loss: 0.2889\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3061/4500], Training Loss: 0.0000\n",
      "Epoch [3061/4500], Validation Loss: 0.2891\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3062/4500], Training Loss: 0.0000\n",
      "Epoch [3062/4500], Validation Loss: 0.2892\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3063/4500], Training Loss: 0.0000\n",
      "Epoch [3063/4500], Validation Loss: 0.2892\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3064/4500], Training Loss: 0.0000\n",
      "Epoch [3064/4500], Validation Loss: 0.2890\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3065/4500], Training Loss: 0.0000\n",
      "Epoch [3065/4500], Validation Loss: 0.2891\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3066/4500], Training Loss: 0.0000\n",
      "Epoch [3066/4500], Validation Loss: 0.2893\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3067/4500], Training Loss: 0.0000\n",
      "Epoch [3067/4500], Validation Loss: 0.2893\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3068/4500], Training Loss: 0.0000\n",
      "Epoch [3068/4500], Validation Loss: 0.2892\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3069/4500], Training Loss: 0.0000\n",
      "Epoch [3069/4500], Validation Loss: 0.2893\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3070/4500], Training Loss: 0.0000\n",
      "Epoch [3070/4500], Validation Loss: 0.2894\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3071/4500], Training Loss: 0.0000\n",
      "Epoch [3071/4500], Validation Loss: 0.2893\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3072/4500], Training Loss: 0.0000\n",
      "Epoch [3072/4500], Validation Loss: 0.2893\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3073/4500], Training Loss: 0.0000\n",
      "Epoch [3073/4500], Validation Loss: 0.2893\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3074/4500], Training Loss: 0.0000\n",
      "Epoch [3074/4500], Validation Loss: 0.2895\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3075/4500], Training Loss: 0.0000\n",
      "Epoch [3075/4500], Validation Loss: 0.2894\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3076/4500], Training Loss: 0.0000\n",
      "Epoch [3076/4500], Validation Loss: 0.2895\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3077/4500], Training Loss: 0.0000\n",
      "Epoch [3077/4500], Validation Loss: 0.2894\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3078/4500], Training Loss: 0.0000\n",
      "Epoch [3078/4500], Validation Loss: 0.2894\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3079/4500], Training Loss: 0.0000\n",
      "Epoch [3079/4500], Validation Loss: 0.2896\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3080/4500], Training Loss: 0.0000\n",
      "Epoch [3080/4500], Validation Loss: 0.2895\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3081/4500], Training Loss: 0.0000\n",
      "Epoch [3081/4500], Validation Loss: 0.2896\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3082/4500], Training Loss: 0.0000\n",
      "Epoch [3082/4500], Validation Loss: 0.2895\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3083/4500], Training Loss: 0.0000\n",
      "Epoch [3083/4500], Validation Loss: 0.2897\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3084/4500], Training Loss: 0.0000\n",
      "Epoch [3084/4500], Validation Loss: 0.2895\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3085/4500], Training Loss: 0.0000\n",
      "Epoch [3085/4500], Validation Loss: 0.2897\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3086/4500], Training Loss: 0.0000\n",
      "Epoch [3086/4500], Validation Loss: 0.2898\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3087/4500], Training Loss: 0.0000\n",
      "Epoch [3087/4500], Validation Loss: 0.2896\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3088/4500], Training Loss: 0.0000\n",
      "Epoch [3088/4500], Validation Loss: 0.2898\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3089/4500], Training Loss: 0.0000\n",
      "Epoch [3089/4500], Validation Loss: 0.2897\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3090/4500], Training Loss: 0.0000\n",
      "Epoch [3090/4500], Validation Loss: 0.2898\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3091/4500], Training Loss: 0.0000\n",
      "Epoch [3091/4500], Validation Loss: 0.2897\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3092/4500], Training Loss: 0.0000\n",
      "Epoch [3092/4500], Validation Loss: 0.2899\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3093/4500], Training Loss: 0.0000\n",
      "Epoch [3093/4500], Validation Loss: 0.2898\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3094/4500], Training Loss: 0.0000\n",
      "Epoch [3094/4500], Validation Loss: 0.2899\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3095/4500], Training Loss: 0.0000\n",
      "Epoch [3095/4500], Validation Loss: 0.2899\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3096/4500], Training Loss: 0.0000\n",
      "Epoch [3096/4500], Validation Loss: 0.2899\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3097/4500], Training Loss: 0.0000\n",
      "Epoch [3097/4500], Validation Loss: 0.2900\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3098/4500], Training Loss: 0.0000\n",
      "Epoch [3098/4500], Validation Loss: 0.2901\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3099/4500], Training Loss: 0.0000\n",
      "Epoch [3099/4500], Validation Loss: 0.2900\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3100/4500], Training Loss: 0.0000\n",
      "Epoch [3100/4500], Validation Loss: 0.2900\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3101/4500], Training Loss: 0.0000\n",
      "Epoch [3101/4500], Validation Loss: 0.2901\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3102/4500], Training Loss: 0.0000\n",
      "Epoch [3102/4500], Validation Loss: 0.2901\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3103/4500], Training Loss: 0.0000\n",
      "Epoch [3103/4500], Validation Loss: 0.2899\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3104/4500], Training Loss: 0.0000\n",
      "Epoch [3104/4500], Validation Loss: 0.2902\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3105/4500], Training Loss: 0.0000\n",
      "Epoch [3105/4500], Validation Loss: 0.2902\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3106/4500], Training Loss: 0.0000\n",
      "Epoch [3106/4500], Validation Loss: 0.2902\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3107/4500], Training Loss: 0.0000\n",
      "Epoch [3107/4500], Validation Loss: 0.2902\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3108/4500], Training Loss: 0.0000\n",
      "Epoch [3108/4500], Validation Loss: 0.2901\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3109/4500], Training Loss: 0.0000\n",
      "Epoch [3109/4500], Validation Loss: 0.2902\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3110/4500], Training Loss: 0.0000\n",
      "Epoch [3110/4500], Validation Loss: 0.2903\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3111/4500], Training Loss: 0.0000\n",
      "Epoch [3111/4500], Validation Loss: 0.2903\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3112/4500], Training Loss: 0.0000\n",
      "Epoch [3112/4500], Validation Loss: 0.2901\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3113/4500], Training Loss: 0.0000\n",
      "Epoch [3113/4500], Validation Loss: 0.2903\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3114/4500], Training Loss: 0.0000\n",
      "Epoch [3114/4500], Validation Loss: 0.2904\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3115/4500], Training Loss: 0.0000\n",
      "Epoch [3115/4500], Validation Loss: 0.2902\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3116/4500], Training Loss: 0.0000\n",
      "Epoch [3116/4500], Validation Loss: 0.2904\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3117/4500], Training Loss: 0.0000\n",
      "Epoch [3117/4500], Validation Loss: 0.2904\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3118/4500], Training Loss: 0.0000\n",
      "Epoch [3118/4500], Validation Loss: 0.2905\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3119/4500], Training Loss: 0.0000\n",
      "Epoch [3119/4500], Validation Loss: 0.2906\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3120/4500], Training Loss: 0.0000\n",
      "Epoch [3120/4500], Validation Loss: 0.2906\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3121/4500], Training Loss: 0.0000\n",
      "Epoch [3121/4500], Validation Loss: 0.2905\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3122/4500], Training Loss: 0.0000\n",
      "Epoch [3122/4500], Validation Loss: 0.2905\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3123/4500], Training Loss: 0.0000\n",
      "Epoch [3123/4500], Validation Loss: 0.2906\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3124/4500], Training Loss: 0.0000\n",
      "Epoch [3124/4500], Validation Loss: 0.2905\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3125/4500], Training Loss: 0.0000\n",
      "Epoch [3125/4500], Validation Loss: 0.2906\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3126/4500], Training Loss: 0.0000\n",
      "Epoch [3126/4500], Validation Loss: 0.2907\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3127/4500], Training Loss: 0.0000\n",
      "Epoch [3127/4500], Validation Loss: 0.2907\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3128/4500], Training Loss: 0.0000\n",
      "Epoch [3128/4500], Validation Loss: 0.2906\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3129/4500], Training Loss: 0.0000\n",
      "Epoch [3129/4500], Validation Loss: 0.2907\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3130/4500], Training Loss: 0.0000\n",
      "Epoch [3130/4500], Validation Loss: 0.2905\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3131/4500], Training Loss: 0.0000\n",
      "Epoch [3131/4500], Validation Loss: 0.2908\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3132/4500], Training Loss: 0.0000\n",
      "Epoch [3132/4500], Validation Loss: 0.2907\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3133/4500], Training Loss: 0.0000\n",
      "Epoch [3133/4500], Validation Loss: 0.2908\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3134/4500], Training Loss: 0.0000\n",
      "Epoch [3134/4500], Validation Loss: 0.2907\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3135/4500], Training Loss: 0.0000\n",
      "Epoch [3135/4500], Validation Loss: 0.2908\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3136/4500], Training Loss: 0.0000\n",
      "Epoch [3136/4500], Validation Loss: 0.2908\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3137/4500], Training Loss: 0.0000\n",
      "Epoch [3137/4500], Validation Loss: 0.2910\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3138/4500], Training Loss: 0.0000\n",
      "Epoch [3138/4500], Validation Loss: 0.2908\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3139/4500], Training Loss: 0.0000\n",
      "Epoch [3139/4500], Validation Loss: 0.2909\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3140/4500], Training Loss: 0.0000\n",
      "Epoch [3140/4500], Validation Loss: 0.2910\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3141/4500], Training Loss: 0.0000\n",
      "Epoch [3141/4500], Validation Loss: 0.2909\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3142/4500], Training Loss: 0.0000\n",
      "Epoch [3142/4500], Validation Loss: 0.2910\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3143/4500], Training Loss: 0.0000\n",
      "Epoch [3143/4500], Validation Loss: 0.2911\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3144/4500], Training Loss: 0.0000\n",
      "Epoch [3144/4500], Validation Loss: 0.2911\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3145/4500], Training Loss: 0.0000\n",
      "Epoch [3145/4500], Validation Loss: 0.2910\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3146/4500], Training Loss: 0.0000\n",
      "Epoch [3146/4500], Validation Loss: 0.2910\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3147/4500], Training Loss: 0.0000\n",
      "Epoch [3147/4500], Validation Loss: 0.2911\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3148/4500], Training Loss: 0.0000\n",
      "Epoch [3148/4500], Validation Loss: 0.2913\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3149/4500], Training Loss: 0.0000\n",
      "Epoch [3149/4500], Validation Loss: 0.2911\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3150/4500], Training Loss: 0.0000\n",
      "Epoch [3150/4500], Validation Loss: 0.2911\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3151/4500], Training Loss: 0.0000\n",
      "Epoch [3151/4500], Validation Loss: 0.2912\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3152/4500], Training Loss: 0.0000\n",
      "Epoch [3152/4500], Validation Loss: 0.2912\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3153/4500], Training Loss: 0.0000\n",
      "Epoch [3153/4500], Validation Loss: 0.2912\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3154/4500], Training Loss: 0.0000\n",
      "Epoch [3154/4500], Validation Loss: 0.2913\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3155/4500], Training Loss: 0.0000\n",
      "Epoch [3155/4500], Validation Loss: 0.2914\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3156/4500], Training Loss: 0.0000\n",
      "Epoch [3156/4500], Validation Loss: 0.2913\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3157/4500], Training Loss: 0.0000\n",
      "Epoch [3157/4500], Validation Loss: 0.2912\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3158/4500], Training Loss: 0.0000\n",
      "Epoch [3158/4500], Validation Loss: 0.2912\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3159/4500], Training Loss: 0.0000\n",
      "Epoch [3159/4500], Validation Loss: 0.2914\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3160/4500], Training Loss: 0.0000\n",
      "Epoch [3160/4500], Validation Loss: 0.2914\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3161/4500], Training Loss: 0.0000\n",
      "Epoch [3161/4500], Validation Loss: 0.2914\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3162/4500], Training Loss: 0.0000\n",
      "Epoch [3162/4500], Validation Loss: 0.2913\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3163/4500], Training Loss: 0.0000\n",
      "Epoch [3163/4500], Validation Loss: 0.2914\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3164/4500], Training Loss: 0.0000\n",
      "Epoch [3164/4500], Validation Loss: 0.2915\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3165/4500], Training Loss: 0.0000\n",
      "Epoch [3165/4500], Validation Loss: 0.2915\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3166/4500], Training Loss: 0.0000\n",
      "Epoch [3166/4500], Validation Loss: 0.2915\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3167/4500], Training Loss: 0.0000\n",
      "Epoch [3167/4500], Validation Loss: 0.2915\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3168/4500], Training Loss: 0.0000\n",
      "Epoch [3168/4500], Validation Loss: 0.2916\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3169/4500], Training Loss: 0.0000\n",
      "Epoch [3169/4500], Validation Loss: 0.2915\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3170/4500], Training Loss: 0.0000\n",
      "Epoch [3170/4500], Validation Loss: 0.2916\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3171/4500], Training Loss: 0.0000\n",
      "Epoch [3171/4500], Validation Loss: 0.2917\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3172/4500], Training Loss: 0.0000\n",
      "Epoch [3172/4500], Validation Loss: 0.2916\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3173/4500], Training Loss: 0.0000\n",
      "Epoch [3173/4500], Validation Loss: 0.2916\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3174/4500], Training Loss: 0.0000\n",
      "Epoch [3174/4500], Validation Loss: 0.2917\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3175/4500], Training Loss: 0.0000\n",
      "Epoch [3175/4500], Validation Loss: 0.2917\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3176/4500], Training Loss: 0.0000\n",
      "Epoch [3176/4500], Validation Loss: 0.2918\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3177/4500], Training Loss: 0.0000\n",
      "Epoch [3177/4500], Validation Loss: 0.2918\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3178/4500], Training Loss: 0.0000\n",
      "Epoch [3178/4500], Validation Loss: 0.2917\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3179/4500], Training Loss: 0.0000\n",
      "Epoch [3179/4500], Validation Loss: 0.2918\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3180/4500], Training Loss: 0.0000\n",
      "Epoch [3180/4500], Validation Loss: 0.2918\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3181/4500], Training Loss: 0.0000\n",
      "Epoch [3181/4500], Validation Loss: 0.2919\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3182/4500], Training Loss: 0.0000\n",
      "Epoch [3182/4500], Validation Loss: 0.2919\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3183/4500], Training Loss: 0.0000\n",
      "Epoch [3183/4500], Validation Loss: 0.2921\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3184/4500], Training Loss: 0.0000\n",
      "Epoch [3184/4500], Validation Loss: 0.2918\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3185/4500], Training Loss: 0.0000\n",
      "Epoch [3185/4500], Validation Loss: 0.2920\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3186/4500], Training Loss: 0.0000\n",
      "Epoch [3186/4500], Validation Loss: 0.2919\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3187/4500], Training Loss: 0.0000\n",
      "Epoch [3187/4500], Validation Loss: 0.2920\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3188/4500], Training Loss: 0.0000\n",
      "Epoch [3188/4500], Validation Loss: 0.2920\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3189/4500], Training Loss: 0.0000\n",
      "Epoch [3189/4500], Validation Loss: 0.2919\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3190/4500], Training Loss: 0.0000\n",
      "Epoch [3190/4500], Validation Loss: 0.2921\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3191/4500], Training Loss: 0.0000\n",
      "Epoch [3191/4500], Validation Loss: 0.2921\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3192/4500], Training Loss: 0.0000\n",
      "Epoch [3192/4500], Validation Loss: 0.2922\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3193/4500], Training Loss: 0.0000\n",
      "Epoch [3193/4500], Validation Loss: 0.2920\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3194/4500], Training Loss: 0.0000\n",
      "Epoch [3194/4500], Validation Loss: 0.2920\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3195/4500], Training Loss: 0.0000\n",
      "Epoch [3195/4500], Validation Loss: 0.2921\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3196/4500], Training Loss: 0.0000\n",
      "Epoch [3196/4500], Validation Loss: 0.2923\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3197/4500], Training Loss: 0.0000\n",
      "Epoch [3197/4500], Validation Loss: 0.2922\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3198/4500], Training Loss: 0.0000\n",
      "Epoch [3198/4500], Validation Loss: 0.2923\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3199/4500], Training Loss: 0.0000\n",
      "Epoch [3199/4500], Validation Loss: 0.2923\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3200/4500], Training Loss: 0.0000\n",
      "Epoch [3200/4500], Validation Loss: 0.2922\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3201/4500], Training Loss: 0.0000\n",
      "Epoch [3201/4500], Validation Loss: 0.2923\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3202/4500], Training Loss: 0.0000\n",
      "Epoch [3202/4500], Validation Loss: 0.2924\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3203/4500], Training Loss: 0.0000\n",
      "Epoch [3203/4500], Validation Loss: 0.2924\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3204/4500], Training Loss: 0.0000\n",
      "Epoch [3204/4500], Validation Loss: 0.2923\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3205/4500], Training Loss: 0.0000\n",
      "Epoch [3205/4500], Validation Loss: 0.2922\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3206/4500], Training Loss: 0.0000\n",
      "Epoch [3206/4500], Validation Loss: 0.2924\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3207/4500], Training Loss: 0.0000\n",
      "Epoch [3207/4500], Validation Loss: 0.2925\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3208/4500], Training Loss: 0.0000\n",
      "Epoch [3208/4500], Validation Loss: 0.2924\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3209/4500], Training Loss: 0.0000\n",
      "Epoch [3209/4500], Validation Loss: 0.2926\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3210/4500], Training Loss: 0.0000\n",
      "Epoch [3210/4500], Validation Loss: 0.2925\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3211/4500], Training Loss: 0.0000\n",
      "Epoch [3211/4500], Validation Loss: 0.2926\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3212/4500], Training Loss: 0.0000\n",
      "Epoch [3212/4500], Validation Loss: 0.2924\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3213/4500], Training Loss: 0.0000\n",
      "Epoch [3213/4500], Validation Loss: 0.2926\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3214/4500], Training Loss: 0.0000\n",
      "Epoch [3214/4500], Validation Loss: 0.2926\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3215/4500], Training Loss: 0.0000\n",
      "Epoch [3215/4500], Validation Loss: 0.2925\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3216/4500], Training Loss: 0.0000\n",
      "Epoch [3216/4500], Validation Loss: 0.2926\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3217/4500], Training Loss: 0.0000\n",
      "Epoch [3217/4500], Validation Loss: 0.2926\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3218/4500], Training Loss: 0.0000\n",
      "Epoch [3218/4500], Validation Loss: 0.2926\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3219/4500], Training Loss: 0.0000\n",
      "Epoch [3219/4500], Validation Loss: 0.2927\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3220/4500], Training Loss: 0.0000\n",
      "Epoch [3220/4500], Validation Loss: 0.2927\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3221/4500], Training Loss: 0.0000\n",
      "Epoch [3221/4500], Validation Loss: 0.2929\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3222/4500], Training Loss: 0.0000\n",
      "Epoch [3222/4500], Validation Loss: 0.2928\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3223/4500], Training Loss: 0.0000\n",
      "Epoch [3223/4500], Validation Loss: 0.2927\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3224/4500], Training Loss: 0.0000\n",
      "Epoch [3224/4500], Validation Loss: 0.2928\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3225/4500], Training Loss: 0.0000\n",
      "Epoch [3225/4500], Validation Loss: 0.2928\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3226/4500], Training Loss: 0.0000\n",
      "Epoch [3226/4500], Validation Loss: 0.2928\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3227/4500], Training Loss: 0.0000\n",
      "Epoch [3227/4500], Validation Loss: 0.2929\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3228/4500], Training Loss: 0.0000\n",
      "Epoch [3228/4500], Validation Loss: 0.2930\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3229/4500], Training Loss: 0.0000\n",
      "Epoch [3229/4500], Validation Loss: 0.2928\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3230/4500], Training Loss: 0.0000\n",
      "Epoch [3230/4500], Validation Loss: 0.2929\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3231/4500], Training Loss: 0.0000\n",
      "Epoch [3231/4500], Validation Loss: 0.2930\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3232/4500], Training Loss: 0.0000\n",
      "Epoch [3232/4500], Validation Loss: 0.2930\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3233/4500], Training Loss: 0.0000\n",
      "Epoch [3233/4500], Validation Loss: 0.2931\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3234/4500], Training Loss: 0.0000\n",
      "Epoch [3234/4500], Validation Loss: 0.2931\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3235/4500], Training Loss: 0.0000\n",
      "Epoch [3235/4500], Validation Loss: 0.2930\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3236/4500], Training Loss: 0.0000\n",
      "Epoch [3236/4500], Validation Loss: 0.2932\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3237/4500], Training Loss: 0.0000\n",
      "Epoch [3237/4500], Validation Loss: 0.2932\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3238/4500], Training Loss: 0.0000\n",
      "Epoch [3238/4500], Validation Loss: 0.2932\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3239/4500], Training Loss: 0.0000\n",
      "Epoch [3239/4500], Validation Loss: 0.2929\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3240/4500], Training Loss: 0.0000\n",
      "Epoch [3240/4500], Validation Loss: 0.2931\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3241/4500], Training Loss: 0.0000\n",
      "Epoch [3241/4500], Validation Loss: 0.2932\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3242/4500], Training Loss: 0.0000\n",
      "Epoch [3242/4500], Validation Loss: 0.2932\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3243/4500], Training Loss: 0.0000\n",
      "Epoch [3243/4500], Validation Loss: 0.2932\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3244/4500], Training Loss: 0.0000\n",
      "Epoch [3244/4500], Validation Loss: 0.2932\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3245/4500], Training Loss: 0.0000\n",
      "Epoch [3245/4500], Validation Loss: 0.2932\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3246/4500], Training Loss: 0.0000\n",
      "Epoch [3246/4500], Validation Loss: 0.2932\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3247/4500], Training Loss: 0.0000\n",
      "Epoch [3247/4500], Validation Loss: 0.2933\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3248/4500], Training Loss: 0.0000\n",
      "Epoch [3248/4500], Validation Loss: 0.2933\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3249/4500], Training Loss: 0.0000\n",
      "Epoch [3249/4500], Validation Loss: 0.2934\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3250/4500], Training Loss: 0.0000\n",
      "Epoch [3250/4500], Validation Loss: 0.2933\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3251/4500], Training Loss: 0.0000\n",
      "Epoch [3251/4500], Validation Loss: 0.2934\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3252/4500], Training Loss: 0.0000\n",
      "Epoch [3252/4500], Validation Loss: 0.2934\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3253/4500], Training Loss: 0.0000\n",
      "Epoch [3253/4500], Validation Loss: 0.2934\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3254/4500], Training Loss: 0.0000\n",
      "Epoch [3254/4500], Validation Loss: 0.2935\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3255/4500], Training Loss: 0.0000\n",
      "Epoch [3255/4500], Validation Loss: 0.2936\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3256/4500], Training Loss: 0.0000\n",
      "Epoch [3256/4500], Validation Loss: 0.2934\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3257/4500], Training Loss: 0.0000\n",
      "Epoch [3257/4500], Validation Loss: 0.2935\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3258/4500], Training Loss: 0.0000\n",
      "Epoch [3258/4500], Validation Loss: 0.2936\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3259/4500], Training Loss: 0.0000\n",
      "Epoch [3259/4500], Validation Loss: 0.2935\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3260/4500], Training Loss: 0.0000\n",
      "Epoch [3260/4500], Validation Loss: 0.2936\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3261/4500], Training Loss: 0.0000\n",
      "Epoch [3261/4500], Validation Loss: 0.2936\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3262/4500], Training Loss: 0.0000\n",
      "Epoch [3262/4500], Validation Loss: 0.2936\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3263/4500], Training Loss: 0.0000\n",
      "Epoch [3263/4500], Validation Loss: 0.2936\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3264/4500], Training Loss: 0.0000\n",
      "Epoch [3264/4500], Validation Loss: 0.2937\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3265/4500], Training Loss: 0.0000\n",
      "Epoch [3265/4500], Validation Loss: 0.2936\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3266/4500], Training Loss: 0.0000\n",
      "Epoch [3266/4500], Validation Loss: 0.2938\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3267/4500], Training Loss: 0.0000\n",
      "Epoch [3267/4500], Validation Loss: 0.2938\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3268/4500], Training Loss: 0.0000\n",
      "Epoch [3268/4500], Validation Loss: 0.2938\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3269/4500], Training Loss: 0.0000\n",
      "Epoch [3269/4500], Validation Loss: 0.2938\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3270/4500], Training Loss: 0.0000\n",
      "Epoch [3270/4500], Validation Loss: 0.2938\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3271/4500], Training Loss: 0.0000\n",
      "Epoch [3271/4500], Validation Loss: 0.2938\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3272/4500], Training Loss: 0.0000\n",
      "Epoch [3272/4500], Validation Loss: 0.2938\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3273/4500], Training Loss: 0.0000\n",
      "Epoch [3273/4500], Validation Loss: 0.2940\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3274/4500], Training Loss: 0.0000\n",
      "Epoch [3274/4500], Validation Loss: 0.2939\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3275/4500], Training Loss: 0.0000\n",
      "Epoch [3275/4500], Validation Loss: 0.2940\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3276/4500], Training Loss: 0.0000\n",
      "Epoch [3276/4500], Validation Loss: 0.2939\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3277/4500], Training Loss: 0.0000\n",
      "Epoch [3277/4500], Validation Loss: 0.2939\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3278/4500], Training Loss: 0.0000\n",
      "Epoch [3278/4500], Validation Loss: 0.2940\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3279/4500], Training Loss: 0.0000\n",
      "Epoch [3279/4500], Validation Loss: 0.2941\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3280/4500], Training Loss: 0.0000\n",
      "Epoch [3280/4500], Validation Loss: 0.2940\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3281/4500], Training Loss: 0.0000\n",
      "Epoch [3281/4500], Validation Loss: 0.2940\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3282/4500], Training Loss: 0.0000\n",
      "Epoch [3282/4500], Validation Loss: 0.2941\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3283/4500], Training Loss: 0.0000\n",
      "Epoch [3283/4500], Validation Loss: 0.2941\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3284/4500], Training Loss: 0.0000\n",
      "Epoch [3284/4500], Validation Loss: 0.2942\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3285/4500], Training Loss: 0.0000\n",
      "Epoch [3285/4500], Validation Loss: 0.2941\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3286/4500], Training Loss: 0.0000\n",
      "Epoch [3286/4500], Validation Loss: 0.2942\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3287/4500], Training Loss: 0.0000\n",
      "Epoch [3287/4500], Validation Loss: 0.2942\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3288/4500], Training Loss: 0.0000\n",
      "Epoch [3288/4500], Validation Loss: 0.2943\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3289/4500], Training Loss: 0.0000\n",
      "Epoch [3289/4500], Validation Loss: 0.2941\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3290/4500], Training Loss: 0.0000\n",
      "Epoch [3290/4500], Validation Loss: 0.2942\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3291/4500], Training Loss: 0.0000\n",
      "Epoch [3291/4500], Validation Loss: 0.2942\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3292/4500], Training Loss: 0.0000\n",
      "Epoch [3292/4500], Validation Loss: 0.2944\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3293/4500], Training Loss: 0.0000\n",
      "Epoch [3293/4500], Validation Loss: 0.2941\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3294/4500], Training Loss: 0.0000\n",
      "Epoch [3294/4500], Validation Loss: 0.2943\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3295/4500], Training Loss: 0.0000\n",
      "Epoch [3295/4500], Validation Loss: 0.2942\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3296/4500], Training Loss: 0.0000\n",
      "Epoch [3296/4500], Validation Loss: 0.2944\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3297/4500], Training Loss: 0.0000\n",
      "Epoch [3297/4500], Validation Loss: 0.2945\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3298/4500], Training Loss: 0.0000\n",
      "Epoch [3298/4500], Validation Loss: 0.2944\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3299/4500], Training Loss: 0.0000\n",
      "Epoch [3299/4500], Validation Loss: 0.2944\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3300/4500], Training Loss: 0.0000\n",
      "Epoch [3300/4500], Validation Loss: 0.2945\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3301/4500], Training Loss: 0.0000\n",
      "Epoch [3301/4500], Validation Loss: 0.2944\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3302/4500], Training Loss: 0.0000\n",
      "Epoch [3302/4500], Validation Loss: 0.2946\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3303/4500], Training Loss: 0.0000\n",
      "Epoch [3303/4500], Validation Loss: 0.2946\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3304/4500], Training Loss: 0.0000\n",
      "Epoch [3304/4500], Validation Loss: 0.2944\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3305/4500], Training Loss: 0.0000\n",
      "Epoch [3305/4500], Validation Loss: 0.2946\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3306/4500], Training Loss: 0.0000\n",
      "Epoch [3306/4500], Validation Loss: 0.2947\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3307/4500], Training Loss: 0.0000\n",
      "Epoch [3307/4500], Validation Loss: 0.2946\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3308/4500], Training Loss: 0.0000\n",
      "Epoch [3308/4500], Validation Loss: 0.2947\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3309/4500], Training Loss: 0.0000\n",
      "Epoch [3309/4500], Validation Loss: 0.2944\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3310/4500], Training Loss: 0.0000\n",
      "Epoch [3310/4500], Validation Loss: 0.2948\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3311/4500], Training Loss: 0.0000\n",
      "Epoch [3311/4500], Validation Loss: 0.2947\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3312/4500], Training Loss: 0.0000\n",
      "Epoch [3312/4500], Validation Loss: 0.2945\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3313/4500], Training Loss: 0.0000\n",
      "Epoch [3313/4500], Validation Loss: 0.2948\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3314/4500], Training Loss: 0.0000\n",
      "Epoch [3314/4500], Validation Loss: 0.2946\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3315/4500], Training Loss: 0.0000\n",
      "Epoch [3315/4500], Validation Loss: 0.2949\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3316/4500], Training Loss: 0.0000\n",
      "Epoch [3316/4500], Validation Loss: 0.2948\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3317/4500], Training Loss: 0.0000\n",
      "Epoch [3317/4500], Validation Loss: 0.2949\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3318/4500], Training Loss: 0.0000\n",
      "Epoch [3318/4500], Validation Loss: 0.2947\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3319/4500], Training Loss: 0.0000\n",
      "Epoch [3319/4500], Validation Loss: 0.2948\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3320/4500], Training Loss: 0.0000\n",
      "Epoch [3320/4500], Validation Loss: 0.2949\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3321/4500], Training Loss: 0.0000\n",
      "Epoch [3321/4500], Validation Loss: 0.2950\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3322/4500], Training Loss: 0.0000\n",
      "Epoch [3322/4500], Validation Loss: 0.2947\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3323/4500], Training Loss: 0.0000\n",
      "Epoch [3323/4500], Validation Loss: 0.2949\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3324/4500], Training Loss: 0.0000\n",
      "Epoch [3324/4500], Validation Loss: 0.2950\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3325/4500], Training Loss: 0.0000\n",
      "Epoch [3325/4500], Validation Loss: 0.2949\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3326/4500], Training Loss: 0.0000\n",
      "Epoch [3326/4500], Validation Loss: 0.2949\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3327/4500], Training Loss: 0.0000\n",
      "Epoch [3327/4500], Validation Loss: 0.2951\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3328/4500], Training Loss: 0.0000\n",
      "Epoch [3328/4500], Validation Loss: 0.2950\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3329/4500], Training Loss: 0.0000\n",
      "Epoch [3329/4500], Validation Loss: 0.2952\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3330/4500], Training Loss: 0.0000\n",
      "Epoch [3330/4500], Validation Loss: 0.2949\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3331/4500], Training Loss: 0.0000\n",
      "Epoch [3331/4500], Validation Loss: 0.2951\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3332/4500], Training Loss: 0.0000\n",
      "Epoch [3332/4500], Validation Loss: 0.2951\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3333/4500], Training Loss: 0.0000\n",
      "Epoch [3333/4500], Validation Loss: 0.2952\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3334/4500], Training Loss: 0.0000\n",
      "Epoch [3334/4500], Validation Loss: 0.2951\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3335/4500], Training Loss: 0.0000\n",
      "Epoch [3335/4500], Validation Loss: 0.2951\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3336/4500], Training Loss: 0.0000\n",
      "Epoch [3336/4500], Validation Loss: 0.2952\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3337/4500], Training Loss: 0.0000\n",
      "Epoch [3337/4500], Validation Loss: 0.2953\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3338/4500], Training Loss: 0.0000\n",
      "Epoch [3338/4500], Validation Loss: 0.2953\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3339/4500], Training Loss: 0.0000\n",
      "Epoch [3339/4500], Validation Loss: 0.2952\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3340/4500], Training Loss: 0.0000\n",
      "Epoch [3340/4500], Validation Loss: 0.2953\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3341/4500], Training Loss: 0.0000\n",
      "Epoch [3341/4500], Validation Loss: 0.2952\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3342/4500], Training Loss: 0.0000\n",
      "Epoch [3342/4500], Validation Loss: 0.2952\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3343/4500], Training Loss: 0.0000\n",
      "Epoch [3343/4500], Validation Loss: 0.2953\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3344/4500], Training Loss: 0.0000\n",
      "Epoch [3344/4500], Validation Loss: 0.2955\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3345/4500], Training Loss: 0.0000\n",
      "Epoch [3345/4500], Validation Loss: 0.2954\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3346/4500], Training Loss: 0.0000\n",
      "Epoch [3346/4500], Validation Loss: 0.2954\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3347/4500], Training Loss: 0.0000\n",
      "Epoch [3347/4500], Validation Loss: 0.2954\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3348/4500], Training Loss: 0.0000\n",
      "Epoch [3348/4500], Validation Loss: 0.2953\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3349/4500], Training Loss: 0.0000\n",
      "Epoch [3349/4500], Validation Loss: 0.2954\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3350/4500], Training Loss: 0.0000\n",
      "Epoch [3350/4500], Validation Loss: 0.2955\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3351/4500], Training Loss: 0.0000\n",
      "Epoch [3351/4500], Validation Loss: 0.2953\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3352/4500], Training Loss: 0.0000\n",
      "Epoch [3352/4500], Validation Loss: 0.2956\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3353/4500], Training Loss: 0.0000\n",
      "Epoch [3353/4500], Validation Loss: 0.2977\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3354/4500], Training Loss: 0.0000\n",
      "Epoch [3354/4500], Validation Loss: 0.2955\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3355/4500], Training Loss: 0.0000\n",
      "Epoch [3355/4500], Validation Loss: 0.2956\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3356/4500], Training Loss: 0.0000\n",
      "Epoch [3356/4500], Validation Loss: 0.2957\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3357/4500], Training Loss: 0.0000\n",
      "Epoch [3357/4500], Validation Loss: 0.2978\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3358/4500], Training Loss: 0.0000\n",
      "Epoch [3358/4500], Validation Loss: 0.2957\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3359/4500], Training Loss: 0.0000\n",
      "Epoch [3359/4500], Validation Loss: 0.2979\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3360/4500], Training Loss: 0.0000\n",
      "Epoch [3360/4500], Validation Loss: 0.2980\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3361/4500], Training Loss: 0.0000\n",
      "Epoch [3361/4500], Validation Loss: 0.2978\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3362/4500], Training Loss: 0.0000\n",
      "Epoch [3362/4500], Validation Loss: 0.2980\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3363/4500], Training Loss: 0.0000\n",
      "Epoch [3363/4500], Validation Loss: 0.2980\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3364/4500], Training Loss: 0.0000\n",
      "Epoch [3364/4500], Validation Loss: 0.2980\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3365/4500], Training Loss: 0.0000\n",
      "Epoch [3365/4500], Validation Loss: 0.2980\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3366/4500], Training Loss: 0.0000\n",
      "Epoch [3366/4500], Validation Loss: 0.2981\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3367/4500], Training Loss: 0.0000\n",
      "Epoch [3367/4500], Validation Loss: 0.2981\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3368/4500], Training Loss: 0.0000\n",
      "Epoch [3368/4500], Validation Loss: 0.2981\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3369/4500], Training Loss: 0.0000\n",
      "Epoch [3369/4500], Validation Loss: 0.2981\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3370/4500], Training Loss: 0.0000\n",
      "Epoch [3370/4500], Validation Loss: 0.2981\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3371/4500], Training Loss: 0.0000\n",
      "Epoch [3371/4500], Validation Loss: 0.2981\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3372/4500], Training Loss: 0.0000\n",
      "Epoch [3372/4500], Validation Loss: 0.2982\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3373/4500], Training Loss: 0.0000\n",
      "Epoch [3373/4500], Validation Loss: 0.2982\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3374/4500], Training Loss: 0.0000\n",
      "Epoch [3374/4500], Validation Loss: 0.2981\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3375/4500], Training Loss: 0.0000\n",
      "Epoch [3375/4500], Validation Loss: 0.2981\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3376/4500], Training Loss: 0.0000\n",
      "Epoch [3376/4500], Validation Loss: 0.2982\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3377/4500], Training Loss: 0.0000\n",
      "Epoch [3377/4500], Validation Loss: 0.2985\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3378/4500], Training Loss: 0.0000\n",
      "Epoch [3378/4500], Validation Loss: 0.2982\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3379/4500], Training Loss: 0.0000\n",
      "Epoch [3379/4500], Validation Loss: 0.2983\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3380/4500], Training Loss: 0.0000\n",
      "Epoch [3380/4500], Validation Loss: 0.2984\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3381/4500], Training Loss: 0.0000\n",
      "Epoch [3381/4500], Validation Loss: 0.2983\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3382/4500], Training Loss: 0.0000\n",
      "Epoch [3382/4500], Validation Loss: 0.2985\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3383/4500], Training Loss: 0.0000\n",
      "Epoch [3383/4500], Validation Loss: 0.2985\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3384/4500], Training Loss: 0.0000\n",
      "Epoch [3384/4500], Validation Loss: 0.2985\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3385/4500], Training Loss: 0.0000\n",
      "Epoch [3385/4500], Validation Loss: 0.2985\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3386/4500], Training Loss: 0.0000\n",
      "Epoch [3386/4500], Validation Loss: 0.2984\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3387/4500], Training Loss: 0.0000\n",
      "Epoch [3387/4500], Validation Loss: 0.2986\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3388/4500], Training Loss: 0.0000\n",
      "Epoch [3388/4500], Validation Loss: 0.2985\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3389/4500], Training Loss: 0.0000\n",
      "Epoch [3389/4500], Validation Loss: 0.2985\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3390/4500], Training Loss: 0.0000\n",
      "Epoch [3390/4500], Validation Loss: 0.2985\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3391/4500], Training Loss: 0.0000\n",
      "Epoch [3391/4500], Validation Loss: 0.2986\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3392/4500], Training Loss: 0.0000\n",
      "Epoch [3392/4500], Validation Loss: 0.2985\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3393/4500], Training Loss: 0.0000\n",
      "Epoch [3393/4500], Validation Loss: 0.2985\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3394/4500], Training Loss: 0.0000\n",
      "Epoch [3394/4500], Validation Loss: 0.2985\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3395/4500], Training Loss: 0.0000\n",
      "Epoch [3395/4500], Validation Loss: 0.2986\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3396/4500], Training Loss: 0.0000\n",
      "Epoch [3396/4500], Validation Loss: 0.2987\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3397/4500], Training Loss: 0.0000\n",
      "Epoch [3397/4500], Validation Loss: 0.2987\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3398/4500], Training Loss: 0.0000\n",
      "Epoch [3398/4500], Validation Loss: 0.2987\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3399/4500], Training Loss: 0.0000\n",
      "Epoch [3399/4500], Validation Loss: 0.2988\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3400/4500], Training Loss: 0.0000\n",
      "Epoch [3400/4500], Validation Loss: 0.2989\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3401/4500], Training Loss: 0.0000\n",
      "Epoch [3401/4500], Validation Loss: 0.2986\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3402/4500], Training Loss: 0.0000\n",
      "Epoch [3402/4500], Validation Loss: 0.2988\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3403/4500], Training Loss: 0.0000\n",
      "Epoch [3403/4500], Validation Loss: 0.2989\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3404/4500], Training Loss: 0.0000\n",
      "Epoch [3404/4500], Validation Loss: 0.2988\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3405/4500], Training Loss: 0.0000\n",
      "Epoch [3405/4500], Validation Loss: 0.2987\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3406/4500], Training Loss: 0.0000\n",
      "Epoch [3406/4500], Validation Loss: 0.2988\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3407/4500], Training Loss: 0.0000\n",
      "Epoch [3407/4500], Validation Loss: 0.2988\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3408/4500], Training Loss: 0.0000\n",
      "Epoch [3408/4500], Validation Loss: 0.2990\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3409/4500], Training Loss: 0.0000\n",
      "Epoch [3409/4500], Validation Loss: 0.2990\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3410/4500], Training Loss: 0.0000\n",
      "Epoch [3410/4500], Validation Loss: 0.2989\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3411/4500], Training Loss: 0.0000\n",
      "Epoch [3411/4500], Validation Loss: 0.2989\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3412/4500], Training Loss: 0.0000\n",
      "Epoch [3412/4500], Validation Loss: 0.2990\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3413/4500], Training Loss: 0.0000\n",
      "Epoch [3413/4500], Validation Loss: 0.2991\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3414/4500], Training Loss: 0.0000\n",
      "Epoch [3414/4500], Validation Loss: 0.2991\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3415/4500], Training Loss: 0.0000\n",
      "Epoch [3415/4500], Validation Loss: 0.2990\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3416/4500], Training Loss: 0.0000\n",
      "Epoch [3416/4500], Validation Loss: 0.2991\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3417/4500], Training Loss: 0.0000\n",
      "Epoch [3417/4500], Validation Loss: 0.2991\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3418/4500], Training Loss: 0.0000\n",
      "Epoch [3418/4500], Validation Loss: 0.2992\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3419/4500], Training Loss: 0.0000\n",
      "Epoch [3419/4500], Validation Loss: 0.2991\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3420/4500], Training Loss: 0.0000\n",
      "Epoch [3420/4500], Validation Loss: 0.2991\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3421/4500], Training Loss: 0.0000\n",
      "Epoch [3421/4500], Validation Loss: 0.2992\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3422/4500], Training Loss: 0.0000\n",
      "Epoch [3422/4500], Validation Loss: 0.2992\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3423/4500], Training Loss: 0.0000\n",
      "Epoch [3423/4500], Validation Loss: 0.2992\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3424/4500], Training Loss: 0.0000\n",
      "Epoch [3424/4500], Validation Loss: 0.2993\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3425/4500], Training Loss: 0.0000\n",
      "Epoch [3425/4500], Validation Loss: 0.2993\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3426/4500], Training Loss: 0.0000\n",
      "Epoch [3426/4500], Validation Loss: 0.2993\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3427/4500], Training Loss: 0.0000\n",
      "Epoch [3427/4500], Validation Loss: 0.2992\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3428/4500], Training Loss: 0.0000\n",
      "Epoch [3428/4500], Validation Loss: 0.2993\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3429/4500], Training Loss: 0.0000\n",
      "Epoch [3429/4500], Validation Loss: 0.2993\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3430/4500], Training Loss: 0.0000\n",
      "Epoch [3430/4500], Validation Loss: 0.2994\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3431/4500], Training Loss: 0.0000\n",
      "Epoch [3431/4500], Validation Loss: 0.2993\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3432/4500], Training Loss: 0.0000\n",
      "Epoch [3432/4500], Validation Loss: 0.2994\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3433/4500], Training Loss: 0.0000\n",
      "Epoch [3433/4500], Validation Loss: 0.2995\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3434/4500], Training Loss: 0.0000\n",
      "Epoch [3434/4500], Validation Loss: 0.2995\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3435/4500], Training Loss: 0.0000\n",
      "Epoch [3435/4500], Validation Loss: 0.2996\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3436/4500], Training Loss: 0.0000\n",
      "Epoch [3436/4500], Validation Loss: 0.2994\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3437/4500], Training Loss: 0.0000\n",
      "Epoch [3437/4500], Validation Loss: 0.2995\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3438/4500], Training Loss: 0.0000\n",
      "Epoch [3438/4500], Validation Loss: 0.2995\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3439/4500], Training Loss: 0.0000\n",
      "Epoch [3439/4500], Validation Loss: 0.2995\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3440/4500], Training Loss: 0.0000\n",
      "Epoch [3440/4500], Validation Loss: 0.2995\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3441/4500], Training Loss: 0.0000\n",
      "Epoch [3441/4500], Validation Loss: 0.2996\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3442/4500], Training Loss: 0.0000\n",
      "Epoch [3442/4500], Validation Loss: 0.2995\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3443/4500], Training Loss: 0.0000\n",
      "Epoch [3443/4500], Validation Loss: 0.2995\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3444/4500], Training Loss: 0.0000\n",
      "Epoch [3444/4500], Validation Loss: 0.2997\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3445/4500], Training Loss: 0.0000\n",
      "Epoch [3445/4500], Validation Loss: 0.2996\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3446/4500], Training Loss: 0.0000\n",
      "Epoch [3446/4500], Validation Loss: 0.2997\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3447/4500], Training Loss: 0.0000\n",
      "Epoch [3447/4500], Validation Loss: 0.2997\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3448/4500], Training Loss: 0.0000\n",
      "Epoch [3448/4500], Validation Loss: 0.2998\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3449/4500], Training Loss: 0.0000\n",
      "Epoch [3449/4500], Validation Loss: 0.2998\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3450/4500], Training Loss: 0.0000\n",
      "Epoch [3450/4500], Validation Loss: 0.2998\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3451/4500], Training Loss: 0.0000\n",
      "Epoch [3451/4500], Validation Loss: 0.2998\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3452/4500], Training Loss: 0.0000\n",
      "Epoch [3452/4500], Validation Loss: 0.2999\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3453/4500], Training Loss: 0.0000\n",
      "Epoch [3453/4500], Validation Loss: 0.2998\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3454/4500], Training Loss: 0.0000\n",
      "Epoch [3454/4500], Validation Loss: 0.2998\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3455/4500], Training Loss: 0.0000\n",
      "Epoch [3455/4500], Validation Loss: 0.2999\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3456/4500], Training Loss: 0.0000\n",
      "Epoch [3456/4500], Validation Loss: 0.2999\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3457/4500], Training Loss: 0.0000\n",
      "Epoch [3457/4500], Validation Loss: 0.2998\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3458/4500], Training Loss: 0.0000\n",
      "Epoch [3458/4500], Validation Loss: 0.3000\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3459/4500], Training Loss: 0.0000\n",
      "Epoch [3459/4500], Validation Loss: 0.2997\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3460/4500], Training Loss: 0.0000\n",
      "Epoch [3460/4500], Validation Loss: 0.3001\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3461/4500], Training Loss: 0.0000\n",
      "Epoch [3461/4500], Validation Loss: 0.3001\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3462/4500], Training Loss: 0.0000\n",
      "Epoch [3462/4500], Validation Loss: 0.3000\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3463/4500], Training Loss: 0.0000\n",
      "Epoch [3463/4500], Validation Loss: 0.2999\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3464/4500], Training Loss: 0.0000\n",
      "Epoch [3464/4500], Validation Loss: 0.3000\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3465/4500], Training Loss: 0.0000\n",
      "Epoch [3465/4500], Validation Loss: 0.3001\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3466/4500], Training Loss: 0.0000\n",
      "Epoch [3466/4500], Validation Loss: 0.3000\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3467/4500], Training Loss: 0.0000\n",
      "Epoch [3467/4500], Validation Loss: 0.3002\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3468/4500], Training Loss: 0.0000\n",
      "Epoch [3468/4500], Validation Loss: 0.3001\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3469/4500], Training Loss: 0.0000\n",
      "Epoch [3469/4500], Validation Loss: 0.3002\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3470/4500], Training Loss: 0.0000\n",
      "Epoch [3470/4500], Validation Loss: 0.3001\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3471/4500], Training Loss: 0.0000\n",
      "Epoch [3471/4500], Validation Loss: 0.3002\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3472/4500], Training Loss: 0.0000\n",
      "Epoch [3472/4500], Validation Loss: 0.3003\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3473/4500], Training Loss: 0.0000\n",
      "Epoch [3473/4500], Validation Loss: 0.3003\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3474/4500], Training Loss: 0.0000\n",
      "Epoch [3474/4500], Validation Loss: 0.3002\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3475/4500], Training Loss: 0.0000\n",
      "Epoch [3475/4500], Validation Loss: 0.3003\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3476/4500], Training Loss: 0.0000\n",
      "Epoch [3476/4500], Validation Loss: 0.3004\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3477/4500], Training Loss: 0.0000\n",
      "Epoch [3477/4500], Validation Loss: 0.3002\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3478/4500], Training Loss: 0.0000\n",
      "Epoch [3478/4500], Validation Loss: 0.3003\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3479/4500], Training Loss: 0.0000\n",
      "Epoch [3479/4500], Validation Loss: 0.3004\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3480/4500], Training Loss: 0.0000\n",
      "Epoch [3480/4500], Validation Loss: 0.3003\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3481/4500], Training Loss: 0.0000\n",
      "Epoch [3481/4500], Validation Loss: 0.3003\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3482/4500], Training Loss: 0.0000\n",
      "Epoch [3482/4500], Validation Loss: 0.3004\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3483/4500], Training Loss: 0.0000\n",
      "Epoch [3483/4500], Validation Loss: 0.3005\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3484/4500], Training Loss: 0.0000\n",
      "Epoch [3484/4500], Validation Loss: 0.3005\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3485/4500], Training Loss: 0.0000\n",
      "Epoch [3485/4500], Validation Loss: 0.3004\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3486/4500], Training Loss: 0.0000\n",
      "Epoch [3486/4500], Validation Loss: 0.3003\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3487/4500], Training Loss: 0.0000\n",
      "Epoch [3487/4500], Validation Loss: 0.3005\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3488/4500], Training Loss: 0.0000\n",
      "Epoch [3488/4500], Validation Loss: 0.3005\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3489/4500], Training Loss: 0.0000\n",
      "Epoch [3489/4500], Validation Loss: 0.3005\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3490/4500], Training Loss: 0.0000\n",
      "Epoch [3490/4500], Validation Loss: 0.3005\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3491/4500], Training Loss: 0.0000\n",
      "Epoch [3491/4500], Validation Loss: 0.3007\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3492/4500], Training Loss: 0.0000\n",
      "Epoch [3492/4500], Validation Loss: 0.3005\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3493/4500], Training Loss: 0.0000\n",
      "Epoch [3493/4500], Validation Loss: 0.3006\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3494/4500], Training Loss: 0.0000\n",
      "Epoch [3494/4500], Validation Loss: 0.3006\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3495/4500], Training Loss: 0.0000\n",
      "Epoch [3495/4500], Validation Loss: 0.3007\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3496/4500], Training Loss: 0.0000\n",
      "Epoch [3496/4500], Validation Loss: 0.3007\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3497/4500], Training Loss: 0.0000\n",
      "Epoch [3497/4500], Validation Loss: 0.3007\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3498/4500], Training Loss: 0.0000\n",
      "Epoch [3498/4500], Validation Loss: 0.3007\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3499/4500], Training Loss: 0.0000\n",
      "Epoch [3499/4500], Validation Loss: 0.3007\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3500/4500], Training Loss: 0.0000\n",
      "Epoch [3500/4500], Validation Loss: 0.3008\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3501/4500], Training Loss: 0.0000\n",
      "Epoch [3501/4500], Validation Loss: 0.3007\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3502/4500], Training Loss: 0.0000\n",
      "Epoch [3502/4500], Validation Loss: 0.3007\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3503/4500], Training Loss: 0.0000\n",
      "Epoch [3503/4500], Validation Loss: 0.3009\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3504/4500], Training Loss: 0.0000\n",
      "Epoch [3504/4500], Validation Loss: 0.3008\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3505/4500], Training Loss: 0.0000\n",
      "Epoch [3505/4500], Validation Loss: 0.3008\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3506/4500], Training Loss: 0.0000\n",
      "Epoch [3506/4500], Validation Loss: 0.3010\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3507/4500], Training Loss: 0.0000\n",
      "Epoch [3507/4500], Validation Loss: 0.3007\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3508/4500], Training Loss: 0.0000\n",
      "Epoch [3508/4500], Validation Loss: 0.3010\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3509/4500], Training Loss: 0.0000\n",
      "Epoch [3509/4500], Validation Loss: 0.3010\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3510/4500], Training Loss: 0.0000\n",
      "Epoch [3510/4500], Validation Loss: 0.3009\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3511/4500], Training Loss: 0.0000\n",
      "Epoch [3511/4500], Validation Loss: 0.3010\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3512/4500], Training Loss: 0.0000\n",
      "Epoch [3512/4500], Validation Loss: 0.3010\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3513/4500], Training Loss: 0.0000\n",
      "Epoch [3513/4500], Validation Loss: 0.3011\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3514/4500], Training Loss: 0.0000\n",
      "Epoch [3514/4500], Validation Loss: 0.3010\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3515/4500], Training Loss: 0.0000\n",
      "Epoch [3515/4500], Validation Loss: 0.3011\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3516/4500], Training Loss: 0.0000\n",
      "Epoch [3516/4500], Validation Loss: 0.3012\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3517/4500], Training Loss: 0.0000\n",
      "Epoch [3517/4500], Validation Loss: 0.3011\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3518/4500], Training Loss: 0.0000\n",
      "Epoch [3518/4500], Validation Loss: 0.3011\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3519/4500], Training Loss: 0.0000\n",
      "Epoch [3519/4500], Validation Loss: 0.3011\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3520/4500], Training Loss: 0.0000\n",
      "Epoch [3520/4500], Validation Loss: 0.3012\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3521/4500], Training Loss: 0.0000\n",
      "Epoch [3521/4500], Validation Loss: 0.3012\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3522/4500], Training Loss: 0.0000\n",
      "Epoch [3522/4500], Validation Loss: 0.3012\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3523/4500], Training Loss: 0.0000\n",
      "Epoch [3523/4500], Validation Loss: 0.3011\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3524/4500], Training Loss: 0.0000\n",
      "Epoch [3524/4500], Validation Loss: 0.3013\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3525/4500], Training Loss: 0.0000\n",
      "Epoch [3525/4500], Validation Loss: 0.3012\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3526/4500], Training Loss: 0.0000\n",
      "Epoch [3526/4500], Validation Loss: 0.3013\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3527/4500], Training Loss: 0.0000\n",
      "Epoch [3527/4500], Validation Loss: 0.3012\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3528/4500], Training Loss: 0.0000\n",
      "Epoch [3528/4500], Validation Loss: 0.3014\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3529/4500], Training Loss: 0.0000\n",
      "Epoch [3529/4500], Validation Loss: 0.3013\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3530/4500], Training Loss: 0.0000\n",
      "Epoch [3530/4500], Validation Loss: 0.3014\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3531/4500], Training Loss: 0.0000\n",
      "Epoch [3531/4500], Validation Loss: 0.3014\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3532/4500], Training Loss: 0.0000\n",
      "Epoch [3532/4500], Validation Loss: 0.3014\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3533/4500], Training Loss: 0.0000\n",
      "Epoch [3533/4500], Validation Loss: 0.3015\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3534/4500], Training Loss: 0.0000\n",
      "Epoch [3534/4500], Validation Loss: 0.3015\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3535/4500], Training Loss: 0.0000\n",
      "Epoch [3535/4500], Validation Loss: 0.3015\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3536/4500], Training Loss: 0.0000\n",
      "Epoch [3536/4500], Validation Loss: 0.3014\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3537/4500], Training Loss: 0.0000\n",
      "Epoch [3537/4500], Validation Loss: 0.3015\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3538/4500], Training Loss: 0.0000\n",
      "Epoch [3538/4500], Validation Loss: 0.3016\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3539/4500], Training Loss: 0.0000\n",
      "Epoch [3539/4500], Validation Loss: 0.3015\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3540/4500], Training Loss: 0.0000\n",
      "Epoch [3540/4500], Validation Loss: 0.3017\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3541/4500], Training Loss: 0.0000\n",
      "Epoch [3541/4500], Validation Loss: 0.3016\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3542/4500], Training Loss: 0.0000\n",
      "Epoch [3542/4500], Validation Loss: 0.3016\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3543/4500], Training Loss: 0.0000\n",
      "Epoch [3543/4500], Validation Loss: 0.3017\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3544/4500], Training Loss: 0.0000\n",
      "Epoch [3544/4500], Validation Loss: 0.3015\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3545/4500], Training Loss: 0.0000\n",
      "Epoch [3545/4500], Validation Loss: 0.3016\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3546/4500], Training Loss: 0.0000\n",
      "Epoch [3546/4500], Validation Loss: 0.3018\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3547/4500], Training Loss: 0.0000\n",
      "Epoch [3547/4500], Validation Loss: 0.3016\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3548/4500], Training Loss: 0.0000\n",
      "Epoch [3548/4500], Validation Loss: 0.3017\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3549/4500], Training Loss: 0.0000\n",
      "Epoch [3549/4500], Validation Loss: 0.3018\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3550/4500], Training Loss: 0.0000\n",
      "Epoch [3550/4500], Validation Loss: 0.3017\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3551/4500], Training Loss: 0.0000\n",
      "Epoch [3551/4500], Validation Loss: 0.3018\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3552/4500], Training Loss: 0.0000\n",
      "Epoch [3552/4500], Validation Loss: 0.3019\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3553/4500], Training Loss: 0.0000\n",
      "Epoch [3553/4500], Validation Loss: 0.3018\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3554/4500], Training Loss: 0.0000\n",
      "Epoch [3554/4500], Validation Loss: 0.3018\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3555/4500], Training Loss: 0.0000\n",
      "Epoch [3555/4500], Validation Loss: 0.3019\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3556/4500], Training Loss: 0.0000\n",
      "Epoch [3556/4500], Validation Loss: 0.3020\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3557/4500], Training Loss: 0.0000\n",
      "Epoch [3557/4500], Validation Loss: 0.3018\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3558/4500], Training Loss: 0.0000\n",
      "Epoch [3558/4500], Validation Loss: 0.3020\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3559/4500], Training Loss: 0.0000\n",
      "Epoch [3559/4500], Validation Loss: 0.3020\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3560/4500], Training Loss: 0.0000\n",
      "Epoch [3560/4500], Validation Loss: 0.3019\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3561/4500], Training Loss: 0.0000\n",
      "Epoch [3561/4500], Validation Loss: 0.3019\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3562/4500], Training Loss: 0.0000\n",
      "Epoch [3562/4500], Validation Loss: 0.3021\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3563/4500], Training Loss: 0.0000\n",
      "Epoch [3563/4500], Validation Loss: 0.3018\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3564/4500], Training Loss: 0.0000\n",
      "Epoch [3564/4500], Validation Loss: 0.3021\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3565/4500], Training Loss: 0.0000\n",
      "Epoch [3565/4500], Validation Loss: 0.3021\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3566/4500], Training Loss: 0.0000\n",
      "Epoch [3566/4500], Validation Loss: 0.3020\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3567/4500], Training Loss: 0.0000\n",
      "Epoch [3567/4500], Validation Loss: 0.3022\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3568/4500], Training Loss: 0.0000\n",
      "Epoch [3568/4500], Validation Loss: 0.3022\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3569/4500], Training Loss: 0.0000\n",
      "Epoch [3569/4500], Validation Loss: 0.3022\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3570/4500], Training Loss: 0.0000\n",
      "Epoch [3570/4500], Validation Loss: 0.3021\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3571/4500], Training Loss: 0.0000\n",
      "Epoch [3571/4500], Validation Loss: 0.3022\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3572/4500], Training Loss: 0.0000\n",
      "Epoch [3572/4500], Validation Loss: 0.3022\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3573/4500], Training Loss: 0.0000\n",
      "Epoch [3573/4500], Validation Loss: 0.3021\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3574/4500], Training Loss: 0.0000\n",
      "Epoch [3574/4500], Validation Loss: 0.3024\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3575/4500], Training Loss: 0.0000\n",
      "Epoch [3575/4500], Validation Loss: 0.3022\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3576/4500], Training Loss: 0.0000\n",
      "Epoch [3576/4500], Validation Loss: 0.3022\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3577/4500], Training Loss: 0.0000\n",
      "Epoch [3577/4500], Validation Loss: 0.3023\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3578/4500], Training Loss: 0.0000\n",
      "Epoch [3578/4500], Validation Loss: 0.3023\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3579/4500], Training Loss: 0.0000\n",
      "Epoch [3579/4500], Validation Loss: 0.3023\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3580/4500], Training Loss: 0.0000\n",
      "Epoch [3580/4500], Validation Loss: 0.3024\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3581/4500], Training Loss: 0.0000\n",
      "Epoch [3581/4500], Validation Loss: 0.3023\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3582/4500], Training Loss: 0.0000\n",
      "Epoch [3582/4500], Validation Loss: 0.3024\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3583/4500], Training Loss: 0.0000\n",
      "Epoch [3583/4500], Validation Loss: 0.3025\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3584/4500], Training Loss: 0.0000\n",
      "Epoch [3584/4500], Validation Loss: 0.3024\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3585/4500], Training Loss: 0.0000\n",
      "Epoch [3585/4500], Validation Loss: 0.3024\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3586/4500], Training Loss: 0.0000\n",
      "Epoch [3586/4500], Validation Loss: 0.3026\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3587/4500], Training Loss: 0.0000\n",
      "Epoch [3587/4500], Validation Loss: 0.3026\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3588/4500], Training Loss: 0.0000\n",
      "Epoch [3588/4500], Validation Loss: 0.3024\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3589/4500], Training Loss: 0.0000\n",
      "Epoch [3589/4500], Validation Loss: 0.3026\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3590/4500], Training Loss: 0.0000\n",
      "Epoch [3590/4500], Validation Loss: 0.3026\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3591/4500], Training Loss: 0.0000\n",
      "Epoch [3591/4500], Validation Loss: 0.3024\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3592/4500], Training Loss: 0.0000\n",
      "Epoch [3592/4500], Validation Loss: 0.3025\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3593/4500], Training Loss: 0.0000\n",
      "Epoch [3593/4500], Validation Loss: 0.3026\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3594/4500], Training Loss: 0.0000\n",
      "Epoch [3594/4500], Validation Loss: 0.3027\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3595/4500], Training Loss: 0.0000\n",
      "Epoch [3595/4500], Validation Loss: 0.3026\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3596/4500], Training Loss: 0.0000\n",
      "Epoch [3596/4500], Validation Loss: 0.3026\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3597/4500], Training Loss: 0.0000\n",
      "Epoch [3597/4500], Validation Loss: 0.3027\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3598/4500], Training Loss: 0.0000\n",
      "Epoch [3598/4500], Validation Loss: 0.3028\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3599/4500], Training Loss: 0.0000\n",
      "Epoch [3599/4500], Validation Loss: 0.3028\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3600/4500], Training Loss: 0.0000\n",
      "Epoch [3600/4500], Validation Loss: 0.3027\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3601/4500], Training Loss: 0.0000\n",
      "Epoch [3601/4500], Validation Loss: 0.3028\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3602/4500], Training Loss: 0.0000\n",
      "Epoch [3602/4500], Validation Loss: 0.3028\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3603/4500], Training Loss: 0.0000\n",
      "Epoch [3603/4500], Validation Loss: 0.3029\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3604/4500], Training Loss: 0.0000\n",
      "Epoch [3604/4500], Validation Loss: 0.3027\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3605/4500], Training Loss: 0.0000\n",
      "Epoch [3605/4500], Validation Loss: 0.3029\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3606/4500], Training Loss: 0.0000\n",
      "Epoch [3606/4500], Validation Loss: 0.3028\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3607/4500], Training Loss: 0.0000\n",
      "Epoch [3607/4500], Validation Loss: 0.3028\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3608/4500], Training Loss: 0.0000\n",
      "Epoch [3608/4500], Validation Loss: 0.3029\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3609/4500], Training Loss: 0.0000\n",
      "Epoch [3609/4500], Validation Loss: 0.3030\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3610/4500], Training Loss: 0.0000\n",
      "Epoch [3610/4500], Validation Loss: 0.3029\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3611/4500], Training Loss: 0.0000\n",
      "Epoch [3611/4500], Validation Loss: 0.3029\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3612/4500], Training Loss: 0.0000\n",
      "Epoch [3612/4500], Validation Loss: 0.3030\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3613/4500], Training Loss: 0.0000\n",
      "Epoch [3613/4500], Validation Loss: 0.3030\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3614/4500], Training Loss: 0.0000\n",
      "Epoch [3614/4500], Validation Loss: 0.3029\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3615/4500], Training Loss: 0.0000\n",
      "Epoch [3615/4500], Validation Loss: 0.3030\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3616/4500], Training Loss: 0.0000\n",
      "Epoch [3616/4500], Validation Loss: 0.3030\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3617/4500], Training Loss: 0.0000\n",
      "Epoch [3617/4500], Validation Loss: 0.3031\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3618/4500], Training Loss: 0.0000\n",
      "Epoch [3618/4500], Validation Loss: 0.3030\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3619/4500], Training Loss: 0.0000\n",
      "Epoch [3619/4500], Validation Loss: 0.3031\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3620/4500], Training Loss: 0.0000\n",
      "Epoch [3620/4500], Validation Loss: 0.3032\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3621/4500], Training Loss: 0.0000\n",
      "Epoch [3621/4500], Validation Loss: 0.3032\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3622/4500], Training Loss: 0.0000\n",
      "Epoch [3622/4500], Validation Loss: 0.3031\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3623/4500], Training Loss: 0.0000\n",
      "Epoch [3623/4500], Validation Loss: 0.3032\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3624/4500], Training Loss: 0.0000\n",
      "Epoch [3624/4500], Validation Loss: 0.3032\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3625/4500], Training Loss: 0.0000\n",
      "Epoch [3625/4500], Validation Loss: 0.3032\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3626/4500], Training Loss: 0.0000\n",
      "Epoch [3626/4500], Validation Loss: 0.3032\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3627/4500], Training Loss: 0.0000\n",
      "Epoch [3627/4500], Validation Loss: 0.3033\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3628/4500], Training Loss: 0.0000\n",
      "Epoch [3628/4500], Validation Loss: 0.3032\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3629/4500], Training Loss: 0.0000\n",
      "Epoch [3629/4500], Validation Loss: 0.3034\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3630/4500], Training Loss: 0.0000\n",
      "Epoch [3630/4500], Validation Loss: 0.3033\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3631/4500], Training Loss: 0.0000\n",
      "Epoch [3631/4500], Validation Loss: 0.3033\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3632/4500], Training Loss: 0.0000\n",
      "Epoch [3632/4500], Validation Loss: 0.3033\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3633/4500], Training Loss: 0.0000\n",
      "Epoch [3633/4500], Validation Loss: 0.3034\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3634/4500], Training Loss: 0.0000\n",
      "Epoch [3634/4500], Validation Loss: 0.3033\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3635/4500], Training Loss: 0.0000\n",
      "Epoch [3635/4500], Validation Loss: 0.3034\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3636/4500], Training Loss: 0.0000\n",
      "Epoch [3636/4500], Validation Loss: 0.3035\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3637/4500], Training Loss: 0.0000\n",
      "Epoch [3637/4500], Validation Loss: 0.3033\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3638/4500], Training Loss: 0.0000\n",
      "Epoch [3638/4500], Validation Loss: 0.3035\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3639/4500], Training Loss: 0.0000\n",
      "Epoch [3639/4500], Validation Loss: 0.3035\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3640/4500], Training Loss: 0.0000\n",
      "Epoch [3640/4500], Validation Loss: 0.3033\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3641/4500], Training Loss: 0.0000\n",
      "Epoch [3641/4500], Validation Loss: 0.3036\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3642/4500], Training Loss: 0.0000\n",
      "Epoch [3642/4500], Validation Loss: 0.3036\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3643/4500], Training Loss: 0.0000\n",
      "Epoch [3643/4500], Validation Loss: 0.3036\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3644/4500], Training Loss: 0.0000\n",
      "Epoch [3644/4500], Validation Loss: 0.3035\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3645/4500], Training Loss: 0.0000\n",
      "Epoch [3645/4500], Validation Loss: 0.3035\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3646/4500], Training Loss: 0.0000\n",
      "Epoch [3646/4500], Validation Loss: 0.3037\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3647/4500], Training Loss: 0.0000\n",
      "Epoch [3647/4500], Validation Loss: 0.3036\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3648/4500], Training Loss: 0.0000\n",
      "Epoch [3648/4500], Validation Loss: 0.3037\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3649/4500], Training Loss: 0.0000\n",
      "Epoch [3649/4500], Validation Loss: 0.3035\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3650/4500], Training Loss: 0.0000\n",
      "Epoch [3650/4500], Validation Loss: 0.3037\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3651/4500], Training Loss: 0.0000\n",
      "Epoch [3651/4500], Validation Loss: 0.3037\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3652/4500], Training Loss: 0.0000\n",
      "Epoch [3652/4500], Validation Loss: 0.3037\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3653/4500], Training Loss: 0.0000\n",
      "Epoch [3653/4500], Validation Loss: 0.3037\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3654/4500], Training Loss: 0.0000\n",
      "Epoch [3654/4500], Validation Loss: 0.3038\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3655/4500], Training Loss: 0.0000\n",
      "Epoch [3655/4500], Validation Loss: 0.3039\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3656/4500], Training Loss: 0.0000\n",
      "Epoch [3656/4500], Validation Loss: 0.3037\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3657/4500], Training Loss: 0.0000\n",
      "Epoch [3657/4500], Validation Loss: 0.3039\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3658/4500], Training Loss: 0.0000\n",
      "Epoch [3658/4500], Validation Loss: 0.3038\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3659/4500], Training Loss: 0.0000\n",
      "Epoch [3659/4500], Validation Loss: 0.3039\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3660/4500], Training Loss: 0.0000\n",
      "Epoch [3660/4500], Validation Loss: 0.3040\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3661/4500], Training Loss: 0.0000\n",
      "Epoch [3661/4500], Validation Loss: 0.3039\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3662/4500], Training Loss: 0.0000\n",
      "Epoch [3662/4500], Validation Loss: 0.3040\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3663/4500], Training Loss: 0.0000\n",
      "Epoch [3663/4500], Validation Loss: 0.3039\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3664/4500], Training Loss: 0.0000\n",
      "Epoch [3664/4500], Validation Loss: 0.3039\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3665/4500], Training Loss: 0.0000\n",
      "Epoch [3665/4500], Validation Loss: 0.3038\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3666/4500], Training Loss: 0.0000\n",
      "Epoch [3666/4500], Validation Loss: 0.3040\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3667/4500], Training Loss: 0.0000\n",
      "Epoch [3667/4500], Validation Loss: 0.3040\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3668/4500], Training Loss: 0.0000\n",
      "Epoch [3668/4500], Validation Loss: 0.3040\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3669/4500], Training Loss: 0.0000\n",
      "Epoch [3669/4500], Validation Loss: 0.3040\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3670/4500], Training Loss: 0.0000\n",
      "Epoch [3670/4500], Validation Loss: 0.3042\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3671/4500], Training Loss: 0.0000\n",
      "Epoch [3671/4500], Validation Loss: 0.3040\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3672/4500], Training Loss: 0.0000\n",
      "Epoch [3672/4500], Validation Loss: 0.3042\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3673/4500], Training Loss: 0.0000\n",
      "Epoch [3673/4500], Validation Loss: 0.3041\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3674/4500], Training Loss: 0.0000\n",
      "Epoch [3674/4500], Validation Loss: 0.3042\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3675/4500], Training Loss: 0.0000\n",
      "Epoch [3675/4500], Validation Loss: 0.3041\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3676/4500], Training Loss: 0.0000\n",
      "Epoch [3676/4500], Validation Loss: 0.3042\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3677/4500], Training Loss: 0.0000\n",
      "Epoch [3677/4500], Validation Loss: 0.3042\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3678/4500], Training Loss: 0.0000\n",
      "Epoch [3678/4500], Validation Loss: 0.3041\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3679/4500], Training Loss: 0.0000\n",
      "Epoch [3679/4500], Validation Loss: 0.3043\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3680/4500], Training Loss: 0.0000\n",
      "Epoch [3680/4500], Validation Loss: 0.3043\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3681/4500], Training Loss: 0.0000\n",
      "Epoch [3681/4500], Validation Loss: 0.3044\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3682/4500], Training Loss: 0.0000\n",
      "Epoch [3682/4500], Validation Loss: 0.3043\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3683/4500], Training Loss: 0.0000\n",
      "Epoch [3683/4500], Validation Loss: 0.3042\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3684/4500], Training Loss: 0.0000\n",
      "Epoch [3684/4500], Validation Loss: 0.3043\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3685/4500], Training Loss: 0.0000\n",
      "Epoch [3685/4500], Validation Loss: 0.3044\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3686/4500], Training Loss: 0.0000\n",
      "Epoch [3686/4500], Validation Loss: 0.3045\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3687/4500], Training Loss: 0.0000\n",
      "Epoch [3687/4500], Validation Loss: 0.3043\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3688/4500], Training Loss: 0.0000\n",
      "Epoch [3688/4500], Validation Loss: 0.3044\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3689/4500], Training Loss: 0.0000\n",
      "Epoch [3689/4500], Validation Loss: 0.3045\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3690/4500], Training Loss: 0.0000\n",
      "Epoch [3690/4500], Validation Loss: 0.3044\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3691/4500], Training Loss: 0.0000\n",
      "Epoch [3691/4500], Validation Loss: 0.3044\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3692/4500], Training Loss: 0.0000\n",
      "Epoch [3692/4500], Validation Loss: 0.3044\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3693/4500], Training Loss: 0.0000\n",
      "Epoch [3693/4500], Validation Loss: 0.3045\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3694/4500], Training Loss: 0.0000\n",
      "Epoch [3694/4500], Validation Loss: 0.3045\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3695/4500], Training Loss: 0.0000\n",
      "Epoch [3695/4500], Validation Loss: 0.3044\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3696/4500], Training Loss: 0.0000\n",
      "Epoch [3696/4500], Validation Loss: 0.3045\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3697/4500], Training Loss: 0.0000\n",
      "Epoch [3697/4500], Validation Loss: 0.3045\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3698/4500], Training Loss: 0.0000\n",
      "Epoch [3698/4500], Validation Loss: 0.3047\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3699/4500], Training Loss: 0.0000\n",
      "Epoch [3699/4500], Validation Loss: 0.3047\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3700/4500], Training Loss: 0.0000\n",
      "Epoch [3700/4500], Validation Loss: 0.3047\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3701/4500], Training Loss: 0.0000\n",
      "Epoch [3701/4500], Validation Loss: 0.3045\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3702/4500], Training Loss: 0.0000\n",
      "Epoch [3702/4500], Validation Loss: 0.3047\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3703/4500], Training Loss: 0.0000\n",
      "Epoch [3703/4500], Validation Loss: 0.3048\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3704/4500], Training Loss: 0.0000\n",
      "Epoch [3704/4500], Validation Loss: 0.3047\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3705/4500], Training Loss: 0.0000\n",
      "Epoch [3705/4500], Validation Loss: 0.3047\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3706/4500], Training Loss: 0.0000\n",
      "Epoch [3706/4500], Validation Loss: 0.3046\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3707/4500], Training Loss: 0.0000\n",
      "Epoch [3707/4500], Validation Loss: 0.3047\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3708/4500], Training Loss: 0.0000\n",
      "Epoch [3708/4500], Validation Loss: 0.3050\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3709/4500], Training Loss: 0.0000\n",
      "Epoch [3709/4500], Validation Loss: 0.3047\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3710/4500], Training Loss: 0.0000\n",
      "Epoch [3710/4500], Validation Loss: 0.3048\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3711/4500], Training Loss: 0.0000\n",
      "Epoch [3711/4500], Validation Loss: 0.3048\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3712/4500], Training Loss: 0.0000\n",
      "Epoch [3712/4500], Validation Loss: 0.3049\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3713/4500], Training Loss: 0.0000\n",
      "Epoch [3713/4500], Validation Loss: 0.3050\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3714/4500], Training Loss: 0.0000\n",
      "Epoch [3714/4500], Validation Loss: 0.3049\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3715/4500], Training Loss: 0.0000\n",
      "Epoch [3715/4500], Validation Loss: 0.3049\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3716/4500], Training Loss: 0.0000\n",
      "Epoch [3716/4500], Validation Loss: 0.3049\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3717/4500], Training Loss: 0.0000\n",
      "Epoch [3717/4500], Validation Loss: 0.3049\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3718/4500], Training Loss: 0.0000\n",
      "Epoch [3718/4500], Validation Loss: 0.3049\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3719/4500], Training Loss: 0.0000\n",
      "Epoch [3719/4500], Validation Loss: 0.3050\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3720/4500], Training Loss: 0.0000\n",
      "Epoch [3720/4500], Validation Loss: 0.3052\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3721/4500], Training Loss: 0.0000\n",
      "Epoch [3721/4500], Validation Loss: 0.3051\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3722/4500], Training Loss: 0.0000\n",
      "Epoch [3722/4500], Validation Loss: 0.3050\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3723/4500], Training Loss: 0.0000\n",
      "Epoch [3723/4500], Validation Loss: 0.3050\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3724/4500], Training Loss: 0.0000\n",
      "Epoch [3724/4500], Validation Loss: 0.3051\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3725/4500], Training Loss: 0.0000\n",
      "Epoch [3725/4500], Validation Loss: 0.3049\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3726/4500], Training Loss: 0.0000\n",
      "Epoch [3726/4500], Validation Loss: 0.3050\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3727/4500], Training Loss: 0.0000\n",
      "Epoch [3727/4500], Validation Loss: 0.3051\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3728/4500], Training Loss: 0.0000\n",
      "Epoch [3728/4500], Validation Loss: 0.3050\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3729/4500], Training Loss: 0.0000\n",
      "Epoch [3729/4500], Validation Loss: 0.3052\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3730/4500], Training Loss: 0.0000\n",
      "Epoch [3730/4500], Validation Loss: 0.3052\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3731/4500], Training Loss: 0.0000\n",
      "Epoch [3731/4500], Validation Loss: 0.3053\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3732/4500], Training Loss: 0.0000\n",
      "Epoch [3732/4500], Validation Loss: 0.3052\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3733/4500], Training Loss: 0.0000\n",
      "Epoch [3733/4500], Validation Loss: 0.3052\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3734/4500], Training Loss: 0.0000\n",
      "Epoch [3734/4500], Validation Loss: 0.3053\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3735/4500], Training Loss: 0.0000\n",
      "Epoch [3735/4500], Validation Loss: 0.3053\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3736/4500], Training Loss: 0.0000\n",
      "Epoch [3736/4500], Validation Loss: 0.3052\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3737/4500], Training Loss: 0.0000\n",
      "Epoch [3737/4500], Validation Loss: 0.3052\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3738/4500], Training Loss: 0.0000\n",
      "Epoch [3738/4500], Validation Loss: 0.3053\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3739/4500], Training Loss: 0.0000\n",
      "Epoch [3739/4500], Validation Loss: 0.3054\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3740/4500], Training Loss: 0.0000\n",
      "Epoch [3740/4500], Validation Loss: 0.3053\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3741/4500], Training Loss: 0.0000\n",
      "Epoch [3741/4500], Validation Loss: 0.3054\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3742/4500], Training Loss: 0.0000\n",
      "Epoch [3742/4500], Validation Loss: 0.3055\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3743/4500], Training Loss: 0.0000\n",
      "Epoch [3743/4500], Validation Loss: 0.3054\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3744/4500], Training Loss: 0.0000\n",
      "Epoch [3744/4500], Validation Loss: 0.3055\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3745/4500], Training Loss: 0.0000\n",
      "Epoch [3745/4500], Validation Loss: 0.3054\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3746/4500], Training Loss: 0.0000\n",
      "Epoch [3746/4500], Validation Loss: 0.3055\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3747/4500], Training Loss: 0.0000\n",
      "Epoch [3747/4500], Validation Loss: 0.3054\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3748/4500], Training Loss: 0.0000\n",
      "Epoch [3748/4500], Validation Loss: 0.3056\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3749/4500], Training Loss: 0.0000\n",
      "Epoch [3749/4500], Validation Loss: 0.3055\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3750/4500], Training Loss: 0.0000\n",
      "Epoch [3750/4500], Validation Loss: 0.3056\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3751/4500], Training Loss: 0.0000\n",
      "Epoch [3751/4500], Validation Loss: 0.3056\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3752/4500], Training Loss: 0.0000\n",
      "Epoch [3752/4500], Validation Loss: 0.3055\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3753/4500], Training Loss: 0.0000\n",
      "Epoch [3753/4500], Validation Loss: 0.3055\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3754/4500], Training Loss: 0.0000\n",
      "Epoch [3754/4500], Validation Loss: 0.3056\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3755/4500], Training Loss: 0.0000\n",
      "Epoch [3755/4500], Validation Loss: 0.3058\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3756/4500], Training Loss: 0.0000\n",
      "Epoch [3756/4500], Validation Loss: 0.3055\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3757/4500], Training Loss: 0.0000\n",
      "Epoch [3757/4500], Validation Loss: 0.3057\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3758/4500], Training Loss: 0.0000\n",
      "Epoch [3758/4500], Validation Loss: 0.3058\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3759/4500], Training Loss: 0.0000\n",
      "Epoch [3759/4500], Validation Loss: 0.3057\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3760/4500], Training Loss: 0.0000\n",
      "Epoch [3760/4500], Validation Loss: 0.3056\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3761/4500], Training Loss: 0.0000\n",
      "Epoch [3761/4500], Validation Loss: 0.3058\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3762/4500], Training Loss: 0.0000\n",
      "Epoch [3762/4500], Validation Loss: 0.3058\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3763/4500], Training Loss: 0.0000\n",
      "Epoch [3763/4500], Validation Loss: 0.3057\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3764/4500], Training Loss: 0.0000\n",
      "Epoch [3764/4500], Validation Loss: 0.3058\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3765/4500], Training Loss: 0.0000\n",
      "Epoch [3765/4500], Validation Loss: 0.3058\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3766/4500], Training Loss: 0.0000\n",
      "Epoch [3766/4500], Validation Loss: 0.3059\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3767/4500], Training Loss: 0.0000\n",
      "Epoch [3767/4500], Validation Loss: 0.3058\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3768/4500], Training Loss: 0.0000\n",
      "Epoch [3768/4500], Validation Loss: 0.3057\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3769/4500], Training Loss: 0.0000\n",
      "Epoch [3769/4500], Validation Loss: 0.3060\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3770/4500], Training Loss: 0.0000\n",
      "Epoch [3770/4500], Validation Loss: 0.3058\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3771/4500], Training Loss: 0.0000\n",
      "Epoch [3771/4500], Validation Loss: 0.3059\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3772/4500], Training Loss: 0.0000\n",
      "Epoch [3772/4500], Validation Loss: 0.3059\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3773/4500], Training Loss: 0.0000\n",
      "Epoch [3773/4500], Validation Loss: 0.3060\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3774/4500], Training Loss: 0.0000\n",
      "Epoch [3774/4500], Validation Loss: 0.3059\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3775/4500], Training Loss: 0.0000\n",
      "Epoch [3775/4500], Validation Loss: 0.3060\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3776/4500], Training Loss: 0.0000\n",
      "Epoch [3776/4500], Validation Loss: 0.3061\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3777/4500], Training Loss: 0.0000\n",
      "Epoch [3777/4500], Validation Loss: 0.3061\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3778/4500], Training Loss: 0.0000\n",
      "Epoch [3778/4500], Validation Loss: 0.3061\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3779/4500], Training Loss: 0.0000\n",
      "Epoch [3779/4500], Validation Loss: 0.3060\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3780/4500], Training Loss: 0.0000\n",
      "Epoch [3780/4500], Validation Loss: 0.3061\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3781/4500], Training Loss: 0.0000\n",
      "Epoch [3781/4500], Validation Loss: 0.3062\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3782/4500], Training Loss: 0.0000\n",
      "Epoch [3782/4500], Validation Loss: 0.3061\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3783/4500], Training Loss: 0.0000\n",
      "Epoch [3783/4500], Validation Loss: 0.3062\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3784/4500], Training Loss: 0.0000\n",
      "Epoch [3784/4500], Validation Loss: 0.3062\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3785/4500], Training Loss: 0.0000\n",
      "Epoch [3785/4500], Validation Loss: 0.3062\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3786/4500], Training Loss: 0.0000\n",
      "Epoch [3786/4500], Validation Loss: 0.3062\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3787/4500], Training Loss: 0.0000\n",
      "Epoch [3787/4500], Validation Loss: 0.3061\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3788/4500], Training Loss: 0.0000\n",
      "Epoch [3788/4500], Validation Loss: 0.3064\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3789/4500], Training Loss: 0.0000\n",
      "Epoch [3789/4500], Validation Loss: 0.3061\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3790/4500], Training Loss: 0.0000\n",
      "Epoch [3790/4500], Validation Loss: 0.3062\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3791/4500], Training Loss: 0.0000\n",
      "Epoch [3791/4500], Validation Loss: 0.3062\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3792/4500], Training Loss: 0.0000\n",
      "Epoch [3792/4500], Validation Loss: 0.3064\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3793/4500], Training Loss: 0.0000\n",
      "Epoch [3793/4500], Validation Loss: 0.3063\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3794/4500], Training Loss: 0.0000\n",
      "Epoch [3794/4500], Validation Loss: 0.3063\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3795/4500], Training Loss: 0.0000\n",
      "Epoch [3795/4500], Validation Loss: 0.3064\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3796/4500], Training Loss: 0.0000\n",
      "Epoch [3796/4500], Validation Loss: 0.3065\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3797/4500], Training Loss: 0.0000\n",
      "Epoch [3797/4500], Validation Loss: 0.3063\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3798/4500], Training Loss: 0.0000\n",
      "Epoch [3798/4500], Validation Loss: 0.3064\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3799/4500], Training Loss: 0.0000\n",
      "Epoch [3799/4500], Validation Loss: 0.3064\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3800/4500], Training Loss: 0.0000\n",
      "Epoch [3800/4500], Validation Loss: 0.3065\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3801/4500], Training Loss: 0.0000\n",
      "Epoch [3801/4500], Validation Loss: 0.3066\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3802/4500], Training Loss: 0.0000\n",
      "Epoch [3802/4500], Validation Loss: 0.3064\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3803/4500], Training Loss: 0.0000\n",
      "Epoch [3803/4500], Validation Loss: 0.3065\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3804/4500], Training Loss: 0.0000\n",
      "Epoch [3804/4500], Validation Loss: 0.3066\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3805/4500], Training Loss: 0.0000\n",
      "Epoch [3805/4500], Validation Loss: 0.3064\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3806/4500], Training Loss: 0.0000\n",
      "Epoch [3806/4500], Validation Loss: 0.3066\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3807/4500], Training Loss: 0.0000\n",
      "Epoch [3807/4500], Validation Loss: 0.3066\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3808/4500], Training Loss: 0.0000\n",
      "Epoch [3808/4500], Validation Loss: 0.3067\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3809/4500], Training Loss: 0.0000\n",
      "Epoch [3809/4500], Validation Loss: 0.3066\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3810/4500], Training Loss: 0.0000\n",
      "Epoch [3810/4500], Validation Loss: 0.3066\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3811/4500], Training Loss: 0.0000\n",
      "Epoch [3811/4500], Validation Loss: 0.3067\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3812/4500], Training Loss: 0.0000\n",
      "Epoch [3812/4500], Validation Loss: 0.3067\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3813/4500], Training Loss: 0.0000\n",
      "Epoch [3813/4500], Validation Loss: 0.3066\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3814/4500], Training Loss: 0.0000\n",
      "Epoch [3814/4500], Validation Loss: 0.3067\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3815/4500], Training Loss: 0.0000\n",
      "Epoch [3815/4500], Validation Loss: 0.3067\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3816/4500], Training Loss: 0.0000\n",
      "Epoch [3816/4500], Validation Loss: 0.3067\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3817/4500], Training Loss: 0.0000\n",
      "Epoch [3817/4500], Validation Loss: 0.3067\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3818/4500], Training Loss: 0.0000\n",
      "Epoch [3818/4500], Validation Loss: 0.3068\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3819/4500], Training Loss: 0.0000\n",
      "Epoch [3819/4500], Validation Loss: 0.3069\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3820/4500], Training Loss: 0.0000\n",
      "Epoch [3820/4500], Validation Loss: 0.3068\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3821/4500], Training Loss: 0.0000\n",
      "Epoch [3821/4500], Validation Loss: 0.3067\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3822/4500], Training Loss: 0.0000\n",
      "Epoch [3822/4500], Validation Loss: 0.3068\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3823/4500], Training Loss: 0.0000\n",
      "Epoch [3823/4500], Validation Loss: 0.3068\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3824/4500], Training Loss: 0.0000\n",
      "Epoch [3824/4500], Validation Loss: 0.3069\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3825/4500], Training Loss: 0.0000\n",
      "Epoch [3825/4500], Validation Loss: 0.3069\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3826/4500], Training Loss: 0.0000\n",
      "Epoch [3826/4500], Validation Loss: 0.3069\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3827/4500], Training Loss: 0.0000\n",
      "Epoch [3827/4500], Validation Loss: 0.3069\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3828/4500], Training Loss: 0.0000\n",
      "Epoch [3828/4500], Validation Loss: 0.3071\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3829/4500], Training Loss: 0.0000\n",
      "Epoch [3829/4500], Validation Loss: 0.3070\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3830/4500], Training Loss: 0.0000\n",
      "Epoch [3830/4500], Validation Loss: 0.3069\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3831/4500], Training Loss: 0.0000\n",
      "Epoch [3831/4500], Validation Loss: 0.3069\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3832/4500], Training Loss: 0.0000\n",
      "Epoch [3832/4500], Validation Loss: 0.3070\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3833/4500], Training Loss: 0.0000\n",
      "Epoch [3833/4500], Validation Loss: 0.3070\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3834/4500], Training Loss: 0.0000\n",
      "Epoch [3834/4500], Validation Loss: 0.3070\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3835/4500], Training Loss: 0.0000\n",
      "Epoch [3835/4500], Validation Loss: 0.3071\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3836/4500], Training Loss: 0.0000\n",
      "Epoch [3836/4500], Validation Loss: 0.3072\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3837/4500], Training Loss: 0.0000\n",
      "Epoch [3837/4500], Validation Loss: 0.3070\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3838/4500], Training Loss: 0.0000\n",
      "Epoch [3838/4500], Validation Loss: 0.3070\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3839/4500], Training Loss: 0.0000\n",
      "Epoch [3839/4500], Validation Loss: 0.3073\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3840/4500], Training Loss: 0.0000\n",
      "Epoch [3840/4500], Validation Loss: 0.3071\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3841/4500], Training Loss: 0.0000\n",
      "Epoch [3841/4500], Validation Loss: 0.3072\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3842/4500], Training Loss: 0.0000\n",
      "Epoch [3842/4500], Validation Loss: 0.3071\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3843/4500], Training Loss: 0.0000\n",
      "Epoch [3843/4500], Validation Loss: 0.3072\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3844/4500], Training Loss: 0.0000\n",
      "Epoch [3844/4500], Validation Loss: 0.3072\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3845/4500], Training Loss: 0.0000\n",
      "Epoch [3845/4500], Validation Loss: 0.3072\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3846/4500], Training Loss: 0.0000\n",
      "Epoch [3846/4500], Validation Loss: 0.3072\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3847/4500], Training Loss: 0.0000\n",
      "Epoch [3847/4500], Validation Loss: 0.3073\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3848/4500], Training Loss: 0.0000\n",
      "Epoch [3848/4500], Validation Loss: 0.3074\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3849/4500], Training Loss: 0.0000\n",
      "Epoch [3849/4500], Validation Loss: 0.3072\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3850/4500], Training Loss: 0.0000\n",
      "Epoch [3850/4500], Validation Loss: 0.3073\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3851/4500], Training Loss: 0.0000\n",
      "Epoch [3851/4500], Validation Loss: 0.3073\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3852/4500], Training Loss: 0.0000\n",
      "Epoch [3852/4500], Validation Loss: 0.3074\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3853/4500], Training Loss: 0.0000\n",
      "Epoch [3853/4500], Validation Loss: 0.3074\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3854/4500], Training Loss: 0.0000\n",
      "Epoch [3854/4500], Validation Loss: 0.3075\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3855/4500], Training Loss: 0.0000\n",
      "Epoch [3855/4500], Validation Loss: 0.3073\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3856/4500], Training Loss: 0.0000\n",
      "Epoch [3856/4500], Validation Loss: 0.3073\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3857/4500], Training Loss: 0.0000\n",
      "Epoch [3857/4500], Validation Loss: 0.3074\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3858/4500], Training Loss: 0.0000\n",
      "Epoch [3858/4500], Validation Loss: 0.3075\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3859/4500], Training Loss: 0.0000\n",
      "Epoch [3859/4500], Validation Loss: 0.3075\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3860/4500], Training Loss: 0.0000\n",
      "Epoch [3860/4500], Validation Loss: 0.3074\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3861/4500], Training Loss: 0.0000\n",
      "Epoch [3861/4500], Validation Loss: 0.3076\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3862/4500], Training Loss: 0.0000\n",
      "Epoch [3862/4500], Validation Loss: 0.3075\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3863/4500], Training Loss: 0.0000\n",
      "Epoch [3863/4500], Validation Loss: 0.3075\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3864/4500], Training Loss: 0.0000\n",
      "Epoch [3864/4500], Validation Loss: 0.3076\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3865/4500], Training Loss: 0.0000\n",
      "Epoch [3865/4500], Validation Loss: 0.3075\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3866/4500], Training Loss: 0.0000\n",
      "Epoch [3866/4500], Validation Loss: 0.3076\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3867/4500], Training Loss: 0.0000\n",
      "Epoch [3867/4500], Validation Loss: 0.3077\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3868/4500], Training Loss: 0.0000\n",
      "Epoch [3868/4500], Validation Loss: 0.3076\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3869/4500], Training Loss: 0.0000\n",
      "Epoch [3869/4500], Validation Loss: 0.3077\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3870/4500], Training Loss: 0.0000\n",
      "Epoch [3870/4500], Validation Loss: 0.3077\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3871/4500], Training Loss: 0.0000\n",
      "Epoch [3871/4500], Validation Loss: 0.3076\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3872/4500], Training Loss: 0.0000\n",
      "Epoch [3872/4500], Validation Loss: 0.3078\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3873/4500], Training Loss: 0.0000\n",
      "Epoch [3873/4500], Validation Loss: 0.3077\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3874/4500], Training Loss: 0.0000\n",
      "Epoch [3874/4500], Validation Loss: 0.3077\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3875/4500], Training Loss: 0.0000\n",
      "Epoch [3875/4500], Validation Loss: 0.3078\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3876/4500], Training Loss: 0.0000\n",
      "Epoch [3876/4500], Validation Loss: 0.3078\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3877/4500], Training Loss: 0.0000\n",
      "Epoch [3877/4500], Validation Loss: 0.3077\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3878/4500], Training Loss: 0.0000\n",
      "Epoch [3878/4500], Validation Loss: 0.3078\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3879/4500], Training Loss: 0.0000\n",
      "Epoch [3879/4500], Validation Loss: 0.3078\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3880/4500], Training Loss: 0.0000\n",
      "Epoch [3880/4500], Validation Loss: 0.3079\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3881/4500], Training Loss: 0.0000\n",
      "Epoch [3881/4500], Validation Loss: 0.3079\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3882/4500], Training Loss: 0.0000\n",
      "Epoch [3882/4500], Validation Loss: 0.3078\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3883/4500], Training Loss: 0.0000\n",
      "Epoch [3883/4500], Validation Loss: 0.3079\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3884/4500], Training Loss: 0.0000\n",
      "Epoch [3884/4500], Validation Loss: 0.3080\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3885/4500], Training Loss: 0.0000\n",
      "Epoch [3885/4500], Validation Loss: 0.3079\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3886/4500], Training Loss: 0.0000\n",
      "Epoch [3886/4500], Validation Loss: 0.3078\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3887/4500], Training Loss: 0.0000\n",
      "Epoch [3887/4500], Validation Loss: 0.3080\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3888/4500], Training Loss: 0.0000\n",
      "Epoch [3888/4500], Validation Loss: 0.3080\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3889/4500], Training Loss: 0.0000\n",
      "Epoch [3889/4500], Validation Loss: 0.3080\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3890/4500], Training Loss: 0.0000\n",
      "Epoch [3890/4500], Validation Loss: 0.3079\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3891/4500], Training Loss: 0.0000\n",
      "Epoch [3891/4500], Validation Loss: 0.3080\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3892/4500], Training Loss: 0.0000\n",
      "Epoch [3892/4500], Validation Loss: 0.3082\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3893/4500], Training Loss: 0.0000\n",
      "Epoch [3893/4500], Validation Loss: 0.3081\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3894/4500], Training Loss: 0.0000\n",
      "Epoch [3894/4500], Validation Loss: 0.3080\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3895/4500], Training Loss: 0.0000\n",
      "Epoch [3895/4500], Validation Loss: 0.3081\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3896/4500], Training Loss: 0.0000\n",
      "Epoch [3896/4500], Validation Loss: 0.3081\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3897/4500], Training Loss: 0.0000\n",
      "Epoch [3897/4500], Validation Loss: 0.3082\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3898/4500], Training Loss: 0.0000\n",
      "Epoch [3898/4500], Validation Loss: 0.3082\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3899/4500], Training Loss: 0.0000\n",
      "Epoch [3899/4500], Validation Loss: 0.3081\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3900/4500], Training Loss: 0.0000\n",
      "Epoch [3900/4500], Validation Loss: 0.3083\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3901/4500], Training Loss: 0.0000\n",
      "Epoch [3901/4500], Validation Loss: 0.3082\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3902/4500], Training Loss: 0.0000\n",
      "Epoch [3902/4500], Validation Loss: 0.3082\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3903/4500], Training Loss: 0.0000\n",
      "Epoch [3903/4500], Validation Loss: 0.3082\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3904/4500], Training Loss: 0.0000\n",
      "Epoch [3904/4500], Validation Loss: 0.3083\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3905/4500], Training Loss: 0.0000\n",
      "Epoch [3905/4500], Validation Loss: 0.3081\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3906/4500], Training Loss: 0.0000\n",
      "Epoch [3906/4500], Validation Loss: 0.3084\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3907/4500], Training Loss: 0.0000\n",
      "Epoch [3907/4500], Validation Loss: 0.3083\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3908/4500], Training Loss: 0.0000\n",
      "Epoch [3908/4500], Validation Loss: 0.3082\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3909/4500], Training Loss: 0.0000\n",
      "Epoch [3909/4500], Validation Loss: 0.3084\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3910/4500], Training Loss: 0.0000\n",
      "Epoch [3910/4500], Validation Loss: 0.3083\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3911/4500], Training Loss: 0.0000\n",
      "Epoch [3911/4500], Validation Loss: 0.3083\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3912/4500], Training Loss: 0.0000\n",
      "Epoch [3912/4500], Validation Loss: 0.3085\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3913/4500], Training Loss: 0.0000\n",
      "Epoch [3913/4500], Validation Loss: 0.3085\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3914/4500], Training Loss: 0.0000\n",
      "Epoch [3914/4500], Validation Loss: 0.3085\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3915/4500], Training Loss: 0.0000\n",
      "Epoch [3915/4500], Validation Loss: 0.3085\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3916/4500], Training Loss: 0.0000\n",
      "Epoch [3916/4500], Validation Loss: 0.3084\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3917/4500], Training Loss: 0.0000\n",
      "Epoch [3917/4500], Validation Loss: 0.3084\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3918/4500], Training Loss: 0.0000\n",
      "Epoch [3918/4500], Validation Loss: 0.3084\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3919/4500], Training Loss: 0.0000\n",
      "Epoch [3919/4500], Validation Loss: 0.3086\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3920/4500], Training Loss: 0.0000\n",
      "Epoch [3920/4500], Validation Loss: 0.3084\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3921/4500], Training Loss: 0.0000\n",
      "Epoch [3921/4500], Validation Loss: 0.3086\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3922/4500], Training Loss: 0.0000\n",
      "Epoch [3922/4500], Validation Loss: 0.3086\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3923/4500], Training Loss: 0.0000\n",
      "Epoch [3923/4500], Validation Loss: 0.3085\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3924/4500], Training Loss: 0.0000\n",
      "Epoch [3924/4500], Validation Loss: 0.3087\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3925/4500], Training Loss: 0.0000\n",
      "Epoch [3925/4500], Validation Loss: 0.3087\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3926/4500], Training Loss: 0.0000\n",
      "Epoch [3926/4500], Validation Loss: 0.3086\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3927/4500], Training Loss: 0.0000\n",
      "Epoch [3927/4500], Validation Loss: 0.3086\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3928/4500], Training Loss: 0.0000\n",
      "Epoch [3928/4500], Validation Loss: 0.3086\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3929/4500], Training Loss: 0.0000\n",
      "Epoch [3929/4500], Validation Loss: 0.3088\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3930/4500], Training Loss: 0.0000\n",
      "Epoch [3930/4500], Validation Loss: 0.3086\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3931/4500], Training Loss: 0.0000\n",
      "Epoch [3931/4500], Validation Loss: 0.3087\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3932/4500], Training Loss: 0.0000\n",
      "Epoch [3932/4500], Validation Loss: 0.3088\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3933/4500], Training Loss: 0.0000\n",
      "Epoch [3933/4500], Validation Loss: 0.3087\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3934/4500], Training Loss: 0.0000\n",
      "Epoch [3934/4500], Validation Loss: 0.3088\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3935/4500], Training Loss: 0.0000\n",
      "Epoch [3935/4500], Validation Loss: 0.3087\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3936/4500], Training Loss: 0.0000\n",
      "Epoch [3936/4500], Validation Loss: 0.3088\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3937/4500], Training Loss: 0.0000\n",
      "Epoch [3937/4500], Validation Loss: 0.3088\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3938/4500], Training Loss: 0.0000\n",
      "Epoch [3938/4500], Validation Loss: 0.3089\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3939/4500], Training Loss: 0.0000\n",
      "Epoch [3939/4500], Validation Loss: 0.3089\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3940/4500], Training Loss: 0.0000\n",
      "Epoch [3940/4500], Validation Loss: 0.3088\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3941/4500], Training Loss: 0.0000\n",
      "Epoch [3941/4500], Validation Loss: 0.3088\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3942/4500], Training Loss: 0.0000\n",
      "Epoch [3942/4500], Validation Loss: 0.3090\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3943/4500], Training Loss: 0.0000\n",
      "Epoch [3943/4500], Validation Loss: 0.3090\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3944/4500], Training Loss: 0.0000\n",
      "Epoch [3944/4500], Validation Loss: 0.3089\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3945/4500], Training Loss: 0.0000\n",
      "Epoch [3945/4500], Validation Loss: 0.3090\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3946/4500], Training Loss: 0.0000\n",
      "Epoch [3946/4500], Validation Loss: 0.3090\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3947/4500], Training Loss: 0.0000\n",
      "Epoch [3947/4500], Validation Loss: 0.3090\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3948/4500], Training Loss: 0.0000\n",
      "Epoch [3948/4500], Validation Loss: 0.3090\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3949/4500], Training Loss: 0.0000\n",
      "Epoch [3949/4500], Validation Loss: 0.3089\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3950/4500], Training Loss: 0.0000\n",
      "Epoch [3950/4500], Validation Loss: 0.3091\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3951/4500], Training Loss: 0.0000\n",
      "Epoch [3951/4500], Validation Loss: 0.3091\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3952/4500], Training Loss: 0.0000\n",
      "Epoch [3952/4500], Validation Loss: 0.3092\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3953/4500], Training Loss: 0.0000\n",
      "Epoch [3953/4500], Validation Loss: 0.3091\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3954/4500], Training Loss: 0.0000\n",
      "Epoch [3954/4500], Validation Loss: 0.3090\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3955/4500], Training Loss: 0.0000\n",
      "Epoch [3955/4500], Validation Loss: 0.3091\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3956/4500], Training Loss: 0.0000\n",
      "Epoch [3956/4500], Validation Loss: 0.3092\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3957/4500], Training Loss: 0.0000\n",
      "Epoch [3957/4500], Validation Loss: 0.3091\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3958/4500], Training Loss: 0.0000\n",
      "Epoch [3958/4500], Validation Loss: 0.3093\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3959/4500], Training Loss: 0.0000\n",
      "Epoch [3959/4500], Validation Loss: 0.3091\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3960/4500], Training Loss: 0.0000\n",
      "Epoch [3960/4500], Validation Loss: 0.3092\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3961/4500], Training Loss: 0.0000\n",
      "Epoch [3961/4500], Validation Loss: 0.3093\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3962/4500], Training Loss: 0.0000\n",
      "Epoch [3962/4500], Validation Loss: 0.3093\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3963/4500], Training Loss: 0.0000\n",
      "Epoch [3963/4500], Validation Loss: 0.3092\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3964/4500], Training Loss: 0.0000\n",
      "Epoch [3964/4500], Validation Loss: 0.3092\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3965/4500], Training Loss: 0.0000\n",
      "Epoch [3965/4500], Validation Loss: 0.3092\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3966/4500], Training Loss: 0.0000\n",
      "Epoch [3966/4500], Validation Loss: 0.3094\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3967/4500], Training Loss: 0.0000\n",
      "Epoch [3967/4500], Validation Loss: 0.3093\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3968/4500], Training Loss: 0.0000\n",
      "Epoch [3968/4500], Validation Loss: 0.3093\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3969/4500], Training Loss: 0.0000\n",
      "Epoch [3969/4500], Validation Loss: 0.3093\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3970/4500], Training Loss: 0.0000\n",
      "Epoch [3970/4500], Validation Loss: 0.3094\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3971/4500], Training Loss: 0.0000\n",
      "Epoch [3971/4500], Validation Loss: 0.3095\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3972/4500], Training Loss: 0.0000\n",
      "Epoch [3972/4500], Validation Loss: 0.3094\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3973/4500], Training Loss: 0.0000\n",
      "Epoch [3973/4500], Validation Loss: 0.3094\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3974/4500], Training Loss: 0.0000\n",
      "Epoch [3974/4500], Validation Loss: 0.3094\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3975/4500], Training Loss: 0.0000\n",
      "Epoch [3975/4500], Validation Loss: 0.3095\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3976/4500], Training Loss: 0.0000\n",
      "Epoch [3976/4500], Validation Loss: 0.3094\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3977/4500], Training Loss: 0.0000\n",
      "Epoch [3977/4500], Validation Loss: 0.3096\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3978/4500], Training Loss: 0.0000\n",
      "Epoch [3978/4500], Validation Loss: 0.3095\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3979/4500], Training Loss: 0.0000\n",
      "Epoch [3979/4500], Validation Loss: 0.3097\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3980/4500], Training Loss: 0.0000\n",
      "Epoch [3980/4500], Validation Loss: 0.3096\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3981/4500], Training Loss: 0.0000\n",
      "Epoch [3981/4500], Validation Loss: 0.3095\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3982/4500], Training Loss: 0.0000\n",
      "Epoch [3982/4500], Validation Loss: 0.3096\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3983/4500], Training Loss: 0.0000\n",
      "Epoch [3983/4500], Validation Loss: 0.3096\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3984/4500], Training Loss: 0.0000\n",
      "Epoch [3984/4500], Validation Loss: 0.3097\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3985/4500], Training Loss: 0.0000\n",
      "Epoch [3985/4500], Validation Loss: 0.3096\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3986/4500], Training Loss: 0.0000\n",
      "Epoch [3986/4500], Validation Loss: 0.3096\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3987/4500], Training Loss: 0.0000\n",
      "Epoch [3987/4500], Validation Loss: 0.3097\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3988/4500], Training Loss: 0.0000\n",
      "Epoch [3988/4500], Validation Loss: 0.3097\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3989/4500], Training Loss: 0.0000\n",
      "Epoch [3989/4500], Validation Loss: 0.3097\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3990/4500], Training Loss: 0.0000\n",
      "Epoch [3990/4500], Validation Loss: 0.3097\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3991/4500], Training Loss: 0.0000\n",
      "Epoch [3991/4500], Validation Loss: 0.3096\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3992/4500], Training Loss: 0.0000\n",
      "Epoch [3992/4500], Validation Loss: 0.3099\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3993/4500], Training Loss: 0.0000\n",
      "Epoch [3993/4500], Validation Loss: 0.3098\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3994/4500], Training Loss: 0.0000\n",
      "Epoch [3994/4500], Validation Loss: 0.3099\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3995/4500], Training Loss: 0.0000\n",
      "Epoch [3995/4500], Validation Loss: 0.3098\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3996/4500], Training Loss: 0.0000\n",
      "Epoch [3996/4500], Validation Loss: 0.3098\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3997/4500], Training Loss: 0.0000\n",
      "Epoch [3997/4500], Validation Loss: 0.3098\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3998/4500], Training Loss: 0.0000\n",
      "Epoch [3998/4500], Validation Loss: 0.3099\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [3999/4500], Training Loss: 0.0000\n",
      "Epoch [3999/4500], Validation Loss: 0.3099\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4000/4500], Training Loss: 0.0000\n",
      "Epoch [4000/4500], Validation Loss: 0.3098\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4001/4500], Training Loss: 0.0000\n",
      "Epoch [4001/4500], Validation Loss: 0.3099\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4002/4500], Training Loss: 0.0000\n",
      "Epoch [4002/4500], Validation Loss: 0.3099\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4003/4500], Training Loss: 0.0000\n",
      "Epoch [4003/4500], Validation Loss: 0.3099\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4004/4500], Training Loss: 0.0000\n",
      "Epoch [4004/4500], Validation Loss: 0.3100\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4005/4500], Training Loss: 0.0000\n",
      "Epoch [4005/4500], Validation Loss: 0.3100\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4006/4500], Training Loss: 0.0000\n",
      "Epoch [4006/4500], Validation Loss: 0.3101\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4007/4500], Training Loss: 0.0000\n",
      "Epoch [4007/4500], Validation Loss: 0.3100\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4008/4500], Training Loss: 0.0000\n",
      "Epoch [4008/4500], Validation Loss: 0.3099\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4009/4500], Training Loss: 0.0000\n",
      "Epoch [4009/4500], Validation Loss: 0.3101\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4010/4500], Training Loss: 0.0000\n",
      "Epoch [4010/4500], Validation Loss: 0.3101\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4011/4500], Training Loss: 0.0000\n",
      "Epoch [4011/4500], Validation Loss: 0.3102\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4012/4500], Training Loss: 0.0000\n",
      "Epoch [4012/4500], Validation Loss: 0.3102\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4013/4500], Training Loss: 0.0000\n",
      "Epoch [4013/4500], Validation Loss: 0.3102\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4014/4500], Training Loss: 0.0000\n",
      "Epoch [4014/4500], Validation Loss: 0.3101\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4015/4500], Training Loss: 0.0000\n",
      "Epoch [4015/4500], Validation Loss: 0.3101\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4016/4500], Training Loss: 0.0000\n",
      "Epoch [4016/4500], Validation Loss: 0.3102\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4017/4500], Training Loss: 0.0000\n",
      "Epoch [4017/4500], Validation Loss: 0.3103\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4018/4500], Training Loss: 0.0000\n",
      "Epoch [4018/4500], Validation Loss: 0.3102\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4019/4500], Training Loss: 0.0000\n",
      "Epoch [4019/4500], Validation Loss: 0.3102\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4020/4500], Training Loss: 0.0000\n",
      "Epoch [4020/4500], Validation Loss: 0.3102\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4021/4500], Training Loss: 0.0000\n",
      "Epoch [4021/4500], Validation Loss: 0.3102\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4022/4500], Training Loss: 0.0000\n",
      "Epoch [4022/4500], Validation Loss: 0.3103\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4023/4500], Training Loss: 0.0000\n",
      "Epoch [4023/4500], Validation Loss: 0.3105\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4024/4500], Training Loss: 0.0000\n",
      "Epoch [4024/4500], Validation Loss: 0.3102\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4025/4500], Training Loss: 0.0000\n",
      "Epoch [4025/4500], Validation Loss: 0.3103\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4026/4500], Training Loss: 0.0000\n",
      "Epoch [4026/4500], Validation Loss: 0.3105\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4027/4500], Training Loss: 0.0000\n",
      "Epoch [4027/4500], Validation Loss: 0.3105\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4028/4500], Training Loss: 0.0000\n",
      "Epoch [4028/4500], Validation Loss: 0.3103\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4029/4500], Training Loss: 0.0000\n",
      "Epoch [4029/4500], Validation Loss: 0.3105\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4030/4500], Training Loss: 0.0000\n",
      "Epoch [4030/4500], Validation Loss: 0.3104\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4031/4500], Training Loss: 0.0000\n",
      "Epoch [4031/4500], Validation Loss: 0.3105\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4032/4500], Training Loss: 0.0000\n",
      "Epoch [4032/4500], Validation Loss: 0.3104\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4033/4500], Training Loss: 0.0000\n",
      "Epoch [4033/4500], Validation Loss: 0.3105\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4034/4500], Training Loss: 0.0000\n",
      "Epoch [4034/4500], Validation Loss: 0.3105\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4035/4500], Training Loss: 0.0000\n",
      "Epoch [4035/4500], Validation Loss: 0.3105\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4036/4500], Training Loss: 0.0000\n",
      "Epoch [4036/4500], Validation Loss: 0.3106\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4037/4500], Training Loss: 0.0000\n",
      "Epoch [4037/4500], Validation Loss: 0.3105\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4038/4500], Training Loss: 0.0000\n",
      "Epoch [4038/4500], Validation Loss: 0.3107\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4039/4500], Training Loss: 0.0000\n",
      "Epoch [4039/4500], Validation Loss: 0.3107\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4040/4500], Training Loss: 0.0000\n",
      "Epoch [4040/4500], Validation Loss: 0.3106\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4041/4500], Training Loss: 0.0000\n",
      "Epoch [4041/4500], Validation Loss: 0.3106\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4042/4500], Training Loss: 0.0000\n",
      "Epoch [4042/4500], Validation Loss: 0.3105\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4043/4500], Training Loss: 0.0000\n",
      "Epoch [4043/4500], Validation Loss: 0.3107\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4044/4500], Training Loss: 0.0000\n",
      "Epoch [4044/4500], Validation Loss: 0.3107\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4045/4500], Training Loss: 0.0000\n",
      "Epoch [4045/4500], Validation Loss: 0.3107\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4046/4500], Training Loss: 0.0000\n",
      "Epoch [4046/4500], Validation Loss: 0.3107\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4047/4500], Training Loss: 0.0000\n",
      "Epoch [4047/4500], Validation Loss: 0.3107\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4048/4500], Training Loss: 0.0000\n",
      "Epoch [4048/4500], Validation Loss: 0.3107\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4049/4500], Training Loss: 0.0000\n",
      "Epoch [4049/4500], Validation Loss: 0.3109\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4050/4500], Training Loss: 0.0000\n",
      "Epoch [4050/4500], Validation Loss: 0.3108\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4051/4500], Training Loss: 0.0000\n",
      "Epoch [4051/4500], Validation Loss: 0.3108\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4052/4500], Training Loss: 0.0000\n",
      "Epoch [4052/4500], Validation Loss: 0.3109\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4053/4500], Training Loss: 0.0000\n",
      "Epoch [4053/4500], Validation Loss: 0.3108\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4054/4500], Training Loss: 0.0000\n",
      "Epoch [4054/4500], Validation Loss: 0.3109\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4055/4500], Training Loss: 0.0000\n",
      "Epoch [4055/4500], Validation Loss: 0.3109\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4056/4500], Training Loss: 0.0000\n",
      "Epoch [4056/4500], Validation Loss: 0.3109\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4057/4500], Training Loss: 0.0000\n",
      "Epoch [4057/4500], Validation Loss: 0.3110\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4058/4500], Training Loss: 0.0000\n",
      "Epoch [4058/4500], Validation Loss: 0.3110\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4059/4500], Training Loss: 0.0000\n",
      "Epoch [4059/4500], Validation Loss: 0.3110\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4060/4500], Training Loss: 0.0000\n",
      "Epoch [4060/4500], Validation Loss: 0.3110\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4061/4500], Training Loss: 0.0000\n",
      "Epoch [4061/4500], Validation Loss: 0.3109\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4062/4500], Training Loss: 0.0000\n",
      "Epoch [4062/4500], Validation Loss: 0.3110\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4063/4500], Training Loss: 0.0000\n",
      "Epoch [4063/4500], Validation Loss: 0.3110\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4064/4500], Training Loss: 0.0000\n",
      "Epoch [4064/4500], Validation Loss: 0.3110\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4065/4500], Training Loss: 0.0000\n",
      "Epoch [4065/4500], Validation Loss: 0.3110\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4066/4500], Training Loss: 0.0000\n",
      "Epoch [4066/4500], Validation Loss: 0.3111\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4067/4500], Training Loss: 0.0000\n",
      "Epoch [4067/4500], Validation Loss: 0.3111\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4068/4500], Training Loss: 0.0000\n",
      "Epoch [4068/4500], Validation Loss: 0.3112\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4069/4500], Training Loss: 0.0000\n",
      "Epoch [4069/4500], Validation Loss: 0.3111\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4070/4500], Training Loss: 0.0000\n",
      "Epoch [4070/4500], Validation Loss: 0.3110\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4071/4500], Training Loss: 0.0000\n",
      "Epoch [4071/4500], Validation Loss: 0.3112\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4072/4500], Training Loss: 0.0000\n",
      "Epoch [4072/4500], Validation Loss: 0.3112\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4073/4500], Training Loss: 0.0000\n",
      "Epoch [4073/4500], Validation Loss: 0.3113\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4074/4500], Training Loss: 0.0000\n",
      "Epoch [4074/4500], Validation Loss: 0.3111\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4075/4500], Training Loss: 0.0000\n",
      "Epoch [4075/4500], Validation Loss: 0.3112\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4076/4500], Training Loss: 0.0000\n",
      "Epoch [4076/4500], Validation Loss: 0.3111\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4077/4500], Training Loss: 0.0000\n",
      "Epoch [4077/4500], Validation Loss: 0.3113\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4078/4500], Training Loss: 0.0000\n",
      "Epoch [4078/4500], Validation Loss: 0.3113\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4079/4500], Training Loss: 0.0000\n",
      "Epoch [4079/4500], Validation Loss: 0.3114\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4080/4500], Training Loss: 0.0000\n",
      "Epoch [4080/4500], Validation Loss: 0.3114\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4081/4500], Training Loss: 0.0000\n",
      "Epoch [4081/4500], Validation Loss: 0.3113\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4082/4500], Training Loss: 0.0000\n",
      "Epoch [4082/4500], Validation Loss: 0.3113\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4083/4500], Training Loss: 0.0000\n",
      "Epoch [4083/4500], Validation Loss: 0.3113\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4084/4500], Training Loss: 0.0000\n",
      "Epoch [4084/4500], Validation Loss: 0.3114\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4085/4500], Training Loss: 0.0000\n",
      "Epoch [4085/4500], Validation Loss: 0.3114\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4086/4500], Training Loss: 0.0000\n",
      "Epoch [4086/4500], Validation Loss: 0.3115\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4087/4500], Training Loss: 0.0000\n",
      "Epoch [4087/4500], Validation Loss: 0.3114\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4088/4500], Training Loss: 0.0000\n",
      "Epoch [4088/4500], Validation Loss: 0.3114\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4089/4500], Training Loss: 0.0000\n",
      "Epoch [4089/4500], Validation Loss: 0.3115\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4090/4500], Training Loss: 0.0000\n",
      "Epoch [4090/4500], Validation Loss: 0.3115\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4091/4500], Training Loss: 0.0000\n",
      "Epoch [4091/4500], Validation Loss: 0.3116\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4092/4500], Training Loss: 0.0000\n",
      "Epoch [4092/4500], Validation Loss: 0.3114\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4093/4500], Training Loss: 0.0000\n",
      "Epoch [4093/4500], Validation Loss: 0.3116\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4094/4500], Training Loss: 0.0000\n",
      "Epoch [4094/4500], Validation Loss: 0.3116\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4095/4500], Training Loss: 0.0000\n",
      "Epoch [4095/4500], Validation Loss: 0.3116\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4096/4500], Training Loss: 0.0000\n",
      "Epoch [4096/4500], Validation Loss: 0.3115\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4097/4500], Training Loss: 0.0000\n",
      "Epoch [4097/4500], Validation Loss: 0.3116\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4098/4500], Training Loss: 0.0000\n",
      "Epoch [4098/4500], Validation Loss: 0.3117\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4099/4500], Training Loss: 0.0000\n",
      "Epoch [4099/4500], Validation Loss: 0.3117\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4100/4500], Training Loss: 0.0000\n",
      "Epoch [4100/4500], Validation Loss: 0.3116\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4101/4500], Training Loss: 0.0000\n",
      "Epoch [4101/4500], Validation Loss: 0.3117\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4102/4500], Training Loss: 0.0000\n",
      "Epoch [4102/4500], Validation Loss: 0.3118\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4103/4500], Training Loss: 0.0000\n",
      "Epoch [4103/4500], Validation Loss: 0.3116\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4104/4500], Training Loss: 0.0000\n",
      "Epoch [4104/4500], Validation Loss: 0.3117\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4105/4500], Training Loss: 0.0000\n",
      "Epoch [4105/4500], Validation Loss: 0.3117\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4106/4500], Training Loss: 0.0000\n",
      "Epoch [4106/4500], Validation Loss: 0.3118\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4107/4500], Training Loss: 0.0000\n",
      "Epoch [4107/4500], Validation Loss: 0.3118\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4108/4500], Training Loss: 0.0000\n",
      "Epoch [4108/4500], Validation Loss: 0.3118\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4109/4500], Training Loss: 0.0000\n",
      "Epoch [4109/4500], Validation Loss: 0.3119\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4110/4500], Training Loss: 0.0000\n",
      "Epoch [4110/4500], Validation Loss: 0.3119\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4111/4500], Training Loss: 0.0000\n",
      "Epoch [4111/4500], Validation Loss: 0.3118\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4112/4500], Training Loss: 0.0000\n",
      "Epoch [4112/4500], Validation Loss: 0.3119\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4113/4500], Training Loss: 0.0000\n",
      "Epoch [4113/4500], Validation Loss: 0.3118\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4114/4500], Training Loss: 0.0000\n",
      "Epoch [4114/4500], Validation Loss: 0.3119\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4115/4500], Training Loss: 0.0000\n",
      "Epoch [4115/4500], Validation Loss: 0.3119\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4116/4500], Training Loss: 0.0000\n",
      "Epoch [4116/4500], Validation Loss: 0.3119\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4117/4500], Training Loss: 0.0000\n",
      "Epoch [4117/4500], Validation Loss: 0.3119\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4118/4500], Training Loss: 0.0000\n",
      "Epoch [4118/4500], Validation Loss: 0.3119\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4119/4500], Training Loss: 0.0000\n",
      "Epoch [4119/4500], Validation Loss: 0.3119\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4120/4500], Training Loss: 0.0000\n",
      "Epoch [4120/4500], Validation Loss: 0.3119\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4121/4500], Training Loss: 0.0000\n",
      "Epoch [4121/4500], Validation Loss: 0.3120\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4122/4500], Training Loss: 0.0000\n",
      "Epoch [4122/4500], Validation Loss: 0.3120\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4123/4500], Training Loss: 0.0000\n",
      "Epoch [4123/4500], Validation Loss: 0.3121\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4124/4500], Training Loss: 0.0000\n",
      "Epoch [4124/4500], Validation Loss: 0.3121\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4125/4500], Training Loss: 0.0000\n",
      "Epoch [4125/4500], Validation Loss: 0.3121\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4126/4500], Training Loss: 0.0000\n",
      "Epoch [4126/4500], Validation Loss: 0.3120\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4127/4500], Training Loss: 0.0000\n",
      "Epoch [4127/4500], Validation Loss: 0.3122\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4128/4500], Training Loss: 0.0000\n",
      "Epoch [4128/4500], Validation Loss: 0.3122\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4129/4500], Training Loss: 0.0000\n",
      "Epoch [4129/4500], Validation Loss: 0.3121\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4130/4500], Training Loss: 0.0000\n",
      "Epoch [4130/4500], Validation Loss: 0.3121\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4131/4500], Training Loss: 0.0000\n",
      "Epoch [4131/4500], Validation Loss: 0.3122\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4132/4500], Training Loss: 0.0000\n",
      "Epoch [4132/4500], Validation Loss: 0.3122\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4133/4500], Training Loss: 0.0000\n",
      "Epoch [4133/4500], Validation Loss: 0.3123\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4134/4500], Training Loss: 0.0000\n",
      "Epoch [4134/4500], Validation Loss: 0.3122\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4135/4500], Training Loss: 0.0000\n",
      "Epoch [4135/4500], Validation Loss: 0.3121\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4136/4500], Training Loss: 0.0000\n",
      "Epoch [4136/4500], Validation Loss: 0.3124\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4137/4500], Training Loss: 0.0000\n",
      "Epoch [4137/4500], Validation Loss: 0.3123\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4138/4500], Training Loss: 0.0000\n",
      "Epoch [4138/4500], Validation Loss: 0.3123\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4139/4500], Training Loss: 0.0000\n",
      "Epoch [4139/4500], Validation Loss: 0.3123\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4140/4500], Training Loss: 0.0000\n",
      "Epoch [4140/4500], Validation Loss: 0.3123\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4141/4500], Training Loss: 0.0000\n",
      "Epoch [4141/4500], Validation Loss: 0.3124\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4142/4500], Training Loss: 0.0000\n",
      "Epoch [4142/4500], Validation Loss: 0.3123\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4143/4500], Training Loss: 0.0000\n",
      "Epoch [4143/4500], Validation Loss: 0.3124\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4144/4500], Training Loss: 0.0000\n",
      "Epoch [4144/4500], Validation Loss: 0.3123\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4145/4500], Training Loss: 0.0000\n",
      "Epoch [4145/4500], Validation Loss: 0.3125\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4146/4500], Training Loss: 0.0000\n",
      "Epoch [4146/4500], Validation Loss: 0.3126\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4147/4500], Training Loss: 0.0000\n",
      "Epoch [4147/4500], Validation Loss: 0.3124\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4148/4500], Training Loss: 0.0000\n",
      "Epoch [4148/4500], Validation Loss: 0.3123\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4149/4500], Training Loss: 0.0000\n",
      "Epoch [4149/4500], Validation Loss: 0.3126\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4150/4500], Training Loss: 0.0000\n",
      "Epoch [4150/4500], Validation Loss: 0.3126\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4151/4500], Training Loss: 0.0000\n",
      "Epoch [4151/4500], Validation Loss: 0.3125\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4152/4500], Training Loss: 0.0000\n",
      "Epoch [4152/4500], Validation Loss: 0.3126\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4153/4500], Training Loss: 0.0000\n",
      "Epoch [4153/4500], Validation Loss: 0.3126\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4154/4500], Training Loss: 0.0000\n",
      "Epoch [4154/4500], Validation Loss: 0.3126\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4155/4500], Training Loss: 0.0000\n",
      "Epoch [4155/4500], Validation Loss: 0.3125\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4156/4500], Training Loss: 0.0000\n",
      "Epoch [4156/4500], Validation Loss: 0.3126\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4157/4500], Training Loss: 0.0000\n",
      "Epoch [4157/4500], Validation Loss: 0.3126\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4158/4500], Training Loss: 0.0000\n",
      "Epoch [4158/4500], Validation Loss: 0.3126\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4159/4500], Training Loss: 0.0000\n",
      "Epoch [4159/4500], Validation Loss: 0.3126\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4160/4500], Training Loss: 0.0000\n",
      "Epoch [4160/4500], Validation Loss: 0.3127\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4161/4500], Training Loss: 0.0000\n",
      "Epoch [4161/4500], Validation Loss: 0.3128\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4162/4500], Training Loss: 0.0000\n",
      "Epoch [4162/4500], Validation Loss: 0.3127\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4163/4500], Training Loss: 0.0000\n",
      "Epoch [4163/4500], Validation Loss: 0.3128\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4164/4500], Training Loss: 0.0000\n",
      "Epoch [4164/4500], Validation Loss: 0.3129\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4165/4500], Training Loss: 0.0000\n",
      "Epoch [4165/4500], Validation Loss: 0.3128\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4166/4500], Training Loss: 0.0000\n",
      "Epoch [4166/4500], Validation Loss: 0.3127\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4167/4500], Training Loss: 0.0000\n",
      "Epoch [4167/4500], Validation Loss: 0.3128\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4168/4500], Training Loss: 0.0000\n",
      "Epoch [4168/4500], Validation Loss: 0.3128\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4169/4500], Training Loss: 0.0000\n",
      "Epoch [4169/4500], Validation Loss: 0.3128\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4170/4500], Training Loss: 0.0000\n",
      "Epoch [4170/4500], Validation Loss: 0.3128\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4171/4500], Training Loss: 0.0000\n",
      "Epoch [4171/4500], Validation Loss: 0.3129\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4172/4500], Training Loss: 0.0000\n",
      "Epoch [4172/4500], Validation Loss: 0.3130\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4173/4500], Training Loss: 0.0000\n",
      "Epoch [4173/4500], Validation Loss: 0.3129\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4174/4500], Training Loss: 0.0000\n",
      "Epoch [4174/4500], Validation Loss: 0.3129\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4175/4500], Training Loss: 0.0000\n",
      "Epoch [4175/4500], Validation Loss: 0.3129\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4176/4500], Training Loss: 0.0000\n",
      "Epoch [4176/4500], Validation Loss: 0.3129\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4177/4500], Training Loss: 0.0000\n",
      "Epoch [4177/4500], Validation Loss: 0.3130\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4178/4500], Training Loss: 0.0000\n",
      "Epoch [4178/4500], Validation Loss: 0.3130\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4179/4500], Training Loss: 0.0000\n",
      "Epoch [4179/4500], Validation Loss: 0.3130\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4180/4500], Training Loss: 0.0000\n",
      "Epoch [4180/4500], Validation Loss: 0.3131\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4181/4500], Training Loss: 0.0000\n",
      "Epoch [4181/4500], Validation Loss: 0.3130\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4182/4500], Training Loss: 0.0000\n",
      "Epoch [4182/4500], Validation Loss: 0.3130\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4183/4500], Training Loss: 0.0000\n",
      "Epoch [4183/4500], Validation Loss: 0.3131\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4184/4500], Training Loss: 0.0000\n",
      "Epoch [4184/4500], Validation Loss: 0.3130\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4185/4500], Training Loss: 0.0000\n",
      "Epoch [4185/4500], Validation Loss: 0.3132\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4186/4500], Training Loss: 0.0000\n",
      "Epoch [4186/4500], Validation Loss: 0.3131\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4187/4500], Training Loss: 0.0000\n",
      "Epoch [4187/4500], Validation Loss: 0.3131\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4188/4500], Training Loss: 0.0000\n",
      "Epoch [4188/4500], Validation Loss: 0.3132\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4189/4500], Training Loss: 0.0000\n",
      "Epoch [4189/4500], Validation Loss: 0.3132\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4190/4500], Training Loss: 0.0000\n",
      "Epoch [4190/4500], Validation Loss: 0.3132\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4191/4500], Training Loss: 0.0000\n",
      "Epoch [4191/4500], Validation Loss: 0.3131\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4192/4500], Training Loss: 0.0000\n",
      "Epoch [4192/4500], Validation Loss: 0.3132\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4193/4500], Training Loss: 0.0000\n",
      "Epoch [4193/4500], Validation Loss: 0.3133\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4194/4500], Training Loss: 0.0000\n",
      "Epoch [4194/4500], Validation Loss: 0.3131\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4195/4500], Training Loss: 0.0000\n",
      "Epoch [4195/4500], Validation Loss: 0.3133\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4196/4500], Training Loss: 0.0000\n",
      "Epoch [4196/4500], Validation Loss: 0.3133\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4197/4500], Training Loss: 0.0000\n",
      "Epoch [4197/4500], Validation Loss: 0.3134\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4198/4500], Training Loss: 0.0000\n",
      "Epoch [4198/4500], Validation Loss: 0.3134\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4199/4500], Training Loss: 0.0000\n",
      "Epoch [4199/4500], Validation Loss: 0.3132\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4200/4500], Training Loss: 0.0000\n",
      "Epoch [4200/4500], Validation Loss: 0.3133\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4201/4500], Training Loss: 0.0000\n",
      "Epoch [4201/4500], Validation Loss: 0.3134\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4202/4500], Training Loss: 0.0000\n",
      "Epoch [4202/4500], Validation Loss: 0.3134\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4203/4500], Training Loss: 0.0000\n",
      "Epoch [4203/4500], Validation Loss: 0.3134\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4204/4500], Training Loss: 0.0000\n",
      "Epoch [4204/4500], Validation Loss: 0.3134\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4205/4500], Training Loss: 0.0000\n",
      "Epoch [4205/4500], Validation Loss: 0.3134\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4206/4500], Training Loss: 0.0000\n",
      "Epoch [4206/4500], Validation Loss: 0.3135\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4207/4500], Training Loss: 0.0000\n",
      "Epoch [4207/4500], Validation Loss: 0.3135\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4208/4500], Training Loss: 0.0000\n",
      "Epoch [4208/4500], Validation Loss: 0.3134\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4209/4500], Training Loss: 0.0000\n",
      "Epoch [4209/4500], Validation Loss: 0.3134\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4210/4500], Training Loss: 0.0000\n",
      "Epoch [4210/4500], Validation Loss: 0.3136\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4211/4500], Training Loss: 0.0000\n",
      "Epoch [4211/4500], Validation Loss: 0.3136\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4212/4500], Training Loss: 0.0000\n",
      "Epoch [4212/4500], Validation Loss: 0.3135\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4213/4500], Training Loss: 0.0000\n",
      "Epoch [4213/4500], Validation Loss: 0.3136\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4214/4500], Training Loss: 0.0000\n",
      "Epoch [4214/4500], Validation Loss: 0.3136\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4215/4500], Training Loss: 0.0000\n",
      "Epoch [4215/4500], Validation Loss: 0.3136\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4216/4500], Training Loss: 0.0000\n",
      "Epoch [4216/4500], Validation Loss: 0.3136\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4217/4500], Training Loss: 0.0000\n",
      "Epoch [4217/4500], Validation Loss: 0.3136\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4218/4500], Training Loss: 0.0000\n",
      "Epoch [4218/4500], Validation Loss: 0.3136\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4219/4500], Training Loss: 0.0000\n",
      "Epoch [4219/4500], Validation Loss: 0.3137\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4220/4500], Training Loss: 0.0000\n",
      "Epoch [4220/4500], Validation Loss: 0.3136\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4221/4500], Training Loss: 0.0000\n",
      "Epoch [4221/4500], Validation Loss: 0.3137\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4222/4500], Training Loss: 0.0000\n",
      "Epoch [4222/4500], Validation Loss: 0.3137\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4223/4500], Training Loss: 0.0000\n",
      "Epoch [4223/4500], Validation Loss: 0.3137\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4224/4500], Training Loss: 0.0000\n",
      "Epoch [4224/4500], Validation Loss: 0.3138\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4225/4500], Training Loss: 0.0000\n",
      "Epoch [4225/4500], Validation Loss: 0.3137\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4226/4500], Training Loss: 0.0000\n",
      "Epoch [4226/4500], Validation Loss: 0.3138\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4227/4500], Training Loss: 0.0000\n",
      "Epoch [4227/4500], Validation Loss: 0.3138\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4228/4500], Training Loss: 0.0000\n",
      "Epoch [4228/4500], Validation Loss: 0.3138\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4229/4500], Training Loss: 0.0000\n",
      "Epoch [4229/4500], Validation Loss: 0.3138\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4230/4500], Training Loss: 0.0000\n",
      "Epoch [4230/4500], Validation Loss: 0.3139\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4231/4500], Training Loss: 0.0000\n",
      "Epoch [4231/4500], Validation Loss: 0.3138\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4232/4500], Training Loss: 0.0000\n",
      "Epoch [4232/4500], Validation Loss: 0.3139\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4233/4500], Training Loss: 0.0000\n",
      "Epoch [4233/4500], Validation Loss: 0.3140\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4234/4500], Training Loss: 0.0000\n",
      "Epoch [4234/4500], Validation Loss: 0.3140\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4235/4500], Training Loss: 0.0000\n",
      "Epoch [4235/4500], Validation Loss: 0.3138\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4236/4500], Training Loss: 0.0000\n",
      "Epoch [4236/4500], Validation Loss: 0.3139\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4237/4500], Training Loss: 0.0000\n",
      "Epoch [4237/4500], Validation Loss: 0.3140\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4238/4500], Training Loss: 0.0000\n",
      "Epoch [4238/4500], Validation Loss: 0.3140\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4239/4500], Training Loss: 0.0000\n",
      "Epoch [4239/4500], Validation Loss: 0.3141\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4240/4500], Training Loss: 0.0000\n",
      "Epoch [4240/4500], Validation Loss: 0.3141\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4241/4500], Training Loss: 0.0000\n",
      "Epoch [4241/4500], Validation Loss: 0.3139\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4242/4500], Training Loss: 0.0000\n",
      "Epoch [4242/4500], Validation Loss: 0.3141\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4243/4500], Training Loss: 0.0000\n",
      "Epoch [4243/4500], Validation Loss: 0.3140\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4244/4500], Training Loss: 0.0000\n",
      "Epoch [4244/4500], Validation Loss: 0.3141\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4245/4500], Training Loss: 0.0000\n",
      "Epoch [4245/4500], Validation Loss: 0.3141\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4246/4500], Training Loss: 0.0000\n",
      "Epoch [4246/4500], Validation Loss: 0.3141\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4247/4500], Training Loss: 0.0000\n",
      "Epoch [4247/4500], Validation Loss: 0.3142\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4248/4500], Training Loss: 0.0000\n",
      "Epoch [4248/4500], Validation Loss: 0.3141\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4249/4500], Training Loss: 0.0000\n",
      "Epoch [4249/4500], Validation Loss: 0.3142\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4250/4500], Training Loss: 0.0000\n",
      "Epoch [4250/4500], Validation Loss: 0.3142\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4251/4500], Training Loss: 0.0000\n",
      "Epoch [4251/4500], Validation Loss: 0.3141\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4252/4500], Training Loss: 0.0000\n",
      "Epoch [4252/4500], Validation Loss: 0.3142\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4253/4500], Training Loss: 0.0000\n",
      "Epoch [4253/4500], Validation Loss: 0.3143\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4254/4500], Training Loss: 0.0000\n",
      "Epoch [4254/4500], Validation Loss: 0.3142\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4255/4500], Training Loss: 0.0000\n",
      "Epoch [4255/4500], Validation Loss: 0.3142\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4256/4500], Training Loss: 0.0000\n",
      "Epoch [4256/4500], Validation Loss: 0.3143\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4257/4500], Training Loss: 0.0000\n",
      "Epoch [4257/4500], Validation Loss: 0.3145\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4258/4500], Training Loss: 0.0000\n",
      "Epoch [4258/4500], Validation Loss: 0.3144\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4259/4500], Training Loss: 0.0000\n",
      "Epoch [4259/4500], Validation Loss: 0.3143\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4260/4500], Training Loss: 0.0000\n",
      "Epoch [4260/4500], Validation Loss: 0.3144\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4261/4500], Training Loss: 0.0000\n",
      "Epoch [4261/4500], Validation Loss: 0.3142\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4262/4500], Training Loss: 0.0000\n",
      "Epoch [4262/4500], Validation Loss: 0.3144\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4263/4500], Training Loss: 0.0000\n",
      "Epoch [4263/4500], Validation Loss: 0.3144\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4264/4500], Training Loss: 0.0000\n",
      "Epoch [4264/4500], Validation Loss: 0.3143\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4265/4500], Training Loss: 0.0000\n",
      "Epoch [4265/4500], Validation Loss: 0.3144\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4266/4500], Training Loss: 0.0000\n",
      "Epoch [4266/4500], Validation Loss: 0.3146\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4267/4500], Training Loss: 0.0000\n",
      "Epoch [4267/4500], Validation Loss: 0.3145\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4268/4500], Training Loss: 0.0000\n",
      "Epoch [4268/4500], Validation Loss: 0.3144\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4269/4500], Training Loss: 0.0000\n",
      "Epoch [4269/4500], Validation Loss: 0.3146\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4270/4500], Training Loss: 0.0000\n",
      "Epoch [4270/4500], Validation Loss: 0.3146\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4271/4500], Training Loss: 0.0000\n",
      "Epoch [4271/4500], Validation Loss: 0.3145\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4272/4500], Training Loss: 0.0000\n",
      "Epoch [4272/4500], Validation Loss: 0.3146\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4273/4500], Training Loss: 0.0000\n",
      "Epoch [4273/4500], Validation Loss: 0.3146\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4274/4500], Training Loss: 0.0000\n",
      "Epoch [4274/4500], Validation Loss: 0.3145\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4275/4500], Training Loss: 0.0000\n",
      "Epoch [4275/4500], Validation Loss: 0.3147\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4276/4500], Training Loss: 0.0000\n",
      "Epoch [4276/4500], Validation Loss: 0.3145\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4277/4500], Training Loss: 0.0000\n",
      "Epoch [4277/4500], Validation Loss: 0.3147\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4278/4500], Training Loss: 0.0000\n",
      "Epoch [4278/4500], Validation Loss: 0.3145\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4279/4500], Training Loss: 0.0000\n",
      "Epoch [4279/4500], Validation Loss: 0.3147\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4280/4500], Training Loss: 0.0000\n",
      "Epoch [4280/4500], Validation Loss: 0.3147\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4281/4500], Training Loss: 0.0000\n",
      "Epoch [4281/4500], Validation Loss: 0.3146\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4282/4500], Training Loss: 0.0000\n",
      "Epoch [4282/4500], Validation Loss: 0.3147\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4283/4500], Training Loss: 0.0000\n",
      "Epoch [4283/4500], Validation Loss: 0.3147\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4284/4500], Training Loss: 0.0000\n",
      "Epoch [4284/4500], Validation Loss: 0.3148\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4285/4500], Training Loss: 0.0000\n",
      "Epoch [4285/4500], Validation Loss: 0.3148\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4286/4500], Training Loss: 0.0000\n",
      "Epoch [4286/4500], Validation Loss: 0.3148\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4287/4500], Training Loss: 0.0000\n",
      "Epoch [4287/4500], Validation Loss: 0.3148\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4288/4500], Training Loss: 0.0000\n",
      "Epoch [4288/4500], Validation Loss: 0.3148\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4289/4500], Training Loss: 0.0000\n",
      "Epoch [4289/4500], Validation Loss: 0.3149\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4290/4500], Training Loss: 0.0000\n",
      "Epoch [4290/4500], Validation Loss: 0.3148\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4291/4500], Training Loss: 0.0000\n",
      "Epoch [4291/4500], Validation Loss: 0.3148\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4292/4500], Training Loss: 0.0000\n",
      "Epoch [4292/4500], Validation Loss: 0.3149\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4293/4500], Training Loss: 0.0000\n",
      "Epoch [4293/4500], Validation Loss: 0.3150\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4294/4500], Training Loss: 0.0000\n",
      "Epoch [4294/4500], Validation Loss: 0.3150\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4295/4500], Training Loss: 0.0000\n",
      "Epoch [4295/4500], Validation Loss: 0.3150\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4296/4500], Training Loss: 0.0000\n",
      "Epoch [4296/4500], Validation Loss: 0.3148\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4297/4500], Training Loss: 0.0000\n",
      "Epoch [4297/4500], Validation Loss: 0.3150\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4298/4500], Training Loss: 0.0000\n",
      "Epoch [4298/4500], Validation Loss: 0.3151\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4299/4500], Training Loss: 0.0000\n",
      "Epoch [4299/4500], Validation Loss: 0.3151\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4300/4500], Training Loss: 0.0000\n",
      "Epoch [4300/4500], Validation Loss: 0.3151\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4301/4500], Training Loss: 0.0000\n",
      "Epoch [4301/4500], Validation Loss: 0.3151\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4302/4500], Training Loss: 0.0000\n",
      "Epoch [4302/4500], Validation Loss: 0.3151\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4303/4500], Training Loss: 0.0000\n",
      "Epoch [4303/4500], Validation Loss: 0.3150\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4304/4500], Training Loss: 0.0000\n",
      "Epoch [4304/4500], Validation Loss: 0.3151\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4305/4500], Training Loss: 0.0000\n",
      "Epoch [4305/4500], Validation Loss: 0.3151\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4306/4500], Training Loss: 0.0000\n",
      "Epoch [4306/4500], Validation Loss: 0.3151\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4307/4500], Training Loss: 0.0000\n",
      "Epoch [4307/4500], Validation Loss: 0.5828\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4308/4500], Training Loss: 0.0000\n",
      "Epoch [4308/4500], Validation Loss: 0.3152\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4309/4500], Training Loss: 0.0000\n",
      "Epoch [4309/4500], Validation Loss: 0.5829\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4310/4500], Training Loss: 0.0000\n",
      "Epoch [4310/4500], Validation Loss: 0.3153\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4311/4500], Training Loss: 0.0000\n",
      "Epoch [4311/4500], Validation Loss: 0.5828\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4312/4500], Training Loss: 0.0000\n",
      "Epoch [4312/4500], Validation Loss: 0.5828\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4313/4500], Training Loss: 0.0000\n",
      "Epoch [4313/4500], Validation Loss: 0.5829\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4314/4500], Training Loss: 0.0000\n",
      "Epoch [4314/4500], Validation Loss: 0.5829\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4315/4500], Training Loss: 0.0000\n",
      "Epoch [4315/4500], Validation Loss: 0.5829\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4316/4500], Training Loss: 0.0000\n",
      "Epoch [4316/4500], Validation Loss: 0.5830\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4317/4500], Training Loss: 0.0000\n",
      "Epoch [4317/4500], Validation Loss: 0.5830\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4318/4500], Training Loss: 0.0000\n",
      "Epoch [4318/4500], Validation Loss: 0.5830\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4319/4500], Training Loss: 0.0000\n",
      "Epoch [4319/4500], Validation Loss: 0.5831\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4320/4500], Training Loss: 0.0000\n",
      "Epoch [4320/4500], Validation Loss: 0.5831\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4321/4500], Training Loss: 0.0000\n",
      "Epoch [4321/4500], Validation Loss: 0.5832\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4322/4500], Training Loss: 0.0000\n",
      "Epoch [4322/4500], Validation Loss: 0.5830\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4323/4500], Training Loss: 0.0000\n",
      "Epoch [4323/4500], Validation Loss: 0.5831\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4324/4500], Training Loss: 0.0000\n",
      "Epoch [4324/4500], Validation Loss: 0.5831\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4325/4500], Training Loss: 0.0000\n",
      "Epoch [4325/4500], Validation Loss: 0.5832\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4326/4500], Training Loss: 0.0000\n",
      "Epoch [4326/4500], Validation Loss: 0.5833\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4327/4500], Training Loss: 0.0000\n",
      "Epoch [4327/4500], Validation Loss: 0.5831\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4328/4500], Training Loss: 0.0000\n",
      "Epoch [4328/4500], Validation Loss: 0.5832\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4329/4500], Training Loss: 0.0000\n",
      "Epoch [4329/4500], Validation Loss: 0.5832\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4330/4500], Training Loss: 0.0000\n",
      "Epoch [4330/4500], Validation Loss: 0.5832\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4331/4500], Training Loss: 0.0000\n",
      "Epoch [4331/4500], Validation Loss: 0.5833\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4332/4500], Training Loss: 0.0000\n",
      "Epoch [4332/4500], Validation Loss: 0.5834\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4333/4500], Training Loss: 0.0000\n",
      "Epoch [4333/4500], Validation Loss: 0.5832\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4334/4500], Training Loss: 0.0000\n",
      "Epoch [4334/4500], Validation Loss: 0.5832\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4335/4500], Training Loss: 0.0000\n",
      "Epoch [4335/4500], Validation Loss: 0.5833\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4336/4500], Training Loss: 0.0000\n",
      "Epoch [4336/4500], Validation Loss: 0.5833\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4337/4500], Training Loss: 0.0000\n",
      "Epoch [4337/4500], Validation Loss: 0.5833\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4338/4500], Training Loss: 0.0000\n",
      "Epoch [4338/4500], Validation Loss: 0.5834\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4339/4500], Training Loss: 0.0000\n",
      "Epoch [4339/4500], Validation Loss: 0.5834\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4340/4500], Training Loss: 0.0000\n",
      "Epoch [4340/4500], Validation Loss: 0.5834\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4341/4500], Training Loss: 0.0000\n",
      "Epoch [4341/4500], Validation Loss: 0.5834\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4342/4500], Training Loss: 0.0000\n",
      "Epoch [4342/4500], Validation Loss: 0.5834\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4343/4500], Training Loss: 0.0000\n",
      "Epoch [4343/4500], Validation Loss: 0.5835\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4344/4500], Training Loss: 0.0000\n",
      "Epoch [4344/4500], Validation Loss: 0.5833\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4345/4500], Training Loss: 0.0000\n",
      "Epoch [4345/4500], Validation Loss: 0.5836\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4346/4500], Training Loss: 0.0000\n",
      "Epoch [4346/4500], Validation Loss: 0.5834\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4347/4500], Training Loss: 0.0000\n",
      "Epoch [4347/4500], Validation Loss: 0.5834\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4348/4500], Training Loss: 0.0000\n",
      "Epoch [4348/4500], Validation Loss: 0.5835\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4349/4500], Training Loss: 0.0000\n",
      "Epoch [4349/4500], Validation Loss: 0.5836\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4350/4500], Training Loss: 0.0000\n",
      "Epoch [4350/4500], Validation Loss: 0.5835\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4351/4500], Training Loss: 0.0000\n",
      "Epoch [4351/4500], Validation Loss: 0.5835\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4352/4500], Training Loss: 0.0000\n",
      "Epoch [4352/4500], Validation Loss: 0.5836\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4353/4500], Training Loss: 0.0000\n",
      "Epoch [4353/4500], Validation Loss: 0.5836\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4354/4500], Training Loss: 0.0000\n",
      "Epoch [4354/4500], Validation Loss: 0.5836\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4355/4500], Training Loss: 0.0000\n",
      "Epoch [4355/4500], Validation Loss: 0.5837\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4356/4500], Training Loss: 0.0000\n",
      "Epoch [4356/4500], Validation Loss: 0.5836\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4357/4500], Training Loss: 0.0000\n",
      "Epoch [4357/4500], Validation Loss: 0.5835\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4358/4500], Training Loss: 0.0000\n",
      "Epoch [4358/4500], Validation Loss: 0.5837\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4359/4500], Training Loss: 0.0000\n",
      "Epoch [4359/4500], Validation Loss: 0.5837\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4360/4500], Training Loss: 0.0000\n",
      "Epoch [4360/4500], Validation Loss: 0.5837\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4361/4500], Training Loss: 0.0000\n",
      "Epoch [4361/4500], Validation Loss: 0.5837\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4362/4500], Training Loss: 0.0000\n",
      "Epoch [4362/4500], Validation Loss: 0.5837\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4363/4500], Training Loss: 0.0000\n",
      "Epoch [4363/4500], Validation Loss: 0.5838\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4364/4500], Training Loss: 0.0000\n",
      "Epoch [4364/4500], Validation Loss: 0.5838\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4365/4500], Training Loss: 0.0000\n",
      "Epoch [4365/4500], Validation Loss: 0.5839\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4366/4500], Training Loss: 0.0000\n",
      "Epoch [4366/4500], Validation Loss: 0.5836\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4367/4500], Training Loss: 0.0000\n",
      "Epoch [4367/4500], Validation Loss: 0.5838\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4368/4500], Training Loss: 0.0000\n",
      "Epoch [4368/4500], Validation Loss: 0.5838\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4369/4500], Training Loss: 0.0000\n",
      "Epoch [4369/4500], Validation Loss: 0.5838\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4370/4500], Training Loss: 0.0000\n",
      "Epoch [4370/4500], Validation Loss: 0.5838\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4371/4500], Training Loss: 0.0000\n",
      "Epoch [4371/4500], Validation Loss: 0.5839\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4372/4500], Training Loss: 0.0000\n",
      "Epoch [4372/4500], Validation Loss: 0.5840\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4373/4500], Training Loss: 0.0000\n",
      "Epoch [4373/4500], Validation Loss: 0.5839\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4374/4500], Training Loss: 0.0000\n",
      "Epoch [4374/4500], Validation Loss: 0.5839\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4375/4500], Training Loss: 0.0000\n",
      "Epoch [4375/4500], Validation Loss: 0.5840\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4376/4500], Training Loss: 0.0000\n",
      "Epoch [4376/4500], Validation Loss: 0.5840\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4377/4500], Training Loss: 0.0000\n",
      "Epoch [4377/4500], Validation Loss: 0.5840\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4378/4500], Training Loss: 0.0000\n",
      "Epoch [4378/4500], Validation Loss: 0.5840\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4379/4500], Training Loss: 0.0000\n",
      "Epoch [4379/4500], Validation Loss: 0.5840\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4380/4500], Training Loss: 0.0000\n",
      "Epoch [4380/4500], Validation Loss: 0.5839\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4381/4500], Training Loss: 0.0000\n",
      "Epoch [4381/4500], Validation Loss: 0.5841\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4382/4500], Training Loss: 0.0000\n",
      "Epoch [4382/4500], Validation Loss: 0.5840\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4383/4500], Training Loss: 0.0000\n",
      "Epoch [4383/4500], Validation Loss: 0.5839\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4384/4500], Training Loss: 0.0000\n",
      "Epoch [4384/4500], Validation Loss: 0.5842\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4385/4500], Training Loss: 0.0000\n",
      "Epoch [4385/4500], Validation Loss: 0.5841\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4386/4500], Training Loss: 0.0000\n",
      "Epoch [4386/4500], Validation Loss: 0.5842\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4387/4500], Training Loss: 0.0000\n",
      "Epoch [4387/4500], Validation Loss: 0.5841\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4388/4500], Training Loss: 0.0000\n",
      "Epoch [4388/4500], Validation Loss: 0.5841\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4389/4500], Training Loss: 0.0000\n",
      "Epoch [4389/4500], Validation Loss: 0.5841\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4390/4500], Training Loss: 0.0000\n",
      "Epoch [4390/4500], Validation Loss: 0.5842\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4391/4500], Training Loss: 0.0000\n",
      "Epoch [4391/4500], Validation Loss: 0.5842\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4392/4500], Training Loss: 0.0000\n",
      "Epoch [4392/4500], Validation Loss: 0.5842\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4393/4500], Training Loss: 0.0000\n",
      "Epoch [4393/4500], Validation Loss: 0.5843\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4394/4500], Training Loss: 0.0000\n",
      "Epoch [4394/4500], Validation Loss: 0.5843\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4395/4500], Training Loss: 0.0000\n",
      "Epoch [4395/4500], Validation Loss: 0.5843\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4396/4500], Training Loss: 0.0000\n",
      "Epoch [4396/4500], Validation Loss: 0.5843\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4397/4500], Training Loss: 0.0000\n",
      "Epoch [4397/4500], Validation Loss: 0.5842\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4398/4500], Training Loss: 0.0000\n",
      "Epoch [4398/4500], Validation Loss: 0.5843\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4399/4500], Training Loss: 0.0000\n",
      "Epoch [4399/4500], Validation Loss: 0.5843\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4400/4500], Training Loss: 0.0000\n",
      "Epoch [4400/4500], Validation Loss: 0.5844\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4401/4500], Training Loss: 0.0000\n",
      "Epoch [4401/4500], Validation Loss: 0.5844\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4402/4500], Training Loss: 0.0000\n",
      "Epoch [4402/4500], Validation Loss: 0.5842\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4403/4500], Training Loss: 0.0000\n",
      "Epoch [4403/4500], Validation Loss: 0.5844\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4404/4500], Training Loss: 0.0000\n",
      "Epoch [4404/4500], Validation Loss: 0.5844\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4405/4500], Training Loss: 0.0000\n",
      "Epoch [4405/4500], Validation Loss: 0.5845\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4406/4500], Training Loss: 0.0000\n",
      "Epoch [4406/4500], Validation Loss: 0.5844\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4407/4500], Training Loss: 0.0000\n",
      "Epoch [4407/4500], Validation Loss: 0.5845\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4408/4500], Training Loss: 0.0000\n",
      "Epoch [4408/4500], Validation Loss: 0.5844\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4409/4500], Training Loss: 0.0000\n",
      "Epoch [4409/4500], Validation Loss: 0.5844\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4410/4500], Training Loss: 0.0000\n",
      "Epoch [4410/4500], Validation Loss: 0.5844\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4411/4500], Training Loss: 0.0000\n",
      "Epoch [4411/4500], Validation Loss: 0.5846\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4412/4500], Training Loss: 0.0000\n",
      "Epoch [4412/4500], Validation Loss: 0.5845\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4413/4500], Training Loss: 0.0000\n",
      "Epoch [4413/4500], Validation Loss: 0.5846\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4414/4500], Training Loss: 0.0000\n",
      "Epoch [4414/4500], Validation Loss: 0.5847\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4415/4500], Training Loss: 0.0000\n",
      "Epoch [4415/4500], Validation Loss: 0.5845\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4416/4500], Training Loss: 0.0000\n",
      "Epoch [4416/4500], Validation Loss: 0.5846\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4417/4500], Training Loss: 0.0000\n",
      "Epoch [4417/4500], Validation Loss: 0.5845\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4418/4500], Training Loss: 0.0000\n",
      "Epoch [4418/4500], Validation Loss: 0.5847\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4419/4500], Training Loss: 0.0000\n",
      "Epoch [4419/4500], Validation Loss: 0.5846\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4420/4500], Training Loss: 0.0000\n",
      "Epoch [4420/4500], Validation Loss: 0.5847\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4421/4500], Training Loss: 0.0000\n",
      "Epoch [4421/4500], Validation Loss: 0.5846\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4422/4500], Training Loss: 0.0000\n",
      "Epoch [4422/4500], Validation Loss: 0.5846\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4423/4500], Training Loss: 0.0000\n",
      "Epoch [4423/4500], Validation Loss: 0.5848\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4424/4500], Training Loss: 0.0000\n",
      "Epoch [4424/4500], Validation Loss: 0.5847\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4425/4500], Training Loss: 0.0000\n",
      "Epoch [4425/4500], Validation Loss: 0.5848\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4426/4500], Training Loss: 0.0000\n",
      "Epoch [4426/4500], Validation Loss: 0.5845\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4427/4500], Training Loss: 0.0000\n",
      "Epoch [4427/4500], Validation Loss: 0.5849\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4428/4500], Training Loss: 0.0000\n",
      "Epoch [4428/4500], Validation Loss: 0.5848\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4429/4500], Training Loss: 0.0000\n",
      "Epoch [4429/4500], Validation Loss: 0.5848\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4430/4500], Training Loss: 0.0000\n",
      "Epoch [4430/4500], Validation Loss: 0.5847\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4431/4500], Training Loss: 0.0000\n",
      "Epoch [4431/4500], Validation Loss: 0.5848\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4432/4500], Training Loss: 0.0000\n",
      "Epoch [4432/4500], Validation Loss: 0.5849\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4433/4500], Training Loss: 0.0000\n",
      "Epoch [4433/4500], Validation Loss: 0.5849\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4434/4500], Training Loss: 0.0000\n",
      "Epoch [4434/4500], Validation Loss: 0.5850\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4435/4500], Training Loss: 0.0000\n",
      "Epoch [4435/4500], Validation Loss: 0.5849\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4436/4500], Training Loss: 0.0000\n",
      "Epoch [4436/4500], Validation Loss: 0.5851\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4437/4500], Training Loss: 0.0000\n",
      "Epoch [4437/4500], Validation Loss: 0.5850\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4438/4500], Training Loss: 0.0000\n",
      "Epoch [4438/4500], Validation Loss: 0.5850\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4439/4500], Training Loss: 0.0000\n",
      "Epoch [4439/4500], Validation Loss: 0.5848\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4440/4500], Training Loss: 0.0000\n",
      "Epoch [4440/4500], Validation Loss: 0.5850\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4441/4500], Training Loss: 0.0000\n",
      "Epoch [4441/4500], Validation Loss: 0.5850\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4442/4500], Training Loss: 0.0000\n",
      "Epoch [4442/4500], Validation Loss: 0.5849\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4443/4500], Training Loss: 0.0000\n",
      "Epoch [4443/4500], Validation Loss: 0.5850\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4444/4500], Training Loss: 0.0000\n",
      "Epoch [4444/4500], Validation Loss: 0.5851\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4445/4500], Training Loss: 0.0000\n",
      "Epoch [4445/4500], Validation Loss: 0.5851\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4446/4500], Training Loss: 0.0000\n",
      "Epoch [4446/4500], Validation Loss: 0.5851\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4447/4500], Training Loss: 0.0000\n",
      "Epoch [4447/4500], Validation Loss: 0.5851\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4448/4500], Training Loss: 0.0000\n",
      "Epoch [4448/4500], Validation Loss: 0.5850\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4449/4500], Training Loss: 0.0000\n",
      "Epoch [4449/4500], Validation Loss: 0.5851\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4450/4500], Training Loss: 0.0000\n",
      "Epoch [4450/4500], Validation Loss: 0.5851\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4451/4500], Training Loss: 0.0000\n",
      "Epoch [4451/4500], Validation Loss: 0.5851\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4452/4500], Training Loss: 0.0000\n",
      "Epoch [4452/4500], Validation Loss: 0.5851\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4453/4500], Training Loss: 0.0000\n",
      "Epoch [4453/4500], Validation Loss: 0.5852\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4454/4500], Training Loss: 0.0000\n",
      "Epoch [4454/4500], Validation Loss: 0.5852\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4455/4500], Training Loss: 0.0000\n",
      "Epoch [4455/4500], Validation Loss: 0.5853\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4456/4500], Training Loss: 0.0000\n",
      "Epoch [4456/4500], Validation Loss: 0.5852\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4457/4500], Training Loss: 0.0000\n",
      "Epoch [4457/4500], Validation Loss: 0.5852\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4458/4500], Training Loss: 0.0000\n",
      "Epoch [4458/4500], Validation Loss: 0.5852\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4459/4500], Training Loss: 0.0000\n",
      "Epoch [4459/4500], Validation Loss: 0.5853\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4460/4500], Training Loss: 0.0000\n",
      "Epoch [4460/4500], Validation Loss: 0.5853\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4461/4500], Training Loss: 0.0000\n",
      "Epoch [4461/4500], Validation Loss: 0.5852\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4462/4500], Training Loss: 0.0000\n",
      "Epoch [4462/4500], Validation Loss: 0.5853\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4463/4500], Training Loss: 0.0000\n",
      "Epoch [4463/4500], Validation Loss: 0.5854\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4464/4500], Training Loss: 0.0000\n",
      "Epoch [4464/4500], Validation Loss: 0.5854\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4465/4500], Training Loss: 0.0000\n",
      "Epoch [4465/4500], Validation Loss: 0.5853\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4466/4500], Training Loss: 0.0000\n",
      "Epoch [4466/4500], Validation Loss: 0.5854\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4467/4500], Training Loss: 0.0000\n",
      "Epoch [4467/4500], Validation Loss: 0.5854\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4468/4500], Training Loss: 0.0000\n",
      "Epoch [4468/4500], Validation Loss: 0.5853\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4469/4500], Training Loss: 0.0000\n",
      "Epoch [4469/4500], Validation Loss: 0.5855\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4470/4500], Training Loss: 0.0000\n",
      "Epoch [4470/4500], Validation Loss: 0.5855\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4471/4500], Training Loss: 0.0000\n",
      "Epoch [4471/4500], Validation Loss: 0.5854\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4472/4500], Training Loss: 0.0000\n",
      "Epoch [4472/4500], Validation Loss: 0.5855\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4473/4500], Training Loss: 0.0000\n",
      "Epoch [4473/4500], Validation Loss: 0.5855\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4474/4500], Training Loss: 0.0000\n",
      "Epoch [4474/4500], Validation Loss: 0.5855\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4475/4500], Training Loss: 0.0000\n",
      "Epoch [4475/4500], Validation Loss: 0.5855\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4476/4500], Training Loss: 0.0000\n",
      "Epoch [4476/4500], Validation Loss: 0.5855\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4477/4500], Training Loss: 0.0000\n",
      "Epoch [4477/4500], Validation Loss: 0.5856\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4478/4500], Training Loss: 0.0000\n",
      "Epoch [4478/4500], Validation Loss: 0.5856\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4479/4500], Training Loss: 0.0000\n",
      "Epoch [4479/4500], Validation Loss: 0.5855\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4480/4500], Training Loss: 0.0000\n",
      "Epoch [4480/4500], Validation Loss: 0.5856\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4481/4500], Training Loss: 0.0000\n",
      "Epoch [4481/4500], Validation Loss: 0.5856\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4482/4500], Training Loss: 0.0000\n",
      "Epoch [4482/4500], Validation Loss: 0.5857\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4483/4500], Training Loss: 0.0000\n",
      "Epoch [4483/4500], Validation Loss: 0.5857\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4484/4500], Training Loss: 0.0000\n",
      "Epoch [4484/4500], Validation Loss: 0.5857\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4485/4500], Training Loss: 0.0000\n",
      "Epoch [4485/4500], Validation Loss: 0.5856\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4486/4500], Training Loss: 0.0000\n",
      "Epoch [4486/4500], Validation Loss: 0.5856\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4487/4500], Training Loss: 0.0000\n",
      "Epoch [4487/4500], Validation Loss: 0.5859\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4488/4500], Training Loss: 0.0000\n",
      "Epoch [4488/4500], Validation Loss: 0.5857\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4489/4500], Training Loss: 0.0000\n",
      "Epoch [4489/4500], Validation Loss: 0.5858\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4490/4500], Training Loss: 0.0000\n",
      "Epoch [4490/4500], Validation Loss: 0.5856\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4491/4500], Training Loss: 0.0000\n",
      "Epoch [4491/4500], Validation Loss: 0.5858\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4492/4500], Training Loss: 0.0000\n",
      "Epoch [4492/4500], Validation Loss: 0.5858\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4493/4500], Training Loss: 0.0000\n",
      "Epoch [4493/4500], Validation Loss: 0.5858\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4494/4500], Training Loss: 0.0000\n",
      "Epoch [4494/4500], Validation Loss: 0.5858\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4495/4500], Training Loss: 0.0000\n",
      "Epoch [4495/4500], Validation Loss: 0.5858\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4496/4500], Training Loss: 0.0000\n",
      "Epoch [4496/4500], Validation Loss: 0.5858\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4497/4500], Training Loss: 0.0000\n",
      "Epoch [4497/4500], Validation Loss: 0.5858\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4498/4500], Training Loss: 0.0000\n",
      "Epoch [4498/4500], Validation Loss: 0.5859\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4499/4500], Training Loss: 0.0000\n",
      "Epoch [4499/4500], Validation Loss: 0.5860\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n",
      "Epoch [4500/4500], Training Loss: 0.0000\n",
      "Epoch [4500/4500], Validation Loss: 0.5860\n",
      "Accuracy: 0.9547, Precision: 0.9757, Recall: 0.9330, F1: 0.9539\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# overfit etmesi için epok sayısını arttırdım.\n",
    "trainData = pd.read_csv('./csv/cure_the_princess_train.csv')\n",
    "validData = pd.read_csv('./csv/cure_the_princess_validation.csv')\n",
    "testData =  pd.read_csv('./csv/cure_the_princess_test.csv')\n",
    "\n",
    "\n",
    "trainX = trainData.drop(columns=['Cured']).values\n",
    "trainY = trainData['Cured'].values\n",
    "validX = validData.drop(columns=['Cured']).values\n",
    "validY = validData['Cured'].values\n",
    "testX = testData.drop(columns=['Cured']).values\n",
    "testY = testData['Cured'].values\n",
    "\n",
    "\n",
    "numInputFeatures = trainX.shape[1]\n",
    "\n",
    "torch.manual_seed(190401070)\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, numInputFeatures):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(numInputFeatures, 100) \n",
    "        self.relu1 = nn.ReLU() \n",
    "        self.fc2 = nn.Linear(100, 50) \n",
    "        self.relu2 = nn.ReLU() \n",
    "        self.fc3 = nn.Linear(50, 1) \n",
    "        self.sigmoid = nn.Sigmoid() \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MLP(numInputFeatures=numInputFeatures)\n",
    "\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0006)\n",
    "\n",
    "\n",
    "numEpochs = 4500\n",
    "batchSize = 16\n",
    "trainLosses = []\n",
    "validLosses = []\n",
    "for epoch in range(numEpochs):\n",
    "    for i in range(0, len(trainX), batchSize):\n",
    "        \n",
    "        batchX = torch.tensor(trainX[i:i+batchSize], dtype=torch.float32)\n",
    "        batchY = torch.tensor(trainY[i:i+batchSize], dtype=torch.float32).view(-1, 1)\n",
    "        \n",
    "        \n",
    "        outputs = model(batchX)\n",
    "        loss = criterion(outputs, batchY)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    \n",
    "    trainLosses.append(loss.item())\n",
    "    print('Epoch [%d/%d], Training Loss: %.4f' % (epoch+1, numEpochs, loss.item()))\n",
    "    \n",
    "   \n",
    "    validLoss = criterion(model(torch.tensor(validX, dtype=torch.float32)), torch.tensor(validY, dtype=torch.float32).view(-1, 1)).item()\n",
    "    validLosses.append(validLoss)\n",
    "    print('Epoch [%d/%d], Validation Loss: %.4f' % (epoch+1, numEpochs, validLoss))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        testOutputs = model(torch.tensor(testX, dtype=torch.float32))\n",
    "        testPredictions = (testOutputs > 0.5).float().view(-1)\n",
    "\n",
    "        \n",
    "        accuracy = (testPredictions == torch.tensor(testY, dtype=torch.float32)).float().mean().item()\n",
    "        precision = (testPredictions[testPredictions == 1] == torch.tensor(testY[testPredictions == 1], dtype=torch.float32)).float().mean().item()\n",
    "        recall = (testPredictions[testY == 1] == torch.tensor(testY[testY == 1], dtype=torch.float32)).float().mean().item()\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "        print('Accuracy: %.4f, Precision: %.4f, Recall: %.4f, F1: %.4f' % (accuracy, precision, recall, f1))\n",
    "\n",
    "\n",
    "plt.plot(trainLosses, label='Training Loss')\n",
    "plt.plot(validLosses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Training Loss: 0.9308\n",
      "Epoch [1/250], Validation Loss: 1.1868\n",
      "Accuracy: 0.6736, Precision: 0.6735, Recall: 0.6804, F1: 0.6769\n",
      "Epoch [2/250], Training Loss: 0.0206\n",
      "Epoch [2/250], Validation Loss: 0.8198\n",
      "Accuracy: 0.6697, Precision: 0.6602, Recall: 0.7062, F1: 0.6824\n",
      "Epoch [3/250], Training Loss: 0.0526\n",
      "Epoch [3/250], Validation Loss: 0.6563\n",
      "Accuracy: 0.6852, Precision: 0.6817, Recall: 0.7010, F1: 0.6912\n",
      "Epoch [4/250], Training Loss: 0.1583\n",
      "Epoch [4/250], Validation Loss: 0.8176\n",
      "Accuracy: 0.7267, Precision: 0.7007, Recall: 0.7964, F1: 0.7455\n",
      "Epoch [5/250], Training Loss: 0.1271\n",
      "Epoch [5/250], Validation Loss: 0.5947\n",
      "Accuracy: 0.7396, Precision: 0.7111, Recall: 0.8119, F1: 0.7581\n",
      "Epoch [6/250], Training Loss: 0.2902\n",
      "Epoch [6/250], Validation Loss: 0.6447\n",
      "Accuracy: 0.7474, Precision: 0.7188, Recall: 0.8170, F1: 0.7648\n",
      "Epoch [7/250], Training Loss: 0.2741\n",
      "Epoch [7/250], Validation Loss: 0.5903\n",
      "Accuracy: 0.7759, Precision: 0.7722, Recall: 0.7861, F1: 0.7791\n",
      "Epoch [8/250], Training Loss: 0.4359\n",
      "Epoch [8/250], Validation Loss: 0.4990\n",
      "Accuracy: 0.7306, Precision: 0.7356, Recall: 0.7242, F1: 0.7299\n",
      "Epoch [9/250], Training Loss: 0.0514\n",
      "Epoch [9/250], Validation Loss: 0.5614\n",
      "Accuracy: 0.7591, Precision: 0.7405, Recall: 0.8015, F1: 0.7698\n",
      "Epoch [10/250], Training Loss: 0.0514\n",
      "Epoch [10/250], Validation Loss: 0.4429\n",
      "Accuracy: 0.7733, Precision: 0.7617, Recall: 0.7990, F1: 0.7799\n",
      "Epoch [11/250], Training Loss: 0.3997\n",
      "Epoch [11/250], Validation Loss: 0.4900\n",
      "Accuracy: 0.7694, Precision: 0.7652, Recall: 0.7809, F1: 0.7730\n",
      "Epoch [12/250], Training Loss: 0.0858\n",
      "Epoch [12/250], Validation Loss: 0.4322\n",
      "Accuracy: 0.7746, Precision: 0.7892, Recall: 0.7526, F1: 0.7704\n",
      "Epoch [13/250], Training Loss: 0.1758\n",
      "Epoch [13/250], Validation Loss: 0.4795\n",
      "Accuracy: 0.7694, Precision: 0.7652, Recall: 0.7809, F1: 0.7730\n",
      "Epoch [14/250], Training Loss: 0.0978\n",
      "Epoch [14/250], Validation Loss: 0.4076\n",
      "Accuracy: 0.7915, Precision: 0.7948, Recall: 0.7887, F1: 0.7917\n",
      "Epoch [15/250], Training Loss: 0.4017\n",
      "Epoch [15/250], Validation Loss: 0.4770\n",
      "Accuracy: 0.8005, Precision: 0.7786, Recall: 0.8428, F1: 0.8094\n",
      "Epoch [16/250], Training Loss: 0.1277\n",
      "Epoch [16/250], Validation Loss: 0.4335\n",
      "Accuracy: 0.7630, Precision: 0.7531, Recall: 0.7861, F1: 0.7692\n",
      "Epoch [17/250], Training Loss: 0.1156\n",
      "Epoch [17/250], Validation Loss: 0.3629\n",
      "Accuracy: 0.7979, Precision: 0.8069, Recall: 0.7861, F1: 0.7963\n",
      "Epoch [18/250], Training Loss: 0.2883\n",
      "Epoch [18/250], Validation Loss: 0.4050\n",
      "Accuracy: 0.7772, Precision: 0.7660, Recall: 0.8015, F1: 0.7834\n",
      "Epoch [19/250], Training Loss: 0.2519\n",
      "Epoch [19/250], Validation Loss: 0.3265\n",
      "Accuracy: 0.7733, Precision: 0.7656, Recall: 0.7912, F1: 0.7782\n",
      "Epoch [20/250], Training Loss: 0.2527\n",
      "Epoch [20/250], Validation Loss: 0.3669\n",
      "Accuracy: 0.8005, Precision: 0.7940, Recall: 0.8144, F1: 0.8041\n",
      "Epoch [21/250], Training Loss: 0.0493\n",
      "Epoch [21/250], Validation Loss: 0.3470\n",
      "Accuracy: 0.7824, Precision: 0.7941, Recall: 0.7655, F1: 0.7795\n",
      "Epoch [22/250], Training Loss: 0.1205\n",
      "Epoch [22/250], Validation Loss: 0.3800\n",
      "Accuracy: 0.8174, Precision: 0.8175, Recall: 0.8196, F1: 0.8185\n",
      "Epoch [23/250], Training Loss: 0.3079\n",
      "Epoch [23/250], Validation Loss: 0.3456\n",
      "Accuracy: 0.8057, Precision: 0.8165, Recall: 0.7912, F1: 0.8037\n",
      "Epoch [24/250], Training Loss: 0.1629\n",
      "Epoch [24/250], Validation Loss: 0.3623\n",
      "Accuracy: 0.8057, Precision: 0.8099, Recall: 0.8015, F1: 0.8057\n",
      "Epoch [25/250], Training Loss: 0.3633\n",
      "Epoch [25/250], Validation Loss: 0.3697\n",
      "Accuracy: 0.8070, Precision: 0.8329, Recall: 0.7706, F1: 0.8005\n",
      "Epoch [26/250], Training Loss: 0.2268\n",
      "Epoch [26/250], Validation Loss: 0.3726\n",
      "Accuracy: 0.8225, Precision: 0.8084, Recall: 0.8479, F1: 0.8277\n",
      "Epoch [27/250], Training Loss: 0.1467\n",
      "Epoch [27/250], Validation Loss: 0.3722\n",
      "Accuracy: 0.8161, Precision: 0.8306, Recall: 0.7964, F1: 0.8132\n",
      "Epoch [28/250], Training Loss: 1.0347\n",
      "Epoch [28/250], Validation Loss: 0.2970\n",
      "Accuracy: 0.8057, Precision: 0.8005, Recall: 0.8170, F1: 0.8087\n",
      "Epoch [29/250], Training Loss: 0.1239\n",
      "Epoch [29/250], Validation Loss: 0.3272\n",
      "Accuracy: 0.8174, Precision: 0.8225, Recall: 0.8119, F1: 0.8171\n",
      "Epoch [30/250], Training Loss: 0.0475\n",
      "Epoch [30/250], Validation Loss: 0.3206\n",
      "Accuracy: 0.8187, Precision: 0.8100, Recall: 0.8351, F1: 0.8223\n",
      "Epoch [31/250], Training Loss: 0.0923\n",
      "Epoch [31/250], Validation Loss: 0.3206\n",
      "Accuracy: 0.8381, Precision: 0.8380, Recall: 0.8402, F1: 0.8391\n",
      "Epoch [32/250], Training Loss: 0.0716\n",
      "Epoch [32/250], Validation Loss: 0.3526\n",
      "Accuracy: 0.8148, Precision: 0.8320, Recall: 0.7912, F1: 0.8111\n",
      "Epoch [33/250], Training Loss: 0.1751\n",
      "Epoch [33/250], Validation Loss: 0.3214\n",
      "Accuracy: 0.8277, Precision: 0.8312, Recall: 0.8247, F1: 0.8279\n",
      "Epoch [34/250], Training Loss: 0.5864\n",
      "Epoch [34/250], Validation Loss: 0.3197\n",
      "Accuracy: 0.8225, Precision: 0.8226, Recall: 0.8247, F1: 0.8237\n",
      "Epoch [35/250], Training Loss: 0.4364\n",
      "Epoch [35/250], Validation Loss: 0.3258\n",
      "Accuracy: 0.8536, Precision: 0.8726, Recall: 0.8299, F1: 0.8507\n",
      "Epoch [36/250], Training Loss: 0.1720\n",
      "Epoch [36/250], Validation Loss: 0.2940\n",
      "Accuracy: 0.8459, Precision: 0.8606, Recall: 0.8273, F1: 0.8436\n",
      "Epoch [37/250], Training Loss: 0.3338\n",
      "Epoch [37/250], Validation Loss: 0.2832\n",
      "Accuracy: 0.8135, Precision: 0.8177, Recall: 0.8093, F1: 0.8135\n",
      "Epoch [38/250], Training Loss: 0.3695\n",
      "Epoch [38/250], Validation Loss: 0.3176\n",
      "Accuracy: 0.8497, Precision: 0.8417, Recall: 0.8634, F1: 0.8524\n",
      "Epoch [39/250], Training Loss: 0.0954\n",
      "Epoch [39/250], Validation Loss: 0.3312\n",
      "Accuracy: 0.8355, Precision: 0.8425, Recall: 0.8273, F1: 0.8349\n",
      "Epoch [40/250], Training Loss: 0.8329\n",
      "Epoch [40/250], Validation Loss: 0.3123\n",
      "Accuracy: 0.8407, Precision: 0.8460, Recall: 0.8351, F1: 0.8405\n",
      "Epoch [41/250], Training Loss: 0.1797\n",
      "Epoch [41/250], Validation Loss: 0.3150\n",
      "Accuracy: 0.8510, Precision: 0.8545, Recall: 0.8479, F1: 0.8512\n",
      "Epoch [42/250], Training Loss: 0.2663\n",
      "Epoch [42/250], Validation Loss: 0.3413\n",
      "Accuracy: 0.8238, Precision: 0.8316, Recall: 0.8144, F1: 0.8229\n",
      "Epoch [43/250], Training Loss: 0.0947\n",
      "Epoch [43/250], Validation Loss: 0.3580\n",
      "Accuracy: 0.8459, Precision: 0.8458, Recall: 0.8479, F1: 0.8468\n",
      "Epoch [44/250], Training Loss: 0.1440\n",
      "Epoch [44/250], Validation Loss: 0.2897\n",
      "Accuracy: 0.8601, Precision: 0.8483, Recall: 0.8789, F1: 0.8633\n",
      "Epoch [45/250], Training Loss: 0.0847\n",
      "Epoch [45/250], Validation Loss: 0.2886\n",
      "Accuracy: 0.8562, Precision: 0.8858, Recall: 0.8196, F1: 0.8514\n",
      "Epoch [46/250], Training Loss: 0.2746\n",
      "Epoch [46/250], Validation Loss: 0.2740\n",
      "Accuracy: 0.8627, Precision: 0.8579, Recall: 0.8711, F1: 0.8645\n",
      "Epoch [47/250], Training Loss: 0.1040\n",
      "Epoch [47/250], Validation Loss: 0.2929\n",
      "Accuracy: 0.8342, Precision: 0.8652, Recall: 0.7938, F1: 0.8280\n",
      "Epoch [48/250], Training Loss: 0.1607\n",
      "Epoch [48/250], Validation Loss: 0.2612\n",
      "Accuracy: 0.8484, Precision: 0.8672, Recall: 0.8247, F1: 0.8454\n",
      "Epoch [49/250], Training Loss: 0.0606\n",
      "Epoch [49/250], Validation Loss: 0.2932\n",
      "Accuracy: 0.8303, Precision: 0.8408, Recall: 0.8170, F1: 0.8288\n",
      "Epoch [50/250], Training Loss: 0.7363\n",
      "Epoch [50/250], Validation Loss: 0.2832\n",
      "Accuracy: 0.8523, Precision: 0.8477, Recall: 0.8608, F1: 0.8542\n",
      "Epoch [51/250], Training Loss: 0.4503\n",
      "Epoch [51/250], Validation Loss: 0.3024\n",
      "Accuracy: 0.8394, Precision: 0.8687, Recall: 0.8015, F1: 0.8338\n",
      "Epoch [52/250], Training Loss: 0.1515\n",
      "Epoch [52/250], Validation Loss: 0.3022\n",
      "Accuracy: 0.8536, Precision: 0.8535, Recall: 0.8557, F1: 0.8546\n",
      "Epoch [53/250], Training Loss: 0.0937\n",
      "Epoch [53/250], Validation Loss: 0.3040\n",
      "Accuracy: 0.8472, Precision: 0.8462, Recall: 0.8505, F1: 0.8483\n",
      "Epoch [54/250], Training Loss: 0.1928\n",
      "Epoch [54/250], Validation Loss: 0.2885\n",
      "Accuracy: 0.8264, Precision: 0.8128, Recall: 0.8505, F1: 0.8312\n",
      "Epoch [55/250], Training Loss: 0.2089\n",
      "Epoch [55/250], Validation Loss: 0.2562\n",
      "Accuracy: 0.8459, Precision: 0.8568, Recall: 0.8325, F1: 0.8444\n",
      "Epoch [56/250], Training Loss: 0.0811\n",
      "Epoch [56/250], Validation Loss: 0.2777\n",
      "Accuracy: 0.8536, Precision: 0.8535, Recall: 0.8557, F1: 0.8546\n",
      "Epoch [57/250], Training Loss: 0.1400\n",
      "Epoch [57/250], Validation Loss: 0.2747\n",
      "Accuracy: 0.8614, Precision: 0.8649, Recall: 0.8582, F1: 0.8616\n",
      "Epoch [58/250], Training Loss: 0.2557\n",
      "Epoch [58/250], Validation Loss: 0.3355\n",
      "Accuracy: 0.8588, Precision: 0.8780, Recall: 0.8351, F1: 0.8560\n",
      "Epoch [59/250], Training Loss: 0.1781\n",
      "Epoch [59/250], Validation Loss: 0.3255\n",
      "Accuracy: 0.8510, Precision: 0.8527, Recall: 0.8505, F1: 0.8516\n",
      "Epoch [60/250], Training Loss: 0.2046\n",
      "Epoch [60/250], Validation Loss: 0.2954\n",
      "Accuracy: 0.8497, Precision: 0.8560, Recall: 0.8428, F1: 0.8494\n",
      "Epoch [61/250], Training Loss: 0.1020\n",
      "Epoch [61/250], Validation Loss: 0.2877\n",
      "Accuracy: 0.8562, Precision: 0.8774, Recall: 0.8299, F1: 0.8530\n",
      "Epoch [62/250], Training Loss: 0.0448\n",
      "Epoch [62/250], Validation Loss: 0.3170\n",
      "Accuracy: 0.8459, Precision: 0.8768, Recall: 0.8067, F1: 0.8403\n",
      "Epoch [63/250], Training Loss: 0.1322\n",
      "Epoch [63/250], Validation Loss: 0.3061\n",
      "Accuracy: 0.8536, Precision: 0.8535, Recall: 0.8557, F1: 0.8546\n",
      "Epoch [64/250], Training Loss: 0.3266\n",
      "Epoch [64/250], Validation Loss: 0.2162\n",
      "Accuracy: 0.8692, Precision: 0.8868, Recall: 0.8479, F1: 0.8669\n",
      "Epoch [65/250], Training Loss: 0.2072\n",
      "Epoch [65/250], Validation Loss: 0.2153\n",
      "Accuracy: 0.8523, Precision: 0.8460, Recall: 0.8634, F1: 0.8546\n",
      "Epoch [66/250], Training Loss: 0.1132\n",
      "Epoch [66/250], Validation Loss: 0.2490\n",
      "Accuracy: 0.8459, Precision: 0.8665, Recall: 0.8196, F1: 0.8424\n",
      "Epoch [67/250], Training Loss: 0.2376\n",
      "Epoch [67/250], Validation Loss: 0.2883\n",
      "Accuracy: 0.8860, Precision: 0.8989, Recall: 0.8711, F1: 0.8848\n",
      "Epoch [68/250], Training Loss: 0.1408\n",
      "Epoch [68/250], Validation Loss: 0.2176\n",
      "Accuracy: 0.8782, Precision: 0.8868, Recall: 0.8686, F1: 0.8776\n",
      "Epoch [69/250], Training Loss: 0.5307\n",
      "Epoch [69/250], Validation Loss: 0.3109\n",
      "Accuracy: 0.8744, Precision: 0.8740, Recall: 0.8763, F1: 0.8752\n",
      "Epoch [70/250], Training Loss: 0.3189\n",
      "Epoch [70/250], Validation Loss: 0.2556\n",
      "Accuracy: 0.8472, Precision: 0.8444, Recall: 0.8531, F1: 0.8487\n",
      "Epoch [71/250], Training Loss: 0.2479\n",
      "Epoch [71/250], Validation Loss: 0.2864\n",
      "Accuracy: 0.8614, Precision: 0.8767, Recall: 0.8428, F1: 0.8594\n",
      "Epoch [72/250], Training Loss: 0.1167\n",
      "Epoch [72/250], Validation Loss: 0.2483\n",
      "Accuracy: 0.8601, Precision: 0.8867, Recall: 0.8273, F1: 0.8560\n",
      "Epoch [73/250], Training Loss: 0.0605\n",
      "Epoch [73/250], Validation Loss: 0.2805\n",
      "Accuracy: 0.8692, Precision: 0.8975, Recall: 0.8351, F1: 0.8652\n",
      "Epoch [74/250], Training Loss: 0.1263\n",
      "Epoch [74/250], Validation Loss: 0.2844\n",
      "Accuracy: 0.8640, Precision: 0.8714, Recall: 0.8557, F1: 0.8635\n",
      "Epoch [75/250], Training Loss: 0.0264\n",
      "Epoch [75/250], Validation Loss: 0.2199\n",
      "Accuracy: 0.8769, Precision: 0.8845, Recall: 0.8686, F1: 0.8765\n",
      "Epoch [76/250], Training Loss: 0.0130\n",
      "Epoch [76/250], Validation Loss: 0.2350\n",
      "Accuracy: 0.8588, Precision: 0.8586, Recall: 0.8608, F1: 0.8597\n",
      "Epoch [77/250], Training Loss: 0.1061\n",
      "Epoch [77/250], Validation Loss: 0.2170\n",
      "Accuracy: 0.8808, Precision: 0.8795, Recall: 0.8840, F1: 0.8817\n",
      "Epoch [78/250], Training Loss: 0.1774\n",
      "Epoch [78/250], Validation Loss: 0.2536\n",
      "Accuracy: 0.8705, Precision: 0.8871, Recall: 0.8505, F1: 0.8684\n",
      "Epoch [79/250], Training Loss: 0.1240\n",
      "Epoch [79/250], Validation Loss: 0.2878\n",
      "Accuracy: 0.8614, Precision: 0.8649, Recall: 0.8582, F1: 0.8616\n",
      "Epoch [80/250], Training Loss: 0.2294\n",
      "Epoch [80/250], Validation Loss: 0.2287\n",
      "Accuracy: 0.8614, Precision: 0.8612, Recall: 0.8634, F1: 0.8623\n",
      "Epoch [81/250], Training Loss: 0.0419\n",
      "Epoch [81/250], Validation Loss: 0.2841\n",
      "Accuracy: 0.8744, Precision: 0.8880, Recall: 0.8582, F1: 0.8729\n",
      "Epoch [82/250], Training Loss: 0.3278\n",
      "Epoch [82/250], Validation Loss: 0.2886\n",
      "Accuracy: 0.8705, Precision: 0.8750, Recall: 0.8660, F1: 0.8705\n",
      "Epoch [83/250], Training Loss: 0.2059\n",
      "Epoch [83/250], Validation Loss: 0.2420\n",
      "Accuracy: 0.8614, Precision: 0.8707, Recall: 0.8505, F1: 0.8605\n",
      "Epoch [84/250], Training Loss: 0.0802\n",
      "Epoch [84/250], Validation Loss: 0.2431\n",
      "Accuracy: 0.8497, Precision: 0.8757, Recall: 0.8170, F1: 0.8453\n",
      "Epoch [85/250], Training Loss: 0.5737\n",
      "Epoch [85/250], Validation Loss: 0.2531\n",
      "Accuracy: 0.8769, Precision: 0.8747, Recall: 0.8814, F1: 0.8780\n",
      "Epoch [86/250], Training Loss: 0.4392\n",
      "Epoch [86/250], Validation Loss: 0.2253\n",
      "Accuracy: 0.8744, Precision: 0.8859, Recall: 0.8608, F1: 0.8732\n",
      "Epoch [87/250], Training Loss: 0.1925\n",
      "Epoch [87/250], Validation Loss: 0.2138\n",
      "Accuracy: 0.8769, Precision: 0.8805, Recall: 0.8737, F1: 0.8771\n",
      "Epoch [88/250], Training Loss: 0.0606\n",
      "Epoch [88/250], Validation Loss: 0.2410\n",
      "Accuracy: 0.8588, Precision: 0.8720, Recall: 0.8428, F1: 0.8571\n",
      "Epoch [89/250], Training Loss: 0.1914\n",
      "Epoch [89/250], Validation Loss: 0.2397\n",
      "Accuracy: 0.8886, Precision: 0.8953, Recall: 0.8814, F1: 0.8883\n",
      "Epoch [90/250], Training Loss: 0.1572\n",
      "Epoch [90/250], Validation Loss: 0.2527\n",
      "Accuracy: 0.8821, Precision: 0.8960, Recall: 0.8660, F1: 0.8807\n",
      "Epoch [91/250], Training Loss: 0.0625\n",
      "Epoch [91/250], Validation Loss: 0.2336\n",
      "Accuracy: 0.8808, Precision: 0.8936, Recall: 0.8660, F1: 0.8796\n",
      "Epoch [92/250], Training Loss: 0.0548\n",
      "Epoch [92/250], Validation Loss: 0.2340\n",
      "Accuracy: 0.8705, Precision: 0.8770, Recall: 0.8634, F1: 0.8701\n",
      "Epoch [93/250], Training Loss: 0.0663\n",
      "Epoch [93/250], Validation Loss: 0.2193\n",
      "Accuracy: 0.8705, Precision: 0.8830, Recall: 0.8557, F1: 0.8691\n",
      "Epoch [94/250], Training Loss: 0.1521\n",
      "Epoch [94/250], Validation Loss: 0.2510\n",
      "Accuracy: 0.8744, Precision: 0.8799, Recall: 0.8686, F1: 0.8742\n",
      "Epoch [95/250], Training Loss: 0.1291\n",
      "Epoch [95/250], Validation Loss: 0.2148\n",
      "Accuracy: 0.8640, Precision: 0.8835, Recall: 0.8402, F1: 0.8613\n",
      "Epoch [96/250], Training Loss: 0.1332\n",
      "Epoch [96/250], Validation Loss: 0.2645\n",
      "Accuracy: 0.8782, Precision: 0.8889, Recall: 0.8660, F1: 0.8773\n",
      "Epoch [97/250], Training Loss: 0.2205\n",
      "Epoch [97/250], Validation Loss: 0.2767\n",
      "Accuracy: 0.8977, Precision: 0.9077, Recall: 0.8866, F1: 0.8970\n",
      "Epoch [98/250], Training Loss: 0.1310\n",
      "Epoch [98/250], Validation Loss: 0.2146\n",
      "Accuracy: 0.8744, Precision: 0.8922, Recall: 0.8531, F1: 0.8722\n",
      "Epoch [99/250], Training Loss: 0.0328\n",
      "Epoch [99/250], Validation Loss: 0.2713\n",
      "Accuracy: 0.8795, Precision: 0.8871, Recall: 0.8711, F1: 0.8791\n",
      "Epoch [100/250], Training Loss: 0.2410\n",
      "Epoch [100/250], Validation Loss: 0.2425\n",
      "Accuracy: 0.8782, Precision: 0.9083, Recall: 0.8428, F1: 0.8743\n",
      "Epoch [101/250], Training Loss: 0.0809\n",
      "Epoch [101/250], Validation Loss: 0.2674\n",
      "Accuracy: 0.8782, Precision: 0.8952, Recall: 0.8582, F1: 0.8763\n",
      "Epoch [102/250], Training Loss: 0.3551\n",
      "Epoch [102/250], Validation Loss: 0.2148\n",
      "Accuracy: 0.8705, Precision: 0.8830, Recall: 0.8557, F1: 0.8691\n",
      "Epoch [103/250], Training Loss: 0.0730\n",
      "Epoch [103/250], Validation Loss: 0.2149\n",
      "Accuracy: 0.8718, Precision: 0.8793, Recall: 0.8634, F1: 0.8713\n",
      "Epoch [104/250], Training Loss: 0.1030\n",
      "Epoch [104/250], Validation Loss: 0.2427\n",
      "Accuracy: 0.8731, Precision: 0.8737, Recall: 0.8737, F1: 0.8737\n",
      "Epoch [105/250], Training Loss: 0.0516\n",
      "Epoch [105/250], Validation Loss: 0.2570\n",
      "Accuracy: 0.8860, Precision: 0.8927, Recall: 0.8789, F1: 0.8857\n",
      "Epoch [106/250], Training Loss: 0.3538\n",
      "Epoch [106/250], Validation Loss: 0.2313\n",
      "Accuracy: 0.8795, Precision: 0.8912, Recall: 0.8660, F1: 0.8784\n",
      "Epoch [107/250], Training Loss: 0.0601\n",
      "Epoch [107/250], Validation Loss: 0.2829\n",
      "Accuracy: 0.8977, Precision: 0.9164, Recall: 0.8763, F1: 0.8959\n",
      "Epoch [108/250], Training Loss: 0.1165\n",
      "Epoch [108/250], Validation Loss: 0.2458\n",
      "Accuracy: 0.8977, Precision: 0.8951, Recall: 0.9021, F1: 0.8986\n",
      "Epoch [109/250], Training Loss: 0.2305\n",
      "Epoch [109/250], Validation Loss: 0.2103\n",
      "Accuracy: 0.8925, Precision: 0.9024, Recall: 0.8814, F1: 0.8918\n",
      "Epoch [110/250], Training Loss: 0.0289\n",
      "Epoch [110/250], Validation Loss: 0.2553\n",
      "Accuracy: 0.8990, Precision: 0.9167, Recall: 0.8789, F1: 0.8974\n",
      "Epoch [111/250], Training Loss: 0.0698\n",
      "Epoch [111/250], Validation Loss: 0.2382\n",
      "Accuracy: 0.8834, Precision: 0.9049, Recall: 0.8582, F1: 0.8810\n",
      "Epoch [112/250], Training Loss: 0.3339\n",
      "Epoch [112/250], Validation Loss: 0.2846\n",
      "Accuracy: 0.8808, Precision: 0.8834, Recall: 0.8789, F1: 0.8811\n",
      "Epoch [113/250], Training Loss: 0.8310\n",
      "Epoch [113/250], Validation Loss: 0.1968\n",
      "Accuracy: 0.8834, Precision: 0.8942, Recall: 0.8711, F1: 0.8825\n",
      "Epoch [114/250], Training Loss: 0.0314\n",
      "Epoch [114/250], Validation Loss: 0.2383\n",
      "Accuracy: 0.8990, Precision: 0.9144, Recall: 0.8814, F1: 0.8976\n",
      "Epoch [115/250], Training Loss: 0.1066\n",
      "Epoch [115/250], Validation Loss: 0.2031\n",
      "Accuracy: 0.8912, Precision: 0.8878, Recall: 0.8969, F1: 0.8923\n",
      "Epoch [116/250], Training Loss: 0.4827\n",
      "Epoch [116/250], Validation Loss: 0.2391\n",
      "Accuracy: 0.8925, Precision: 0.9003, Recall: 0.8840, F1: 0.8921\n",
      "Epoch [117/250], Training Loss: 0.3919\n",
      "Epoch [117/250], Validation Loss: 0.2085\n",
      "Accuracy: 0.8808, Precision: 0.8936, Recall: 0.8660, F1: 0.8796\n",
      "Epoch [118/250], Training Loss: 0.1348\n",
      "Epoch [118/250], Validation Loss: 0.2171\n",
      "Accuracy: 0.8834, Precision: 0.9093, Recall: 0.8531, F1: 0.8803\n",
      "Epoch [119/250], Training Loss: 0.0176\n",
      "Epoch [119/250], Validation Loss: 0.2517\n",
      "Accuracy: 0.8847, Precision: 0.8987, Recall: 0.8686, F1: 0.8834\n",
      "Epoch [120/250], Training Loss: 0.0315\n",
      "Epoch [120/250], Validation Loss: 0.2393\n",
      "Accuracy: 0.8873, Precision: 0.9035, Recall: 0.8686, F1: 0.8857\n",
      "Epoch [121/250], Training Loss: 0.2839\n",
      "Epoch [121/250], Validation Loss: 0.2354\n",
      "Accuracy: 0.8821, Precision: 0.8837, Recall: 0.8814, F1: 0.8826\n",
      "Epoch [122/250], Training Loss: 0.0702\n",
      "Epoch [122/250], Validation Loss: 0.2310\n",
      "Accuracy: 0.8951, Precision: 0.9072, Recall: 0.8814, F1: 0.8941\n",
      "Epoch [123/250], Training Loss: 0.0660\n",
      "Epoch [123/250], Validation Loss: 0.2359\n",
      "Accuracy: 0.9003, Precision: 0.8997, Recall: 0.9021, F1: 0.9009\n",
      "Epoch [124/250], Training Loss: 0.1428\n",
      "Epoch [124/250], Validation Loss: 0.2099\n",
      "Accuracy: 0.8731, Precision: 0.8877, Recall: 0.8557, F1: 0.8714\n",
      "Epoch [125/250], Training Loss: 0.1455\n",
      "Epoch [125/250], Validation Loss: 0.2289\n",
      "Accuracy: 0.9041, Precision: 0.9198, Recall: 0.8866, F1: 0.9029\n",
      "Epoch [126/250], Training Loss: 0.0772\n",
      "Epoch [126/250], Validation Loss: 0.2495\n",
      "Accuracy: 0.8886, Precision: 0.9103, Recall: 0.8634, F1: 0.8862\n",
      "Epoch [127/250], Training Loss: 0.3624\n",
      "Epoch [127/250], Validation Loss: 0.2397\n",
      "Accuracy: 0.9054, Precision: 0.9223, Recall: 0.8866, F1: 0.9041\n",
      "Epoch [128/250], Training Loss: 0.0726\n",
      "Epoch [128/250], Validation Loss: 0.2094\n",
      "Accuracy: 0.8951, Precision: 0.9205, Recall: 0.8660, F1: 0.8924\n",
      "Epoch [129/250], Training Loss: 0.0217\n",
      "Epoch [129/250], Validation Loss: 0.2139\n",
      "Accuracy: 0.9054, Precision: 0.9268, Recall: 0.8814, F1: 0.9036\n",
      "Epoch [130/250], Training Loss: 0.0222\n",
      "Epoch [130/250], Validation Loss: 0.2250\n",
      "Accuracy: 0.8834, Precision: 0.8901, Recall: 0.8763, F1: 0.8831\n",
      "Epoch [131/250], Training Loss: 0.1642\n",
      "Epoch [131/250], Validation Loss: 0.1919\n",
      "Accuracy: 0.9016, Precision: 0.9262, Recall: 0.8737, F1: 0.8992\n",
      "Epoch [132/250], Training Loss: 0.1325\n",
      "Epoch [132/250], Validation Loss: 0.2361\n",
      "Accuracy: 0.8821, Precision: 0.8960, Recall: 0.8660, F1: 0.8807\n",
      "Epoch [133/250], Training Loss: 0.2124\n",
      "Epoch [133/250], Validation Loss: 0.2468\n",
      "Accuracy: 0.8756, Precision: 0.8904, Recall: 0.8582, F1: 0.8740\n",
      "Epoch [134/250], Training Loss: 0.1574\n",
      "Epoch [134/250], Validation Loss: 0.2474\n",
      "Accuracy: 0.8938, Precision: 0.9048, Recall: 0.8814, F1: 0.8930\n",
      "Epoch [135/250], Training Loss: 0.0305\n",
      "Epoch [135/250], Validation Loss: 0.2203\n",
      "Accuracy: 0.8912, Precision: 0.9043, Recall: 0.8763, F1: 0.8901\n",
      "Epoch [136/250], Training Loss: 0.1552\n",
      "Epoch [136/250], Validation Loss: 0.2197\n",
      "Accuracy: 0.8977, Precision: 0.9142, Recall: 0.8789, F1: 0.8962\n",
      "Epoch [137/250], Training Loss: 0.1676\n",
      "Epoch [137/250], Validation Loss: 0.2217\n",
      "Accuracy: 0.8756, Precision: 0.8782, Recall: 0.8737, F1: 0.8760\n",
      "Epoch [138/250], Training Loss: 0.1614\n",
      "Epoch [138/250], Validation Loss: 0.1993\n",
      "Accuracy: 0.9003, Precision: 0.9191, Recall: 0.8789, F1: 0.8986\n",
      "Epoch [139/250], Training Loss: 0.1953\n",
      "Epoch [139/250], Validation Loss: 0.1843\n",
      "Accuracy: 0.8834, Precision: 0.9005, Recall: 0.8634, F1: 0.8816\n",
      "Epoch [140/250], Training Loss: 0.1450\n",
      "Epoch [140/250], Validation Loss: 0.2760\n",
      "Accuracy: 0.8860, Precision: 0.8886, Recall: 0.8840, F1: 0.8863\n",
      "Epoch [141/250], Training Loss: 0.1310\n",
      "Epoch [141/250], Validation Loss: 0.2072\n",
      "Accuracy: 0.9093, Precision: 0.9229, Recall: 0.8943, F1: 0.9084\n",
      "Epoch [142/250], Training Loss: 0.0315\n",
      "Epoch [142/250], Validation Loss: 0.1817\n",
      "Accuracy: 0.8951, Precision: 0.9050, Recall: 0.8840, F1: 0.8944\n",
      "Epoch [143/250], Training Loss: 0.0524\n",
      "Epoch [143/250], Validation Loss: 0.2199\n",
      "Accuracy: 0.8899, Precision: 0.9040, Recall: 0.8737, F1: 0.8886\n",
      "Epoch [144/250], Training Loss: 0.1853\n",
      "Epoch [144/250], Validation Loss: 0.2093\n",
      "Accuracy: 0.8977, Precision: 0.9280, Recall: 0.8634, F1: 0.8945\n",
      "Epoch [145/250], Training Loss: 0.1251\n",
      "Epoch [145/250], Validation Loss: 0.2010\n",
      "Accuracy: 0.8964, Precision: 0.9118, Recall: 0.8789, F1: 0.8950\n",
      "Epoch [146/250], Training Loss: 0.2506\n",
      "Epoch [146/250], Validation Loss: 0.2016\n",
      "Accuracy: 0.8860, Precision: 0.9054, Recall: 0.8634, F1: 0.8839\n",
      "Epoch [147/250], Training Loss: 0.0435\n",
      "Epoch [147/250], Validation Loss: 0.2817\n",
      "Accuracy: 0.9016, Precision: 0.9216, Recall: 0.8789, F1: 0.8997\n",
      "Epoch [148/250], Training Loss: 0.3427\n",
      "Epoch [148/250], Validation Loss: 0.2502\n",
      "Accuracy: 0.8977, Precision: 0.9164, Recall: 0.8763, F1: 0.8959\n",
      "Epoch [149/250], Training Loss: 0.0912\n",
      "Epoch [149/250], Validation Loss: 0.2012\n",
      "Accuracy: 0.8977, Precision: 0.9142, Recall: 0.8789, F1: 0.8962\n",
      "Epoch [150/250], Training Loss: 0.3047\n",
      "Epoch [150/250], Validation Loss: 0.2531\n",
      "Accuracy: 0.8808, Precision: 0.9000, Recall: 0.8582, F1: 0.8786\n",
      "Epoch [151/250], Training Loss: 0.3471\n",
      "Epoch [151/250], Validation Loss: 0.2369\n",
      "Accuracy: 0.8912, Precision: 0.8938, Recall: 0.8892, F1: 0.8915\n",
      "Epoch [152/250], Training Loss: 0.0567\n",
      "Epoch [152/250], Validation Loss: 0.1980\n",
      "Accuracy: 0.8925, Precision: 0.8920, Recall: 0.8943, F1: 0.8932\n",
      "Epoch [153/250], Training Loss: 0.0839\n",
      "Epoch [153/250], Validation Loss: 0.2036\n",
      "Accuracy: 0.9003, Precision: 0.9039, Recall: 0.8969, F1: 0.9004\n",
      "Epoch [154/250], Training Loss: 0.0341\n",
      "Epoch [154/250], Validation Loss: 0.1842\n",
      "Accuracy: 0.8964, Precision: 0.9208, Recall: 0.8686, F1: 0.8939\n",
      "Epoch [155/250], Training Loss: 0.0632\n",
      "Epoch [155/250], Validation Loss: 0.2157\n",
      "Accuracy: 0.8925, Precision: 0.9088, Recall: 0.8737, F1: 0.8909\n",
      "Epoch [156/250], Training Loss: 0.2214\n",
      "Epoch [156/250], Validation Loss: 0.1767\n",
      "Accuracy: 0.8977, Precision: 0.9077, Recall: 0.8866, F1: 0.8970\n",
      "Epoch [157/250], Training Loss: 0.0965\n",
      "Epoch [157/250], Validation Loss: 0.2070\n",
      "Accuracy: 0.8951, Precision: 0.9160, Recall: 0.8711, F1: 0.8930\n",
      "Epoch [158/250], Training Loss: 0.0704\n",
      "Epoch [158/250], Validation Loss: 0.1804\n",
      "Accuracy: 0.8977, Precision: 0.9098, Recall: 0.8840, F1: 0.8967\n",
      "Epoch [159/250], Training Loss: 0.2692\n",
      "Epoch [159/250], Validation Loss: 0.2092\n",
      "Accuracy: 0.9003, Precision: 0.9307, Recall: 0.8660, F1: 0.8972\n",
      "Epoch [160/250], Training Loss: 0.0719\n",
      "Epoch [160/250], Validation Loss: 0.2366\n",
      "Accuracy: 0.9016, Precision: 0.9309, Recall: 0.8686, F1: 0.8987\n",
      "Epoch [161/250], Training Loss: 0.1019\n",
      "Epoch [161/250], Validation Loss: 0.2027\n",
      "Accuracy: 0.8990, Precision: 0.9258, Recall: 0.8686, F1: 0.8963\n",
      "Epoch [162/250], Training Loss: 0.1209\n",
      "Epoch [162/250], Validation Loss: 0.1751\n",
      "Accuracy: 0.9080, Precision: 0.9319, Recall: 0.8814, F1: 0.9060\n",
      "Epoch [163/250], Training Loss: 0.0600\n",
      "Epoch [163/250], Validation Loss: 0.1972\n",
      "Accuracy: 0.8808, Precision: 0.8795, Recall: 0.8840, F1: 0.8817\n",
      "Epoch [164/250], Training Loss: 0.1300\n",
      "Epoch [164/250], Validation Loss: 0.2185\n",
      "Accuracy: 0.8951, Precision: 0.9183, Recall: 0.8686, F1: 0.8927\n",
      "Epoch [165/250], Training Loss: 0.1544\n",
      "Epoch [165/250], Validation Loss: 0.1906\n",
      "Accuracy: 0.8977, Precision: 0.9210, Recall: 0.8711, F1: 0.8954\n",
      "Epoch [166/250], Training Loss: 0.1167\n",
      "Epoch [166/250], Validation Loss: 0.1924\n",
      "Accuracy: 0.8925, Precision: 0.9088, Recall: 0.8737, F1: 0.8909\n",
      "Epoch [167/250], Training Loss: 0.0643\n",
      "Epoch [167/250], Validation Loss: 0.1957\n",
      "Accuracy: 0.9028, Precision: 0.9173, Recall: 0.8866, F1: 0.9017\n",
      "Epoch [168/250], Training Loss: 0.0475\n",
      "Epoch [168/250], Validation Loss: 0.2241\n",
      "Accuracy: 0.9003, Precision: 0.9169, Recall: 0.8814, F1: 0.8988\n",
      "Epoch [169/250], Training Loss: 0.0290\n",
      "Epoch [169/250], Validation Loss: 0.1864\n",
      "Accuracy: 0.8912, Precision: 0.9000, Recall: 0.8814, F1: 0.8906\n",
      "Epoch [170/250], Training Loss: 0.0410\n",
      "Epoch [170/250], Validation Loss: 0.1912\n",
      "Accuracy: 0.8925, Precision: 0.9088, Recall: 0.8737, F1: 0.8909\n",
      "Epoch [171/250], Training Loss: 0.1035\n",
      "Epoch [171/250], Validation Loss: 0.2133\n",
      "Accuracy: 0.9041, Precision: 0.9089, Recall: 0.8995, F1: 0.9041\n",
      "Epoch [172/250], Training Loss: 0.0968\n",
      "Epoch [172/250], Validation Loss: 0.1982\n",
      "Accuracy: 0.8925, Precision: 0.9201, Recall: 0.8608, F1: 0.8895\n",
      "Epoch [173/250], Training Loss: 0.1693\n",
      "Epoch [173/250], Validation Loss: 0.1710\n",
      "Accuracy: 0.9054, Precision: 0.9091, Recall: 0.9021, F1: 0.9056\n",
      "Epoch [174/250], Training Loss: 0.0212\n",
      "Epoch [174/250], Validation Loss: 0.1708\n",
      "Accuracy: 0.8990, Precision: 0.9282, Recall: 0.8660, F1: 0.8960\n",
      "Epoch [175/250], Training Loss: 0.1527\n",
      "Epoch [175/250], Validation Loss: 0.1950\n",
      "Accuracy: 0.8977, Precision: 0.9187, Recall: 0.8737, F1: 0.8956\n",
      "Epoch [176/250], Training Loss: 0.0925\n",
      "Epoch [176/250], Validation Loss: 0.1835\n",
      "Accuracy: 0.8873, Precision: 0.8950, Recall: 0.8789, F1: 0.8869\n",
      "Epoch [177/250], Training Loss: 0.0377\n",
      "Epoch [177/250], Validation Loss: 0.2243\n",
      "Accuracy: 0.9054, Precision: 0.9134, Recall: 0.8969, F1: 0.9051\n",
      "Epoch [178/250], Training Loss: 0.0439\n",
      "Epoch [178/250], Validation Loss: 0.2163\n",
      "Accuracy: 0.9145, Precision: 0.9305, Recall: 0.8969, F1: 0.9134\n",
      "Epoch [179/250], Training Loss: 0.1067\n",
      "Epoch [179/250], Validation Loss: 0.1666\n",
      "Accuracy: 0.9003, Precision: 0.9260, Recall: 0.8711, F1: 0.8977\n",
      "Epoch [180/250], Training Loss: 0.1888\n",
      "Epoch [180/250], Validation Loss: 0.2269\n",
      "Accuracy: 0.9067, Precision: 0.9051, Recall: 0.9098, F1: 0.9075\n",
      "Epoch [181/250], Training Loss: 0.1750\n",
      "Epoch [181/250], Validation Loss: 0.1880\n",
      "Accuracy: 0.9249, Precision: 0.9388, Recall: 0.9098, F1: 0.9241\n",
      "Epoch [182/250], Training Loss: 0.1150\n",
      "Epoch [182/250], Validation Loss: 0.1884\n",
      "Accuracy: 0.8990, Precision: 0.9016, Recall: 0.8969, F1: 0.8992\n",
      "Epoch [183/250], Training Loss: 0.0488\n",
      "Epoch [183/250], Validation Loss: 0.2048\n",
      "Accuracy: 0.9003, Precision: 0.9125, Recall: 0.8866, F1: 0.8993\n",
      "Epoch [184/250], Training Loss: 0.2956\n",
      "Epoch [184/250], Validation Loss: 0.2151\n",
      "Accuracy: 0.9119, Precision: 0.9301, Recall: 0.8918, F1: 0.9105\n",
      "Epoch [185/250], Training Loss: 0.0363\n",
      "Epoch [185/250], Validation Loss: 0.1827\n",
      "Accuracy: 0.8964, Precision: 0.8990, Recall: 0.8943, F1: 0.8966\n",
      "Epoch [186/250], Training Loss: 0.0886\n",
      "Epoch [186/250], Validation Loss: 0.2232\n",
      "Accuracy: 0.9093, Precision: 0.9297, Recall: 0.8866, F1: 0.9077\n",
      "Epoch [187/250], Training Loss: 0.0269\n",
      "Epoch [187/250], Validation Loss: 0.2012\n",
      "Accuracy: 0.9106, Precision: 0.9299, Recall: 0.8892, F1: 0.9091\n",
      "Epoch [188/250], Training Loss: 0.0776\n",
      "Epoch [188/250], Validation Loss: 0.2050\n",
      "Accuracy: 0.9197, Precision: 0.9429, Recall: 0.8943, F1: 0.9180\n",
      "Epoch [189/250], Training Loss: 0.0311\n",
      "Epoch [189/250], Validation Loss: 0.2271\n",
      "Accuracy: 0.9080, Precision: 0.9319, Recall: 0.8814, F1: 0.9060\n",
      "Epoch [190/250], Training Loss: 0.0894\n",
      "Epoch [190/250], Validation Loss: 0.1982\n",
      "Accuracy: 0.9054, Precision: 0.9315, Recall: 0.8763, F1: 0.9031\n",
      "Epoch [191/250], Training Loss: 0.1276\n",
      "Epoch [191/250], Validation Loss: 0.2149\n",
      "Accuracy: 0.8925, Precision: 0.8920, Recall: 0.8943, F1: 0.8932\n",
      "Epoch [192/250], Training Loss: 0.1746\n",
      "Epoch [192/250], Validation Loss: 0.2030\n",
      "Accuracy: 0.8964, Precision: 0.9096, Recall: 0.8814, F1: 0.8953\n",
      "Epoch [193/250], Training Loss: 0.5029\n",
      "Epoch [193/250], Validation Loss: 0.1952\n",
      "Accuracy: 0.8951, Precision: 0.8926, Recall: 0.8995, F1: 0.8960\n",
      "Epoch [194/250], Training Loss: 0.1024\n",
      "Epoch [194/250], Validation Loss: 0.1754\n",
      "Accuracy: 0.9041, Precision: 0.9198, Recall: 0.8866, F1: 0.9029\n",
      "Epoch [195/250], Training Loss: 0.0592\n",
      "Epoch [195/250], Validation Loss: 0.2022\n",
      "Accuracy: 0.9080, Precision: 0.9319, Recall: 0.8814, F1: 0.9060\n",
      "Epoch [196/250], Training Loss: 0.1455\n",
      "Epoch [196/250], Validation Loss: 0.1988\n",
      "Accuracy: 0.9093, Precision: 0.9321, Recall: 0.8840, F1: 0.9074\n",
      "Epoch [197/250], Training Loss: 0.2073\n",
      "Epoch [197/250], Validation Loss: 0.1603\n",
      "Accuracy: 0.9016, Precision: 0.9171, Recall: 0.8840, F1: 0.9003\n",
      "Epoch [198/250], Training Loss: 0.1629\n",
      "Epoch [198/250], Validation Loss: 0.1850\n",
      "Accuracy: 0.9080, Precision: 0.9342, Recall: 0.8789, F1: 0.9057\n",
      "Epoch [199/250], Training Loss: 0.0422\n",
      "Epoch [199/250], Validation Loss: 0.1873\n",
      "Accuracy: 0.9171, Precision: 0.9263, Recall: 0.9072, F1: 0.9167\n",
      "Epoch [200/250], Training Loss: 0.4250\n",
      "Epoch [200/250], Validation Loss: 0.2241\n",
      "Accuracy: 0.8977, Precision: 0.9120, Recall: 0.8814, F1: 0.8965\n",
      "Epoch [201/250], Training Loss: 0.2049\n",
      "Epoch [201/250], Validation Loss: 0.2102\n",
      "Accuracy: 0.9041, Precision: 0.9361, Recall: 0.8686, F1: 0.9011\n",
      "Epoch [202/250], Training Loss: 0.0417\n",
      "Epoch [202/250], Validation Loss: 0.1690\n",
      "Accuracy: 0.9067, Precision: 0.9136, Recall: 0.8995, F1: 0.9065\n",
      "Epoch [203/250], Training Loss: 0.0343\n",
      "Epoch [203/250], Validation Loss: 0.1844\n",
      "Accuracy: 0.8925, Precision: 0.8920, Recall: 0.8943, F1: 0.8932\n",
      "Epoch [204/250], Training Loss: 0.2156\n",
      "Epoch [204/250], Validation Loss: 0.2080\n",
      "Accuracy: 0.9106, Precision: 0.9276, Recall: 0.8918, F1: 0.9093\n",
      "Epoch [205/250], Training Loss: 0.1957\n",
      "Epoch [205/250], Validation Loss: 0.2062\n",
      "Accuracy: 0.9054, Precision: 0.9245, Recall: 0.8840, F1: 0.9038\n",
      "Epoch [206/250], Training Loss: 0.0643\n",
      "Epoch [206/250], Validation Loss: 0.1809\n",
      "Accuracy: 0.9171, Precision: 0.9263, Recall: 0.9072, F1: 0.9167\n",
      "Epoch [207/250], Training Loss: 0.0505\n",
      "Epoch [207/250], Validation Loss: 0.1803\n",
      "Accuracy: 0.9067, Precision: 0.9341, Recall: 0.8763, F1: 0.9043\n",
      "Epoch [208/250], Training Loss: 0.1364\n",
      "Epoch [208/250], Validation Loss: 0.1976\n",
      "Accuracy: 0.9080, Precision: 0.9204, Recall: 0.8943, F1: 0.9072\n",
      "Epoch [209/250], Training Loss: 0.0444\n",
      "Epoch [209/250], Validation Loss: 0.2135\n",
      "Accuracy: 0.9067, Precision: 0.9225, Recall: 0.8892, F1: 0.9055\n",
      "Epoch [210/250], Training Loss: 0.1492\n",
      "Epoch [210/250], Validation Loss: 0.2015\n",
      "Accuracy: 0.9054, Precision: 0.9112, Recall: 0.8995, F1: 0.9053\n",
      "Epoch [211/250], Training Loss: 0.0156\n",
      "Epoch [211/250], Validation Loss: 0.2016\n",
      "Accuracy: 0.9016, Precision: 0.9216, Recall: 0.8789, F1: 0.8997\n",
      "Epoch [212/250], Training Loss: 0.0223\n",
      "Epoch [212/250], Validation Loss: 0.1914\n",
      "Accuracy: 0.9093, Precision: 0.9321, Recall: 0.8840, F1: 0.9074\n",
      "Epoch [213/250], Training Loss: 0.0339\n",
      "Epoch [213/250], Validation Loss: 0.1843\n",
      "Accuracy: 0.9223, Precision: 0.9362, Recall: 0.9072, F1: 0.9215\n",
      "Epoch [214/250], Training Loss: 0.1616\n",
      "Epoch [214/250], Validation Loss: 0.1615\n",
      "Accuracy: 0.9080, Precision: 0.9440, Recall: 0.8686, F1: 0.9047\n",
      "Epoch [215/250], Training Loss: 0.1433\n",
      "Epoch [215/250], Validation Loss: 0.2193\n",
      "Accuracy: 0.9171, Precision: 0.9402, Recall: 0.8918, F1: 0.9153\n",
      "Epoch [216/250], Training Loss: 0.4379\n",
      "Epoch [216/250], Validation Loss: 0.1790\n",
      "Accuracy: 0.9054, Precision: 0.9200, Recall: 0.8892, F1: 0.9043\n",
      "Epoch [217/250], Training Loss: 0.1798\n",
      "Epoch [217/250], Validation Loss: 0.2136\n",
      "Accuracy: 0.9016, Precision: 0.9171, Recall: 0.8840, F1: 0.9003\n",
      "Epoch [218/250], Training Loss: 0.1899\n",
      "Epoch [218/250], Validation Loss: 0.2332\n",
      "Accuracy: 0.9003, Precision: 0.9169, Recall: 0.8814, F1: 0.8988\n",
      "Epoch [219/250], Training Loss: 0.0706\n",
      "Epoch [219/250], Validation Loss: 0.1900\n",
      "Accuracy: 0.9106, Precision: 0.9370, Recall: 0.8814, F1: 0.9084\n",
      "Epoch [220/250], Training Loss: 0.0452\n",
      "Epoch [220/250], Validation Loss: 0.1872\n",
      "Accuracy: 0.9080, Precision: 0.9117, Recall: 0.9046, F1: 0.9082\n",
      "Epoch [221/250], Training Loss: 0.1382\n",
      "Epoch [221/250], Validation Loss: 0.1960\n",
      "Accuracy: 0.9003, Precision: 0.9081, Recall: 0.8918, F1: 0.8999\n",
      "Epoch [222/250], Training Loss: 0.0697\n",
      "Epoch [222/250], Validation Loss: 0.2002\n",
      "Accuracy: 0.9145, Precision: 0.9448, Recall: 0.8814, F1: 0.9120\n",
      "Epoch [223/250], Training Loss: 0.1580\n",
      "Epoch [223/250], Validation Loss: 0.2027\n",
      "Accuracy: 0.9197, Precision: 0.9312, Recall: 0.9072, F1: 0.9191\n",
      "Epoch [224/250], Training Loss: 0.0617\n",
      "Epoch [224/250], Validation Loss: 0.1697\n",
      "Accuracy: 0.9016, Precision: 0.9149, Recall: 0.8866, F1: 0.9005\n",
      "Epoch [225/250], Training Loss: 0.0809\n",
      "Epoch [225/250], Validation Loss: 0.1717\n",
      "Accuracy: 0.9249, Precision: 0.9459, Recall: 0.9021, F1: 0.9235\n",
      "Epoch [226/250], Training Loss: 0.0586\n",
      "Epoch [226/250], Validation Loss: 0.1927\n",
      "Accuracy: 0.9158, Precision: 0.9401, Recall: 0.8892, F1: 0.9139\n",
      "Epoch [227/250], Training Loss: 0.0557\n",
      "Epoch [227/250], Validation Loss: 0.1796\n",
      "Accuracy: 0.9080, Precision: 0.9204, Recall: 0.8943, F1: 0.9072\n",
      "Epoch [228/250], Training Loss: 0.3029\n",
      "Epoch [228/250], Validation Loss: 0.1748\n",
      "Accuracy: 0.9003, Precision: 0.9125, Recall: 0.8866, F1: 0.8993\n",
      "Epoch [229/250], Training Loss: 0.1127\n",
      "Epoch [229/250], Validation Loss: 0.2012\n",
      "Accuracy: 0.9119, Precision: 0.9278, Recall: 0.8943, F1: 0.9108\n",
      "Epoch [230/250], Training Loss: 0.1188\n",
      "Epoch [230/250], Validation Loss: 0.1665\n",
      "Accuracy: 0.9080, Precision: 0.9182, Recall: 0.8969, F1: 0.9074\n",
      "Epoch [231/250], Training Loss: 0.0271\n",
      "Epoch [231/250], Validation Loss: 0.2128\n",
      "Accuracy: 0.9054, Precision: 0.9245, Recall: 0.8840, F1: 0.9038\n",
      "Epoch [232/250], Training Loss: 0.0616\n",
      "Epoch [232/250], Validation Loss: 0.2127\n",
      "Accuracy: 0.9119, Precision: 0.9278, Recall: 0.8943, F1: 0.9108\n",
      "Epoch [233/250], Training Loss: 0.1021\n",
      "Epoch [233/250], Validation Loss: 0.2324\n",
      "Accuracy: 0.9145, Precision: 0.9328, Recall: 0.8943, F1: 0.9132\n",
      "Epoch [234/250], Training Loss: 0.0153\n",
      "Epoch [234/250], Validation Loss: 0.1941\n",
      "Accuracy: 0.9119, Precision: 0.9211, Recall: 0.9021, F1: 0.9115\n",
      "Epoch [235/250], Training Loss: 0.0546\n",
      "Epoch [235/250], Validation Loss: 0.2062\n",
      "Accuracy: 0.9054, Precision: 0.9178, Recall: 0.8918, F1: 0.9046\n",
      "Epoch [236/250], Training Loss: 0.0649\n",
      "Epoch [236/250], Validation Loss: 0.1674\n",
      "Accuracy: 0.9171, Precision: 0.9355, Recall: 0.8969, F1: 0.9158\n",
      "Epoch [237/250], Training Loss: 0.0672\n",
      "Epoch [237/250], Validation Loss: 0.2358\n",
      "Accuracy: 0.9054, Precision: 0.9200, Recall: 0.8892, F1: 0.9043\n",
      "Epoch [238/250], Training Loss: 0.0555\n",
      "Epoch [238/250], Validation Loss: 0.2142\n",
      "Accuracy: 0.9197, Precision: 0.9503, Recall: 0.8866, F1: 0.9173\n",
      "Epoch [239/250], Training Loss: 0.4670\n",
      "Epoch [239/250], Validation Loss: 0.1949\n",
      "Accuracy: 0.9339, Precision: 0.9493, Recall: 0.9175, F1: 0.9332\n",
      "Epoch [240/250], Training Loss: 0.0980\n",
      "Epoch [240/250], Validation Loss: 0.2114\n",
      "Accuracy: 0.9145, Precision: 0.9305, Recall: 0.8969, F1: 0.9134\n",
      "Epoch [241/250], Training Loss: 0.0370\n",
      "Epoch [241/250], Validation Loss: 0.1993\n",
      "Accuracy: 0.9067, Precision: 0.9225, Recall: 0.8892, F1: 0.9055\n",
      "Epoch [242/250], Training Loss: 0.0622\n",
      "Epoch [242/250], Validation Loss: 0.1892\n",
      "Accuracy: 0.9106, Precision: 0.9164, Recall: 0.9046, F1: 0.9105\n",
      "Epoch [243/250], Training Loss: 0.0953\n",
      "Epoch [243/250], Validation Loss: 0.1929\n",
      "Accuracy: 0.9016, Precision: 0.9239, Recall: 0.8763, F1: 0.8995\n",
      "Epoch [244/250], Training Loss: 0.0353\n",
      "Epoch [244/250], Validation Loss: 0.2198\n",
      "Accuracy: 0.9041, Precision: 0.9110, Recall: 0.8969, F1: 0.9039\n",
      "Epoch [245/250], Training Loss: 0.0242\n",
      "Epoch [245/250], Validation Loss: 0.1668\n",
      "Accuracy: 0.9184, Precision: 0.9243, Recall: 0.9124, F1: 0.9183\n",
      "Epoch [246/250], Training Loss: 0.0212\n",
      "Epoch [246/250], Validation Loss: 0.1864\n",
      "Accuracy: 0.9067, Precision: 0.9180, Recall: 0.8943, F1: 0.9060\n",
      "Epoch [247/250], Training Loss: 0.0415\n",
      "Epoch [247/250], Validation Loss: 0.1917\n",
      "Accuracy: 0.9080, Precision: 0.9249, Recall: 0.8892, F1: 0.9067\n",
      "Epoch [248/250], Training Loss: 0.0671\n",
      "Epoch [248/250], Validation Loss: 0.2362\n",
      "Accuracy: 0.9067, Precision: 0.9341, Recall: 0.8763, F1: 0.9043\n",
      "Epoch [249/250], Training Loss: 0.2405\n",
      "Epoch [249/250], Validation Loss: 0.1793\n",
      "Accuracy: 0.9301, Precision: 0.9260, Recall: 0.9356, F1: 0.9308\n",
      "Epoch [250/250], Training Loss: 0.0509\n",
      "Epoch [250/250], Validation Loss: 0.1668\n",
      "Accuracy: 0.9106, Precision: 0.9299, Recall: 0.8892, F1: 0.9091\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# regülariyasyon yöntemleri eklendi\n",
    "\n",
    "\n",
    "import math\n",
    "trainData = pd.read_csv('./csv/cure_the_princess_train.csv')\n",
    "validData = pd.read_csv('./csv/cure_the_princess_validation.csv')\n",
    "testData =  pd.read_csv('./csv/cure_the_princess_test.csv')\n",
    "\n",
    "\n",
    "trainX = trainData.drop(columns=['Cured']).values\n",
    "trainY = trainData['Cured'].values\n",
    "validX = validData.drop(columns=['Cured']).values\n",
    "validY = validData['Cured'].values\n",
    "testX = testData.drop(columns=['Cured']).values\n",
    "testY = testData['Cured'].values\n",
    "\n",
    "\n",
    "numInputFeatures = trainX.shape[1]\n",
    "\n",
    "torch.manual_seed(190401070)\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, numInputFeatures):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(numInputFeatures, 100) \n",
    "        nn.init.xavier_uniform_(self.fc1.weight, gain=math.sqrt(2))\n",
    "        self.relu1 = nn.ReLU() \n",
    "        self.dropout1 = nn.Dropout(p=0.1) \n",
    "        self.fc2 = nn.Linear(100, 50)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight, gain=math.sqrt(2))\n",
    "        self.relu2 = nn.ReLU() \n",
    "        self.dropout2 = nn.Dropout(p=0.1) \n",
    "        self.fc3 = nn.Linear(50, 1) \n",
    "        nn.init.xavier_uniform_(self.fc3.weight, gain=math.sqrt(2))\n",
    "        self.sigmoid = nn.Sigmoid() \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MLP(numInputFeatures=numInputFeatures)\n",
    "\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0006)\n",
    "\n",
    "\n",
    "numEpochs = 250\n",
    "batchSize = 16\n",
    "trainLosses = []\n",
    "validLosses = []\n",
    "\n",
    "\n",
    "for epoch in range(numEpochs):\n",
    "    for i in range(0, len(trainX), batchSize):\n",
    "        \n",
    "        batchX = torch.tensor(trainX[i:i+batchSize], dtype=torch.float32)\n",
    "        batchY = torch.tensor(trainY[i:i+batchSize], dtype=torch.float32).view(-1, 1)\n",
    "        \n",
    "        \n",
    "        outputs = model(batchX)\n",
    "        loss = criterion(outputs, batchY)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    \n",
    "    trainLosses.append(loss.item())\n",
    "    print('Epoch [%d/%d], Training Loss: %.4f' % (epoch+1, numEpochs, loss.item()))\n",
    "    \n",
    "   \n",
    "    validLoss = criterion(model(torch.tensor(validX, dtype=torch.float32)), torch.tensor(validY, dtype=torch.float32).view(-1, 1)).item()\n",
    "    validLosses.append(validLoss)\n",
    "    print('Epoch [%d/%d], Validation Loss: %.4f' % (epoch+1, numEpochs, validLoss))\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        testOutputs = model(torch.tensor(testX, dtype=torch.float32))\n",
    "        testPredictions = (testOutputs > 0.5).float().view(-1)\n",
    "\n",
    "        \n",
    "        accuracy = (testPredictions == torch.tensor(testY, dtype=torch.float32)).float().mean().item()\n",
    "        precision = (testPredictions[testPredictions == 1] == torch.tensor(testY[testPredictions == 1], dtype=torch.float32)).float().mean().item()\n",
    "        recall = (testPredictions[testY == 1] == torch.tensor(testY[testY == 1], dtype=torch.float32)).float().mean().item()\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "        print('Accuracy: %.4f, Precision: %.4f, Recall: %.4f, F1: %.4f' % (accuracy, precision, recall, f1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(trainLosses, label='Training Loss')\n",
    "plt.plot(validLosses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
